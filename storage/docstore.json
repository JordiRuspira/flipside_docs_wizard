{"docstore/metadata": {"1ec67adafad93061c867a7daf5ef065d61813b7c": {"doc_hash": "407ef33b389af96af0159f5bc39a2e839de00bc465b3f12a236445a641e0ec6f"}, "ed7858fd27a03a1c2fb01c5578b8d90c812970fe": {"doc_hash": "59f839d53f139cf698287d2536a2b63d13803177e907445e1f0ee221ad34a0fb"}, "6a1f69ff7b6a45db2de4b23dada647440c48b859": {"doc_hash": "4793bdf4386f43754f652f3a63cde079558219f1e146302ded3682802beeda52"}, "e163cfecc89b678ef8edaf2b20c177cc64780689": {"doc_hash": "e5e13859fb886b0d0ab8339f7c9a33eb4631d69ea942a65485ee53b0d88f4835"}, "8f45a4884bae7d5dbf5d348d00b346174b97b489": {"doc_hash": "4d3841a26a7ae9f4765e18cb607cdd4497ab7227f3663e55af9c27b57f535eba"}, "688974d536678972e8fb78b96fb8be87efb7924a": {"doc_hash": "fdfacd9cc1cbc58e6c5d61fde44de15a67fa118b322ebb06c586dd78486d2507"}, "e881b5fd2dba254153fa35adb717e87b5836c7d2": {"doc_hash": "8d00de59338138811cf0378c4dabb50a30aa7c78ba4060aab2a8916cfffd8a8e"}, "ff6356498de3c813a24924cdbf9114f8ece22faa": {"doc_hash": "b5deef9938ba5b327518610d022e7fb5a0cbe77e4ed45348bd212a28fb7822d2"}, "2e80efa87b8cb5f49f56c4de80054b778742df38": {"doc_hash": "45da4019d8cef9355281cb499141308a3b8edaa14d0a1cf94de1780772e73b4a"}, "a9712c14dfb54f2187c0a0f38786cb41561f67df": {"doc_hash": "e4d4c3aca2e8f1c385f7fec643706e1b4770e33b684ab1e571fa6351d65acbaa"}, "5e341cb077901a100270cb1d379e5df790964168": {"doc_hash": "2b0b2eade4d0a92879cb268cf7765d67588201e94caac492c8b7c0037468ce15"}, "6da9912dfa407c2655de68449c7f8dc8f22e0e2f": {"doc_hash": "acd798289e9f8cbc285f94604ab3416405d9bd4320d91f7d24f230a272a00623"}, "541485deeceabc7677192a2f588ee381e138c038": {"doc_hash": "b98c535af27986d022a94a08ce36c71af0620bc1fb58270d5441b88e75c7a56c"}, "42c22f3ee37a352f736947c39d56dc934443a34e": {"doc_hash": "f84304560586845d8c51dbcbae82bdb74af2d4c3476f828249c8fa99fa8b52bb"}, "81d66ca829f3f244a5f8fceb32fe05ec6b10a389": {"doc_hash": "c75bd1c795606dbc8ba4056e014b68ab7957aa3167cbfff47887b93820aa4821"}, "65788ed3a52740a5d20a43ca5641bf4038899151": {"doc_hash": "baef80ceb536fe216328820d160f137e82c5b914d5a3a5d0b8c4e555fde20afd"}, "8dc010af0db2fcc9db9f9c23db6ed3a2f5644e39": {"doc_hash": "f537037aae5fdf0fbf1aed933a1932e95a8a7bd424f0e2822aebde60b11ff701"}, "fb6e1495c297e2c98d22e485362addc5f4086d7b": {"doc_hash": "b3e245c7b933e347a9156e6f1bf43fd65952ed3a8ee3b8a807c3f2c1ae20be66"}, "1ef7f1624e04f49dda014356fec5109184fd5ac9": {"doc_hash": "445912e51239258f90c197da134c5dec15a2596bf4df59e942d6d6886860453e"}, "efe2d8928da28dcac2206c5aaabcc0269cd911cd": {"doc_hash": "501295b4539224e082018b418ed0b5b49ffc11e4c4682e5f2db72df0ca9f303f"}, "f0ebb4e9a8e3ba41efa0a590709f9def98cb48c5": {"doc_hash": "132288fdaa7412d6e5882ca057a1d48eaa7cee0d4cc734e5604e3ef664fe4612"}, "fc98b150ec32caa79b409a81a22df8f1c9d29970": {"doc_hash": "892b1c82e372952455f9c923c5dbfec49e24f7ddab25592848b9b56dbecff241"}, "75fdb7ce0c015bdb6192677d1a04da8080373b32": {"doc_hash": "7ecbfc3836e3f7b8182c6615e6992038c1b6f56001ac117288d46395d07d1c66"}, "6e8399335ad01ebf5bc8c610ad9a8cd928437f60": {"doc_hash": "abaae3ee7a2b475b3c423794a6c113ab2fd8e79367f28e387982b8dccfc6bb46"}, "be9bc7a8dc64606386116f4514bd22682be4921d": {"doc_hash": "2cde6535e0cc4556042f297f2f32c5632aedb34efde8e7023cba2bf384074a02"}, "12dbbe33d490e31bbf50851055623592349db141": {"doc_hash": "6a8ed025003fa5527c346ba5a5b34fe6cabb98e859b855664d5d1a48a2d7edea"}, "e603e7e87a17aeb00f17727731f1dbfb611eb121": {"doc_hash": "ca4c3fe00bd22ebab7bbe44ecc79c5b767b86ed7c8addc34ef567a1118a45f71"}, "5ae1301cc542880d92f78213d959b10a0a2868e7": {"doc_hash": "b602a19781fc29576a3e012a7c505e1498b8e10ff38603cb6159ac2ba01806fc"}, "9f8de3b5c2fb0d2f94ff7a4f3f5f2c33255ff8cc": {"doc_hash": "33dab703715752c890d34f36f2806cb453150f109cf5b9f3fd9ec1aded990801"}, "c54cdf811912bf0d1b093377bb878115a1c7559a": {"doc_hash": "32740d7b628a0ea24b7e5dc2e926d0fcc04f2aa870c7b473b3a92f7583d20428"}, "b6dde3875b506f0d450a3f8b9a50728329973410": {"doc_hash": "a9f7d657d7ee95e78bae3065711e05b54614ea870e2f19dee06a5602de062809"}, "e0cf334a6611aab79be64eada67f526c545e65dd": {"doc_hash": "65ded9c1c49b1a4a1f591c076a7f3961eb81a7cb7c990dc9e086304826ef4c3f"}, "02de8b5c5cf82beb550cb7373a766ec393999aa4": {"doc_hash": "924ca130c45803cd36e55af8cebb2a68a07aca731f7b2aeb4ffbff7f8061ad91"}, "b04767a5b3481e7dc5d3fd5a34d3b27a19875aab": {"doc_hash": "a53e8ca3f61fe23da1b345395a6e0c952c477a7315301e58d4ba647bae5af6f8"}, "82a6b008f7988e12a413c401a38b423aed1b854b": {"doc_hash": "622985c9ddc9e5b47d263241339481dbe56884953ed2b63637d0953efcd49771"}, "98e09188b958147c3d6bc7ea404bf3cd9b4c4df1": {"doc_hash": "332124ee51960e0d52547c5d63ff34f7400af96204f406056848e5da4dda0ae6"}, "20215a3c1c7147517a946a03fe51e5b219211688": {"doc_hash": "54f0e9d0844badcdf72de64bb4170103b0b3d2ee90874c24b50cddc1d5cfa667"}, "2ae98d5f1e2d0b0467799fcb1fc9bd4b794803d7": {"doc_hash": "44ccaaa7c2666f89c200063b58822a7d4ab01e158331b0f73b9f85ffa73e96e3"}, "37ee1ab8a924f48d373c8d3915cf04d056a9ac2a": {"doc_hash": "c6a9f39c0bbb2f73bf94679c8634b6d82ae8e577e43a753e6cfe502f3f5935f5"}, "53dd871c76c7b89720ebfb5b249ebe8bdb0f69e8": {"doc_hash": "fc1b3835cbe0ad7fcd4f72866546dc5bebdd8151e1fc6011a83aaa580bf7a651"}, "289fdcc7bb684cb250ebb6c44e8e64e8240df2c5": {"doc_hash": "2376968ed77a50925350ce1cbe09cd15f3646fff731e0b66915dc1515f13437e"}, "931ad55b2927da963c205adc9283abdccc064f0c": {"doc_hash": "be661d53365754d70ddc48f21e8df8059fd302e259adf5948a7e894a11e3c871"}, "2a6f7d19dc780c431987c6ecf37dcc6ad21ac4b6": {"doc_hash": "92bd7fe5c77e677cdaac09b54493095372d4f312f2b5c5224082bacfea12d63c"}, "e39e6325eee6099ae006fe360d3deabc3ecb97ec": {"doc_hash": "8417916a831fb76167ff5a093d3d3ad2492c8be90956917b2d2db0bb919e704b"}, "e193f392c8bf7ebbb52bce2abb2f050810796ba4": {"doc_hash": "15849bc4116e999731b954cdcf582b158608c1ba4f0565bb8a85cd4878edc29f"}, "12b396288e590ffc0362e7d51ba2bf194980cf88": {"doc_hash": "4a274d02eb1a7a6a6d34a6a0202db7707dc14f3709c191762b64a95a9a0a8310"}, "3b7d233595bfeff028b98d61a84fe66cdeae663c": {"doc_hash": "8a60f84261952b82ea4b8b3c38205d2c5161ae943c86701ff79b1d611684f6e4"}, "6944cccd045271bb98ad1db1f322bc71b7a63115": {"doc_hash": "ad11f195f9db66098bb14838e7b0e9e4a8090f91f45fa2030ac685244e786f13"}, "e360a49dd06db3a0d936fecb9de73d34719da9d2": {"doc_hash": "2f4c23a90dc205f66a858909dc347e52a76ea9e71b3dc00cc6cd4d7e9f1e9ac1"}, "0651df3c0cc49a752054e4604f91e922493abae2": {"doc_hash": "b768ddf9eb26101e4b267cbaa8f8d26964d184d8b317ed90a2cef6d77679eaae"}, "9624e926c5a83e17eb6fe1fe7a2ffaf0e8a714bb": {"doc_hash": "0c646c10651bbec4e2fabe2d3b043724e4a0fe82bf4b6d369eba4c637e1359a2"}, "370c8923e15916e05edcb8e1a1879cbc37601680": {"doc_hash": "d4a7f21e6bb1e66674ff074b3984da5cf8efdfc0bcd79e96cafa6a753b379511"}, "67fb5f46a65071875838118624d06d4ed15a010c": {"doc_hash": "ecd2f5b2acd887e663dd5c08dfd7d31c9ce1ca820ecc5f1c0163157e0bad9391"}, "8ac25b1c3280d05c59576e696bcd034c11ad1635": {"doc_hash": "86fc41452599b028cb8ec71eb299d22cea5d3b2172d35d48f41a81a1c776439a"}, "3bbfb8391058b4049afe30bcaa711ab70c115862": {"doc_hash": "80abe19af589efd99bcd5bcded10828c939cb3e31be465cfa6f06d12fcaa28f4"}, "ed15f18ac6d87a916a49197c931e955d77bef99f": {"doc_hash": "59d3184c7518e56c6d9541233c8ac4a02b46bb8a5efb7b53f8e028a9430a6b1b"}, "d4a21cab679cd538a27b55474d5e5acfdc44b848": {"doc_hash": "3f279d37ad9273aabc64493d4923f49e518f69f2f5c97acd8884dc99180fad42"}, "9fc9b94a80404af3d46f3ac3c761a5f8df00a645": {"doc_hash": "20934fce9fa3d29271f955293631cc84e45ae77272f315644e994763b015b049"}, "c184523682f190fefdd4ceb314550e8cd2fb5648": {"doc_hash": "fccbd93c93f4479a569dacc93ea788451d99a7e76893d7880c05d08630b5b1ac"}, "a64c22f8cf2a4269a785f12ef963236cd939ee16": {"doc_hash": "77f1e1b4defab2e6923216f91ca99d37424cb3bab5224a013289474862145ba1"}, "46d72f633611ea3d8528ad61981d9057ad748792": {"doc_hash": "728ba38b3a79a86f6e3e554103db50fffb17b724b354ab78cbafe86354687a15"}, "5c689c9c40fef2d51e1273867b9f8f2dbf57dd77": {"doc_hash": "239b067917e5f3f524ce1eafadd2cd2963f9c01bdd33105bf8c36b054d5245a9"}, "98836337801044fe47e1f9675805d35799fe40c7": {"doc_hash": "3444aae4a6dd3e2069877b4b03332e9b6fc610fefb16f871d5003ad2c8639ccd"}, "460797ef1dd00cc2de7eebf75c628486a95f868f": {"doc_hash": "9bcefa9e7e01bb86cdc1d31364b1afb2086af75e0bdacad82b12813df1bb2d1b"}, "7d1af784439981fa4387d660eaf2c2d0f3d1973d": {"doc_hash": "a85169393e514b9a81034eea1c987fad59739509274072e02c01ea555c238b4c"}, "1e0cc5749df2e5e1cf7a2ea52d712364e36f2ec6": {"doc_hash": "55dba3d9c39fbf785b32da2e5aa2cb811d128dadd5246fd498a0aaa9c09a8f3d"}, "fd71e1bfe6e282bf0326070e42576b034847f203": {"doc_hash": "27d7ba01c1448f90f85141b3f24484c4c76b0c698828551717bc856fc0b09f96"}, "a3cd7362b146852b1c8e39b11f0ab90571b01186": {"doc_hash": "491451279df96a4454da8d3e0e449f1f1faaf797550e327020b24628b283ab67"}, "1cb7db9df2541410c506b5bb60849d2f2d0f7d32": {"doc_hash": "79957cbdd2752634e9a440034b2776a0920a3fb2736a89b2f12d5eab0312fb8b"}, "221ca909151ea84cfde102e709e67e090f0b60da": {"doc_hash": "5328cbf593265e0815804ac89170136b458610480b43db5750e224f2a130ae6a"}, "513f7e01ad1d2a060f4b3fc64d0a0768b3292171": {"doc_hash": "2334f9490ec08829ed2be5c24257956794f1ddfd6a3c28f812caba2e90f3b573"}, "eb99779273e4d5e649ce7ed9a6bb892b66f7ba64": {"doc_hash": "acd4b5e2042b4f0d38fbdb42a9a8115bd1b8c4cd97ee058e19662a98f430d5c9"}, "56919e8e56101797085f0ac142cb1e86d3dfefc6": {"doc_hash": "3bab7a6f6a430f98cee88568c18d46bc68e8d90afcf01c29c5bdfc6549c0945c"}, "b4ad10650e8eac5e709c087fa3b569ea10ef018a": {"doc_hash": "016032f541a03952f34b641d455eac75664ec6864ff8e3b841fbe2fd750ea268"}, "d57c71b5ef37f03cfcff7ef6f2775a8d517a145a": {"doc_hash": "32076b982185d4e09a3c85da4422496ee4a7ea52ee250707d40965e03a992aff"}, "066d1391242cf88445c8d7eb218fdd8306eee8a8": {"doc_hash": "fee5a80dfb72546c6a6aa6f2f1ccd7845fa053c985ce5c254b0913c0cbff7a6e"}, "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7": {"doc_hash": "de9474c8c46bd8d70ef2277be8dab118c8bd2efe6d4036540613877814bfb2a7"}, "0d64e4202485d0f5aa45c05ef5e329a651e33cf5": {"doc_hash": "a0a679fb33b328097e4b063a4857b395feb05d317e777a40078aaeeda983a271"}, "06c0b39d09ed42720b55d3bbe0dbaf4ac24e8a38": {"doc_hash": "bdc6a9c670ef660634e1494a4d3e2b58d763d8777ee8e21fb9d58a8b7402a058"}, "f043f3380d1f2e3bdb20217f6665d1cf95860ab8": {"doc_hash": "74b35846404d11f7a1bb54acaa95bf4881bd60cff156b785284f76493cb71f73"}, "0ee3e4c07af94ede0ae8cecd50917977db44d7e8": {"doc_hash": "1efe6ba643472ed8e16c98115b51e8a418464853d8d373bb063f8207b45715fd"}, "a21fee5e6788aef76f96cfd5e128ec3b8be3caf7": {"doc_hash": "e7b8b7523c9365bde529c36fc041323337bb9007d0a73f08b658f89272c0e597"}, "d92e82a6719b8794e1b2d28b212ea63ea03ef218": {"doc_hash": "bf98f151985952ebc3beaf2a9dbdff9f27be3cd4b06aec19ac9667e4d6e87da4"}, "3e2403e32ef0f367e18352da3695a88684dba3f8": {"doc_hash": "3591d1061345db13ae522ceb84b68f284f07663417f0b71a96671785d7adbd54"}, "cefef4718b805070345764e7a6bb54afe738f236": {"doc_hash": "afdfebffe2d3db38b5d8f1130e064d341d814cfd172926b78e78ab48fadbf814"}, "2168413a22fcc28b3ee9b9ae6ce4c2c77266e951": {"doc_hash": "c3144d782a754b1cb3c131eaf42135883cfcf6a7e3b3e1ed62dda01dd9e97fc4"}, "fc66b7490b3ef2a06eab0ee1846e6ff62eca48df": {"doc_hash": "8bf24a50854ba706b060efc83066d395863689a6d7729743b1240be56cda3d50"}, "283cccbb1c96b4ef412c449e542b348230110de1": {"doc_hash": "cb38c1bbb41498fef2fec283dfd67bc62ce29581c651a4e375d44fa5d0fd672c"}, "c641e41c03008b2290c54aaa4544847d1bd5d8ac": {"doc_hash": "a6c8a52d00d160441613f9ba87eb285db6cace85dcff68b36a6d20c2f6b8b4b7"}, "23a3e62f3f2acb009592e6b5b57db1faa03b59d2": {"doc_hash": "f91cb594dcbab85c6ddb068ac7a6f8f3be9cc96f5c412a39b80902d38e8fcc85"}, "21045d21783395b894914b57930b2f2aa791975b": {"doc_hash": "172c6a9ddfb9dd3bbcb5fc5e92c45e66bfd737a76a3580a15f4d0958a35d93da"}, "eefab96eb5b30e083cfbbf70a8f94370d27df740": {"doc_hash": "7a1c3643ae170071f8d07d904ed24b29a89238fede80b12948840a19cd0b066a"}, "d6dbc002044115ecc482e398d504f15ac752c9a6": {"doc_hash": "3c1a398ea118f4155529cb2a79a8cfb32b7cb48409e37ff4b7a9774916269d18"}, "c2f8dcf099a14b0c2fee340828b861470b856884": {"doc_hash": "24e8c11f0dae85fdf3873795ff96f10c4321215c68b46871cefea219f3fbc71c"}, "0beeece78fed944f13822510497b29d6e3f60ea3": {"doc_hash": "8c5d0d81e9a51af75eae1324f0e39e6e469167191844e1b46cf89979dfb27cae"}, "d109bf6f8b57ebd0329491439a533b66201c9535": {"doc_hash": "da82709d7989aa63e67640fe4fb15ef3c79ba7ca77919471ba1d81efffc56155"}, "1c85bc511dc511c37c3ecf59b3dd59f24e415731": {"doc_hash": "105d6d24a1597079332988fc1e7ed7e11efd4e285db340d631366067383a209d"}, "b9bf45d386b7abfd56184bdf9f902d4080a313ad": {"doc_hash": "2ed61236472e0361b9e688a3aeef5c9b9fdc0216b501a23b78ac776c712e267a"}, "823815552e9904bbecd26edfe8aeb78a9a46ff4a": {"doc_hash": "da2a9c87aa19c983d92a438ab87cadb6381f62a36ad8ff275faa64bc06b71a82"}, "1c0086e721dbdfb14ccb34937b80956eb381a0e7": {"doc_hash": "7ee7ffa5cf8ca5805393201928eb50c4b6c05bc1ff0a92b01f6d1eb2952b61e4"}, "74bb533a5510cec6582906aeaa72cf76c6e215cb": {"doc_hash": "302dc6d32d5c282a90bc14931205bf5a31252bdea54366f10aae897435758654"}, "95a4df97cd4b186da3008e46be33463ce5bbdb2b": {"doc_hash": "ca61f68f563ff82ce6f8fe51ff69d00a3b6dd6f66bdf93bf91a4b5927c8c5ebf"}, "11c2231859919e5c426286139b4f8a646f01f196": {"doc_hash": "31bb9e3029f2de17b02b0d88d1ca6a61c926347cc6e1ece5fffd1a837c48bc00"}, "1c8201fa333751c86b68ffeb9bde3b9ed43e6d74": {"doc_hash": "5f64267d9f2828bbc15776858a803895282aa7d94e44852a61b0c03664174acf"}, "f7dc87a714740bc664e069b2703bde045e1b864a": {"doc_hash": "c66bdb7394a95f2dbfbea3c6a3c9086e7d4dba87130e154e4399609f8fa021fd"}, "57218f210fc19c7aaa4905608df8dedf4a5a9eb1": {"doc_hash": "988d2ca2e83c3eaf60ee2768b3b79c6b491a42fda1a82f0163db1a682be83936"}, "702dc3e4a27955421bc6547a65cd6d15ef07b272": {"doc_hash": "960d1b0c0ed56f59dc3b02d19296268ddfef377c28b803223a28aae28f86c9d9"}, "f6ba683c6473cd3a6df1fa8c3e908339794669e9": {"doc_hash": "be9d319d792c769f3aa56886be90b8a500ddf3adfccf2ca87d602d525ae121fd"}, "83e70db047942a49741ea84000ab3d37820dd24a": {"doc_hash": "925b9743a02d69e237d54fbb877f90cbeb9a10685238e941149ec5a084289893"}, "54df972ad7f2dbdfd18a315f51bc502a5e1a24be": {"doc_hash": "bf491d31001609e3255c299bc9a2295f4ea892e1cc9cf9cec888e0b7e58b9310"}, "c7c50dfaeab91cad40cbb455d832b860e3e220f1": {"doc_hash": "b1de7596ccb6caa62bdf65a1c63a25143ae022b8d45e68296a43d161d65fd4e7"}, "f40cd9380740eff0176ae51621e285600bdff08f": {"doc_hash": "d1c55aeae52766fbf3f08686468c29fd159fb305169a2b0810c8a472210dd27c"}, "a6862ae86aeebd0d2a552f49918a5c585d690125": {"doc_hash": "7535655a4e480a9f9a2a6ab2c5e2b22c24a2fbc0e155d67a66ee24b0af46823f"}, "3835cf4523eb2e570be91df2075436476b9df2a0": {"doc_hash": "e0165c6c535479529a6789921992d4af85021aa6d2061f5c5544cc1e4bcdd0d6"}, "605b5e82f33cc49ee0315b1c79c10859aa611738": {"doc_hash": "4e8e71bd5f8e94a73a80564b62c6833889b83145a26c7916f02f734ba2050ff8"}, "93ac7374f6bfe9dfe845be7ad99c32b028be673c": {"doc_hash": "0967662d370d8055413b977aae7c9de87a051e178c127b1a0f443178f61f345d"}, "99d7b566516d0df3047c5f6ad9f1de74e264bba8": {"doc_hash": "b94665d3142cb556f110f91383352c231a7aae27c6a61fec41695e9934de6e91"}, "1a20d4e9546875ebc47b2265f675fece5d271bfd": {"doc_hash": "34aad33c1135b396a49c686770c7235d916aeb219cd7be4c499efb464f1b0d42"}, "4b95232cca47456f08d70378bc8527b6dc416f37": {"doc_hash": "bc645bb46299739d49df8a5562d0102786019ccfe8f3eb6fcbcc7815821199ed"}, "6cd0bce7108b1e2da0267c6f0229a8c4b9dd86db": {"doc_hash": "80ef4aa0de9a32e1c5b53de640e435d6761ba7dda278b80461ef816705e6d601"}, "c0c03f3d7fc8050052ab5378ab24ec56aa189b89": {"doc_hash": "82f7e8d2c11ea9f6c1dd96ed7e454699a5336389844ad9605e6431885aad532d"}, "5e40d91595902954d6cfd8b4060f62d358fc47a3": {"doc_hash": "435d16ffcf1c48025d2a7e9b486fdc30056a235f2295110ca6e1f21be09c15d7"}, "b941e25beab4714a2991c561a8045df5a671467e": {"doc_hash": "0f74078fd0929ebf07ce539eb197ff7977d6bf230df66ac3fdf92f5cf387c2a2"}, "865cf46b429b4adeee71193b63c30921809f4bb8": {"doc_hash": "997f2f41440016d7804626da50c4a14e12b4f2a427fe315bf5e49c41484a890c"}, "95bd3a3ff0209fd9511fac413a38c1a56818775d": {"doc_hash": "10cd7c1808e8febba0aad773a020429b72d578eb801f182b81eaa687e3171ec7"}, "cb0006c38d2b16470cfc3402d02a2eb66a6cb9d4": {"doc_hash": "fb924404bc72789f16c2b137b63cd91ac995b9072530a65479891d93ed96e403"}, "9d7c7cbf680009058d6fa27fda32323e8be11c81": {"doc_hash": "fa4f309017237ea709027a66834e31623960c2068120c17849f8042050800ff1"}, "aa0adab1a07c50fc3f1a38830c026e002e5cb7e0": {"doc_hash": "bb65d8bf35706e82df36c4d9f02aa79a39f25440c25831632cd3efaa5ee65b8e"}, "fa15efb471b788d149d1993c822fa18ea619a49c": {"doc_hash": "d81da3709d354183d2c6a7509f61824f173df8379893e71e467b29ae68dc8989"}, "863bfb8affce16421dfdefe28fd7e85ab66f8e61": {"doc_hash": "9e152b56151c1be1a588c7def9b21909610af023734aef9780d32f408b2f6e35"}, "3ae8c3a974d6f57476d54c5070b003581677d03f": {"doc_hash": "b236a76b31da48872738080971e4de72fb260881b3239ed65b238eff97ad86d2"}, "2267eb40d6bc0cf1e7b8eee28bd8c5acf05c342a": {"doc_hash": "3cfa6bf016f6054f8a459dc007374cd84274e6a1a1004bc8e1dbe1bf8fe36728"}, "420e8cf9959cc5896252761eb2a396c43d712daf": {"doc_hash": "f48d8b6e01928d2ea625048558d90f5e4d41fa6d2b8f0e799c1861ebe0f12601"}, "972293085b68603417c72038f245e4c2652e50da": {"doc_hash": "89928400f0208d848be8d1f27b5a5a45a58987c6dbcf6d3d1258f9d9ad5b16e6"}, "75261e68400d3d3c28eec769c722bf8206dfce99": {"doc_hash": "c922b0ae5b5e82e5625d2bcec8e00c6a6909ba3769a66f0bac7518d701602341"}, "6df4e3127c93f09bdae012d6ea0679cb85edbc34": {"doc_hash": "4d3bba3c03ab0a44b517c3a4f4e2392b9ba9222658b89062b09e5d62d0653fed"}, "58608d569516c575d0314b0529ec02e2d565dce0": {"doc_hash": "c59eaa6abf09efeb191d1f36b459778cbf868b0550b81b80fbc8c7b8d5b1ca45"}, "c9b150ac1b55d595a22ca441f225bf76260144f3": {"doc_hash": "616bb7a71146aef5191ad6cf83acfa383cb8d2b694d513be24ebb9265db455df"}, "fe8ba53394a005842201e62311b5aba3ca1bce5b": {"doc_hash": "6f6f3cfd15f711364fac6799690ea9a66f3f422116464f52afece33aeaa85ab7"}, "ca0402ec5262d2a05eadabc76f234ea726a10c2f": {"doc_hash": "9b407612f8849ce9f3e026d4b48288129791a4fe896f60b50d2faccbf32691d2"}, "138c19485a3a39062cf9e5bf5d763628293f8d04": {"doc_hash": "c2b5d6b596b82f7c9bacb1bfc50343237513360e8261b83973624337c52ae139"}, "3e4ae7b170bf476ad9044821008319ffb8a3c313": {"doc_hash": "c47fd3889c08e3ba6fa690f37d5105bf61e3421d978a48cc5ae28f08537a95c2"}, "50e0e9befd28ed9949c1518313e73d69eb519baf": {"doc_hash": "2fafeee668f4e5fa9b3e37b174f6bc30a9771b8b012b76a96c9c4cb49058f143"}, "749d7ac379a27450e367352d4b92ded8eed698e1": {"doc_hash": "414b8291ef11fc9bbc5a6a3b841c015dacef42ebb0b29d4b7f91e6375d05e97d"}, "95d36b23e4dbc89c2029ab325ee782b717a15197": {"doc_hash": "d587e6d6457aabdf8349354d3c94594ef1fc53ac4253ed4cf16178c91b7afe52"}, "c0e4570df74c2800c6d0175958794aaab6005e8a": {"doc_hash": "37944500047642fcc8b1b7ad7ad1c8a7f552f93a818bcab1343e4ac0db91e7ee"}, "96ff14aee8a5065612d649e60db2ed9f190ae2a6": {"doc_hash": "fedf94331aa325d067c6e83b40b61a149cfb7c5b426229502e69536bd6ce6b3c"}, "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1": {"doc_hash": "c99b50912e5de94f29234f399bf8714a9b2a051b7dde8aff59090fdb853bb7c8"}, "04d6e2e1e0c3fc9f807882e34c50e0f86946aec8": {"doc_hash": "032623e744c6d6d594f4988b9506318ade16b57af330776e0f460f7c0ebd1616"}, "6993eebd2537d70993e0c65b5b0846eb4623564b": {"doc_hash": "f7bd6a099394797fefbf1007300b9042fb1ff133d0efd1340066fc905aa54b93"}, "549295068b5590e149f4567700f54dc3e37e7dc2": {"doc_hash": "f122f3ecc3628c681ecf826c67c223b3318a22f91b46af0d0ec605f4608d9da7"}, "b0cd1db956ebfe5c1cd8be18bd57dfe901bbee01": {"doc_hash": "d67887d343cbb86912820177b365fd4354f11c603803ca52b41ad3a3213a9e8f"}, "abbef2a85ac74b6b4d06a927e94b5ceea0ae00ef": {"doc_hash": "d0fed6accb08fd728bf8836b17ee05409ada49f6b71807e749f6fabe465a34e2"}, "f68dac6bdd5ca8d920200669a808ce2f38342e60": {"doc_hash": "146f62ddc8cc05e405f594886c224d26aa56d24c96d4db160a750bd67f31c2c2"}, "16ca6f86583488a6d995bf6b9ebc65c54927017e": {"doc_hash": "baa286177214045164e1602b45aa4087edbddaba706cb335e0f8c17ee7257014"}, "cf8d1ce1afc681f25b26aa6d4465f545543454b2": {"doc_hash": "c41efeb587b45092702f45f2768e6559e2b35e844e894c14e4b9ad0130ee44ef"}, "b2846ac788b66d5edb228c099391b2677705c859": {"doc_hash": "279d7c7e568b0f3ecc5d586efc6a5e3c9f5759b915971e9441c51935bbe9fec3"}, "8d53adfef0c6cf93e1ff25759d5514747b3ab794": {"doc_hash": "aef93ce1cb2dbeae17be317cdb75b802532fc12a902caf9acc2c8605ed447d8e"}, "9d076c2fdc9d99eb241f667da6671ada777b3b6e": {"doc_hash": "950e948c87b55e73d0818d9db0772e6dc0acac1b6ee184084dff8f036406e274"}, "e55bf918e7d312377ca19e115df19f7bf18033da": {"doc_hash": "ebeaa40fc500ce8898e26e403e015a6d80f7bbb919e0b39fef1a536d1227e1e1"}, "2d488b6677a66d4503b9f49ba6878fb344f61f90": {"doc_hash": "43b23ff81f75e3085c7bceb1f3c06ff888eedebca83f6ec1aa911f581866fc0a"}, "8a3f654706292a82d0fe36909ba8407a9ee6f166": {"doc_hash": "9154d4011e543bc3fbc7469e8caf92188760e2567b3a4db8d171dc463ac5b1bb"}, "ce365e6c157eb365fde71d972ee493f1660789fc": {"doc_hash": "56edf1a006027025c61bb965d3206caf811c23f8339d14a21477f83969be3de0"}, "097b18888685db3b4562b73d73275d5346264fa5": {"doc_hash": "bddcaf769e623cf42cbe6f366a5b8a037877309fdcf7a87fa55fc5ff37243098"}, "6368f797c590508363076d28a49b64d5eb433091": {"doc_hash": "b7f8b93f6698e026cd25cccc1c0323299853a4d9cf123b81a6c35c40a00f48bb"}, "7afa618ea49b3ff559ca5ccfa3514e799fbd7fc4": {"doc_hash": "c7efa497d7ae42860913c26f2b6fc25b1e244649c5975e242d1f611328b8c562"}, "74fa64853c91471be07cbd3bd65bea9bb9dff866": {"doc_hash": "c9a63b92faa67b3fd8fc7f8aa24e93349d1d54e197a49550ebba42c0c3c239d6"}, "9a8056fb6210281fa3ccc658a5a7899d0d2973e7": {"doc_hash": "3bbe28db43fd47e54b14f4457569fcdacb25b14a96649be47455b57258bbb231"}, "773276682d7d34e3c64b738e27fb2877edd71df7": {"doc_hash": "cca27238189a5a0b07e529d09d1e23f7211423a8fb2134a668c8af27844c4444"}, "a8cbb69a63ddd8d563d3c5ba325d3da01e26a906": {"doc_hash": "deda01c913daa18fbe95db1adfdbdac0511c90aebfe848a89e4afb5283048315"}, "ee3d8f95624e46759068e987fde30203bcfd1802": {"doc_hash": "3cc2306cf96e04e509f4e7ec0499ab8ac23a9f4d683ba95febc921dd3f1d9b96"}, "04168beb41d762f692d99c7628c8e7f66188d41c": {"doc_hash": "6956d65b72877235d125b98848e6d27aacc769c7ff1fc67dd715bf7cfda52e52"}, "e9b826d0877608e104fd6ca7c1177f78c2651ccd": {"doc_hash": "e50d094fc375ce830752989e56237c826a1ecf3416dd0a5902f9e32217a07e36"}, "8c9031686dfe23473f2d31c75d2b325a3fc9a9dd": {"doc_hash": "d1c0f03517e64d520de439d8b13dd0e483e4a6457ffa6e3d5502d9327937368f"}, "b746db3c8f1522c6026ac33c398ab33f79471031": {"doc_hash": "2ab9ecc4e2b1afbfe09df8aa9b0eb258a4270915cb41956a9c5f9263c5ebaf09"}, "2d828ecde9b0b3efe4bfac0a52eeb11a75d45169": {"doc_hash": "54309024fe6fa5a6fe2249ef6f41061bd604d508d4fc5c71eeb050d8b306837d"}, "370acb5cf3546337e11094d1cf3ab0fe82e3f9f5": {"doc_hash": "d8ceb4c82fbe62b83b81a5b97c4f828a3c6446df95110c5b3958f7b861268db6"}, "09278556c8740eaac8985264d09e4f8b5429e714": {"doc_hash": "e17935938597b117b0e0b17ce6e29a3119bd137ade6c55cda06188b4393831cc"}, "f98eee6afad0958bd913b26f2c39da3fe7663e33": {"doc_hash": "70700ad1900a907b5f6f86ec386f2deab416a6e2bc220556cc1d54b3a988b208"}, "b76f2e2ce98ded7830f3c0abda7404f624838fc7": {"doc_hash": "16c410a33a93719068ace37af6970e1043fe8a793788381197a910c4f93e65e3"}, "fa30bc56f2755065c0ff02de0019982df9854e56": {"doc_hash": "fcf908d1c360ad6cd7ee96a9846fcf4c8db0090461bb5f918a1f3223ae1f6a71"}, "44ab32cf40b2001706c247122acb08c8c33340b3": {"doc_hash": "869b14b73ea0836f8edf774860361f8364fc629a4a78a8700208948a468ce02c"}, "2d2de793bd7a82c664d96928dec3587425dd4522": {"doc_hash": "943615462605de28d2ee7e0ac7d80fe4859eeeaa2d8e58d5f1511b2d26955d6f"}, "a6fbf783f9cb3b304136a43e5f783991de2efd39": {"doc_hash": "cfdd456c1ce7e5da8dd14fc770ad1700f7a13f0cdafb0ca22f63c2c27cdf69f9"}, "510f55d8602316b1644265e636c6f243122bfc91": {"doc_hash": "4d195deced991d8cbe21b9732779daebffc56bf48c8b5101e2c0c1ef503e49a6"}, "7315845a94cddef314e2b305c18b02404f6746f3": {"doc_hash": "24fb112a03ee8bbaadcb31bc60abccccc90e6d8c94e28da3a5de65212a2206c2"}, "05cf5184-7ed8-4a70-85ca-7796343a9b01": {"doc_hash": "6af12931e0a0655aee4417b107d54e9c0d747d3eb51ce2702e4c3049f9dfffc1", "ref_doc_id": "1ec67adafad93061c867a7daf5ef065d61813b7c"}, "d6eff9df-5d7a-4796-bc26-b5ee81f78a68": {"doc_hash": "b4d3c57b071336d544310b6bba863458ba6ea86c291b9ef946bbb3dcc6ed2ba3", "ref_doc_id": "1ec67adafad93061c867a7daf5ef065d61813b7c"}, "a7fd5883-860d-4b47-b7a6-38a1cbfcd413": {"doc_hash": "59f839d53f139cf698287d2536a2b63d13803177e907445e1f0ee221ad34a0fb", "ref_doc_id": "ed7858fd27a03a1c2fb01c5578b8d90c812970fe"}, "05e700b9-ff3a-46e0-b856-9221c2c01aa3": {"doc_hash": "4793bdf4386f43754f652f3a63cde079558219f1e146302ded3682802beeda52", "ref_doc_id": "6a1f69ff7b6a45db2de4b23dada647440c48b859"}, "2d5f888a-209e-412f-b0e9-30359a548e82": {"doc_hash": "e5e13859fb886b0d0ab8339f7c9a33eb4631d69ea942a65485ee53b0d88f4835", "ref_doc_id": "e163cfecc89b678ef8edaf2b20c177cc64780689"}, "7375fe59-7889-4ba3-811f-ece549008c8c": {"doc_hash": "4d3841a26a7ae9f4765e18cb607cdd4497ab7227f3663e55af9c27b57f535eba", "ref_doc_id": "8f45a4884bae7d5dbf5d348d00b346174b97b489"}, "7e84a302-a2c6-4b59-bfb3-283219831e53": {"doc_hash": "ec5ed4fa22d9893a1165bef8c4c496c67c21c07d06ab9337a85d99f41f367b4a", "ref_doc_id": "688974d536678972e8fb78b96fb8be87efb7924a"}, "8c43348c-be78-4117-aa38-9710127375d9": {"doc_hash": "43426e093acef129a38a296237150facc43e5158f67ebead4e697e66cc4eeec6", "ref_doc_id": "688974d536678972e8fb78b96fb8be87efb7924a"}, "4ad40ed5-411d-42a1-8795-25f6bdb5f933": {"doc_hash": "1ece6dfd42dd7c7dfaff9ac39ea275f421cc268148d7166702d97cd6d09f4d69", "ref_doc_id": "e881b5fd2dba254153fa35adb717e87b5836c7d2"}, "72a14ea9-fcd3-4077-8efc-dcd55f764aa8": {"doc_hash": "4f94c162b2c063a6a15695d98ec436468bcc5dcf65ba59de3c0d166b60e1eea0", "ref_doc_id": "e881b5fd2dba254153fa35adb717e87b5836c7d2"}, "1f6eea81-afeb-40d3-aca3-fbe397732ec8": {"doc_hash": "df9e956b1c9348376ff020fb39531ea63f32a45af960f32a106ca521972abfae", "ref_doc_id": "e881b5fd2dba254153fa35adb717e87b5836c7d2"}, "819de6ee-508e-424c-bee2-cb5a43e44a48": {"doc_hash": "8593969e614aa71810c8052eac64f28a46661b76258147808f7b1ab34bb6ba37", "ref_doc_id": "ff6356498de3c813a24924cdbf9114f8ece22faa"}, "2edf009c-9de9-4f36-a121-92db089881ab": {"doc_hash": "912db7035c3ff037b2f7d5b9981b2199caa1923158073a6632ae61b3353e1457", "ref_doc_id": "ff6356498de3c813a24924cdbf9114f8ece22faa"}, "dda94b1a-37b4-412c-8bd1-92955465b22c": {"doc_hash": "45da4019d8cef9355281cb499141308a3b8edaa14d0a1cf94de1780772e73b4a", "ref_doc_id": "2e80efa87b8cb5f49f56c4de80054b778742df38"}, "b89ced50-f684-4511-a841-c2c7a8853e15": {"doc_hash": "2543786a0bc573ceb03a634ade947d10b8334731192942d5749f8fe6e061c3b2", "ref_doc_id": "a9712c14dfb54f2187c0a0f38786cb41561f67df"}, "5b8663f5-e876-4e0c-b936-e7f901a94ec7": {"doc_hash": "732d8475638e073a7bb38203dee34c37bbc29f7820a5f5fc491d3c827d5d9db4", "ref_doc_id": "a9712c14dfb54f2187c0a0f38786cb41561f67df"}, "c3d93dce-932c-42c6-8ed5-6908cb9c10dd": {"doc_hash": "cd15e24cb693d33e85c61301a0a0c04c007d71d78f87024431e6416e2de315ac", "ref_doc_id": "5e341cb077901a100270cb1d379e5df790964168"}, "935a5bf8-686f-4acd-a70e-216403e75ff5": {"doc_hash": "b344b41af681c70b5aaa9397320e802c39b7392cc11590ecf83bdb5b5e56ffb5", "ref_doc_id": "5e341cb077901a100270cb1d379e5df790964168"}, "763d2b2e-c051-46b4-8568-de07572e0151": {"doc_hash": "acd798289e9f8cbc285f94604ab3416405d9bd4320d91f7d24f230a272a00623", "ref_doc_id": "6da9912dfa407c2655de68449c7f8dc8f22e0e2f"}, "b3582480-0df3-444a-8ab1-459b424b4a21": {"doc_hash": "b98c535af27986d022a94a08ce36c71af0620bc1fb58270d5441b88e75c7a56c", "ref_doc_id": "541485deeceabc7677192a2f588ee381e138c038"}, "7f96947e-a62b-40d3-a3d2-0607e6098717": {"doc_hash": "59c2b126ed901d6b88bdaa2045c3d4ed57b24d4b14f191eac1243fc1c590bf28", "ref_doc_id": "42c22f3ee37a352f736947c39d56dc934443a34e"}, "4179b3f5-8577-4f2a-8397-64fefe61b52c": {"doc_hash": "10d4ec01353b5681ef264446c9152dc0de73344098788bf879d3430a6767a91b", "ref_doc_id": "42c22f3ee37a352f736947c39d56dc934443a34e"}, "70f5f376-a252-45e4-9ec5-96bdbdb9ab93": {"doc_hash": "d2561dcc28a51af167847c9b2b50284b8b5ea1e591e619e0aeef8f97aac24669", "ref_doc_id": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389"}, "db20b10a-2cb4-4c67-a8d2-6aa6c8be0089": {"doc_hash": "bcf765127e2efe501583c480d4eae4f766e3de95e6129073f41795e53bab9c92", "ref_doc_id": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389"}, "c66e3977-4027-47c2-b496-e191e996c0f1": {"doc_hash": "cd200042884bca5be080f75bbb3dd0578df076cf4a8cfc1919bc6b072fa6e339", "ref_doc_id": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389"}, "61d7795d-2a48-4b70-9e2f-d606df97780e": {"doc_hash": "5705ee9616e5a5f0b0a3450375096fa2e2d1caee8eaaba7d60c2e7c128ad49d6", "ref_doc_id": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389"}, "743f3699-bbe4-4ac1-9a73-08f3cefef767": {"doc_hash": "34b88031226c96ed7d120d231860e9bca9450603dce5696774f853b7a1516303", "ref_doc_id": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389"}, "9ef186eb-cf32-4e7e-92ed-3d98ecc0f9d3": {"doc_hash": "d95a10041bec78c2f6a0b1a2d19ef947ff51833f45c7e6382b593847e1d91d94", "ref_doc_id": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389"}, "37d0b15e-a7ba-4f3b-86ef-fa9a9a8248b3": {"doc_hash": "ceec4d9e569f18527c310089ffae9e80ecc0c892f0be5c3fdeac0bf18b36b7c3", "ref_doc_id": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389"}, "519d0f3f-8c1c-45e0-8b5b-7985829bdcf6": {"doc_hash": "baef80ceb536fe216328820d160f137e82c5b914d5a3a5d0b8c4e555fde20afd", "ref_doc_id": "65788ed3a52740a5d20a43ca5641bf4038899151"}, "8fd7274f-8d46-4cd6-973e-9a975d17b8c9": {"doc_hash": "bfb87658ec11be93e7cdfa9195a50f670e0fbc3d292a8bf42cabede115b37447", "ref_doc_id": "8dc010af0db2fcc9db9f9c23db6ed3a2f5644e39"}, "bdf217ca-d262-4c92-8357-92adaf1e493b": {"doc_hash": "d510eb3f628393d99221e42182baf4d9a9cc7b1be79cf32640c52547c992184b", "ref_doc_id": "8dc010af0db2fcc9db9f9c23db6ed3a2f5644e39"}, "b9bbb261-4cb7-4b7d-a5fb-4489f077c5c8": {"doc_hash": "b3f59a6145581aa3daac8f9065d58ef3f23627ccc8ea19214e36807ee667d80b", "ref_doc_id": "fb6e1495c297e2c98d22e485362addc5f4086d7b"}, "50732a05-df51-4e8e-9546-a75340544c1d": {"doc_hash": "ae98c533a10e9c2a9888e198d4e72e66986e745c52e8cdc51cde2bc0f862baa3", "ref_doc_id": "fb6e1495c297e2c98d22e485362addc5f4086d7b"}, "a83f8ec6-4060-4fd2-8499-22b0008e8808": {"doc_hash": "445912e51239258f90c197da134c5dec15a2596bf4df59e942d6d6886860453e", "ref_doc_id": "1ef7f1624e04f49dda014356fec5109184fd5ac9"}, "8750ca7f-6588-40b7-9082-5775d7d93f84": {"doc_hash": "37db042ee0506258e86a1c09d71e6115b9293aae5507d214d8896ab491679cea", "ref_doc_id": "efe2d8928da28dcac2206c5aaabcc0269cd911cd"}, "2dc178c5-ae63-4b32-837b-9d422ec96e17": {"doc_hash": "0216ea45200c0d9930c30d5ed959ea9787f1ebb3e695ad805b34d4456b93b3cf", "ref_doc_id": "efe2d8928da28dcac2206c5aaabcc0269cd911cd"}, "a3bf8534-fa35-4d0b-b07e-3c52d80339bd": {"doc_hash": "b36326cf339901cfd8acf5623a5b77164600433bc2bdb1461940b05c6b016b5d", "ref_doc_id": "efe2d8928da28dcac2206c5aaabcc0269cd911cd"}, "2af4e6b7-3d2f-44ca-84a5-a6fbd5d3bbe1": {"doc_hash": "132288fdaa7412d6e5882ca057a1d48eaa7cee0d4cc734e5604e3ef664fe4612", "ref_doc_id": "f0ebb4e9a8e3ba41efa0a590709f9def98cb48c5"}, "1d5818de-df6a-43e5-b869-386e83fd3415": {"doc_hash": "892b1c82e372952455f9c923c5dbfec49e24f7ddab25592848b9b56dbecff241", "ref_doc_id": "fc98b150ec32caa79b409a81a22df8f1c9d29970"}, "f8246d4e-ae76-4c23-9693-2b2818f0863d": {"doc_hash": "777935ef09c2508f378b98a04b84396691edbd235867c0d65eb2b8d7c122e096", "ref_doc_id": "75fdb7ce0c015bdb6192677d1a04da8080373b32"}, "d561730d-93ee-4b45-b723-870826b628b4": {"doc_hash": "56892a877a5c3e0f3e5237a8aab39c11a47215c31e0260119f067c5ff2f72e83", "ref_doc_id": "75fdb7ce0c015bdb6192677d1a04da8080373b32"}, "b37e8d45-bcf3-4bcf-999c-d5f3647c1f3e": {"doc_hash": "abaae3ee7a2b475b3c423794a6c113ab2fd8e79367f28e387982b8dccfc6bb46", "ref_doc_id": "6e8399335ad01ebf5bc8c610ad9a8cd928437f60"}, "1f92112a-651d-40fc-9066-389909366c25": {"doc_hash": "0259f7e1f12df9b9103284bf7e4dcd1674dfd2b4ed4e58e380993e94ef638e6b", "ref_doc_id": "be9bc7a8dc64606386116f4514bd22682be4921d"}, "57846725-b06b-4935-90bd-e6c67a549c26": {"doc_hash": "e084c09cf1571acb6e4ceb0f9141582d6d0bbf75ca37f4f29c1896309184ba13", "ref_doc_id": "be9bc7a8dc64606386116f4514bd22682be4921d"}, "b3be340a-d2b5-4fe8-b375-1c661132b8cb": {"doc_hash": "551d3897ef6c229d18ab2d86ceace870de941e9ef07ee0460cb046b7f4a792ad", "ref_doc_id": "12dbbe33d490e31bbf50851055623592349db141"}, "c07ac0ae-0067-4d4d-842b-fa15ae190b68": {"doc_hash": "66bbc641c69a6914e729f7578f144a1ce8b7d5e4adb15392a35ab252b044f12e", "ref_doc_id": "12dbbe33d490e31bbf50851055623592349db141"}, "902c7cc8-ab57-420e-bc5b-6d83e2d9748f": {"doc_hash": "ca4c3fe00bd22ebab7bbe44ecc79c5b767b86ed7c8addc34ef567a1118a45f71", "ref_doc_id": "e603e7e87a17aeb00f17727731f1dbfb611eb121"}, "b19fe1a0-d685-4692-8f4a-2542490a5f91": {"doc_hash": "2a36ed56caec1f1f005782e9e33574a8314668d61ff12af501b43fbe84b64d21", "ref_doc_id": "5ae1301cc542880d92f78213d959b10a0a2868e7"}, "05078c76-7257-4dd9-90b8-06c2f41c65ed": {"doc_hash": "5e7a417e0667fedb0acb1eafb9dfcabadff115689215550dca9cc2f9666088b5", "ref_doc_id": "5ae1301cc542880d92f78213d959b10a0a2868e7"}, "e1b52bc8-dde9-4cea-8133-5a6107a3b7db": {"doc_hash": "019b41358ca9ddddc3b92c9cd4e3a059afaa7cce149dc25abe5033cb67022635", "ref_doc_id": "9f8de3b5c2fb0d2f94ff7a4f3f5f2c33255ff8cc"}, "0bdb0904-80b6-4b63-bbdd-0b9242191e87": {"doc_hash": "82d5cd28f5ce61d2af5cd971c18de1dbc409f53dbce3b20a0b69867e039be0e6", "ref_doc_id": "9f8de3b5c2fb0d2f94ff7a4f3f5f2c33255ff8cc"}, "aa3b2ddf-596b-4f7f-83cb-10ea1c0de835": {"doc_hash": "7bd3d8d891293b766e3f64ec430c267d1fd8c627917b4ffda9721a5c8c136f14", "ref_doc_id": "9f8de3b5c2fb0d2f94ff7a4f3f5f2c33255ff8cc"}, "a6850047-8ac0-4c91-b2ad-da55471ef0bf": {"doc_hash": "32740d7b628a0ea24b7e5dc2e926d0fcc04f2aa870c7b473b3a92f7583d20428", "ref_doc_id": "c54cdf811912bf0d1b093377bb878115a1c7559a"}, "fee71c90-2d4d-4f64-8dcf-651544d1bb04": {"doc_hash": "a9f7d657d7ee95e78bae3065711e05b54614ea870e2f19dee06a5602de062809", "ref_doc_id": "b6dde3875b506f0d450a3f8b9a50728329973410"}, "693b903e-6743-4d1d-be52-9ea9ce5c8d40": {"doc_hash": "65ded9c1c49b1a4a1f591c076a7f3961eb81a7cb7c990dc9e086304826ef4c3f", "ref_doc_id": "e0cf334a6611aab79be64eada67f526c545e65dd"}, "9afd63ca-98e6-49e7-ae49-7466ac597092": {"doc_hash": "924ca130c45803cd36e55af8cebb2a68a07aca731f7b2aeb4ffbff7f8061ad91", "ref_doc_id": "02de8b5c5cf82beb550cb7373a766ec393999aa4"}, "20f0d466-9944-49e2-aff3-674d6f167b52": {"doc_hash": "a53e8ca3f61fe23da1b345395a6e0c952c477a7315301e58d4ba647bae5af6f8", "ref_doc_id": "b04767a5b3481e7dc5d3fd5a34d3b27a19875aab"}, "b040e289-cec8-4900-a28e-3e6073f6d396": {"doc_hash": "8bcd149d1b0f673613b232f08162225c05fe0134b909fce022450ad87f6f7545", "ref_doc_id": "82a6b008f7988e12a413c401a38b423aed1b854b"}, "554b3218-f5e6-4611-9edc-55a30c8cd66f": {"doc_hash": "fc404009245f21e8e170a1f51ca959e642f863ecfeecea80193080b690a4fcef", "ref_doc_id": "82a6b008f7988e12a413c401a38b423aed1b854b"}, "cadc3249-2231-48bf-b80d-451402044792": {"doc_hash": "8df86f7caf4debfbada6a2c9ae2929269118b6ae9e84575837eebc460d4d27a9", "ref_doc_id": "98e09188b958147c3d6bc7ea404bf3cd9b4c4df1"}, "33a1322f-d516-4332-b2e3-43449d291066": {"doc_hash": "4f64c4a6cef82dfb78fc0adb55685a55e8f181dfad9b70c277c89ea7632e588c", "ref_doc_id": "98e09188b958147c3d6bc7ea404bf3cd9b4c4df1"}, "f273704c-11d1-4a41-807f-0e66d7072d80": {"doc_hash": "54f0e9d0844badcdf72de64bb4170103b0b3d2ee90874c24b50cddc1d5cfa667", "ref_doc_id": "20215a3c1c7147517a946a03fe51e5b219211688"}, "afd26714-7d65-4168-bd98-0f4794f08e36": {"doc_hash": "44ccaaa7c2666f89c200063b58822a7d4ab01e158331b0f73b9f85ffa73e96e3", "ref_doc_id": "2ae98d5f1e2d0b0467799fcb1fc9bd4b794803d7"}, "854c7191-ebb6-4594-be0c-b6e66a741a74": {"doc_hash": "c6a9f39c0bbb2f73bf94679c8634b6d82ae8e577e43a753e6cfe502f3f5935f5", "ref_doc_id": "37ee1ab8a924f48d373c8d3915cf04d056a9ac2a"}, "5c8059f1-1401-4f54-ac6b-1301b07d4d2d": {"doc_hash": "4ccf18d79776c5de5058bfed99af1dc91e96f9e5332858a6f0c7c527e1d4d8db", "ref_doc_id": "53dd871c76c7b89720ebfb5b249ebe8bdb0f69e8"}, "1279dbd0-37cb-4f67-949b-7dab1b7ca70d": {"doc_hash": "f20ca9a28141c6d11d281db3586a700c5fdc10efec0f75ce80623d1cdc2960da", "ref_doc_id": "53dd871c76c7b89720ebfb5b249ebe8bdb0f69e8"}, "a2fc14f8-20f2-48ba-bac4-db154a32aba5": {"doc_hash": "5ce9f1163ef198c5ac967972cb1fb87f4580384772dcafc5042ea54271a93877", "ref_doc_id": "289fdcc7bb684cb250ebb6c44e8e64e8240df2c5"}, "49d365f1-e2f0-4f56-8c0f-9db721174c8a": {"doc_hash": "d254b68fa8b99dc6a853555132addca17bc9eebbe67b2dad71c613ac8e5aac89", "ref_doc_id": "289fdcc7bb684cb250ebb6c44e8e64e8240df2c5"}, "89f93007-789a-4127-bbd3-0e154e59ae15": {"doc_hash": "be661d53365754d70ddc48f21e8df8059fd302e259adf5948a7e894a11e3c871", "ref_doc_id": "931ad55b2927da963c205adc9283abdccc064f0c"}, "541b6c04-b8f0-4cf6-bd3b-ecd0242f5e60": {"doc_hash": "92bd7fe5c77e677cdaac09b54493095372d4f312f2b5c5224082bacfea12d63c", "ref_doc_id": "2a6f7d19dc780c431987c6ecf37dcc6ad21ac4b6"}, "8053d478-544d-438c-a923-753619cf6bc2": {"doc_hash": "2fd9e3a1ea43a01a35663035627ab0b3da2b3969cf8dae3b1444d18aa94fe35e", "ref_doc_id": "e39e6325eee6099ae006fe360d3deabc3ecb97ec"}, "dd514643-e072-463f-8241-aa6879f935f2": {"doc_hash": "ab1fa00502de44dc26f6ddf55ca25b85d0b84ffd570880f9e1d714f6940d74c5", "ref_doc_id": "e39e6325eee6099ae006fe360d3deabc3ecb97ec"}, "4a3d6c75-2992-4386-9e85-a113c95eb4cc": {"doc_hash": "5830c6cc831d7092044af0d6cc05a7f0acf318e09c9f77811a459d96506bfff1", "ref_doc_id": "e193f392c8bf7ebbb52bce2abb2f050810796ba4"}, "8702ae4e-4d6f-4132-b6a7-fb60864c10fc": {"doc_hash": "f23773a6ebfb0341c2df6222aa727c155c8cfbde3a77a23bf9e9407706885aba", "ref_doc_id": "e193f392c8bf7ebbb52bce2abb2f050810796ba4"}, "3c14273b-380d-4fe1-babd-c1078638dd16": {"doc_hash": "687c83c3acbea7f2553956665900a962f923a1a74895a7ccceb3b512e29ea478", "ref_doc_id": "12b396288e590ffc0362e7d51ba2bf194980cf88"}, "c10d08d1-558b-4ed9-8c0e-c1e64ea2d08d": {"doc_hash": "b6bd39b4cf2ce9fecbf28819ad24527b2d5525766909d80a29f6121ab9e5aa9c", "ref_doc_id": "12b396288e590ffc0362e7d51ba2bf194980cf88"}, "5dc29253-a690-4b39-ba33-f11a5a8dbbb4": {"doc_hash": "647ddff9d27afeb19e4d8624ccd942ea955df14e5ae6ee1b28d80805dcf9aeda", "ref_doc_id": "3b7d233595bfeff028b98d61a84fe66cdeae663c"}, "66ec64ae-11f6-48a1-a238-672c41ac062c": {"doc_hash": "126801669e52bcc4571de62a475a71960e51c7a8c9880e88ee838392eda232f4", "ref_doc_id": "3b7d233595bfeff028b98d61a84fe66cdeae663c"}, "f74e5e13-75f3-4481-9898-eae14123c143": {"doc_hash": "1f3a77be702b8b17ef6936ab5ba469c9ce5ef076e7bd8db8b7e2d221bb76034b", "ref_doc_id": "6944cccd045271bb98ad1db1f322bc71b7a63115"}, "fb750b13-8f7e-442f-9660-575bb7200a71": {"doc_hash": "4f2ecf72e4cc7d0284290ef87e2276a4b8bc8b9efe85fd0f4c1e5ba80755c9fb", "ref_doc_id": "6944cccd045271bb98ad1db1f322bc71b7a63115"}, "8c5abd63-edd2-4b05-95d9-809d33f1a84f": {"doc_hash": "2f4c23a90dc205f66a858909dc347e52a76ea9e71b3dc00cc6cd4d7e9f1e9ac1", "ref_doc_id": "e360a49dd06db3a0d936fecb9de73d34719da9d2"}, "e16a6454-c0d0-42e2-837e-ba24f94d19b7": {"doc_hash": "a2ce2975a9b1170d36c93385689e77f5f52c491e50b292b6b082a0cfd78d5ef5", "ref_doc_id": "0651df3c0cc49a752054e4604f91e922493abae2"}, "e9acfd82-4baf-4e66-9ef6-1d3e1dfde643": {"doc_hash": "113c011cf303f74081c25123e9dac3037fb62a283d370994f00e2639fe4c435e", "ref_doc_id": "0651df3c0cc49a752054e4604f91e922493abae2"}, "45c832d7-e5e6-4592-9b1a-ded4634ea5bb": {"doc_hash": "0c646c10651bbec4e2fabe2d3b043724e4a0fe82bf4b6d369eba4c637e1359a2", "ref_doc_id": "9624e926c5a83e17eb6fe1fe7a2ffaf0e8a714bb"}, "52cd6ab5-df3f-403d-88a0-4e2ff6566230": {"doc_hash": "aab9c900364384f18646f9daf5c220f301c9a1d8f73dae5d748a373b0c1f21c5", "ref_doc_id": "370c8923e15916e05edcb8e1a1879cbc37601680"}, "a64b5701-3647-4d70-9cdd-6fccf7d7025b": {"doc_hash": "a641113bd79bd97e0091d6bbd0a7f27ac9bee35dc7e169054fe6c5a56f44bd9a", "ref_doc_id": "370c8923e15916e05edcb8e1a1879cbc37601680"}, "094ea4bd-b58b-4ad3-a0b1-6b46e21693a6": {"doc_hash": "6132b2a7fd2b340b39d896befc824bb660da7c7db30da8ee05dd8c5adbbc05b9", "ref_doc_id": "67fb5f46a65071875838118624d06d4ed15a010c"}, "5f2b026e-2155-45d9-a336-1b0dac2b671c": {"doc_hash": "ae7f0eb181e7eb8facda027727047a189cb48e985bf3a66a1d87f34bf68ab893", "ref_doc_id": "67fb5f46a65071875838118624d06d4ed15a010c"}, "d1b62e87-c568-4ffc-996c-a53396b512a2": {"doc_hash": "c8c76ccd58416dbd4f1b10c4538dbba1fef82449c3113cd236dc25e0c235cf4a", "ref_doc_id": "8ac25b1c3280d05c59576e696bcd034c11ad1635"}, "a5035c45-c2f8-429f-b5ac-cdae104270fc": {"doc_hash": "405bb8de3c253f2ace7f58fcd18034103c7deaf8c7f3b3edee89ce4e042942d8", "ref_doc_id": "8ac25b1c3280d05c59576e696bcd034c11ad1635"}, "4b95ea82-1432-450f-89c7-c63ed469e0c5": {"doc_hash": "41bd2181770efea35f5f29f96c69817c8d5ed285b493ff6e387b7711adf8a0c0", "ref_doc_id": "3bbfb8391058b4049afe30bcaa711ab70c115862"}, "f23b28b3-5c9b-4320-b9fd-f0f96646de5e": {"doc_hash": "a4a456e811e473f19357079f89393cd5b4e82d0157aa9ff2dfbf173be0fddc42", "ref_doc_id": "3bbfb8391058b4049afe30bcaa711ab70c115862"}, "e826487b-6088-4659-b119-450fcd0ddc72": {"doc_hash": "ec5366975febb3889301418b401b0f27e77dd3ca23ded983fa6f39d4060a644d", "ref_doc_id": "ed15f18ac6d87a916a49197c931e955d77bef99f"}, "6eabf164-4859-4803-9e08-3848f21425ca": {"doc_hash": "7d8a28a8bf0a9100ac9704508557a68c4f02ee7bcb48c73f6ee0e51f13e32851", "ref_doc_id": "ed15f18ac6d87a916a49197c931e955d77bef99f"}, "2d08803e-0110-4ed1-a2f9-9053d30947e4": {"doc_hash": "0cbfcf64e956669adae32d523cdd259ea1ecb207034407687b8cc8a6c10b3509", "ref_doc_id": "ed15f18ac6d87a916a49197c931e955d77bef99f"}, "3a94ec9b-c779-4c1d-aaf3-01dc71515bf5": {"doc_hash": "342edb1b658c7307e7f747b2057302d0cea29ff0c2b14012c6eadfca61e60b9b", "ref_doc_id": "ed15f18ac6d87a916a49197c931e955d77bef99f"}, "064bc582-56a7-4eac-b273-f2c34ffc0f32": {"doc_hash": "3f279d37ad9273aabc64493d4923f49e518f69f2f5c97acd8884dc99180fad42", "ref_doc_id": "d4a21cab679cd538a27b55474d5e5acfdc44b848"}, "64809586-c097-44c3-8194-c55ff1b5ec96": {"doc_hash": "20934fce9fa3d29271f955293631cc84e45ae77272f315644e994763b015b049", "ref_doc_id": "9fc9b94a80404af3d46f3ac3c761a5f8df00a645"}, "7da876af-eabb-4f89-b033-69c12c012f20": {"doc_hash": "49549c88f409ba69d21fc085e7c727994bd49fa27b00bd1dabf7db021c070876", "ref_doc_id": "c184523682f190fefdd4ceb314550e8cd2fb5648"}, "3183cef5-7201-42fc-811c-22387e99f946": {"doc_hash": "192c49c32fbbf60958152242c039d2d51343fb25e21f7073615b31325812b4d9", "ref_doc_id": "c184523682f190fefdd4ceb314550e8cd2fb5648"}, "14b9cea9-28cf-4846-9ec4-d17880048ce2": {"doc_hash": "21b28cb164a8ba6f5d64e85c8ff5f0a034644c463cd25ba6264aad4bfff40252", "ref_doc_id": "c184523682f190fefdd4ceb314550e8cd2fb5648"}, "76c81058-80ac-43d9-81a7-d98d3f356e7b": {"doc_hash": "7881808ad84e75ac41b05d55b2d83468b6187d1cfed08b4d7a9cafabe86f7024", "ref_doc_id": "a64c22f8cf2a4269a785f12ef963236cd939ee16"}, "03cfe848-fdc8-426f-bffd-3e369a87706b": {"doc_hash": "48542e8ec8af090475cb63ef2b3646b8481989be818a5fb308bd467567f2fa4f", "ref_doc_id": "a64c22f8cf2a4269a785f12ef963236cd939ee16"}, "7deb9cbf-533e-4c40-86da-4dbfdcbf6fd7": {"doc_hash": "715ee20cef0cf5ba608dfecb581634f685f2c1a09755a45f1d11bfbc83d8dc6e", "ref_doc_id": "a64c22f8cf2a4269a785f12ef963236cd939ee16"}, "fd3dbbc0-894c-46f5-8802-096b46cf7264": {"doc_hash": "728ba38b3a79a86f6e3e554103db50fffb17b724b354ab78cbafe86354687a15", "ref_doc_id": "46d72f633611ea3d8528ad61981d9057ad748792"}, "7955af9e-815e-4466-b428-f08ba067ff7a": {"doc_hash": "f1662153d134f61abb1ef9431c389d16e48fb983573735ab0af331daaff53899", "ref_doc_id": "5c689c9c40fef2d51e1273867b9f8f2dbf57dd77"}, "8f333e4d-44c3-4e6f-b2fc-30368d0cfed8": {"doc_hash": "58b5d6cc61d64868e63838afec4a813432b46544b5e640ced7ce9ee48ab62e08", "ref_doc_id": "5c689c9c40fef2d51e1273867b9f8f2dbf57dd77"}, "733d348f-c230-4e91-acdb-f51d889dd601": {"doc_hash": "19a2d8dd0d04a00ce27d75bcb813df4c234e0571592c1d808c41cd51f6e8af75", "ref_doc_id": "5c689c9c40fef2d51e1273867b9f8f2dbf57dd77"}, "5915644c-4f41-41c0-a7f5-891f5bdd6318": {"doc_hash": "47ba8c9c7a4a416310c273ff78a95b746d9bee37149a3f3255291246caf05bdc", "ref_doc_id": "98836337801044fe47e1f9675805d35799fe40c7"}, "9b7ee9a7-ab2d-48c5-941f-90e821ef792d": {"doc_hash": "192a3f2d396bd24919005c763af6f434a992362be6c83b39f47987f7bf0f7368", "ref_doc_id": "98836337801044fe47e1f9675805d35799fe40c7"}, "53f65dde-c43c-47df-9b81-8e17db2fb70f": {"doc_hash": "610c4244fa1f2e6d04b0fbf685eb75e18162b2e54449beddefdd666471e8aa8e", "ref_doc_id": "460797ef1dd00cc2de7eebf75c628486a95f868f"}, "9666ebfc-0745-49f2-a45d-d62236189929": {"doc_hash": "0225a707e3730ea4511fd4ffc3a658b6801723d4a61eda59127dd3117d4a5710", "ref_doc_id": "460797ef1dd00cc2de7eebf75c628486a95f868f"}, "22ddc996-f92b-4b11-9c62-85a3bf248ece": {"doc_hash": "a045e92430759b68198a6563d4db8bbac5ab4b715b39dd7a3916cbcbd559face", "ref_doc_id": "460797ef1dd00cc2de7eebf75c628486a95f868f"}, "c3e89e0c-d6bd-4fe9-a98d-8198a8e1fd9f": {"doc_hash": "d242ae3e859cf55ae837d13d4991feea37f287cf86dd532b06c203774917c9fc", "ref_doc_id": "460797ef1dd00cc2de7eebf75c628486a95f868f"}, "f574a492-08a8-44f2-89b5-ba22876e1aa5": {"doc_hash": "3adbf0526544ec6723f550305a1c2b60b27295fc0f4bc8959015876d55b83b23", "ref_doc_id": "460797ef1dd00cc2de7eebf75c628486a95f868f"}, "4c153586-19d9-44df-87ba-d1e4bd8dcbde": {"doc_hash": "2cbc31c2f00591b4e0f6729f7bc9e59f2f76466a22bf546b20a80ba7a2ced896", "ref_doc_id": "460797ef1dd00cc2de7eebf75c628486a95f868f"}, "f26f48b4-e594-4019-809b-806b8ea6b149": {"doc_hash": "68f0cfd81baa5e0ee479db798dbde1ef41b477ae0c2236fa432783b8c571d250", "ref_doc_id": "7d1af784439981fa4387d660eaf2c2d0f3d1973d"}, "06121cdf-c16a-49ba-a0ae-b221f343e48c": {"doc_hash": "17be6cd4577ab3e06af4918a87c55cb92b630451bc9404e540a9e3739d75bb8e", "ref_doc_id": "7d1af784439981fa4387d660eaf2c2d0f3d1973d"}, "6c861a1c-8acf-4aaf-8243-2a7208ebfb52": {"doc_hash": "b4d17c62e629a99f40876987629d27a0c796fa63bebd62bfefc9804f2b5f1148", "ref_doc_id": "1e0cc5749df2e5e1cf7a2ea52d712364e36f2ec6"}, "c1ebf3ed-884d-48fd-a6a3-a0934dbef765": {"doc_hash": "6b6b54a171b407cb4d8993ce9bc7906381b108828b2bd49ecd225c8fe0b1e291", "ref_doc_id": "1e0cc5749df2e5e1cf7a2ea52d712364e36f2ec6"}, "47680fc0-fa44-4ce3-9a59-e7aa5540931c": {"doc_hash": "27d7ba01c1448f90f85141b3f24484c4c76b0c698828551717bc856fc0b09f96", "ref_doc_id": "fd71e1bfe6e282bf0326070e42576b034847f203"}, "01f07a90-184d-4356-aca9-06f1708545dd": {"doc_hash": "d4d8240f55aee5589433b43b7f64b6bfc28abc58739e6dfb41847a8a658e3102", "ref_doc_id": "a3cd7362b146852b1c8e39b11f0ab90571b01186"}, "22304e58-2267-4292-a3ea-4630e87bcf4d": {"doc_hash": "a0b2642904fa476943ce7b5bb47d93db09d0055086418e441aad6a89915d5eab", "ref_doc_id": "a3cd7362b146852b1c8e39b11f0ab90571b01186"}, "853dbd37-d6f1-4a7c-931c-fca8cace01c2": {"doc_hash": "06a3c9f228a9b3988d2602ff90d3e9c0a68787ecb3f29e10eafdb29f4bfbe77c", "ref_doc_id": "a3cd7362b146852b1c8e39b11f0ab90571b01186"}, "2a250e28-5ef0-4329-8dfb-6f402694dd09": {"doc_hash": "a074e051c2781a0314194769aaebdb3d8bd3a62093a43801870ee8e7197e9490", "ref_doc_id": "a3cd7362b146852b1c8e39b11f0ab90571b01186"}, "62c37351-a198-4c61-a644-0d021f1b481b": {"doc_hash": "f9b5996dc56a5752226bd347d6f6161564bcd5e05c46b4068902341dacaf1fa1", "ref_doc_id": "1cb7db9df2541410c506b5bb60849d2f2d0f7d32"}, "bbd9b67d-6800-43f0-a1c3-f303b0b13044": {"doc_hash": "38e9d0b84decee6ba1bdd0a30f95c1ca03196e563d48913b9871f94ae98ed919", "ref_doc_id": "1cb7db9df2541410c506b5bb60849d2f2d0f7d32"}, "ba9606d9-5384-476d-9a55-1b342d8ab0fe": {"doc_hash": "3f91fb29ba9ba1e48f4c13a360e89742a491026d3cc379e0b477938e6372cfd0", "ref_doc_id": "1cb7db9df2541410c506b5bb60849d2f2d0f7d32"}, "29e8792f-68ea-433a-9737-983c1767998b": {"doc_hash": "72d9f5d3feab7e4d4515640eccf29dcf416a4138f69a23299f2ffcdbff136694", "ref_doc_id": "221ca909151ea84cfde102e709e67e090f0b60da"}, "b811a527-a404-4cce-812b-a27c32c606ef": {"doc_hash": "406473e17a105bb9664a30ab648c6f7674bf360a5136b0c5c96171a65d1b1148", "ref_doc_id": "221ca909151ea84cfde102e709e67e090f0b60da"}, "90fef2e3-98d4-43d5-8777-193e134da1ad": {"doc_hash": "c3be743b62775cae166ea913bb40c5b53860421a2885a162c6ff14b7b896356d", "ref_doc_id": "513f7e01ad1d2a060f4b3fc64d0a0768b3292171"}, "26ff6998-e343-4710-989d-b6004c159320": {"doc_hash": "7ff47d50036d2dca5449d991307ab7eb7e57491007e3cebc3562e037e46a4b97", "ref_doc_id": "513f7e01ad1d2a060f4b3fc64d0a0768b3292171"}, "2e2de33b-4989-4684-8161-a325cacf504e": {"doc_hash": "180807e4738d1b9db4c428351ec5f607f8335cdb16f7a9c563d6fc449864109a", "ref_doc_id": "eb99779273e4d5e649ce7ed9a6bb892b66f7ba64"}, "532ff16d-3776-42c0-a119-93f6f898b8d0": {"doc_hash": "6ffbaee7db19384a4aa298edf55ca639bbd2ad6126badb11301d653370007339", "ref_doc_id": "eb99779273e4d5e649ce7ed9a6bb892b66f7ba64"}, "d37305b4-20fb-40cc-b88f-47509b714a15": {"doc_hash": "3bab7a6f6a430f98cee88568c18d46bc68e8d90afcf01c29c5bdfc6549c0945c", "ref_doc_id": "56919e8e56101797085f0ac142cb1e86d3dfefc6"}, "97dbe69d-8295-40af-af47-950c84aa10bc": {"doc_hash": "016032f541a03952f34b641d455eac75664ec6864ff8e3b841fbe2fd750ea268", "ref_doc_id": "b4ad10650e8eac5e709c087fa3b569ea10ef018a"}, "143ee9d7-38be-4782-a5b7-e318cd9f72ae": {"doc_hash": "32076b982185d4e09a3c85da4422496ee4a7ea52ee250707d40965e03a992aff", "ref_doc_id": "d57c71b5ef37f03cfcff7ef6f2775a8d517a145a"}, "4cef0b77-f8aa-41a6-a7ea-8f7795bdad5e": {"doc_hash": "fee5a80dfb72546c6a6aa6f2f1ccd7845fa053c985ce5c254b0913c0cbff7a6e", "ref_doc_id": "066d1391242cf88445c8d7eb218fdd8306eee8a8"}, "c86fa5d8-ecba-4e2b-92c3-ff7e75678280": {"doc_hash": "4f63012d6efbf36d9465d1809f2d9fa46e9391d1964493c784a66eb14c305b8a", "ref_doc_id": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7"}, "e732f692-cd36-4f56-b895-b30fec0e963e": {"doc_hash": "8d8ceb07a18fa9ea721127d71a77b8a79954e3b28b6d70bda0bfc5eb2bced9dd", "ref_doc_id": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7"}, "748eae3f-125c-4029-a851-fd809d2c6697": {"doc_hash": "28caa6fe119ea0f2f0450c8334fc1525fd6bd140b0812805b27f6198e0aa68f4", "ref_doc_id": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7"}, "57e41555-12f3-4770-82d9-f0aad1b6412a": {"doc_hash": "8ea76972df8bc9166199591357c3667ba62f8959dcf73e42050614d01bf1edcc", "ref_doc_id": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7"}, "c3916487-3131-4d50-adf5-9fa53486bf77": {"doc_hash": "245d95c71c85c59df071bfeba7bd1da8a923f70439b60ebb7c559bd11876a142", "ref_doc_id": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7"}, "afaca212-91ca-4b9a-98bf-fab669e3328d": {"doc_hash": "758c09a77d28e1473552880c7a960283d536310a50f1c7f48e528397bfc472eb", "ref_doc_id": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7"}, "6e708be5-e0aa-4428-8549-d8152a28cf43": {"doc_hash": "9aab10a545ef1be1e500b8904786408f6d70ef8c572fd63c31399ae18e411ccc", "ref_doc_id": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7"}, "278dc771-dfcf-4ca3-a5de-b7f2a6b78e8b": {"doc_hash": "5a9175c3086611c275b060d4e490829372c8ed20817cb08056a1f4b4f8fca1af", "ref_doc_id": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5"}, "9e035d68-9ea5-45a7-b068-b60a772d41f6": {"doc_hash": "4a2b47769c74329c744b26632af9e7c90a04d0a0e7f24cf0d10e3bae886df92a", "ref_doc_id": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5"}, "3342e4f8-6172-42e5-bf5f-9af21d06d8f7": {"doc_hash": "7e2f2b19393f1eb0664df95fa396ed76980f20d4397446b625bb0cd0bd569cca", "ref_doc_id": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5"}, "90849325-0bc1-4513-8447-9828f136d15e": {"doc_hash": "8f888ec749175fb96e0295af83790090786f23ffce6dabfffe104955b5dfa37c", "ref_doc_id": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5"}, "40e1be1d-46ef-423c-94a3-78b9a259608a": {"doc_hash": "60578e3378f7fad133ff4c1ac130fa6939166ea501e6e050a0dd046cda68ca30", "ref_doc_id": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5"}, "250b3bb1-506b-4362-9929-e6833bb0120a": {"doc_hash": "dd2b3b8698bc7637ddcf8ac2ae73037458d0b3af616891ec17c445980535698f", "ref_doc_id": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5"}, "8d10a680-acc6-41de-9572-045e687528e5": {"doc_hash": "329b511d26702b42843e7a17ab0956569b340b71b32743ff271a4aedc8b1c4b5", "ref_doc_id": "06c0b39d09ed42720b55d3bbe0dbaf4ac24e8a38"}, "e32797e1-c383-44f7-b5b8-b224348fd87e": {"doc_hash": "3956918990189e63ece047854c6dc7e76dc1aaec2dde6df7a84f97cc85dc6cdd", "ref_doc_id": "06c0b39d09ed42720b55d3bbe0dbaf4ac24e8a38"}, "8fa4d92f-fb35-4c30-9319-eb77734dfdbe": {"doc_hash": "cb8b646ffc7216a437fd4127546b084bfcf0de3ed9b80e93de810ba3c2a5a03b", "ref_doc_id": "06c0b39d09ed42720b55d3bbe0dbaf4ac24e8a38"}, "803f4148-56ab-43bd-ab3c-f1d462b909c4": {"doc_hash": "3af88de9774312a2455efd91220a828ca4b3ddab2d1fb081a377e9348fa10453", "ref_doc_id": "f043f3380d1f2e3bdb20217f6665d1cf95860ab8"}, "e960c0c7-a8a3-4093-989c-23dee3b19f66": {"doc_hash": "235eceb6223cd942d63b5c88692d7bf4396895425540954255ec64c99d084b7c", "ref_doc_id": "f043f3380d1f2e3bdb20217f6665d1cf95860ab8"}, "f6ab8d66-b8d4-4268-953b-d29ac73ffd01": {"doc_hash": "1efe6ba643472ed8e16c98115b51e8a418464853d8d373bb063f8207b45715fd", "ref_doc_id": "0ee3e4c07af94ede0ae8cecd50917977db44d7e8"}, "f754d93d-64c7-424c-b9c3-f656cff42e51": {"doc_hash": "7128ad23418249f10849da5573aaf0633acf91e144595af1bbd96a93b59f8164", "ref_doc_id": "a21fee5e6788aef76f96cfd5e128ec3b8be3caf7"}, "425e6521-cb82-4b62-9f2a-b14a778a969d": {"doc_hash": "eed5fce32db27cd88b20580365161ef38c496bf704ff56e3d7f7022f29aac4fc", "ref_doc_id": "a21fee5e6788aef76f96cfd5e128ec3b8be3caf7"}, "1c725a50-f148-437d-a78d-60e09043751b": {"doc_hash": "f3a227e0ab9504e9d6a01c9af7ab8d8d814c11332ef7fac289064cffe42c4938", "ref_doc_id": "a21fee5e6788aef76f96cfd5e128ec3b8be3caf7"}, "1fa2cdc6-b813-4957-a709-ff3cbc08b525": {"doc_hash": "4f4ce36fe99a6096dd19262999c2c5ad97f0c3236802f802321e2fe08f606b23", "ref_doc_id": "d92e82a6719b8794e1b2d28b212ea63ea03ef218"}, "2c1b56d2-9571-424e-a805-24f96feffccc": {"doc_hash": "ac848501430c984875100baa682826f6e61b1dd45df67af256830e2bf34b9555", "ref_doc_id": "d92e82a6719b8794e1b2d28b212ea63ea03ef218"}, "a3dc409f-41a5-4adb-b7bb-ab5fd4ead5d9": {"doc_hash": "713081e95b722cb7076c02efcc84ae5c6af851aac441fb48a01c51edc965e5ca", "ref_doc_id": "d92e82a6719b8794e1b2d28b212ea63ea03ef218"}, "f0399098-01e3-46d7-b6ac-cec7bfff6215": {"doc_hash": "58da9fd06e4a50677b70318d36fc59edaec3f539416e50f76b53d4362ebd87bf", "ref_doc_id": "d92e82a6719b8794e1b2d28b212ea63ea03ef218"}, "b833923a-83e9-4f66-b827-bda4969a8438": {"doc_hash": "be18215e0ea85ebff3eb62b46ffca7baadb48155b6ea8d313958b71a01070677", "ref_doc_id": "3e2403e32ef0f367e18352da3695a88684dba3f8"}, "897cb772-962f-464d-b84a-e1e6dd034784": {"doc_hash": "7d02ab1216852d09fde4f7dc3c07db0bb027663523c35493682c87f22b2d3c89", "ref_doc_id": "3e2403e32ef0f367e18352da3695a88684dba3f8"}, "d8c4454d-fd05-4a31-9902-3426c258e8d3": {"doc_hash": "afdfebffe2d3db38b5d8f1130e064d341d814cfd172926b78e78ab48fadbf814", "ref_doc_id": "cefef4718b805070345764e7a6bb54afe738f236"}, "3fee16fb-0df8-46da-91e8-56b07412c687": {"doc_hash": "7672cd7b5c526d5ce6426e2a1e4e8125f91dfbd367073435bf87329a13b4685f", "ref_doc_id": "2168413a22fcc28b3ee9b9ae6ce4c2c77266e951"}, "98880794-3419-4e65-b782-cc284bac55ef": {"doc_hash": "24bac069288f79aa0873ef5a8c0f246e0870a5b6c2332d2796ab2f1a10bf2f58", "ref_doc_id": "2168413a22fcc28b3ee9b9ae6ce4c2c77266e951"}, "c63449e2-18fa-480b-a4ba-6923ac2f3f3a": {"doc_hash": "abcc313f265e7db0fb1480d5a29f777e63fb04cda35aa7764c876a263141119c", "ref_doc_id": "fc66b7490b3ef2a06eab0ee1846e6ff62eca48df"}, "dde2f544-2a17-4009-ba5f-46181e5043e5": {"doc_hash": "7d3a30d51248b63743e31f3181c5c488a7265c734e3343295e4943c2f7424a2f", "ref_doc_id": "fc66b7490b3ef2a06eab0ee1846e6ff62eca48df"}, "66676581-3a48-45ae-b38b-5b0ca6596d5c": {"doc_hash": "cb38c1bbb41498fef2fec283dfd67bc62ce29581c651a4e375d44fa5d0fd672c", "ref_doc_id": "283cccbb1c96b4ef412c449e542b348230110de1"}, "0009ad3c-86d1-448b-96bf-f207288296e8": {"doc_hash": "19cd9682764ad7b3df4c5852dca2e5fee536576b7a8d8c8a5cd7b560dc79a603", "ref_doc_id": "c641e41c03008b2290c54aaa4544847d1bd5d8ac"}, "c565b9de-ddb9-4e36-96d5-c6efc59c9ca6": {"doc_hash": "ac54f6b00a39e452b39a9c1f2971ede6cc9bb03a9481ec0ac82be302ff4ab86b", "ref_doc_id": "c641e41c03008b2290c54aaa4544847d1bd5d8ac"}, "d695faf3-3c93-45b6-95f0-42eced039888": {"doc_hash": "fda39011062209a93036756413cf32be7e177a4bca9062e25ae09c576fef6300", "ref_doc_id": "c641e41c03008b2290c54aaa4544847d1bd5d8ac"}, "65b3424e-539c-458a-bf2a-78dd3c48e473": {"doc_hash": "f91cb594dcbab85c6ddb068ac7a6f8f3be9cc96f5c412a39b80902d38e8fcc85", "ref_doc_id": "23a3e62f3f2acb009592e6b5b57db1faa03b59d2"}, "9dc54506-73e0-4c75-a463-3125a74c1ea3": {"doc_hash": "172c6a9ddfb9dd3bbcb5fc5e92c45e66bfd737a76a3580a15f4d0958a35d93da", "ref_doc_id": "21045d21783395b894914b57930b2f2aa791975b"}, "736879d9-b9bb-4566-9ebb-98e72a32451f": {"doc_hash": "d36901fa8de8b9345e081c5acfa39af22c0abb21c67816835008d5e44b125e2a", "ref_doc_id": "eefab96eb5b30e083cfbbf70a8f94370d27df740"}, "52b32d33-a3f9-4b95-89a6-274b0051d061": {"doc_hash": "b78cf8e29ef7a2563204a29da31992bd6373e696d80951ca6b5dac4ab5e4f01d", "ref_doc_id": "eefab96eb5b30e083cfbbf70a8f94370d27df740"}, "2e421799-71d3-4791-99c7-eed2588d0807": {"doc_hash": "521b287b120336d359df0f4d0011e668687ba4b896f52d09b2115ad7cc6b670d", "ref_doc_id": "eefab96eb5b30e083cfbbf70a8f94370d27df740"}, "cf21b248-0263-4557-ad99-5db6494f6ae2": {"doc_hash": "3c1a398ea118f4155529cb2a79a8cfb32b7cb48409e37ff4b7a9774916269d18", "ref_doc_id": "d6dbc002044115ecc482e398d504f15ac752c9a6"}, "2e53f527-e982-4f58-9c6a-bcaa40d19f8e": {"doc_hash": "24e8c11f0dae85fdf3873795ff96f10c4321215c68b46871cefea219f3fbc71c", "ref_doc_id": "c2f8dcf099a14b0c2fee340828b861470b856884"}, "8945383e-2707-45c1-bfde-2f01e19fef6a": {"doc_hash": "53d1167a436233d4bca2c2dd6711fdff428a614987f09bc1141b87b8d30c03fb", "ref_doc_id": "0beeece78fed944f13822510497b29d6e3f60ea3"}, "02d9b2c2-3638-4aaf-8c58-a6492d177be7": {"doc_hash": "7fb3eb67b434f1fa8bd0d34528250026149669c30d46e2bb9d74d59588b75921", "ref_doc_id": "0beeece78fed944f13822510497b29d6e3f60ea3"}, "3d0d22e2-d02d-4fe4-91a8-68e71a31607d": {"doc_hash": "792efb28b8d13adef079b226c256d8f6539daa31e0b24167ec3cbc48c536210d", "ref_doc_id": "d109bf6f8b57ebd0329491439a533b66201c9535"}, "ea70a347-9a43-44b5-8515-3842fe4aa913": {"doc_hash": "f3ec0d4c355e5877195cc81e63eb01871e7b9be818ed50c7fa65912d4bd10962", "ref_doc_id": "d109bf6f8b57ebd0329491439a533b66201c9535"}, "3aa20ee2-d4ae-4f34-a70a-cc8f952c3f40": {"doc_hash": "686987774c64aab1adcc2d17a8e1d7380358b7a813f863e842a0d322eb2f5297", "ref_doc_id": "d109bf6f8b57ebd0329491439a533b66201c9535"}, "60ce5d98-016a-4d00-9298-9194f34006bd": {"doc_hash": "e370a914913d986404d74622e24b5f9b50c9e0fd241e0fff4227ad16738a380b", "ref_doc_id": "1c85bc511dc511c37c3ecf59b3dd59f24e415731"}, "9f5e04f2-bb2b-4998-ae29-e58ecf350e6d": {"doc_hash": "a130fc9fab377c076502f89db3941223fcb7f82006b8eb0b53ba8c11839c3aeb", "ref_doc_id": "1c85bc511dc511c37c3ecf59b3dd59f24e415731"}, "9f6decb0-2e10-4d40-b469-793011e914fb": {"doc_hash": "2ed61236472e0361b9e688a3aeef5c9b9fdc0216b501a23b78ac776c712e267a", "ref_doc_id": "b9bf45d386b7abfd56184bdf9f902d4080a313ad"}, "4c84d6d9-e4dc-4aba-a965-54b66090abc3": {"doc_hash": "da2a9c87aa19c983d92a438ab87cadb6381f62a36ad8ff275faa64bc06b71a82", "ref_doc_id": "823815552e9904bbecd26edfe8aeb78a9a46ff4a"}, "3a3fa97d-ec3c-400c-840f-d7823bc6b16b": {"doc_hash": "ae74738ce595b443d140db0ab9cb736f2fd2fc73acae578f2cbd44900bfa9e64", "ref_doc_id": "1c0086e721dbdfb14ccb34937b80956eb381a0e7"}, "75906804-8f96-4425-ad10-f2d7002b5730": {"doc_hash": "78b3c09c3834cf44f74fecd0d8c9de88fe193e1b9d89148a7f327ae4bd5d93c0", "ref_doc_id": "1c0086e721dbdfb14ccb34937b80956eb381a0e7"}, "fa1627f6-6980-4c7c-b3b9-b3a97d4b21f4": {"doc_hash": "a6c6983c9811b096e3f0385510a1ef966aa1a203c1628dc9444aa3ee4d9c078c", "ref_doc_id": "1c0086e721dbdfb14ccb34937b80956eb381a0e7"}, "2e74faaf-829a-4ab6-8aa1-242cad4b2030": {"doc_hash": "28fd36fd4dcdb24e579c40d5f72564d65e26659c4072e3453a7bde09488ad979", "ref_doc_id": "1c0086e721dbdfb14ccb34937b80956eb381a0e7"}, "e85b27c2-453e-475a-b4ad-4a6cb8ba9179": {"doc_hash": "ce41367bf6e16ad233056f95b876c60294e833700dd97a8cca921b343579700c", "ref_doc_id": "1c0086e721dbdfb14ccb34937b80956eb381a0e7"}, "3564b2a1-d50c-4b38-8602-0b88d4815c01": {"doc_hash": "16c90124145a58d754c276a35cc4dcbeea592a1808375bf5414c5541c878eeaa", "ref_doc_id": "1c0086e721dbdfb14ccb34937b80956eb381a0e7"}, "3e40e01a-4376-4920-a2bb-1d73943b0d87": {"doc_hash": "2dfaac10e06b38d21d01eb8c290dac4f0f56f91738874308caafa926f7bb5071", "ref_doc_id": "74bb533a5510cec6582906aeaa72cf76c6e215cb"}, "5114300e-fbcb-4f90-b9a2-1bdd3f568c87": {"doc_hash": "7425d73b52b055936492f19f66a7ac07d0814d33ed0d9842650f776f4fdfd9cf", "ref_doc_id": "74bb533a5510cec6582906aeaa72cf76c6e215cb"}, "2c37b66a-16d4-4143-9b73-6afd0ecd807d": {"doc_hash": "c3ddf8e11414f976a6ec972f50b4616574e0a09f102873c38435a61d7a531174", "ref_doc_id": "74bb533a5510cec6582906aeaa72cf76c6e215cb"}, "267e9a02-9646-40ee-9338-87d1b8b32956": {"doc_hash": "e7f4281cedede8ba69573f186abf9546119751bf47dce75dc4cc161bcc4c8ec4", "ref_doc_id": "74bb533a5510cec6582906aeaa72cf76c6e215cb"}, "8c1b88cd-a6b1-40b1-b4c0-13f466ba7657": {"doc_hash": "43bf80aaf879e39a58d31674c0803dfb92b5a8e47ed9b6a3962ef7c419f0ca29", "ref_doc_id": "74bb533a5510cec6582906aeaa72cf76c6e215cb"}, "f432c8b4-798e-436f-9703-5aab4d6f057d": {"doc_hash": "0dcaee5fba8a45e204f6fbe296b0233f95e7d462678aa7296439fe05e5523acb", "ref_doc_id": "74bb533a5510cec6582906aeaa72cf76c6e215cb"}, "1149e5ff-31ff-47fb-957b-5aa9f2281193": {"doc_hash": "70bc206f01f417d8d5193c0849c205b9cc45e744b340b46e38281ce5c518f0cc", "ref_doc_id": "95a4df97cd4b186da3008e46be33463ce5bbdb2b"}, "d34ea9fb-0042-4b14-8749-a71c78cf17e1": {"doc_hash": "9419e8f99c87b3e0a6506de2faaaba3fd70d2a889918c1a4b4b4b9f1e628d40c", "ref_doc_id": "95a4df97cd4b186da3008e46be33463ce5bbdb2b"}, "3b65d3aa-bef9-42cb-8ab7-95996283b08f": {"doc_hash": "f5040246a9bf7c9ebd34407cbd5ebf8d307ac9245b78eafb4693dfe8ce43ecde", "ref_doc_id": "11c2231859919e5c426286139b4f8a646f01f196"}, "1d223c54-9d43-470d-8f40-c55c063cf828": {"doc_hash": "c9ad8c32bc3f9cf9349e74ea72dd5695f2195218cbe2812f67358af6acc395fc", "ref_doc_id": "11c2231859919e5c426286139b4f8a646f01f196"}, "251d9477-3963-4237-bc9d-d87fae787294": {"doc_hash": "5619e52f7a44f561cb340ffa1b75453f379bff30a704397c7ee1bd0508071ea0", "ref_doc_id": "1c8201fa333751c86b68ffeb9bde3b9ed43e6d74"}, "3df3f45b-a21b-4e3c-82af-097cc4e90d4e": {"doc_hash": "968da8f17c6838cdf2bd55a3dfb193a0459a9cab3f250e3785776d11d0b88499", "ref_doc_id": "1c8201fa333751c86b68ffeb9bde3b9ed43e6d74"}, "daf89df2-2d36-43ac-9caa-d54fb1b3f233": {"doc_hash": "1cfeb55d6a23a45ecb65c4f6298edb3f0ea57491a9ccaa0e7bea042bc595e391", "ref_doc_id": "1c8201fa333751c86b68ffeb9bde3b9ed43e6d74"}, "0081dda6-832e-478d-96a2-ce3db5e92d03": {"doc_hash": "58b9b930a7460db4100b3dac9487c6b1babc6cfffc6f872263fd2ae5616c89f8", "ref_doc_id": "f7dc87a714740bc664e069b2703bde045e1b864a"}, "c82cab1b-0979-469a-8f4e-3be408d0e4e6": {"doc_hash": "6f94f91ff804b7be3a5b670628e99165f175dd0b480bd76bb7677333100a2253", "ref_doc_id": "f7dc87a714740bc664e069b2703bde045e1b864a"}, "156219dc-882e-4497-9c64-9f5bb59a7845": {"doc_hash": "988d2ca2e83c3eaf60ee2768b3b79c6b491a42fda1a82f0163db1a682be83936", "ref_doc_id": "57218f210fc19c7aaa4905608df8dedf4a5a9eb1"}, "a5c63800-a8a3-43ab-8c49-df5330025ea5": {"doc_hash": "09b0a177214f042c327249e5231b2d8793e052c0231f7ad5ac030d51c0e43fcb", "ref_doc_id": "702dc3e4a27955421bc6547a65cd6d15ef07b272"}, "02ba00a8-ed4b-4619-869f-12f6ca0a6330": {"doc_hash": "378010253fd9afc53f3065cae65103390fb4d027776431d2058605a51de49823", "ref_doc_id": "702dc3e4a27955421bc6547a65cd6d15ef07b272"}, "7eadf116-90df-4bba-a7b0-a6d97641274a": {"doc_hash": "5e577a16f010ce984583d7cdd85cbf3853dee851defc4bc412d1a5a70d3b1fc8", "ref_doc_id": "702dc3e4a27955421bc6547a65cd6d15ef07b272"}, "e7e6193e-f910-4454-8ea4-e6116a382a0a": {"doc_hash": "a467f11df880f3f1f96d54ab6c9f7c118e826ba4a8b2d73e2d475519b2b6da0e", "ref_doc_id": "702dc3e4a27955421bc6547a65cd6d15ef07b272"}, "650945f8-b90c-423f-90be-d4060c5f240f": {"doc_hash": "2d41e545552a04a444f68a141464a972f746dd3c1a63db15894d4bf757328131", "ref_doc_id": "702dc3e4a27955421bc6547a65cd6d15ef07b272"}, "390680d0-5366-4669-a91c-bc9b35b38940": {"doc_hash": "d6de8ccd195ee9b97f6b8875c81e96524dc424a3c3521e40e8981b845feed583", "ref_doc_id": "702dc3e4a27955421bc6547a65cd6d15ef07b272"}, "ad891fee-0d1f-418b-8f1f-06130585c458": {"doc_hash": "5a30d3847e322469af5578db34f6d7546dba4777d483372b659e7d0a7ec08826", "ref_doc_id": "702dc3e4a27955421bc6547a65cd6d15ef07b272"}, "b71e0166-ac13-48c9-9d31-4ef1985eb777": {"doc_hash": "cd08d0b4cb6bdcc501b8d2bcc24b4c1567eace802ee4801b9e649f4c163c300b", "ref_doc_id": "702dc3e4a27955421bc6547a65cd6d15ef07b272"}, "6df20991-9e56-4946-ace0-45cb7b15e139": {"doc_hash": "19998eefbd0a8811aff413c21d56b91ccefb065c69f82da62ef11df1089a2bdd", "ref_doc_id": "702dc3e4a27955421bc6547a65cd6d15ef07b272"}, "ec7028d0-6bce-476e-ad45-d51f4e8e70a3": {"doc_hash": "69ee9f700c343377998e70c54950f8a5baf6fcf18ff9a09bd4d10bf84ac0f226", "ref_doc_id": "702dc3e4a27955421bc6547a65cd6d15ef07b272"}, "32161ec0-3cab-4004-9732-f5d583a56ca2": {"doc_hash": "be9d319d792c769f3aa56886be90b8a500ddf3adfccf2ca87d602d525ae121fd", "ref_doc_id": "f6ba683c6473cd3a6df1fa8c3e908339794669e9"}, "fa3a9d81-7d4d-4e45-80d9-444f08dbc65f": {"doc_hash": "925b9743a02d69e237d54fbb877f90cbeb9a10685238e941149ec5a084289893", "ref_doc_id": "83e70db047942a49741ea84000ab3d37820dd24a"}, "476dcb35-8d4e-4344-b342-b24ea700104d": {"doc_hash": "bf491d31001609e3255c299bc9a2295f4ea892e1cc9cf9cec888e0b7e58b9310", "ref_doc_id": "54df972ad7f2dbdfd18a315f51bc502a5e1a24be"}, "af0ef1bd-1d2e-4f7e-a376-c8972fce5e52": {"doc_hash": "658991a76e31b35ecee1d6fae33e89d7d83efdc69e50519a64c99f735a4ef17a", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "ff3b0afa-e047-42b3-a473-80f522823b5d": {"doc_hash": "f3787bf3fabb835f84dd13af686ba5d0f04a87fe712b208172673f56be5c5539", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "1ddf2704-0cf9-4719-8ebb-3957684e955c": {"doc_hash": "220ab388588614a54fccdf2a11b219af5322b006aa8a03729cb95f3682f203e7", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "1e5b77ec-d0c1-4ff6-ac44-6ee4f3ba1f1d": {"doc_hash": "97c485763b93ed9971d423829fea2b6dd5e13714f774c73f63748ae80e5c4aef", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "0124ba20-1aa1-4873-847f-487f9bd5f391": {"doc_hash": "ef33445304b29419d8e005734e000a971981db846223b79a16d532f1d363cb33", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "4a8e1008-069e-47ef-b4cc-2673f7663c00": {"doc_hash": "24c628a37eb5f9a6bc0570f21c594a90d43d517b003b6ccc2641765e7c2e5635", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "862043aa-d260-4902-a0c3-0a63be34df97": {"doc_hash": "86ed9565461432649a8e6b28528ba26912b390708b972219bcdc9773a5073979", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "4b6d0f99-5078-4c3d-aeee-0a7187cf6d96": {"doc_hash": "4fb5a1993975c516da1e2aab0f37f7b740222c1ca20de0a0361048d9e7952d42", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "6fd0a250-a461-4f06-8771-c8002258d3e8": {"doc_hash": "80b456bf3dcb70f4cfd6e7bd61a32cb73da5c4bf7b1100a16a7f4feba63f9d30", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "27cc0b9f-3e38-4725-a175-f7fec59bd7a7": {"doc_hash": "a92c38abee15b34c2cc4511c537992b4f328fa268453359237ee5e4939256215", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "cf05d3d8-3e40-405a-b5fe-b55575048fbf": {"doc_hash": "faf57389845eba5a1efd03e1dbf821666e7ad0d6495caa00ed9bc648c5ce677b", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "c06fd51f-2158-4dae-95ad-31ae45dd7880": {"doc_hash": "7de54784594486e35eefb05ab72c1fa273f6a39b461236e4872cf398c46b4627", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "7e594392-2881-4bf3-8145-63edcf45c152": {"doc_hash": "46f31d0c5c56b44229743f9a839f82f8d8290c9ddb17cea476c8fa4a1db10745", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "ca741a93-427f-42d7-b452-a06ae456198b": {"doc_hash": "8a5d1454972bb7092c78cabd40720ab5f1d479427e7b805e623e4dd2ea622637", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "ae995665-7d65-4af0-b5b6-7be34fb7434d": {"doc_hash": "891b4f6eab0a195b0fb1bf186912ebe5b9a2c1682bb2b5c700a604570971f802", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "7090f775-2cc2-4d5a-b83a-42fe9ae7a357": {"doc_hash": "8d20980c48d46e7f074980a15a7e8dabd928a61c0ba734d12db5b0feffe77771", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "128ae49c-a2c7-4c0b-a1b8-5002f0e27d81": {"doc_hash": "c14caa2694321d33a11511a26831bb873efceb0e2fcfeee534e64ba150ed7c59", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "05f5e274-02a6-437b-8658-577a517c7754": {"doc_hash": "d92557e7330be8c4bb5f155200bdbfaff091e9b7e5138a2a8513cae45f8c93b2", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "fc9a7b07-aac7-4a96-8d2f-f6c109d82ffb": {"doc_hash": "aa0df74ff1e318af002a0d12828a9fe81d366bdca1ef6d6592c9e4f5872e4aab", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "ccbade4c-6b85-4876-9354-cbf51ad71298": {"doc_hash": "62ddab0783be79d6f41a5b79aeffb6c25e84e56e3cabedf46796abb665d377e0", "ref_doc_id": "c7c50dfaeab91cad40cbb455d832b860e3e220f1"}, "a5c40de4-ebb3-473a-a373-60327f589248": {"doc_hash": "4ad6445df362c7d8b87613663e020e463f68b1c830b62d1f4bdae197b1caefd1", "ref_doc_id": "f40cd9380740eff0176ae51621e285600bdff08f"}, "72a1a59d-0f7f-4cd1-888a-bd8cb19d0fd9": {"doc_hash": "b303e287ee4f606b18fc31e122e31cca7c03f5f8c675e3f4db1a62f76adf7758", "ref_doc_id": "f40cd9380740eff0176ae51621e285600bdff08f"}, "3f718723-b803-46ee-b34b-515fc2bf63c1": {"doc_hash": "0ea18592a18ff6cf632919f1f230494306b37805aacaa225433a7923013d5b11", "ref_doc_id": "a6862ae86aeebd0d2a552f49918a5c585d690125"}, "786d4d9d-b0d8-4d83-b860-49c9e2872db4": {"doc_hash": "a4c7a4551ae8454458efdc905358324983513a9b9ed65483292648f7710fce29", "ref_doc_id": "a6862ae86aeebd0d2a552f49918a5c585d690125"}, "aa76c0b9-a63c-4023-8251-a9e0ae4af85e": {"doc_hash": "b802b2678d880e18424455420b711fdb2a074766b615b92190bfc59ea1a492e5", "ref_doc_id": "a6862ae86aeebd0d2a552f49918a5c585d690125"}, "421b0b9d-87cb-4d4d-a04a-4e9e4ffbbd85": {"doc_hash": "71789de71f80d79f9dcce21372a4c13db4ee90f6e1c651aacf54d19c773c0e20", "ref_doc_id": "a6862ae86aeebd0d2a552f49918a5c585d690125"}, "080b4e9a-c148-4fcd-96f8-cf8f3d14576e": {"doc_hash": "5d26b0d8bae7cc37ac049d5573204034d1a8f73e9c4123b466ed54a798851311", "ref_doc_id": "a6862ae86aeebd0d2a552f49918a5c585d690125"}, "06b249ba-50af-4a2b-98f0-47cb73af850b": {"doc_hash": "5a7a5f96db6ff43b785efed08e0c21105f01ff62c4e148732627ca7efdc3c72f", "ref_doc_id": "a6862ae86aeebd0d2a552f49918a5c585d690125"}, "b8ef17ac-6b0c-4f52-90ab-42d21d068f11": {"doc_hash": "982b92d082f8121e64406634f6c017607c72203b6d57ce7121e2504049a82590", "ref_doc_id": "a6862ae86aeebd0d2a552f49918a5c585d690125"}, "83ade6fc-f559-4b19-b909-e32a53e0ba7e": {"doc_hash": "1f138bcc0a2820a150cdbdcd48479d5a228d9e812491a44a19bb8af1d063867d", "ref_doc_id": "a6862ae86aeebd0d2a552f49918a5c585d690125"}, "0d25c5d7-a26d-4ea1-b4a5-696f569d50b5": {"doc_hash": "391aa115826f5b80e57f8785be1dd0adbdf964e4a383eee9292bee74fd96e576", "ref_doc_id": "a6862ae86aeebd0d2a552f49918a5c585d690125"}, "9247f59f-6218-4ebe-8efe-3990f4ccfc44": {"doc_hash": "6998a601590bcc07e7f88b48db7ba2e96fac35368f6dc97e91f5e6a502a5c15d", "ref_doc_id": "a6862ae86aeebd0d2a552f49918a5c585d690125"}, "991fc9d6-8cd4-45cb-986a-273a4be18677": {"doc_hash": "d16e2b9ca3fc505ddfaf8a9da8dec9fe1b33cf52fa68807ecbee0b5226189a34", "ref_doc_id": "3835cf4523eb2e570be91df2075436476b9df2a0"}, "c79cb631-9334-4f74-929a-302aba46aa37": {"doc_hash": "5ce65a082766efd4699e2dadb06689cfa78057e7fd7e2819903bce9e73267619", "ref_doc_id": "3835cf4523eb2e570be91df2075436476b9df2a0"}, "7aa6553a-d662-4300-b24a-bebb1b3c9966": {"doc_hash": "a0488238bdb4e4c3b07a863c57a5b56b23b8077a6b868a571e0d920ab5cc2fe9", "ref_doc_id": "3835cf4523eb2e570be91df2075436476b9df2a0"}, "1086a26c-c8a2-4b93-a381-555673ddcc8c": {"doc_hash": "525f623bf5470fb2df0884609e9620fbff4bc3c26502c7891d12c6bb8fac9558", "ref_doc_id": "3835cf4523eb2e570be91df2075436476b9df2a0"}, "6b822332-752c-4865-9c14-aeca89ec6091": {"doc_hash": "6817c899cb999fe062a3f2d551bd25fc8520bfd53afe1925e8ded09f6f853f51", "ref_doc_id": "3835cf4523eb2e570be91df2075436476b9df2a0"}, "bcf61072-3ca2-4852-a9bd-f1ea0486a6dd": {"doc_hash": "a0749d26086286094d4657867a4f66ee7983193fbc52ceab67c0be774dcacc58", "ref_doc_id": "3835cf4523eb2e570be91df2075436476b9df2a0"}, "a93c4ede-134c-4389-8b9b-5bfeba630a6a": {"doc_hash": "2e2ecf492d2966f0f3d43bc297dcd2d708e4393e5c256e4c1a607c42fe929404", "ref_doc_id": "3835cf4523eb2e570be91df2075436476b9df2a0"}, "3b8f9544-0db4-49df-9eec-2f16be0fa94a": {"doc_hash": "cfa23624a8c6da88804d978faae1d33b5c4e90da92b5d094e865de334be7b6fb", "ref_doc_id": "3835cf4523eb2e570be91df2075436476b9df2a0"}, "563221d2-b46c-4ddb-a62a-3c13a6c618dc": {"doc_hash": "e5d742fea536641776a46272dafbaa895e0209eb03b9271f9ff5cfac29d0a3de", "ref_doc_id": "3835cf4523eb2e570be91df2075436476b9df2a0"}, "fe89d6a5-3c1c-4d65-bce4-be1b9470ca35": {"doc_hash": "8edcd84a02e33fd559aa9f8a77dcd5b34eff41f4e1bf3f9645fbd5889b314118", "ref_doc_id": "3835cf4523eb2e570be91df2075436476b9df2a0"}, "6e715757-924a-4eaa-a77f-595f0628af0e": {"doc_hash": "4e8e71bd5f8e94a73a80564b62c6833889b83145a26c7916f02f734ba2050ff8", "ref_doc_id": "605b5e82f33cc49ee0315b1c79c10859aa611738"}, "642490c5-dd0c-4d98-82ee-1307a410939f": {"doc_hash": "f1574fc6723d670b6733a57ebb22b59f6ad85abbcc6be3f4758b3339b20c32ce", "ref_doc_id": "93ac7374f6bfe9dfe845be7ad99c32b028be673c"}, "af0d9b97-d3b5-4cb8-9c97-cad1cea92b24": {"doc_hash": "0046ef2e80ed3fa7c8baab44d3adcd8dabc75e29c25951488b03f945709607d3", "ref_doc_id": "93ac7374f6bfe9dfe845be7ad99c32b028be673c"}, "0706f04f-e140-4531-9afb-ca892cdf1b5b": {"doc_hash": "066e1c2ddca93870ff893bc9ca0964f7fa75ddf2cbe913d390bf646e0990865f", "ref_doc_id": "93ac7374f6bfe9dfe845be7ad99c32b028be673c"}, "afa87745-b32b-4940-a142-b37ce9ab7856": {"doc_hash": "61eabd51659c6a60ffd3ee25ed83f8642ae99f71bebb458094053e1b5d878a39", "ref_doc_id": "99d7b566516d0df3047c5f6ad9f1de74e264bba8"}, "880d9436-52fb-4385-8363-4aa27ccaa1d7": {"doc_hash": "a4ebf3dcf285736a8f78ae20070fd39c1139d211a9399a92a02a61a0a105a698", "ref_doc_id": "99d7b566516d0df3047c5f6ad9f1de74e264bba8"}, "bde8c9d0-e68f-4d69-933a-11c18cb39a57": {"doc_hash": "5a04b2e018245d44c02a4c71b389b8c6c149b29ce15765b45d92dcf1aef3070f", "ref_doc_id": "99d7b566516d0df3047c5f6ad9f1de74e264bba8"}, "c50c54b7-a9b8-4e82-806d-11513062d2f9": {"doc_hash": "8d269d2c47e5bf6d600ecd566f915ecb21320eaf6e62133729d4b7658e6eeee9", "ref_doc_id": "1a20d4e9546875ebc47b2265f675fece5d271bfd"}, "49e9c908-27b7-4869-924c-5308798bb17c": {"doc_hash": "2f277d082771fa7ebc340eb1da255c8f7d8d521ad9428d96a0b115847c1b48a4", "ref_doc_id": "1a20d4e9546875ebc47b2265f675fece5d271bfd"}, "e6edbcb1-58e9-4e0e-8f45-0377d79209ba": {"doc_hash": "bc645bb46299739d49df8a5562d0102786019ccfe8f3eb6fcbcc7815821199ed", "ref_doc_id": "4b95232cca47456f08d70378bc8527b6dc416f37"}, "72e2f566-3403-46f4-8cf9-8f1ae8a8cbe7": {"doc_hash": "cbe859cf9b48721b5913afbc7959c7c0ef1b9a699ced8ec68c73632f184fc15f", "ref_doc_id": "6cd0bce7108b1e2da0267c6f0229a8c4b9dd86db"}, "28fbd09a-5a46-4e5e-b26b-11183bff01c1": {"doc_hash": "a8aae6d47929108eae6a672c6791d5f5f913c193e32532126bc8305c1c967480", "ref_doc_id": "6cd0bce7108b1e2da0267c6f0229a8c4b9dd86db"}, "3a502aef-b32f-4bcc-b315-30cb40b8e95b": {"doc_hash": "7672ad29dfa715b9a23039393d4c3a84c94b24d232609664cd0675113880aed2", "ref_doc_id": "6cd0bce7108b1e2da0267c6f0229a8c4b9dd86db"}, "45ebac77-fb68-46b5-834c-c2a62ac314aa": {"doc_hash": "75b1dc388a623ef146d441f4f9c6eb8f0aa28a19f7a7453f220f478364e96216", "ref_doc_id": "c0c03f3d7fc8050052ab5378ab24ec56aa189b89"}, "707a707c-784b-4b2e-b56c-6291a4ea08a9": {"doc_hash": "a13baf55cce1ac58328ad756e4814d9c028164eb481eabb0235d23296e91c8a9", "ref_doc_id": "c0c03f3d7fc8050052ab5378ab24ec56aa189b89"}, "abaa565c-8620-4cd9-9f1f-25313a0b6f5b": {"doc_hash": "7b42f750a7a99e031508fe64620adb543a061e37f1ef6e023577ee790ffef0fa", "ref_doc_id": "c0c03f3d7fc8050052ab5378ab24ec56aa189b89"}, "22b5ea76-02af-405f-bee0-d5a3c0c5c49f": {"doc_hash": "7f2a08157a760365ad42224c918d5383d3279e5b31b303c17ad4df51049f9fe2", "ref_doc_id": "5e40d91595902954d6cfd8b4060f62d358fc47a3"}, "d3b98b06-604b-4c2a-8a16-bf41b5c32505": {"doc_hash": "363dda860ee89a22afc46e00b20778bae5d8ebde58b864fad22a3068c5e7a5a6", "ref_doc_id": "5e40d91595902954d6cfd8b4060f62d358fc47a3"}, "fdfe23ee-66c0-413b-b702-1a6f416e205e": {"doc_hash": "1075867572fa59fe82d2137a9cc82465b29f5259f6484520ecb0dbf9bfb407d6", "ref_doc_id": "5e40d91595902954d6cfd8b4060f62d358fc47a3"}, "e068dc45-9190-4f6b-8ee7-d9709798a220": {"doc_hash": "c563352245932a372a6a39b0569893b8e8c670d5e591e9481787e34370416d2e", "ref_doc_id": "5e40d91595902954d6cfd8b4060f62d358fc47a3"}, "ad243e5d-adbb-4603-9156-fa2c15434de4": {"doc_hash": "0f74078fd0929ebf07ce539eb197ff7977d6bf230df66ac3fdf92f5cf387c2a2", "ref_doc_id": "b941e25beab4714a2991c561a8045df5a671467e"}, "37da259f-40d4-459e-93b8-3984a452ce0a": {"doc_hash": "997f2f41440016d7804626da50c4a14e12b4f2a427fe315bf5e49c41484a890c", "ref_doc_id": "865cf46b429b4adeee71193b63c30921809f4bb8"}, "fe0e73d8-ab73-40f1-875b-14cfed8e1f78": {"doc_hash": "10cd7c1808e8febba0aad773a020429b72d578eb801f182b81eaa687e3171ec7", "ref_doc_id": "95bd3a3ff0209fd9511fac413a38c1a56818775d"}, "04171a41-dc7d-4865-9c22-41ae9ce2d1d6": {"doc_hash": "fb924404bc72789f16c2b137b63cd91ac995b9072530a65479891d93ed96e403", "ref_doc_id": "cb0006c38d2b16470cfc3402d02a2eb66a6cb9d4"}, "ff5ea6c8-6d98-4ec0-8b4a-c06bb2dfb38e": {"doc_hash": "fa4f309017237ea709027a66834e31623960c2068120c17849f8042050800ff1", "ref_doc_id": "9d7c7cbf680009058d6fa27fda32323e8be11c81"}, "3f871c8a-e01b-431a-8079-d74421b1ca53": {"doc_hash": "bb65d8bf35706e82df36c4d9f02aa79a39f25440c25831632cd3efaa5ee65b8e", "ref_doc_id": "aa0adab1a07c50fc3f1a38830c026e002e5cb7e0"}, "febc905c-c65d-46d7-a64a-d68d275f4cc7": {"doc_hash": "c017dfa7effde044d5b98666616a50dff481d9b0a191cc80e684f1c80f08c396", "ref_doc_id": "fa15efb471b788d149d1993c822fa18ea619a49c"}, "e4035023-6fdb-40af-9e53-ff486ea8d5f4": {"doc_hash": "04b7942f26f59e1d92c211f85e1dcb1f0c4e3061f3b47cd9a84d66b55188011a", "ref_doc_id": "fa15efb471b788d149d1993c822fa18ea619a49c"}, "855530bb-74f6-47ed-83f9-2ede21784336": {"doc_hash": "64c4eab90ceafb17beef085a509cfecb967af196a98c6786c52025d8432899e2", "ref_doc_id": "863bfb8affce16421dfdefe28fd7e85ab66f8e61"}, "9daa592b-8b7b-4006-9630-aa6d6a58e9b5": {"doc_hash": "952381db58fddff7693e50bf7f8f32ab45c4527ef9b3b68ec8ec5ea2e881af5f", "ref_doc_id": "863bfb8affce16421dfdefe28fd7e85ab66f8e61"}, "08711a83-754a-4069-a058-04da6c960cc0": {"doc_hash": "b236a76b31da48872738080971e4de72fb260881b3239ed65b238eff97ad86d2", "ref_doc_id": "3ae8c3a974d6f57476d54c5070b003581677d03f"}, "18ba54ed-8318-4f01-824b-6888d954cc39": {"doc_hash": "a06f2cb258bf186bfee6acae34935da5242bea05b7e0ec9a1591d9d90b421b3f", "ref_doc_id": "2267eb40d6bc0cf1e7b8eee28bd8c5acf05c342a"}, "07ae1165-0d60-40fa-af5a-ed64313b06f2": {"doc_hash": "aa30431e8b1f91c34e80724ba5a9d205e97cbef57a479cb23f08ec0eb02677c2", "ref_doc_id": "2267eb40d6bc0cf1e7b8eee28bd8c5acf05c342a"}, "b2d95a78-9934-4761-8b0a-527589b47693": {"doc_hash": "f48d8b6e01928d2ea625048558d90f5e4d41fa6d2b8f0e799c1861ebe0f12601", "ref_doc_id": "420e8cf9959cc5896252761eb2a396c43d712daf"}, "ccf7ae75-94ff-4d0f-bd65-177281bff8dd": {"doc_hash": "89928400f0208d848be8d1f27b5a5a45a58987c6dbcf6d3d1258f9d9ad5b16e6", "ref_doc_id": "972293085b68603417c72038f245e4c2652e50da"}, "7333f29b-6762-4e30-961c-9bfaf2c2fb6b": {"doc_hash": "07553a37e95057ae928e3d4a099206052f0c4557c673247ecddfa73c6c196724", "ref_doc_id": "75261e68400d3d3c28eec769c722bf8206dfce99"}, "0ad3b069-5d4c-4330-b73f-fe648a169fe9": {"doc_hash": "27c8cf0ad25e3eca1cf45860874e20e0ca88cc01a6fbcd096a9ee77dd0d79321", "ref_doc_id": "75261e68400d3d3c28eec769c722bf8206dfce99"}, "716c710a-8559-4208-9fa8-a091bacd8cce": {"doc_hash": "4d3bba3c03ab0a44b517c3a4f4e2392b9ba9222658b89062b09e5d62d0653fed", "ref_doc_id": "6df4e3127c93f09bdae012d6ea0679cb85edbc34"}, "0453c618-7209-47d4-983e-85c81c4118f5": {"doc_hash": "c59eaa6abf09efeb191d1f36b459778cbf868b0550b81b80fbc8c7b8d5b1ca45", "ref_doc_id": "58608d569516c575d0314b0529ec02e2d565dce0"}, "b81d0fd4-43ed-4458-b1b2-60df6b5b63e1": {"doc_hash": "616bb7a71146aef5191ad6cf83acfa383cb8d2b694d513be24ebb9265db455df", "ref_doc_id": "c9b150ac1b55d595a22ca441f225bf76260144f3"}, "a76f6bd5-8e0f-4dc8-b997-bd890289e967": {"doc_hash": "6f6f3cfd15f711364fac6799690ea9a66f3f422116464f52afece33aeaa85ab7", "ref_doc_id": "fe8ba53394a005842201e62311b5aba3ca1bce5b"}, "73aade9a-e941-433f-9146-0babc895bf40": {"doc_hash": "9b407612f8849ce9f3e026d4b48288129791a4fe896f60b50d2faccbf32691d2", "ref_doc_id": "ca0402ec5262d2a05eadabc76f234ea726a10c2f"}, "cf075db0-8e6f-44b1-8de6-5e97de799a1b": {"doc_hash": "c2b5d6b596b82f7c9bacb1bfc50343237513360e8261b83973624337c52ae139", "ref_doc_id": "138c19485a3a39062cf9e5bf5d763628293f8d04"}, "8123b4c7-e453-42cc-b189-6f0f0896f824": {"doc_hash": "c47fd3889c08e3ba6fa690f37d5105bf61e3421d978a48cc5ae28f08537a95c2", "ref_doc_id": "3e4ae7b170bf476ad9044821008319ffb8a3c313"}, "22445c7a-2a51-41b2-94e4-7afde869a605": {"doc_hash": "2fafeee668f4e5fa9b3e37b174f6bc30a9771b8b012b76a96c9c4cb49058f143", "ref_doc_id": "50e0e9befd28ed9949c1518313e73d69eb519baf"}, "6f607011-d6b6-4793-89c2-ee55be0926af": {"doc_hash": "3f3075a05cd01fc70caea4a78170c957a791864fa92574cb62c2c1431a4533fb", "ref_doc_id": "749d7ac379a27450e367352d4b92ded8eed698e1"}, "8363113b-4e81-4571-b14f-66d900bbee55": {"doc_hash": "966bf1cbf83c3b12e617eaa2c2adc1b12fdee3642a239dab304678b99e36bf63", "ref_doc_id": "749d7ac379a27450e367352d4b92ded8eed698e1"}, "8df1292f-7242-4c70-a166-2efe09ecb2a1": {"doc_hash": "823e7d31252dc4aee1110600196fb819b9666b78bae4aeb9df8c192c0cf70087", "ref_doc_id": "749d7ac379a27450e367352d4b92ded8eed698e1"}, "81c04137-e576-4cee-a9a3-e0f5dd54bad1": {"doc_hash": "36ff5684e83a9dcb0d3e802dec075d87cba771982869ed10021cd65b952ec57f", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "52ba728c-5a94-4340-ac94-de1a81f3887f": {"doc_hash": "5031594f37278236aefb575de6dcbaca49b22447841053581eb73f7653da066f", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "807b2e49-9214-4061-8efd-2d6d0924d0ee": {"doc_hash": "e8cd7cee035eb8e58910e72b0a25dfbdb6071a1d9fee3a8adec0b02b1c60d379", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "6f89deb0-55ac-4b5c-933a-289ea5deaf78": {"doc_hash": "693d3a100606a684f0de5c6f9984937c5af20a6e22197b3f01592078003d94b5", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "2899474e-70a5-4d8f-91cb-b5912c682fc4": {"doc_hash": "51ea49fca0d96d391587b69405d7ce56aefced3f479761650286137b9fea2737", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "9c1c5efa-a030-4bc8-bd4e-0f7cd0f7c08c": {"doc_hash": "cf8400c5930b8c7b184cb13cdc9556c15c6ee7202b4bbea2e9a0f65b890430b7", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "e5135386-3caa-4a3f-8dd1-7a7244f28117": {"doc_hash": "fe7ab11baf9068a48d613f4a61f846b8f278c6534874abb622382e87830d5a7a", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "f84c4cea-b5e2-4ae0-b272-27cd5984eebb": {"doc_hash": "77bfba8777719575e1698354b59a9cab5254e534cd68d130823905a155ff68ea", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "3041c0d5-6d1d-4621-ad3f-53102a814f95": {"doc_hash": "349d678deabf690226cf0128bd885dc5eb72265ea4ffb32ff75d5036c0daaaf3", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "66267e7b-95ed-42ee-bd41-512c8edad777": {"doc_hash": "039afcb29aa6c4cec9c7fd777cc2f27e08aeff9a71c370a64d2b889c413bd507", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "b2cf7808-4912-405d-bc30-c573cd4e1f22": {"doc_hash": "1a1398ef78bcf83ac5cdc7b303440787058b871d805b8f94a4e520322fbdc122", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "c16cd77b-fb22-4660-98f0-eaadf2a8f8a9": {"doc_hash": "cec5e3ed4aff41aa22db8fd62ea0f9823109e5a0683f2b6e1dea1ca251759d5d", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "f9d918e4-94be-424b-ba50-e341aea92ecb": {"doc_hash": "14cb9144641fd845030d8a7273d675fe58a6722663f8fb8dcfb91c904fc335f6", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "c4969280-f679-467c-8b40-ab655393e4d5": {"doc_hash": "327c896e934f8e4095a3568fe028d26d0758ea1e06a3b04b1757c2c4860eff38", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "1ce17cd3-6ee4-4c36-a8b3-2c9aa5e603f2": {"doc_hash": "741e1c5f68233bab4a028aa718e0f0700a3a26bad57426cfa72884347e7192d6", "ref_doc_id": "95d36b23e4dbc89c2029ab325ee782b717a15197"}, "cf84ba4f-f7af-48cf-9bfb-66df4287b04e": {"doc_hash": "37944500047642fcc8b1b7ad7ad1c8a7f552f93a818bcab1343e4ac0db91e7ee", "ref_doc_id": "c0e4570df74c2800c6d0175958794aaab6005e8a"}, "c7c6980f-9c0a-408d-8410-eaad9d40c04e": {"doc_hash": "fedf94331aa325d067c6e83b40b61a149cfb7c5b426229502e69536bd6ce6b3c", "ref_doc_id": "96ff14aee8a5065612d649e60db2ed9f190ae2a6"}, "f344de3d-aea4-432e-999a-39f8c30e3f2b": {"doc_hash": "bbbc4bdbc179af5cc176919e0212be7503cb743ee25b194d710d8d2748bd0802", "ref_doc_id": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1"}, "385b9c18-ab8f-48c0-a795-b237e2adbb79": {"doc_hash": "a272fad183804d5f4161bcb767490692e064c9029701a0d165e80e24a7cb3e88", "ref_doc_id": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1"}, "040046f7-a507-4793-acf8-96ff143a40f4": {"doc_hash": "5a6d1043528d757344ceef50e132d45073033fd35bc8b897b01fec69e7d0d1a1", "ref_doc_id": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1"}, "5c853bfe-675f-487f-86cc-e3bb8bad68e7": {"doc_hash": "af7d542a412d00307c5764a8008bea18cd9e5e96091ff0588f31e9dfa97321fd", "ref_doc_id": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1"}, "dbcef1c3-fb8b-41d6-afd8-476227742d84": {"doc_hash": "03bc46db33d09afd30da4a0238eb5708a04ce2de3ce493a3a705ff56d2aae8ab", "ref_doc_id": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1"}, "1a5ec9ec-fc58-46a0-8997-54483e531171": {"doc_hash": "529ee7cf6cb0592e265bfe422d5a19414b2b2fb91db54014d990638e8b6f22bb", "ref_doc_id": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1"}, "b5bd0a6c-2ab4-4a52-ba6a-94e59ba84b98": {"doc_hash": "71e413d28f43f39c67b4289632afcc388d28721ed5009f8d986274a828e54fbd", "ref_doc_id": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1"}, "6c643b48-4521-47a0-b585-efca4c172b03": {"doc_hash": "de1205f17b87e422e60f613428768baf0656dce69be65fd7887dd8e75186b61d", "ref_doc_id": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1"}, "b551807a-eeb7-4640-a6d7-600dba4154eb": {"doc_hash": "ee2a4b47628d196df6d031ac8c257baf9d41ed1d6420f0e84362c2717ca59cea", "ref_doc_id": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1"}, "4627ce52-5e65-4ace-8978-ec38cf99a421": {"doc_hash": "343034a2fefec2ba3eafac5bef05f879385d7d8d983b07530e48ed25a38a0a6b", "ref_doc_id": "04d6e2e1e0c3fc9f807882e34c50e0f86946aec8"}, "bb4e5517-6ad8-44b9-8279-60751190722c": {"doc_hash": "2c3efe8f11c6f122d8655ef60dccc3b832f99d06625175c406f2c646ff6ee9e1", "ref_doc_id": "04d6e2e1e0c3fc9f807882e34c50e0f86946aec8"}, "190b7750-8e49-4601-952b-a55a4c1ab492": {"doc_hash": "59f9da6bbae89f46d17061218ca5a8600fc33584c9457c6c2524c9a817d2397e", "ref_doc_id": "6993eebd2537d70993e0c65b5b0846eb4623564b"}, "9b6edfbe-edba-4d54-b6f5-163e3337a45f": {"doc_hash": "1f2da82b8161acc3c7220dab2dd1b2b195fa56d65e773c5f001c1f19177f3f36", "ref_doc_id": "6993eebd2537d70993e0c65b5b0846eb4623564b"}, "82c85b93-3e95-49f5-8250-0e6b541343cd": {"doc_hash": "6695986847f8ffc87b627d9eb7c830024fc295e47580a734b5dfa003e6882670", "ref_doc_id": "6993eebd2537d70993e0c65b5b0846eb4623564b"}, "0f3770c9-28d1-48de-9ec4-43fcbae071e6": {"doc_hash": "07c42940b3d5a6f55b5615b51f922ea312a083939e159c357381408028322ec9", "ref_doc_id": "6993eebd2537d70993e0c65b5b0846eb4623564b"}, "6999b07a-a95c-40bf-85fd-7feb395c939c": {"doc_hash": "f122f3ecc3628c681ecf826c67c223b3318a22f91b46af0d0ec605f4608d9da7", "ref_doc_id": "549295068b5590e149f4567700f54dc3e37e7dc2"}, "0faf15cd-5b8e-4dfc-beb2-bdc1e42f598d": {"doc_hash": "d67887d343cbb86912820177b365fd4354f11c603803ca52b41ad3a3213a9e8f", "ref_doc_id": "b0cd1db956ebfe5c1cd8be18bd57dfe901bbee01"}, "03541a3b-1099-423c-b573-d2ffe824ecb3": {"doc_hash": "d0fed6accb08fd728bf8836b17ee05409ada49f6b71807e749f6fabe465a34e2", "ref_doc_id": "abbef2a85ac74b6b4d06a927e94b5ceea0ae00ef"}, "f997fd22-eb0f-48a1-9be4-3be3a5ce880a": {"doc_hash": "ff9db9ff92020ecb428d15e8bd600e55582fcd3bd9d21f30fcfd63af7c3e433f", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "51d7ec80-d8b2-47f6-a5f6-febff2788e49": {"doc_hash": "8e42428248d55522d3be9bda0548953241601d59f167006041a4b9ab3291018b", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "005fa866-df7d-41f3-a7f3-53c40e586e18": {"doc_hash": "23cb7c4c7c79490a06f705bd917b4f232cb8c77ab06d9698565afbe8e263fd94", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "aa93ca9a-7809-45cf-b36b-02ef893c06bb": {"doc_hash": "fc95fc56d101b01fcf2b60e5495eddecbbddde493dd15999678fe217db8011a0", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "afd4eadd-04ba-4d97-92ee-5438461e7c04": {"doc_hash": "949b011b82c922c08ecef4105b3b26e1ba0011065775aa51066cd522c15cf84c", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "9bff07a0-2971-4253-bd25-6344bb9de53d": {"doc_hash": "2eaae2f6ff8db116f35d48514d0f7721d0ebc3a9fb3e4dd15e22b58143745ad8", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "05205551-e89b-42b3-b428-70c806071d01": {"doc_hash": "78bb01095b0f954c51930d2efef4888f0f7fa1eae6cb5c5d2081712235f1d62b", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "4904b7c6-a6b6-4412-a7cc-0998aabcbce5": {"doc_hash": "164d96225913e477a8778df817f7e73ac820be18c92249ba81e90f588e58b83f", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "58ca41ae-0eeb-43e5-af1a-428f8f77367d": {"doc_hash": "f3c01257593150ca6864a779d078d14d236405b15112df3fcce40605247a2dd9", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "fdd64274-085a-473f-9581-29668a3365a3": {"doc_hash": "8799c47d999438f587a827d84369c63e960d0637c58be6838abf27e04d9cbef3", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "13beae33-5993-4ad5-b38b-1f38405dfa47": {"doc_hash": "d7338d4a35ffdab3776ee274d73f368aa802cd0ca1395ba65354662dbbed0471", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "33a40ddb-0a7e-4a06-b617-084a29e40815": {"doc_hash": "957deae27e28b77cc1977661371ccc4ede84a1c88351692a744ebc962bab9dd3", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "6f50a509-cf53-46ac-9233-917a0f68ff1c": {"doc_hash": "13a4c5d0e2089b8145a616a11a0eeee023536a72e2901b3ae5dfc1b2ae75654a", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "6c175b95-8b08-42cb-8a4c-d26359be0d7a": {"doc_hash": "0545dfc0a177430c33c10dc97632284320b59a4cc4c5626377d5d87aad7dc59c", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "9021442b-6c62-4412-bfba-f5e3381d0bfd": {"doc_hash": "51306be527c22bbc96289dc121eada57e44060df0cec3bfae610038f3b7bf292", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "5801ddc5-ab39-480e-9650-814d4d2c89ba": {"doc_hash": "d0f7cfba77c46480fa7572936d66e70a99e0d22bd21ab41819e80e5796e61c38", "ref_doc_id": "f68dac6bdd5ca8d920200669a808ce2f38342e60"}, "fa1f91df-6225-4383-9b65-37c3b4127ea2": {"doc_hash": "baa286177214045164e1602b45aa4087edbddaba706cb335e0f8c17ee7257014", "ref_doc_id": "16ca6f86583488a6d995bf6b9ebc65c54927017e"}, "96c4e3b1-cc77-4839-a5c4-00fdd95f940b": {"doc_hash": "c41efeb587b45092702f45f2768e6559e2b35e844e894c14e4b9ad0130ee44ef", "ref_doc_id": "cf8d1ce1afc681f25b26aa6d4465f545543454b2"}, "52932894-feb3-48d3-b03f-a06ef50604d3": {"doc_hash": "279d7c7e568b0f3ecc5d586efc6a5e3c9f5759b915971e9441c51935bbe9fec3", "ref_doc_id": "b2846ac788b66d5edb228c099391b2677705c859"}, "5b4c9bb9-5cea-4352-9ce6-ec4c2a343e73": {"doc_hash": "aef93ce1cb2dbeae17be317cdb75b802532fc12a902caf9acc2c8605ed447d8e", "ref_doc_id": "8d53adfef0c6cf93e1ff25759d5514747b3ab794"}, "babc3d13-5673-461c-b3ec-2711cb46902c": {"doc_hash": "950e948c87b55e73d0818d9db0772e6dc0acac1b6ee184084dff8f036406e274", "ref_doc_id": "9d076c2fdc9d99eb241f667da6671ada777b3b6e"}, "f1ba7a0e-9bc2-4989-9927-51b14e0f6343": {"doc_hash": "ebeaa40fc500ce8898e26e403e015a6d80f7bbb919e0b39fef1a536d1227e1e1", "ref_doc_id": "e55bf918e7d312377ca19e115df19f7bf18033da"}, "2c8fb682-6e00-4d10-a313-12d57b114d9d": {"doc_hash": "43b23ff81f75e3085c7bceb1f3c06ff888eedebca83f6ec1aa911f581866fc0a", "ref_doc_id": "2d488b6677a66d4503b9f49ba6878fb344f61f90"}, "bbe73472-de83-4c36-881b-74024c76352e": {"doc_hash": "9154d4011e543bc3fbc7469e8caf92188760e2567b3a4db8d171dc463ac5b1bb", "ref_doc_id": "8a3f654706292a82d0fe36909ba8407a9ee6f166"}, "57343cdb-88f3-4eb9-b389-a10d589328de": {"doc_hash": "56edf1a006027025c61bb965d3206caf811c23f8339d14a21477f83969be3de0", "ref_doc_id": "ce365e6c157eb365fde71d972ee493f1660789fc"}, "488858f6-cd0d-43a2-9fed-59327c3bf46e": {"doc_hash": "bddcaf769e623cf42cbe6f366a5b8a037877309fdcf7a87fa55fc5ff37243098", "ref_doc_id": "097b18888685db3b4562b73d73275d5346264fa5"}, "7409b460-f6b9-42a7-bc30-ebfc80dc088d": {"doc_hash": "b7f8b93f6698e026cd25cccc1c0323299853a4d9cf123b81a6c35c40a00f48bb", "ref_doc_id": "6368f797c590508363076d28a49b64d5eb433091"}, "ffceaa65-f346-476e-a27b-c7b8eac146a3": {"doc_hash": "c7efa497d7ae42860913c26f2b6fc25b1e244649c5975e242d1f611328b8c562", "ref_doc_id": "7afa618ea49b3ff559ca5ccfa3514e799fbd7fc4"}, "016647e5-1dc2-4afd-99d0-e745b235a1cb": {"doc_hash": "c9a63b92faa67b3fd8fc7f8aa24e93349d1d54e197a49550ebba42c0c3c239d6", "ref_doc_id": "74fa64853c91471be07cbd3bd65bea9bb9dff866"}, "008073fa-830b-46e7-bb1d-18d275925ba4": {"doc_hash": "892f18cf033458e322382a2b4fb84724274a816bb487bb7d2479739496dce7e8", "ref_doc_id": "9a8056fb6210281fa3ccc658a5a7899d0d2973e7"}, "8367c16b-b179-4b55-bff0-54ef356f0908": {"doc_hash": "9f701b1e18d461273ff7373c6ad6adbd8566bcf6c5d03c21e7da99e83811f7f3", "ref_doc_id": "9a8056fb6210281fa3ccc658a5a7899d0d2973e7"}, "c051edd3-9f84-44e5-9ceb-351062c7f0f5": {"doc_hash": "748477cca52ce991353daed02f7749611878c3e741f31f835561bd1331b19659", "ref_doc_id": "9a8056fb6210281fa3ccc658a5a7899d0d2973e7"}, "e8e90b63-1811-400f-9446-1ffe3aa554d5": {"doc_hash": "288950d1f7754f23cecf49ba449c2e3f0257e3db0b3614cba845a7be143b78e8", "ref_doc_id": "9a8056fb6210281fa3ccc658a5a7899d0d2973e7"}, "ec907295-3f60-490f-bb72-afd907111571": {"doc_hash": "71855566c0994755fbaba8b73c9a3f4d15f8d41d93ee3de0207287dafe84f2ea", "ref_doc_id": "9a8056fb6210281fa3ccc658a5a7899d0d2973e7"}, "979d2728-fb1e-4741-8eae-4bb17fd22aa3": {"doc_hash": "cca27238189a5a0b07e529d09d1e23f7211423a8fb2134a668c8af27844c4444", "ref_doc_id": "773276682d7d34e3c64b738e27fb2877edd71df7"}, "9455f95b-9925-44ef-a016-acf1d825a598": {"doc_hash": "f2f43e2b7aa5a90d73d7df393e08901f21e546ee3a16e6a89fd5bce3dd767402", "ref_doc_id": "a8cbb69a63ddd8d563d3c5ba325d3da01e26a906"}, "ea73ad8b-612a-4cf5-8264-e8a66aa90545": {"doc_hash": "1fe926a61cd940659004eaa13ec4de6d4b35c79500c3397974fd1ddaf4d925cd", "ref_doc_id": "a8cbb69a63ddd8d563d3c5ba325d3da01e26a906"}, "58b280b5-1856-43ee-ab38-d4aadfc3eca3": {"doc_hash": "50ad0012d330012744179c5e4ca77954212d1ac9e35795d4d8b6baa9a3f1f9fc", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "90612da4-2571-4908-b270-54ca9eeeb078": {"doc_hash": "71ac69ac0c016b4aa49f48f95da46886e6cdc86d6e918a27c639f4fb3b95d9c1", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "4d15162c-7f3c-479d-9ba9-bae5f5b62251": {"doc_hash": "85a8d93362669749b896008e36e262894a89a6af1a50373e1379d22fac2ea99c", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "8bb3cc4d-d0a6-429a-a91f-79c504107831": {"doc_hash": "37a1e822b02b996ce37ba1d42c1bb0707fe4dd2bd6cc13894022e466ca11a602", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "053dbaea-71f6-4756-b7c1-de736a5b1eb6": {"doc_hash": "bc69fac02950d8abcf0569d274cdc0c8b1f9af34a7dc2b638e91d10aef28f295", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "a488ce4f-ff80-43a7-ac05-579cfc86232d": {"doc_hash": "314fb7bee78aef22bcc9eaca1d0426c6a7d22b2181fa18e95c3a10095f6a69c9", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "4b20769e-929c-4ebc-8c35-66b017022e94": {"doc_hash": "f9f2fd7b5156f8e3863f7f591b84aefe48a95be7b0e220c7e8b5101e64861d68", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "22d842d4-920b-468b-af0e-fe9192305a01": {"doc_hash": "97d405e5c4481e89c5b038a12fec227647d255abbde384a3a88f168ab210fe54", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "04f89cb8-5a4c-4142-bcbf-017ce28aaa26": {"doc_hash": "e69ae4716f0d07fc3c3ba1c28e108153059848b86556f8c65b3240044400ceee", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "ba6105d3-0e3b-4a3d-bd57-58406b2bd4cc": {"doc_hash": "f5c08dc89240f38f94bb50f39af6ab8d7fb52435b32a6752a7effcd5d0880df7", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "a031b799-fc06-4f77-b7c1-2d4e80c44de8": {"doc_hash": "722ebd88ee4a440e98b2fb2547a5d9bf6c393e522d7c9240bab2029ec4c6b422", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "f27b4114-9cce-4bd2-8c10-894dde93b2d7": {"doc_hash": "f7b74c6eeb2bea8ffd0b72af62464969b89bd4b314d4d3533274fec2674e0ab4", "ref_doc_id": "ee3d8f95624e46759068e987fde30203bcfd1802"}, "159ed8b6-7c68-434b-8849-97e6f859a59d": {"doc_hash": "fb6284b9999f9b17f795833edfc395164fe66abf0b86c4cd5912d0470906ba01", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "18b1776e-3547-46a3-b00a-590ceed5981e": {"doc_hash": "6e3c407f15b78172fd6f1c7399bd938b9203b12cd4c9a02681d0b4678b1a0c61", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "476c7178-5d7e-4f18-bcf6-f04cc6fbe218": {"doc_hash": "dfe3504023b25dbabea214e6bb02abc52f2d4f50cff9107b465b9b985a3beae3", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "c8508c12-7bc8-4e13-b688-bb068e58f950": {"doc_hash": "ecc105f844e30efb5aa86fed350e7fbc057a86f28c3b04f60ae83c2ae5c5f886", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "bfc01fdc-b24d-42a4-9744-96ea79c1e030": {"doc_hash": "4f270ffdb14234a6b93727c49dba64fe0bc66eb1ef4d5fa29fb369c29df259ef", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "057ea006-052c-43c7-b559-3da5071c11f2": {"doc_hash": "3d0c85afc920dadb5c8b11c27aa85571d4d65aa4e2a3ab17bab8f5458153c284", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "c8f8bc7d-eaa0-4e47-9e05-7b3fc986563b": {"doc_hash": "e85cb0c56df4454af7f7a4164aaf7ec802bab9b1d31dde93471cbd96eba70ec3", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "881da39c-bb87-43fc-b28c-a113775284bf": {"doc_hash": "8bbcd8302dc2865c7722eaf64a3669047c5b2618eecd7b075f4cd59b27858f19", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "72824150-4557-47be-bf7c-d6079f5e716f": {"doc_hash": "1676e5eca61006f5e8d51e27fc483543a0dc452450e150d34ef2865a545c14b0", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "acc865b8-cb8f-40f4-bf25-b1f90a58c9f1": {"doc_hash": "ec35e3ee5c06e7d289705a614770f119549b392df46d0cf037897e1534a5e8c4", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "e75a0a1f-c403-481e-9109-689fa794b93c": {"doc_hash": "a5a15e9ac5dc352cbaf3202b1665339f3e37496150fd513a62bdd01819d911c5", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "55f24f37-e59b-40c1-a5f9-d461deb0b0c5": {"doc_hash": "78bd92e05593a2d1b1647f603709739dc18da2affc4fcea5b680654f1f9f78bf", "ref_doc_id": "04168beb41d762f692d99c7628c8e7f66188d41c"}, "2160814b-742e-455e-bab7-fd0b057c2ad7": {"doc_hash": "7a19030698b0e7146735e152417a853cf72975076d42292fabaa189cfb629c9c", "ref_doc_id": "e9b826d0877608e104fd6ca7c1177f78c2651ccd"}, "7012149e-cc50-4656-875f-64908ec4b6df": {"doc_hash": "df1ab8f844b8f9878b9b1de7f1c2f00465846587ffdc40f23a9659cfa179743f", "ref_doc_id": "e9b826d0877608e104fd6ca7c1177f78c2651ccd"}, "a19b8444-4406-4246-a90e-cc941b3b16c8": {"doc_hash": "d1c0f03517e64d520de439d8b13dd0e483e4a6457ffa6e3d5502d9327937368f", "ref_doc_id": "8c9031686dfe23473f2d31c75d2b325a3fc9a9dd"}, "1ad451cb-c5c2-4b4a-a16e-5b1b0e6a3747": {"doc_hash": "5953a623e2aabfe063d9db07c90464fb8f2d73b5f088b293628248291d1a149e", "ref_doc_id": "b746db3c8f1522c6026ac33c398ab33f79471031"}, "714e2964-44a6-40b5-9b72-42c2956c848b": {"doc_hash": "fc526bf8c2341f1a13bd974ee3147e2110e38e0d6d714c1915869d378b8040c7", "ref_doc_id": "b746db3c8f1522c6026ac33c398ab33f79471031"}, "65f891c2-38db-41c2-adf7-4e9419e28994": {"doc_hash": "6b1c9bfea897e6547274166d5adca75abfb7e999c2daae48dc68b14f2c92d455", "ref_doc_id": "b746db3c8f1522c6026ac33c398ab33f79471031"}, "321b9cb7-45b5-4ec0-a7bd-b4e80638e846": {"doc_hash": "314f0b1f0f83482c55dd1dc0873bf0b68d08d7c6aa017098bd8a05d7320b0bf5", "ref_doc_id": "2d828ecde9b0b3efe4bfac0a52eeb11a75d45169"}, "8301d2c4-ae88-45ae-80ac-a01872901a9d": {"doc_hash": "719e39050fada0c6f9ec1b7f0cdc859620075c53cd99845d40901648c3bdf9d9", "ref_doc_id": "2d828ecde9b0b3efe4bfac0a52eeb11a75d45169"}, "2f9bb95a-f856-4fd5-9528-ee4e33c3b664": {"doc_hash": "d8ceb4c82fbe62b83b81a5b97c4f828a3c6446df95110c5b3958f7b861268db6", "ref_doc_id": "370acb5cf3546337e11094d1cf3ab0fe82e3f9f5"}, "15d841cf-8400-4e86-bb7a-ae08cc454849": {"doc_hash": "8989437674f2cf45e3300528825b119268fe68b00a5e1ed78bb7383fc00632a1", "ref_doc_id": "09278556c8740eaac8985264d09e4f8b5429e714"}, "b6772a80-ab2d-470f-a963-0c757238fa15": {"doc_hash": "9206ede800c63b28c8c30621e0e7c27ee68fa3dbcfb90cfbed00448bfafba74d", "ref_doc_id": "09278556c8740eaac8985264d09e4f8b5429e714"}, "41862796-570a-47db-937b-c9c26b4865ce": {"doc_hash": "9056c8a7e49703887e8911344f261999c01364cc0aa870badbcca234738ffb83", "ref_doc_id": "09278556c8740eaac8985264d09e4f8b5429e714"}, "a6e93cd6-10b7-4daf-a196-5b5c2c706362": {"doc_hash": "809853455ada57a101a226a7f68f4f160f29d113acc1ffee71a81d0982e4e4ed", "ref_doc_id": "09278556c8740eaac8985264d09e4f8b5429e714"}, "dec85e87-a690-4e04-948f-eea61422cdbc": {"doc_hash": "ca7af56067c08eaf426c00516ebd679295cf073805b72feb15befe19ff9eb4bb", "ref_doc_id": "f98eee6afad0958bd913b26f2c39da3fe7663e33"}, "8228e574-a7b8-4f7e-b4fd-476071f35ab5": {"doc_hash": "7e62dec728fbaf1a48ce45eaaa3724ea3ce9e2067b750b4e360c90a34f665489", "ref_doc_id": "f98eee6afad0958bd913b26f2c39da3fe7663e33"}, "8463d18c-eaab-4228-9aa1-007a34b8d84b": {"doc_hash": "0a39d4c5f2f268e34ea78271cc54f2e78952499904b38cbe8d82119e7c5fa8d0", "ref_doc_id": "f98eee6afad0958bd913b26f2c39da3fe7663e33"}, "5c3988e1-c86c-439b-8410-da4b4649e412": {"doc_hash": "2797d24bf710137459fd95fd1a84cf0be41b840a6f7f18078bc1eb08476e9c08", "ref_doc_id": "b76f2e2ce98ded7830f3c0abda7404f624838fc7"}, "518e1fff-47b9-4fd7-b5ad-101bd0e7c6a9": {"doc_hash": "ba8ca30b1e924bc331ddc01bfa6e602cf2ddca222837f20f09778cf0531119e8", "ref_doc_id": "b76f2e2ce98ded7830f3c0abda7404f624838fc7"}, "f239beac-6aeb-4487-95be-3e785fe81fc2": {"doc_hash": "7ab65a7c058bd87607c4ac47a2d9110ea4b0da021525af6d7fa9c3de061e975a", "ref_doc_id": "fa30bc56f2755065c0ff02de0019982df9854e56"}, "3e92e13a-d602-4266-ab2a-73c20414e517": {"doc_hash": "1f2615250e236f47a9bd0b93689e093529445c22a812278b5e8c686fcbce7e8e", "ref_doc_id": "fa30bc56f2755065c0ff02de0019982df9854e56"}, "42b98d55-b4a7-42a4-a633-c416a3248775": {"doc_hash": "869b14b73ea0836f8edf774860361f8364fc629a4a78a8700208948a468ce02c", "ref_doc_id": "44ab32cf40b2001706c247122acb08c8c33340b3"}, "fc91a4ae-2d20-4918-8218-fa856f7db604": {"doc_hash": "78753da7082ed8523ca51922b7132053efd19781504914e57b2d4a1dae6147ce", "ref_doc_id": "2d2de793bd7a82c664d96928dec3587425dd4522"}, "49258516-ddfb-4482-91e1-053bd7774eea": {"doc_hash": "05b7e2ac997ded9666cb924a9519950cdf141e297d6ac29c22ce60b3245777c8", "ref_doc_id": "2d2de793bd7a82c664d96928dec3587425dd4522"}, "8d277df4-9aba-4b40-b2f6-1b89cb459b2c": {"doc_hash": "1bc577696d195dd3b2bff2dcb0e358c3edc43edd34ce69a2abde6613f2088b58", "ref_doc_id": "2d2de793bd7a82c664d96928dec3587425dd4522"}, "46f1e19d-72c1-4951-9047-9e103db524ec": {"doc_hash": "c7af069b862a2a4566ba897273ed1cf46468a5031b5c13435698f3a1223c004c", "ref_doc_id": "2d2de793bd7a82c664d96928dec3587425dd4522"}, "d9715b24-c189-48e2-8032-b7f0bffcc5d9": {"doc_hash": "cfdd456c1ce7e5da8dd14fc770ad1700f7a13f0cdafb0ca22f63c2c27cdf69f9", "ref_doc_id": "a6fbf783f9cb3b304136a43e5f783991de2efd39"}, "113cae10-7e20-45cf-bea4-c5317d21c168": {"doc_hash": "4d195deced991d8cbe21b9732779daebffc56bf48c8b5101e2c0c1ef503e49a6", "ref_doc_id": "510f55d8602316b1644265e636c6f243122bfc91"}, "febba113-1e89-4071-ab9d-2d863a169583": {"doc_hash": "24fb112a03ee8bbaadcb31bc60abccccc90e6d8c94e28da3a5de65212a2206c2", "ref_doc_id": "7315845a94cddef314e2b305c18b02404f6746f3"}}, "docstore/data": {"05cf5184-7ed8-4a70-85ca-7796343a9b01": {"__data__": {"text": "---\ntitle: Learning Resources\ndescription: End to End tutorials on how to analyze specific protocols\n---\n\nAfter you've gone through the [quickstart guide](quickstart.md), you'll be ready to really start learning how to navigate the Web3 data analytics space.\n\nAnalyzing protocols in web3 is both really easy and really hard. It's really easy because everything is transparent and standardized - a deployed contract has a set of functions and events that are pretty much immutable. However, it's an ever expanding data arena as new protocols, tokens, and wallets join the fray. \n\nTo build your reputation as an expert wizard, you must stay centered on what you want to analyze and what metrics you want to present.\n\n*The following sections contain links to community contributed guides and dashboards.* \n### Finding What To Analyze\n\nOnce you've learned [basic SQL and blockchain concepts](https://web3datadegens.substack.com/p/a-basic-wizard-guide-to-dune-sql), you're ready to start doing your own end-to-end analysis. It's easy to get lost in an ever-expanding web of tables and analysis - so here are some top tips on scoping your work. \n\nWhen looking into a protocol, you'll need to understand the contract architecture and context. That starts with functions, events, and wallets overviews. There is a [quickstart dashboard](https://dune.com/duniversity/contract-quickstart) built just for this, you can see a walkthrough analyzing Opensea [here](https://web3datadegens.substack.com/p/how-to-start-analyzing-any-web3-protocol). \n\nRemember that no protocol lives in isolation - there is always some mix of onchain events happening. That could be some new airdrop, a new upstream/downstream protocol integration, large whales making moves, governance changes in protocol parameters, and more. Once you have a solid understanding of protocol history in usage, user, and integration trends, you're ready to start building some metrics.\n\n### Metrics Driven Analysis\n\nThere are two great end-to-end video series guides for metrics analysis we've created:\n\n- [Uniswap in 12 Days](https://www.youtube.com/watch?v=FtnGiI9MGgA&list=PLK3b5d4iK10cIrN8c_au9RrC0_eBCOyR2&index=1&t=149s) (includes metrics like price impact, TVL, MEV volume, liquidity stability)\n\n- [Gnosis Safe Point-in-Time](https://www.youtube.com/watch?v=8atzYkpez5I) (includes metrics like signers, diversification, valuations)\n\nProtocol metrics are usually dependent on different token and wallet segments. For example, Uniswap allows you to create pairs of two tokens at a time to add liquidity and swap through. However, the USDC-WETH pair will have a very different behaviors from SHIB-WETH. \n\nTo understand token trends and contexts, check out this [ERC20 dashboard](https://dune.com/ilemi/Token-Overview-Metrics) and this [NFT dashboard](https://dune.com/rantum/NFT-Collection-Dashboard). \n\nTo understand wallet/user segments, you'll need to leverage [labels](data-tables/spellbook/top-tables/labels.md) to enhance your analysis.\n\nOnce you have metrics and also understand the underlying tokens and users, it will start to become clear what that real narrative is. Try and pull together a few insights, and then create a really compelling dashboard and story around them. Don't try too hard to capture everything at once - it will become overwhelming for both you those you share it with. \n\n### Share your work with the Community\n\nWhen you're done, be sure to share your work [in the Discord](https://discord.com/invite/ErrzwBz)", "doc_id": "05cf5184-7ed8-4a70-85ca-7796343a9b01", "embedding": null, "doc_hash": "6af12931e0a0655aee4417b107d54e9c0d747d3eb51ce2702e4c3049f9dfffc1", "extra_info": {"file_path": "docs/analytics_guidelines.md", "file_name": "analytics_guidelines.md"}, "node_info": {"start": 0, "end": 3495, "_node_type": "1"}, "relationships": {"1": "1ec67adafad93061c867a7daf5ef065d61813b7c", "3": "d6eff9df-5d7a-4796-bc26-b5ee81f78a68"}}, "__type__": "1"}, "d6eff9df-5d7a-4796-bc26-b5ee81f78a68": {"__data__": {"text": "Discord](https://discord.com/invite/ErrzwBz) `#\ud83d\udcfa\ufe31show-your-work` channel and on Twitter tagging [@duneanalytics](https://twitter.com/DuneAnalytics). We'll be sure to give great analysts a boost! Web3 is all about connecting with communities - your queries and dashboards will do nothing if you don't share it around.\n\n## OurNetwork Course\n\n!!! note\n    This course is based on Dune's V1 engine. The domain logic still applies, but the SQL syntax has now switched from [postgreSQL to Dune SQL](query/syntax-differences.md).\n\nIn collaboration with the Dune Team and Community, our friends at OurNetwork created a course with an ambitious goal: teach 30 people web3 data analytics in 30 days.\n\nHosted by some of our community's top Wizards, you can now access the presentations for free! More details and all of the course materials can be found here:\n\n<div class=\"cards grid\" markdown>\n- [OurNetwork Course](https://ournetwork.mirror.xyz/gP16wLY-9BA1E_ZuOSv1EUAgYGfK9mELNza8cfgMWPQ)\n</div>\n\nVideos are also available on YouTube:\n\n![type:video](https://www.youtube.com/embed/yDSmTUrpdoQ)\n", "doc_id": "d6eff9df-5d7a-4796-bc26-b5ee81f78a68", "embedding": null, "doc_hash": "b4d3c57b071336d544310b6bba863458ba6ea86c291b9ef946bbb3dcc6ed2ba3", "extra_info": {"file_path": "docs/analytics_guidelines.md", "file_name": "analytics_guidelines.md"}, "node_info": {"start": 3451, "end": 4536, "_node_type": "1"}, "relationships": {"1": "1ec67adafad93061c867a7daf5ef065d61813b7c", "2": "05cf5184-7ed8-4a70-85ca-7796343a9b01"}}, "__type__": "1"}, "a7fd5883-860d-4b47-b7a6-38a1cbfcd413": {"__data__": {"text": "---\ntitle: Dune API Functionality\ndescription: Answers to questions about how the Dune API works.\n---\n# FAQ: Functionality\n\n## General\n\n### How many Requests Per Minute can I make?\n\nThe API is currently set to a rate limit of 60 requests per minute. This will soon be set to match the rate limiits specified in the varying API plan tiers. \n\n### Are there specified SLAs?\n\nSLAs will be available in the future on Enterprise pricing plans.\n\n## Executing Queries\n\n### How do I find a query id?\n\nWhen navigating to a query, it\u2019s the first number after \u201c/queries/\u201d in the URL.\n\n![query-id-example](../images/query-id-example.jpg)\n\n### Does the API support Query Parameters?\n\nThe API does support Query Parameters!\n\nFor Dune Queries that include Parameters, you can pass parameter data as part of the [Execute Query ID endpoint](../../api/api-reference/execute-query-id.md)!\n\nLearn more about [building Dune Queries with Parameters here](../../app/query-editor/query-window.md#parameters).\n\nAnd learn how to pass parameter data using [cURL here](../../api/api-reference/execute-query-id.md#curl-with-parameters) and with [Python here](../../api/quick-start/api-py.md#parameterized-queries).\n\n### What are the performance and overall differences between the Dune API and the Dune web app? What are the differences in what I can query?\n\nThere are no major performance differences or differences in what can be accessed between the two if both are using the same app plan tier.\n\nThe Dune API gives you programmatic access to the capabilities and data sets that can already be accessed from the Dune web app.\n\n### What is the execution timeout limit and can I request a longer limit?\n\nThe query execution timeout limit matches the Dune web app - 30 minutes.\n\n### Which query engine should I use with the API?\n\nWe recommend using the API with v2 Dune SQL as we\u2019re slowly deprecating usage and support of the old v1 engine and v2 Spark SQL.\n\n\n## Check Execution Status\n\n### What is the difference between the states \u201cExecuting\u201d and \u201cPending\u201d?\n\nPending means, the execution is waiting for an available execution connection slot.\n\nExecuting means the query is currently executing against the database.\n\n## Reading Results Data\n\n### Can I ingest data by getting a direct connection to the database instead?\n    \nNot currently. In the interim we recommend periodically fetching from \u201cmax(latestBlockNumber) - 2\u201d to \u201clastFetchedBlockNumber\u201d in regular intervals. Fetching from 2 behind the latest block number ensures you receive full sets of data from each new request.\n\n### Are query results data saved for faster retrieval?\n    \nYes!\n\n### How long are the results data from an execution stored for?\n    \nCurrently set to 2 years but we may reduce this to something closer to 90 days in the future. This is visible on the API response on the \u201cexpires_at\u201d field in the execution status and results body.\n\n### How much data can I retrieve in a single API result call?\n    \nThere is currently a 250MB limit, but there is a chance we increase this for certain paid plans. The API does not currently return an explicit error upon hitting this limit but will instead fail (timeout) when attempting to retrieve the results.\n", "doc_id": "a7fd5883-860d-4b47-b7a6-38a1cbfcd413", "embedding": null, "doc_hash": "59f839d53f139cf698287d2536a2b63d13803177e907445e1f0ee221ad34a0fb", "extra_info": {"file_path": "docs/api/FAQ/functionality.md", "file_name": "functionality.md"}, "node_info": {"start": 0, "end": 3202, "_node_type": "1"}, "relationships": {"1": "ed7858fd27a03a1c2fb01c5578b8d90c812970fe"}}, "__type__": "1"}, "05e700b9-ff3a-46e0-b856-9221c2c01aa3": {"__data__": {"text": "---\ntitle: Authentication\ndescription: Here's how to authenticate your API requests.\n---\n\nThe Dune API uses API keys to authenticate requests. Your API key is used to determine the permissions of private queries you may call, as well as which account to bill for the requests, so be sure to keep them secure! \n\n**Do not share your secret API keys in publicly accessible areas such as GitHub, client-side code, and so forth.**\n\nAuthentication with the API is performed by adding an \u201cx-dune-api-key\u201d property to the request header. This is needed on all request types!\n\nHere's one example of doing this with an Execute POST API request:\n\n```\ncurl -X POST -H x-dune-api-key:{{api_key}} \"https://api.dune.com/api/v1/query/{{query_id}}/execute\"\n```", "doc_id": "05e700b9-ff3a-46e0-b856-9221c2c01aa3", "embedding": null, "doc_hash": "4793bdf4386f43754f652f3a63cde079558219f1e146302ded3682802beeda52", "extra_info": {"file_path": "docs/api/api-reference/authentication.md", "file_name": "authentication.md"}, "node_info": {"start": 0, "end": 743, "_node_type": "1"}, "relationships": {"1": "6a1f69ff7b6a45db2de4b23dada647440c48b859"}}, "__type__": "1"}, "2d5f888a-209e-412f-b0e9-30359a548e82": {"__data__": {"text": "---\ntitle: Cancel Execution\ndescription: Here's how to cancel your Dune API execution requests.\n---\n\n# [POST] Cancel Execution\n\nHere's how to cancel your Dune API execution requests.\n\n## Example Request\n\nYou need to pass the `execution_id` you obtained from making a [Execute Query ID POST](execute-query-id.md) request to the complete a Cancel Execution API request.\n\n```\nPOST v1/execution/{{execution_id}}/cancel\n\nhttps://api.dune.com/api/v1/execution/{{execution_id}}/cancel\n```\n## Returns\n\nReturns a boolean for whether the execution is successfully canceled.\n\n## Query Parameters\n\nYou can't use query parameters here.\n\n### cURL\n\n```\ncurl -X POST -H x-dune-api-key:{{api_key}} \"https://api.dune.com/api/v1/execution/{{execution_id}}/cancel\"\n```\n\n## Example Response\n\n!!! info \"Dune API responses are delivered in JSON format.\"\n\n```json\n{\n    \"success\": true\n}\n```\n\n - *success* : A boolean, indicating whether the request to cancel the query execution was made successfully.", "doc_id": "2d5f888a-209e-412f-b0e9-30359a548e82", "embedding": null, "doc_hash": "e5e13859fb886b0d0ab8339f7c9a33eb4631d69ea942a65485ee53b0d88f4835", "extra_info": {"file_path": "docs/api/api-reference/cancel-execution.md", "file_name": "cancel-execution.md"}, "node_info": {"start": 0, "end": 978, "_node_type": "1"}, "relationships": {"1": "e163cfecc89b678ef8edaf2b20c177cc64780689"}}, "__type__": "1"}, "7375fe59-7889-4ba3-811f-ece549008c8c": {"__data__": {"text": "---\ntitle: Errors Codes\ndescription: Here's how to handle errors that may come up when working with the Dune API.\n---\n\nIn cases when things do not work as expected, feel free to reach out to us on the [#dune-api Discord channel](https://discord.com/channels/757637422384283659/1019910980634939433) and we'll help out when you're stuck!\n\nHere are a few common error scenarios:\n\n## Invalid API Key\n\n### Response Object\n\n```\n {'error': 'invalid API Key'}\n```\n\n#### Checks\n \n  -  Make sure that you are passing your API key to our endpoint *in a header*. See the section on [Authentication](../api-reference/authentication.md) for how to do that, and our [quick start guides](../quick-start/api-py.md) for specific language examples.\n  - If you are already passing the API key in an header, make sure that it is correctly entered.\n\n\n## An Internal Error Occurred\n\n### Response Object\n\n```\n {'error': 'An internal error occurred'}\n```\n#### Checks\n\n  - If you are using one of our GET endpoints, ensure that the `query_id` you have entered is correct.\n  - If you are using one of our POST endpoints, ensure that the `execution_id` you obtained from your GET endpoint has been correctly passed on to your POST endpoint.\n\n\nThe documentation here isn't exhaustive!\n\nWhile we are working on making it better, again, the best place to get any support is our [#dune-api Discord channel](https://discord.com/channels/757637422384283659/1019910980634939433).\n", "doc_id": "7375fe59-7889-4ba3-811f-ece549008c8c", "embedding": null, "doc_hash": "4d3841a26a7ae9f4765e18cb607cdd4497ab7227f3663e55af9c27b57f535eba", "extra_info": {"file_path": "docs/api/api-reference/errors.md", "file_name": "errors.md"}, "node_info": {"start": 0, "end": 1445, "_node_type": "1"}, "relationships": {"1": "8f45a4884bae7d5dbf5d348d00b346174b97b489"}}, "__type__": "1"}, "7e84a302-a2c6-4b59-bfb3-283219831e53": {"__data__": {"text": "---\ntitle: Execute Query ID\ndescription: Here's how to execute (run) a Query with or without parameters to retrieve data.\n---\n# [POST] Execute Query ID\n\nHere's how to execute (run) a query for a specific query id. You can choose to include a `performance` parameter, by default it will use the \"medium\" performance tier which consumes 10 credits. \"large\" will use 20 credits. You cannot run API executions on the free tier.\n\n!!!info \"Careful of Credit Limits\"\n  Make sure you check the query in the app interface to see how many rows and columns of data are being returned, so that you don't spend all of your credits in one query read. The free tier gets 2.5k credits, which at 1000 datapoints a credit allows you to return 2.5 million rows and 1 column (or 1.25m rows and 2 columns, 250k rows and 10 columns, etc.). There won't be overage charges (unless you've changed this setting), but still be sure to double check.\n\n## Example Request\n\n```\nPOST v1/query/{{query_id}}/execute\n\nhttps://api.dune.com/api/v1/query/{{query_id}}/execute\n```\n## Returns\n\nReturns an `execution_id` for the specified request.\n## Query Parameters\n\nIf the query has parameters and you don't add them in your API call, it will just run the default params. You may add query parameters as part of the POST params data: ([see this example](#curl-with-parameters)).\n## Python\n```\nimport dotenv\nimport os\nimport json\nimport requests\nimport pandas as pd\nimport time\n\n# load .env file\ndotenv.load_dotenv('/Users/zokum/Documents/Workspace/misc/.env')\n# get API key\napi_key = os.environ[\"DUNE_API_KEY\"]\n# authentiction with api key\nheaders = {\"X-Dune-API-Key\": api_key}\n\nquery_id = 1252207\nbase_url = f\"https://api.dune.com/api/v1/query/{query_id}/execute\"\nparams = {\n    \"performance\": \"large\",\n}\nresult_response = requests.request(\"POST\", base_url, headers=headers, params=params)\n```\n\nThis will give the response\n\n```\n{'execution_id': '01GXXWZSXR85GYT6K5EBRSYZ7C', 'state': 'QUERY_STATE_PENDING'}\n```\n\n\n### cURL\n\n```\ncurl -X POST \"https://api.dune.com/api/v1/query/{{query_id}}/execute\"   \\\n  -H X-Dune-API-key: {{api_key}}\n```\n\n### cURL with Parameters\n\n```\ncurl -X POST \"https://api.dune.com/api/v1/query/{{query_id}}/execute\"   \\\n  -H \"X-Dune-API-Key: {{api_key}}                                       \\\n  -H \"Content-Type: application/json\"                                   \\\n  -d '{\"query_parameters\": {\"param1\":24}, \"performance\": \"large\"}'\n```\n\n## Example Response\n\n!!! info \"Dune API responses are delivered in JSON format.\"\n\n```json\n{\n    \"execution_id\": \"01GB1Y2MRA4C9PNQ0EQYVT4K6R\",\n    \"state\": \"QUERY_STATE_PENDING\"\n}\n```\n\n - *execution_id* : A unique ID that is generated every time this API is called. You might want to save it to later pass on to other API endpoints.\n -", "doc_id": "7e84a302-a2c6-4b59-bfb3-283219831e53", "embedding": null, "doc_hash": "ec5ed4fa22d9893a1165bef8c4c496c67c21c07d06ab9337a85d99f41f367b4a", "extra_info": {"file_path": "docs/api/api-reference/execute-query-id.md", "file_name": "execute-query-id.md"}, "node_info": {"start": 0, "end": 2760, "_node_type": "1"}, "relationships": {"1": "688974d536678972e8fb78b96fb8be87efb7924a", "3": "8c43348c-be78-4117-aa38-9710127375d9"}}, "__type__": "1"}, "8c43348c-be78-4117-aa38-9710127375d9": {"__data__": {"text": "called. You might want to save it to later pass on to other API endpoints.\n - *state* : The current state of the query's execution. Check our `FAQ` section to see what different status codes mean.\n", "doc_id": "8c43348c-be78-4117-aa38-9710127375d9", "embedding": null, "doc_hash": "43426e093acef129a38a296237150facc43e5158f67ebead4e697e66cc4eeec6", "extra_info": {"file_path": "docs/api/api-reference/execute-query-id.md", "file_name": "execute-query-id.md"}, "node_info": {"start": 2683, "end": 2880, "_node_type": "1"}, "relationships": {"1": "688974d536678972e8fb78b96fb8be87efb7924a", "2": "7e84a302-a2c6-4b59-bfb3-283219831e53"}}, "__type__": "1"}, "4ad40ed5-411d-42a1-8795-25f6bdb5f933": {"__data__": {"text": "---\ntitle: Execution Results\ndescription: Here's how to get the results data of an execution request.\n---\n\n# [GET] Execution Results\n\nHere's how to get the results data of an execution request.\n\n## Example Request\n\nYou need to pass the `execution_id` you obtained from making a [Execute Query ID POST](execute-query-id.md) request to the complete an Execution Results API request.\n\n```\nGET v1/execution/{{execution_id}}/results\n\nhttps://api.dune.com/api/v1/execution/{{execution_id}}/results\n```\n## Returns\n\nReturns back the status, metadata, and query results from a query execution.\n## Query Parameters\n\nYou can't use query parameters here.\n### cURL\n\n```\ncurl -X GET \"https://api.dune.com/api/v1/execution/{{execution_id}}/results\" -H x-dune-api-key:{{api_key}}\n```\n\nThere is a default 250,000 datapoints limit to make sure you don't accidently spend all your credits in one call. You can see it with the API param below:\n\n```\ncurl -X GET \"https://api.dune.com/api/v1/execution/{{execution_id}}/results/?ignore_max_datapoints_per_request=true\" -H x-dune-api-key:{{api_key}}\n```\n\n## Example Response\n### JSON Format\n\n```json\n{\n    \"execution_id\": \"01GBM4W2N0NMCGPZYW8AYK4YF1\",\n    \"query_id\": 980708,\n    \"state\": \"QUERY_STATE_COMPLETED\",\n    \"submitted_at\": \"2022-08-29T06:33:24.913138Z\",\n    \"expires_at\": \"2024-08-28T06:36:41.58847Z\",\n    \"execution_started_at\": \"2022-08-29T06:33:24.916543Z\",\n    \"execution_ended_at\": \"2022-08-29T06:36:41.588467Z\",\n    \"result\": {\n        \"rows\": [\n            {\n                \"TableName\": \"eth_blocks\",\n                \"ct\": 6296\n            },\n            {\n                \"TableName\": \"eth_traces\",\n                \"ct\": 4474223\n            },\n            {\n                \"TableName\": \"eth_creation_traces\",\n                \"ct\": 10155\n            },\n            {\n                \"TableName\": \"eth_logs\",\n                \"ct\": 2137508\n            },\n            {\n                \"TableName\": \"eth_transactions\",\n                \"ct\": 1039890\n            },\n            {\n                \"TableName\": \"sol_transactions\",\n         ", "doc_id": "4ad40ed5-411d-42a1-8795-25f6bdb5f933", "embedding": null, "doc_hash": "1ece6dfd42dd7c7dfaff9ac39ea275f421cc268148d7166702d97cd6d09f4d69", "extra_info": {"file_path": "docs/api/api-reference/execution-results.md", "file_name": "execution-results.md"}, "node_info": {"start": 0, "end": 2079, "_node_type": "1"}, "relationships": {"1": "e881b5fd2dba254153fa35adb717e87b5836c7d2", "3": "72a14ea9-fcd3-4077-8efc-dcd55f764aa8"}}, "__type__": "1"}, "72a14ea9-fcd3-4077-8efc-dcd55f764aa8": {"__data__": {"text": "\"TableName\": \"sol_transactions\",\n                \"ct\": 37185158\n            },\n            {\n                \"TableName\": \"bnb_transactions\",\n                \"ct\": 2942005\n            },\n            {\n                \"TableName\": \"optimism_transactions\",\n                \"ct\": 120973\n            }\n        ],\n        \"metadata\": {\n            \"column_names\": [\n                \"ct\",\n                \"TableName\"\n            ],\n            \"result_set_bytes\": 194,\n            \"total_row_count\": 8,\n            \"datapoint_count\": 16,\n            \"pending_time_millis\": 8,\n            \"execution_time_millis\": 24\n        }\n    }\n}\n```\n\n - *execution_id* : The execution ID for which this API was called.\n - *query_id* : The ID of the Dune Query executed with this request.\n - *state* : The current state of the query's execution. Check our `FAQ` section to see what different status codes for `state` mean.\n - *submitted_at* : The timestamp at which the API for executing this query was called.\n - *expires_at* : The time upto which results from this query's execution shall be stored in our Database.\n - *execution_started_at* : The time at which query execution started for this request in our servers.\n - *execution_ended_at* : The time at which the query execution for this request got completed in our servers.\n - *result* :\n    - *rows* : The actual rows of data being returned for this request.\n    - *metadata* : Some properties of the queried data being returned.\n        - *column_names* : Names of the columns in the data returned.\n        - *result_set_bytes* : The size of the returned data.\n        - *total_row_count* : The number of rows in the data.\n        - *datapoint_count* : Total number of datapoints returned with this request, should equal to (`total_row_count` x number of columns).\n        - *pending_time_millis* : The time (in milliseconds) it took to assign a slot in our server for this request.\n        - *execution_time_millis* : The time (in milliseconds) it took for the actual execution of the query with this request.\n\n### CSV Format\n\n```\nct,TableName\n6296,eth_blocks\n4.474223e+06,eth_traces\n10155,eth_creation_traces\n2.137508e+06,eth_logs\n1.03989e+06,eth_transactions\n3.7185158e+07,sol_transactions\n2.942005e+06,bnb_transactions\n120973,optimism_transactions\n```\nIn order to get the results in CSV format, use the same URL pattern with \"/csv\" appended. The results will be returned", "doc_id": "72a14ea9-fcd3-4077-8efc-dcd55f764aa8", "embedding": null, "doc_hash": "4f94c162b2c063a6a15695d98ec436468bcc5dcf65ba59de3c0d166b60e1eea0", "extra_info": {"file_path": "docs/api/api-reference/execution-results.md", "file_name": "execution-results.md"}, "node_info": {"start": 2048, "end": 4463, "_node_type": "1"}, "relationships": {"1": "e881b5fd2dba254153fa35adb717e87b5836c7d2", "2": "4ad40ed5-411d-42a1-8795-25f6bdb5f933", "3": "1f6eea81-afeb-40d3-aca3-fbe397732ec8"}}, "__type__": "1"}, "1f6eea81-afeb-40d3-aca3-fbe397732ec8": {"__data__": {"text": "use the same URL pattern with \"/csv\" appended. The results will be returned in CSV format without additional metadata details like the JSON response.\n\n```\nGET v1/execution/{{execution_id}}/results/csv\n\nhttps://api.dune.com/api/v1/execution/{{execution_id}}/results/csv\n```\nAdditionally you can use \"api_key\" as a param to enable use cases such as importing results into a google sheet. (We advise against doing this any public document where your API key can be viewed and compromised.)\n\n![image (7)](https://user-images.githubusercontent.com/105652677/220012986-aaf6f372-8f4c-4e30-8da3-25e87a5271ab.png)\n\n\n## Reading Results Data FAQ\n\n### Can I ingest data by getting a direct connection to the database instead?\n\nNot currently. In the interim we recommend periodically fetching from \u201cmax(latestBlockNumber) - 2\u201d to \u201clastFetchedBlockNumber\u201d in regular intervals. Fetching from 2 behind the latest block number ensures you receive full sets of data from each new request.\n\n### Are query results data saved for faster retrieval?\n\nYes\n\n### How long are the results data from an execution stored for?\n\nCurrently set to 2 years but we may reduce this to something closer to 90 days in the future. This is visible on the API response on the \u201cexpires_at\u201d field in the execution status and results body.\n\n### How much data can I retrieve in a single API result call?\n\nThere is currently a 1GB limit, but there is a chance we reduce this overall or based on varying paid plan types.\n", "doc_id": "1f6eea81-afeb-40d3-aca3-fbe397732ec8", "embedding": null, "doc_hash": "df9e956b1c9348376ff020fb39531ea63f32a45af960f32a106ca521972abfae", "extra_info": {"file_path": "docs/api/api-reference/execution-results.md", "file_name": "execution-results.md"}, "node_info": {"start": 4420, "end": 5895, "_node_type": "1"}, "relationships": {"1": "e881b5fd2dba254153fa35adb717e87b5836c7d2", "2": "72a14ea9-fcd3-4077-8efc-dcd55f764aa8"}}, "__type__": "1"}, "819de6ee-508e-424c-bee2-cb5a43e44a48": {"__data__": {"text": "---\ntitle: Execution Status\ndescription: Here's how to check the status of an execution request.\n---\n\n# [GET] Execution Status\n\nHere's how to check the status of an execution request.\n\n## Example Request\n\nYou need to pass the `execution_id` you obtained from making a [Execute Query ID POST](execute-query-id.md) request to the complete an Execution Status API request.\n\n```\nGET v1/execution/{{execution_id}}/status\n\nhttps://api.dune.com/api/v1/execution/{{execution_id}}/status\n```\n## Returns\n\nReturns the status of a query execution along with relevant metadata of the results if the execution is completed.\n## Query Parameters\n\nYou can't use query parameters here.\n### cURL\n\n```\ncurl -X GET \"https://api.dune.com/api/v1/execution/{{execution_id}}/status\" -H x-dune-api-key:{{api_key}}\n```\n\n## Example Response\n\n!!! info \"Dune API responses are delivered in JSON format.\"\n\n### Query Executing\n\n```json\n{\n    \"execution_id\": \"01GBM4W2N0NMCGPZYW8AYK4YF1\",\n    \"query_id\": 980708,\n    \"state\": \"QUERY_STATE_EXECUTING\",\n    \"submitted_at\": \"2022-08-29T06:33:24.913138Z\",\n    \"expires_at\": \"1970-01-01T00:00:00Z\",\n    \"execution_started_at\": \"2022-08-29T06:33:24.916543331Z\"\n}\n```\n\n### Execution Complete\n\n```json\n{\n    \"execution_id\": \"01GBM4W2N0NMCGPZYW8AYK4YF1\",\n    \"query_id\": 980708,\n    \"state\": \"QUERY_STATE_COMPLETED\",\n    \"submitted_at\": \"2022-08-29T06:33:24.913138Z\",\n    \"expires_at\": \"2024-08-28T06:36:41.58847Z\",\n    \"execution_started_at\": \"2022-08-29T06:33:24.916543Z\",\n    \"execution_ended_at\": \"2022-08-29T06:36:41.588467Z\",\n    \"result_metadata\": {\n        \"column_names\": [\n            \"ct\",\n            \"TableName\"\n        ],\n        \"result_set_bytes\": 194,\n        \"total_row_count\": 8,\n        \"datapoint_count\": 16,\n        \"pending_time_millis\": 8,\n        \"execution_time_millis\": 24\n    }\n}\n```\n\n - *execution_id* : The execution ID with which this API was called.\n - *query_id* : The ID of the Dune Query being executed with this request.\n - *state* : The current state of the query's execution. Check our `FAQ` section to see what different status codes for `state` mean.\n - *submitted_at* : The timestamp at which the API for executing this query was called.\n - *expires_at* : The time upto which results from this query's execution shall be stored in our Database.\n - *execution_started_at* : The time at which execution started for this request in our servers.\n - *execution_ended_at* : The time at which the execution for this request got completed in our servers.\n - *result_metadata* : Some properties of the response data generated", "doc_id": "819de6ee-508e-424c-bee2-cb5a43e44a48", "embedding": null, "doc_hash": "8593969e614aa71810c8052eac64f28a46661b76258147808f7b1ab34bb6ba37", "extra_info": {"file_path": "docs/api/api-reference/execution-status.md", "file_name": "execution-status.md"}, "node_info": {"start": 0, "end": 2565, "_node_type": "1"}, "relationships": {"1": "ff6356498de3c813a24924cdbf9114f8ece22faa", "3": "2edf009c-9de9-4f36-a121-92db089881ab"}}, "__type__": "1"}, "2edf009c-9de9-4f36-a121-92db089881ab": {"__data__": {"text": "in our servers.\n - *result_metadata* : Some properties of the response data generated with this request.\n    - *column_names* : Names of the columns in the response data that is generated for this request.\n    - *result_set_bytes* : The size of the response data in bytes\n    - *total_row_count* : The number of rows in response data\n    - *datapoint_count* : Total number of datapoints returned with this request, should equal to (`total_row_count` x number of columns).\n    - *pending_time_millis* : The time (in milliseconds) it took to assign a slot in our server for this request.\n    - *execution_time_millis* : The time (in milliseconds) it took for the actual execution of the query with this request.\n\n## Check Execution Status FAQ\n\n### What is the difference between the states \u201cExecuting\u201d and \u201cPending\u201d?\n\nPending means, the execution is waiting for an available execution connection slot.\nExecuting means the query is currently executing against the database.\n\nHere is a list of all Status Codes for reference.\n\n   - QUERY_STATE_PENDING  - query execution is waiting for execution slot\n   - QUERY_STATE_EXECUTING - query is executing\n   - QUERY_STATE_FAILED - execution failed\n   - QUERY_STATE_COMPLETED - execution completed successfully\n   - QUERY_STATE_CANCELLED - execution cancelled by user\n   - QUERY_STATE_EXPIRED - query execution expired, result no longer available", "doc_id": "2edf009c-9de9-4f36-a121-92db089881ab", "embedding": null, "doc_hash": "912db7035c3ff037b2f7d5b9981b2199caa1923158073a6632ae61b3353e1457", "extra_info": {"file_path": "docs/api/api-reference/execution-status.md", "file_name": "execution-status.md"}, "node_info": {"start": 2480, "end": 3865, "_node_type": "1"}, "relationships": {"1": "ff6356498de3c813a24924cdbf9114f8ece22faa", "2": "819de6ee-508e-424c-bee2-cb5a43e44a48"}}, "__type__": "1"}, "dda94b1a-37b4-412c-8bd1-92955465b22c": {"__data__": {"text": "---\ntitle: API Endpoint Reference\ndescription: Learn about our API endpoints and common errors here.\n---\n### Execution and Results Flow\n\nGoing through these endpoints will teach you how to run an execution and grab it's results. You can specify the `performance` level of executions (see example in [execute query id](../api-reference/execute-query-id.md)).\n\n<div class=\"cards grid\" markdown>\n- [Authentication](../api-reference/authentication.md)\n- [Execute Query ID](../api-reference/execute-query-id.md)\n- [Execution Status](../api-reference/execution-status.md)\n- [Execution Results](../api-reference/execution-results.md)\n- [Latest Query Results](../api-reference/latest_results.md)\n- [Cancel Execution](../api-reference/cancel-execution.md)\n</div>\n\nYou will likely need to reference the common [error codes](../api-reference/errors.md) too.\n\n### Latest Results Endpoint\n\nIf you don't need the most up to date data and just want to query for most recently refreshed results of a query, check out the [get latest results](../api-reference/latest_results.md) endpoint.\n", "doc_id": "dda94b1a-37b4-412c-8bd1-92955465b22c", "embedding": null, "doc_hash": "45da4019d8cef9355281cb499141308a3b8edaa14d0a1cf94de1780772e73b4a", "extra_info": {"file_path": "docs/api/api-reference/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 1072, "_node_type": "1"}, "relationships": {"1": "2e80efa87b8cb5f49f56c4de80054b778742df38"}}, "__type__": "1"}, "b89ced50-f684-4511-a841-c2c7a8853e15": {"__data__": {"text": "---\ntitle: Latest Query Results\ndescription: Here\"s how to get the latest results of a query run\n---\n\n# [GET] Latest Query Results\n\nHere's how to get the latest results of a query, regardless of the job id/run or if it is run in the app or the api.\n\n## Example Request\n\n`query_id` is the id of the query you are trying to pull results from. It must either be public or a query you have ownership of. \n\n```\nGET v1/query/{{query_id}}/results\n\nhttps://api.dune.com/api/v1/query/{{query_id}}/results\n```\n## Returns\n\nReturns the latest execution id and results of the run. \n\n!!!note \"Keep in mind\"\n    - this endpoint does NOT trigger execution but does consume credits through datapoints\n\n## Query Parameters\n\nFor query params, we recommend you to not have spaces for a parameter, use underscore instead like `https://api.dune.com/api/v1/query/2340912/results?params.LooksRare%20Wash%20Trading%20Filter=ON`. If no query params are provided, the request will fetch the latest results regardless of parameter (not just default!)\n### cURL\n\n```\ncurl -X GET \"https://api.dune.com/api/v1/query/{{query_id}}/results\" -H x-dune-api-key:{{api_key}}\n```\n\nThere is a default 250,000 datapoints limit to make sure you don't accidently spend all your credits in one call. You can see it with the API param below:\n\n```\ncurl -X GET \"https://api.dune.com/api/v1/query/{{query_id}}/results\\?ignore_max_datapoints_per_request=true\" -H x-dune-api-key:{{api_key}}\n```\n\n### Python\n\n```\nimport dotenv\nimport os\nimport json\nimport requests\nimport pandas as pd\nimport time\n\napi_key = os.environ[\"DUNE_API_KEY\"]\n\n# authentiction with api key\nheaders = {\"x-dune-api-key\": api_key}\n\nquery_id = 1252207\nbase_url = f\"https://api.dune.com/api/v1/query/{query_id}/results\"\nparams = {\n    \"params.LooksRare Wash Trading Filter\": \"ON\", # one and only param for this query\n}\nresult_response = requests.request(\"GET\", base_url, headers=headers, params=params)\n```\n\nYou can partially fill parameters as well, say there are three parameters - if you only pass in two then the other one will use the default parameters:\n\n```\n# case 4: partial match of the existing params that were executed will work aka 200\nquery_id = 1064888\nbase_url = f\"https://api.dune.com/api/v1/query/{query_id}/results\"\nparams = {\n    \"params.Show Today\": \"No\",\n    \"params.Time Period\": \"day\" \n    # there is one more param for this query \"Trailing Num Periods\" which we are not passing\n}\nresult_response = requests.request(\"GET\", base_url, headers=headers, params=params)\n```\n\n!!! warning \"Parameter 404 Behaviors\"\n    If a certain parameter has never been run before, i.e. putting in \"OFF\" above when only \"ON\" has been executed in app, then you will get a 404. Same thing if you try and use a parameter that doesn't exist on the query.\n\n\n## Example Response\n\n!!! info \"Dune API responses are delivered in JSON format.\"\n\n```json\n{\"execution_id\": \"01GXDTYMM2CKFRBEW44X5S0WZE\",\n \"query_id\": 1252207,\n \"state\": \"QUERY_STATE_COMPLETED\",\n \"submitted_at\":", "doc_id": "b89ced50-f684-4511-a841-c2c7a8853e15", "embedding": null, "doc_hash": "2543786a0bc573ceb03a634ade947d10b8334731192942d5749f8fe6e061c3b2", "extra_info": {"file_path": "docs/api/api-reference/latest_results.md", "file_name": "latest_results.md"}, "node_info": {"start": 0, "end": 2985, "_node_type": "1"}, "relationships": {"1": "a9712c14dfb54f2187c0a0f38786cb41561f67df", "3": "5b8663f5-e876-4e0c-b936-e7f901a94ec7"}}, "__type__": "1"}, "5b8663f5-e876-4e0c-b936-e7f901a94ec7": {"__data__": {"text": "\"state\": \"QUERY_STATE_COMPLETED\",\n \"submitted_at\": \"2023-04-07T12:27:09.314513Z\",\n \"expires_at\": \"2025-04-06T12:27:15.749155Z\",\n \"execution_started_at\": \"2023-04-07T12:27:09.387366Z\",\n \"execution_ended_at\": \"2023-04-07T12:27:15.749154Z\",\n \"result\": {\"rows\": [\n    {\"24 Hours Volume\": 10501366.303435229,\n    \"7 Days Volume\": 83500570.47565666,\n    \"Rank\": 1,\n    \"Total Volume\": 35184444503.17035,\n    \"project\": \"opensea\"},\n   {\"24 Hours Volume\": 2905815.0342120747,\n    \"7 Days Volume\": 34792342.84606525,\n    \"Rank\": 2,\n    \"Total Volume\": 4897580325.593282,\n    \"project\": \"x2y2\"},\n   {\"24 Hours Volume\": 21859216.193396263,\n    \"7 Days Volume\": 256722523.89635494,\n    \"Rank\": 3,\n    \"Total Volume\": 4037590713.6422567,\n    \"project\": \"blur\"}\n    ],\n   \"result_set_bytes\": 1524,\n   \"total_row_count\": 26,\n   \"datapoint_count\": 135,\n   \"pending_time_millis\": 72,\n   \"execution_time_millis\": 6361}\n}\n```\n", "doc_id": "5b8663f5-e876-4e0c-b936-e7f901a94ec7", "embedding": null, "doc_hash": "732d8475638e073a7bb38203dee34c37bbc29f7820a5f5fc491d3c827d5d9db4", "extra_info": {"file_path": "docs/api/api-reference/latest_results.md", "file_name": "latest_results.md"}, "node_info": {"start": 2935, "end": 3842, "_node_type": "1"}, "relationships": {"1": "a9712c14dfb54f2187c0a0f38786cb41561f67df", "2": "b89ced50-f684-4511-a841-c2c7a8853e15"}}, "__type__": "1"}, "c3d93dce-932c-42c6-8ed5-6908cb9c10dd": {"__data__": {"text": "---\ntitle: Dune API FAQ\ndescription: Dune API FAQ\n---\n\n# Dune API FAQ\n\n## FAQ: Functionality\n\n#### How many Requests Per Minute can I make?\n\nThe API rate limit currently varies by [subscription plan](https://dune.com/pricing). This is an overall rate limit for any type of API call made. \n\n#### Are there specified SLAs?\n\nSLAs will be available in the future on Enterprise pricing plans.\n\n#### How do I find a query id?\n\nWhen navigating to a query, it\u2019s the first number after \u201c/queries/\u201d in the URL. For example in `https://dune.com/queries/241/388`, \"241\" is the query id.\n\n#### Does the API support Query Parameters?\n\nThe API does support Query Parameters!\n\nFor Dune Queries that include Parameters, you can pass parameter data as part of the [Execute Query ID endpoint](api-reference/execute-query-id.md)!\n\nLearn more about [building Dune Queries with Parameters here](../app/query-editor/query-window.md#parameters).\n\nAnd learn how to pass parameter data using [cURL here](api-reference/execute-query-id.md#curl-with-parameters) and with [Python here](quick-start/api-py.md#parameterized-queries).\n\n#### What are the performance and overall differences between the Dune API and the Dune web app? What are the differences in what I can query?\n\nThere are no major performance differences within a specific performance tier when used through the Dune API or Dune web app.\n\nThe Dune API gives you programmatic access to the capabilities and data sets that can already be accessed from the Dune web app.\n\n#### What is the execution timeout limit and can I request a longer limit?\n\nThe query execution timeout limit matches the Dune web app - 30 minutes.\n\n#### Which query engine should I use with the API?\n\nWe recommend using the API with v2 Dune SQL as we\u2019re slowly deprecating usage and support of the old v1 engine and v2 Spark SQL.\n\n#### What is the difference between the states \u201cExecuting\u201d and \u201cPending\u201d?\n\nPending means, the execution is waiting for an available execution connection slot.\n\nExecuting means the query is currently executing against the database.\n\n#### Can I ingest data by getting a direct connection to the database instead?\n    \nNot currently. In the interim we recommend periodically fetching from \u201cmax(latestBlockNumber) - 2\u201d to \u201clastFetchedBlockNumber\u201d in regular intervals. Fetching from 2 behind the latest block number ensures you receive full sets of data from each new request.\n\n#### Are query results data saved for faster retrieval?\n    \nYes!\n\n#### How long are the results data from an execution stored for?\n    \nThe resutls storage period can be found on the API response on the \u201cexpires_at\u201d field in the execution status and results body.\n\n#### How much data can I retrieve in a single API result call?\n    \nThere is currently a ~1GB limit. The API does not currently return an explicit error upon hitting this limit but will instead fail (timeout) when attempting to retrieve the results.\n\n## FAQ: Billing & Pricing\n    \n#### How will API Billing work with the new Team plans?\nAny API usage billing will be based on what account the API key is associated with. If you use your team api key to call a public query belonging to yourself, the billing will be associated to the team (and vice versa).\n\n#### What\u2019s a datapoint?\n\nA datapoint can in most cases be thought of rows * columns with an additional limit of 100 avg bytes per cell in a set of results. This can be expressed as:\n\nDatapoints = max(rows*columns, ceil(totalbytes/100))\n\n#### Do I get charged datapoints for every result read?\n\nWe charge the data points in the result for the 1st read result of every", "doc_id": "c3d93dce-932c-42c6-8ed5-6908cb9c10dd", "embedding": null, "doc_hash": "cd15e24cb693d33e85c61301a0a0c04c007d71d78f87024431e6416e2de315ac", "extra_info": {"file_path": "docs/api/faq.md", "file_name": "faq.md"}, "node_info": {"start": 0, "end": 3603, "_node_type": "1"}, "relationships": {"1": "5e341cb077901a100270cb1d379e5df790964168", "3": "935a5bf8-686f-4acd-a70e-216403e75ff5"}}, "__type__": "1"}, "935a5bf8-686f-4acd-a70e-216403e75ff5": {"__data__": {"text": "read?\n\nWe charge the data points in the result for the 1st read result of every distinct query execution and every subsequent 100th read per billing cycle.\n\n#### Any other questions?\n\nPlease reach out to [api-feedback@dune.com](mailto:api-feedback@dune.com) or our #[dune-api](https://discord.com/channels/757637422384283659/1019910980634939433) Discord channel for the fastest path towards getting additional questions answered!\n\n[Find our API Terms of Service Here](https://dune.com/api-terms)\n", "doc_id": "935a5bf8-686f-4acd-a70e-216403e75ff5", "embedding": null, "doc_hash": "b344b41af681c70b5aaa9397320e802c39b7392cc11590ecf83bdb5b5e56ffb5", "extra_info": {"file_path": "docs/api/faq.md", "file_name": "faq.md"}, "node_info": {"start": 3524, "end": 4020, "_node_type": "1"}, "relationships": {"1": "5e341cb077901a100270cb1d379e5df790964168", "2": "c3d93dce-932c-42c6-8ed5-6908cb9c10dd"}}, "__type__": "1"}, "763d2b2e-c051-46b4-8568-de07572e0151": {"__data__": {"text": "---\ntitle: API\ndescription: Welcome to the Dune API\n---\n\n# Welcome to the Dune API\n\n![dune API Cover](images/dune-api-banner.png)\n\nThe Dune API gives you full access to the queries and data you can see on the Dune website. This means you can execute and read results from any public query, as well as any personal private queries your Dune account has access to.\n\nThis documentation describes all of the available API calls and properties of the returned objects. If you have any questions or feedback, please reach out to [api-feedback@dune.com](mailto:api-feedback@dune.com) or our #[dune-api](https://discord.com/channels/757637422384283659/1019910980634939433) Discord channel!\n\n### Obtaining an API Key\nAll plans on our new [credit-based pricing system](https://dune.com/pricing) come bundled with API access.\nYou'll have seperate API keys for your [individual accounts](https://dune.com/settings/api) and [team accounts](https://dune.com/settings/teams).\n\n### API Quickstart Guides\n\nGet started with our API in a few lines of code using these quick start guides:\n\n<div class=\"cards grid\" markdown>\n- [Python](quick-start/api-py.md)\n- [Javascript](quick-start/api-js.md)\n</div>\n\nYou should check out our [community API clients (sdks)](quick-start/community-clients.md) as well.\n\nFor building a simple data ingestion pipeline, see [using Python and Celery](https://adamparrish.xyz/downstream-data-extract-transform-load).\n\nIf you aren't sure what queries to start with, check out the [API-ready query list](quick-start/index.md).\n\n### API Pricing\nPricing for API is charged along two dimensions.\n\n| Dimension | Credits Charged | Relevant API endpoints |\n|---|---|---|\n| Executions | 10 credits per medium query engine executions (Default)<br>20 credits per large query engine executions | Execute Query |\n| Datapoints | 1 credit per 1,000 datapoints | Execution Results<br>Latest Query Results |\n\nA datapoint applies to query results after the query is run, and can in most cases be thought of `rows * columns` with an additional limit of 100 avg bytes per cell in a set of results. This can be expressed as: \n```math\nCredits = Datapoints/1000 = max(rows*columns, ceil(totalbytes/100))\n```\nMore details can be found on our [FAQ page](https://dune.com/docs/api/faq/#faq-billing-pricing).\n\n### All API Endpoints\n\nCheck out full explanations and documentation of endpoints in the [api endpoint reference](api-reference/index.md).\n", "doc_id": "763d2b2e-c051-46b4-8568-de07572e0151", "embedding": null, "doc_hash": "acd798289e9f8cbc285f94604ab3416405d9bd4320d91f7d24f230a272a00623", "extra_info": {"file_path": "docs/api/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 2431, "_node_type": "1"}, "relationships": {"1": "6da9912dfa407c2655de68449c7f8dc8f22e0e2f"}}, "__type__": "1"}, "b3582480-0df3-444a-8ab1-459b424b4a21": {"__data__": {"text": "---\ntitle: API Use Cases\ndescription: Here's ways in which our early adopters are using the API!\n---\n\nWe haven't even launched publicly yet. But even the early adopters from our community have surprised us with the number of ways they have utilized the Dune API.\n\n### Alerts for On Chain Activity, and more!\n\nOne of the most killer use cases of the API is to build an alerting system for on chain activity. Our frens at [Cow Protocol](https://dune.com/cowprotocol) have not only built a tool for this, which they are actively using. They have also open sourced it. You can checkout their code at [this link](https://github.com/cowprotocol/dune-alerts).\n\nIn the light of all the hacks that ensued in the ecosystem over the recent past; these alerting systems can be crucial for the next generation of dapps. Any malicious actiity can be stopped, right in its tracks. And this is just one of the ways alerting systems are useful.\n\nWe have to give a shoutout to our fren [@bh2smith](https://dune.com/bh2smith) from the Cow Protocol, who has been building community goods with the Dune API at a pace faster than we can keep up with. We highly recommend checking out [the talk](https://www.youtube.com/watch?v=_OXTE2lU6MQ) he gave at [DuneCon 2022](https://dunecon.com) on building Backend Data Infrastructure with the Dune API.\n\n### Making the data flow to the last mile\n\nData has never been as open as it is on Blockchains. While Dune directly enables this data to flow through data analysts and engineers. We are being joined by our community to further us in our mission.\n\n#### Moonblock - Web3 brand intelligence\n\nWe will directly quote the words [Moonblock](https://moonblock.io/) uses to describe what they are doing with On Chain Data - \"We enable marketing managers to make faster, smarter decisions by organizing, analyzing and visualizing the world\u2019s Web3 information.\"\n\nUsing the Dune API to make the data flow to non-technical power users and decision makers, not bad, right?\n\n#### Boto - On Chain automation with No Code \n\n[Boto](https://boto.io/) enables you to automate the work you have to manually do to check activites on chain (aka Build bots with No Code).\n\nAgain, using the Dune API to empower a much wider range of users with Open Data.\n\nOur beta users have been so promising that we might in fact launch a special program for Startups to build with the Dune API. Stay tuned on our [socials](https://dune.com/community) for any updates.\n\n### Hackathon Projects\n\nThe Dune API got used by hackers at EthBerlin, EthSF and EthIndia in 2022. We had 63 submissions across these events. If you are a builder or a wizard and want to start tinkering with the API. Checkout some of the work our bounty winners from these hackathons have worked on.\n\n- [Eth Berlin](https://twitter.com/DuneAnalytics/status/1571564677968105472)\n- [Eth India](https://twitter.com/dvdkll/status/1599385593892347905)", "doc_id": "b3582480-0df3-444a-8ab1-459b424b4a21", "embedding": null, "doc_hash": "b98c535af27986d022a94a08ce36c71af0620bc1fb58270d5441b88e75c7a56c", "extra_info": {"file_path": "docs/api/quick-start/.api-use-cases.md", "file_name": ".api-use-cases.md"}, "node_info": {"start": 0, "end": 2902, "_node_type": "1"}, "relationships": {"1": "541485deeceabc7677192a2f588ee381e138c038"}}, "__type__": "1"}, "7f96947e-a62b-40d3-a3d2-0607e6098717": {"__data__": {"text": "---\ntitle: Javascript\ndescription: Here's how to access the Dune API via JavaScript.\n---\n\n!!! Warning\n    This guide is not yet comprehensive. If you have questions, please reach out to our team via the #[dune-api](https://discord.com/channels/757637422384283659/1019910980634939433) channel on Discord.\n\nLet's get started using the Dune API via JavaScript!\n\nWe'll show you one of the several ways the API can be consumed via JavaScript, in this case using the `node-fetch` package. You can also try to use the native fetch funcionality which is available in the newest LTS version of node, node 18. We would be upgrading this guide in the near future to use the same.\n\n!!! example \"Prerequisites\"\n    This Quick Start Guide assumes you have some level of familiarity with Node.js (Node), Node Package Manager (NPM) and Node Version Manager (NVM).\n\nTo start, make sure you're using the current LTS version of Node.js (Node 18) and the latest version of NPM:\n\n## Want to just get it to quickly work?\n\nUse the [cowprotocol Dune client](https://www.npmjs.com/package/@cowprotocol/ts-dune-client) in Typescript to get started:\n\n```\nimport { QueryParameter, DuneClient } from \"@cowprotocol/ts-dune-client\";\nconst { DUNE_API_KEY } = process.env;\n\nconst client = new DuneClient(DUNE_API_KEY ?? \"\");\nconst queryID = 1215383;\nconst parameters = [\n  QueryParameter.text(\"TextField\", \"Plain Text\"),\n  QueryParameter.number(\"NumberField\", 3.1415926535),\n  QueryParameter.date(\"DateField\", \"2022-05-04 00:00:00\"),\n  QueryParameter.enum(\"ListField\", \"Option 1\"),\n];\n\nclient\n  .refresh(queryID, parameters)\n  .then((executionResult) => console.log(executionResult.result?.rows));\n```\n\nOr check out the longer guide to go more low level.\n\n## Getting Set Up\n\n```\nnvm use --lts\nnpm install latest\n```\n\nThen install the node-fetch package:\n\n```\nnpm install node-fetch\n```\n\nNext, create a project directory and initiate an ESMcompatible Node project:\n\n```\nmkdir dune_api_js\ncd dune_api_js\nnpm init esm --yes\n```\n\nThis will initiate a project for you which will include a `package.json` file. Open this file and add the following line to it:\n\n``` json\n\"type\": \"module\"\n```\n\n## Example Dune API Script\n\nFor the example here, we have used a simple example Query that fetches a small set of data, this query has the`query_id`, `1258228`.\n\nReplace `#! YOUR_API_KEY` with your Dune API key in the following code, then add it to the `main.js` file in your project:\n\n``` js\nimport { Headers } from 'node-fetch';\nimport fetch from 'node-fetch';\n\n// Add the API key to an header object\nconst meta = {\n    \"x-dune-api-key\": \"YOUR_API_KEY\"\n};\nconst header = new Headers(meta);\n\n//  Call the Dune API\nconst response = await fetch('https://api.dune.com/api/v1/query/1258228/execute', {\n    method: 'POST',\n    headers: header\n});\nconst body = await response.text();\n\n// Log the returned response\nconsole.log(body);\n\n```\n\n## Example Dune API Script for a Parameterized Query\n\nIf you are working with a parameterized query, use the script in this section instead of the previous one. For the example here, we have used a simple query that takes in a wallet address as a parameter.", "doc_id": "7f96947e-a62b-40d3-a3d2-0607e6098717", "embedding": null, "doc_hash": "59c2b126ed901d6b88bdaa2045c3d4ed57b24d4b14f191eac1243fc1c590bf28", "extra_info": {"file_path": "docs/api/quick-start/api-js.md", "file_name": "api-js.md"}, "node_info": {"start": 0, "end": 3144, "_node_type": "1"}, "relationships": {"1": "42c22f3ee37a352f736947c39d56dc934443a34e", "3": "4179b3f5-8577-4f2a-8397-64fefe61b52c"}}, "__type__": "1"}, "4179b3f5-8577-4f2a-8397-64fefe61b52c": {"__data__": {"text": "here, we have used a simple query that takes in a wallet address as a parameter. This query has the `query_id`, `1258228`. And we pass an example address as a value to the `wallet_address` parameter.\n\nReplace `#! YOUR_API_KEY` with your Dune API key in the following code, then add it to the `main.js` file in your project:\n\n``` js\nimport { Headers } from 'node-fetch';\nimport fetch from 'node-fetch';\n\n// Add the API key to an header object\nconst meta = {\n    \"x-dune-api-key\": \"YOUR_API_KEY\"\n};\nconst header = new Headers(meta);\n\n// Add parameters we would pass to the query\nvar params = { \"query_parameters\" : { \"wallet_address\": \"0xb10f35351ff21bb81dc02d4fd901ac5ae34e8dc4\" }};\nvar body = JSON.stringify(params);\n\n//  Call the Dune API\nconst response = await fetch('https://api.dune.com/api/v1/query/638435/execute', {\n    method: 'POST',\n    headers: header,\n    body: body // This is where we pass the parameters\n});\nconst response_object = await response.text();\n\n// Log the returned response\nconsole.log(response_object);\n\n```\n\n## Running the Script\n\nYou can now run your script from the command line.\n\n```\nnode main.js\n```\nYou should see a response being returned.\n\nYou can also edit the Query URL to fetch data from any other Queries you'd like! \ud83e\ude84\nIf it is a parameterized query, you would need to accordingly update the parameters as well.\n\nPlease note that the code here only calls the API end point that starts the execution of the query. To fetch the data generated from the execution of this query, you would need to call other API endpoints. See the [API Reference](../api-reference/authentication.md) section to learn more about various endpoints the Dune API currently offers.\n\n!!! Link to Code\n    You can also find some code from this tutorial in this [Github Repository](https://github.com/SusmeetJain/dune_api_js).\n", "doc_id": "4179b3f5-8577-4f2a-8397-64fefe61b52c", "embedding": null, "doc_hash": "10d4ec01353b5681ef264446c9152dc0de73344098788bf879d3430a6767a91b", "extra_info": {"file_path": "docs/api/quick-start/api-js.md", "file_name": "api-js.md"}, "node_info": {"start": 3064, "end": 4901, "_node_type": "1"}, "relationships": {"1": "42c22f3ee37a352f736947c39d56dc934443a34e", "2": "7f96947e-a62b-40d3-a3d2-0607e6098717"}}, "__type__": "1"}, "70f5f376-a252-45e4-9ec5-96bdbdb9ab93": {"__data__": {"text": "---\ntitle: Python\ndescription: Here's how to access the Dune API via Python.\n---\n\nLet's get started using the Dune API via Python!\n\nIn this example we'll be using Python3. We recommend using a virtual environment and the `pip` package manager.\n\n!!! example \"Prerequisites\"\n    This Quick Start Guide assumes you have some prior experience using Python, though we aimed to make the code here easy to follow. If you have questions, please reach out to our team via the #[dune-api](https://discord.com/channels/757637422384283659/1019910980634939433) channel on Discord.\n\n## Want to just get it to quickly work? \n\nLeverage the [cowprotocol Dune client](https://github.com/cowprotocol/dune-client) to get started in only a few lines:\n\n```\nimport dotenv\nimport os\nimport pandas as pd\n\nfrom dune_client.types import QueryParameter\nfrom dune_client.client import DuneClient\nfrom dune_client.query import Query\n\nquery = Query(\n    name=\"Sample Query\",\n    query_id=1215383,\n    params=[\n        QueryParameter.text_type(name=\"TextField\", value=\"Word\"),\n        QueryParameter.number_type(name=\"NumberField\", value=3.1415926535),\n        QueryParameter.date_type(name=\"DateField\", value=\"2022-05-04 00:00:00\"),\n        QueryParameter.enum_type(name=\"ListField\", value=\"Option 1\"),\n    ],\n)\nprint(\"Results available at\", query.url())\n\ndotenv.load_dotenv()\ndune = DuneClient(os.environ[\"DUNE_API_KEY\"])\npd = dune.refresh_into_dataframe(query)\n```\n\nIf you want to understand the details, then check out the full walkthrough of endpoints below.\n\n## Getting Set Up\n\nWe'll primarily be working with the `requests` library to access the API, so let's install it:\n\n``` bash\npip install requests\n```\n\nWe'll also use `pandas` to load the data returned from APIs into a neat DataFrame (table), and `jupyter notebooks` to have a nice interactive interface to do all of this.\n\nSo let us install these as well:\n\n``` bash\npip install pandas\npip install jupyter notebook\n```\n\nWe recommend following rest of the Quick Start in a jupyter notebook. You can start the interface with this simple command:\n\n``` bash\njupyter notebook\n```\n\n### Import the necessary libraries\n\n``` py\nfrom requests import get, post\nimport pandas as pd\n```\n\n### API Keys\n\nAny call you make to the Dune API will require you to pass your API key with your call's header:\n\n``` py\nAPI_KEY = \"YOUR_API_KEY\"\nHEADER = {\"x-dune-api-key\" : API_KEY}\n```\n\n### Simplifying URL generation\n\nThough not a necessary step, using this function will make it easier to generate URLs for different API endpoints:\n\n``` py\nBASE_URL = \"https://api.dune.com/api/v1/\"\n\ndef make_api_url(module, action, ID):\n    \"\"\"\n    We shall use this function to generate a URL to call the API.\n    \"\"\"\n    \n\turl = BASE_URL + module + \"/\" + ID + \"/\" + action\n\t\n    return url\n```\n\n## Wrapping API endpoints in functions\n\nThe Dune API currently has four primary end points as documented in the [API Reference](../api-reference/authentication.md) section. We are going to wrap these up in neat functions which will make using the Dune API as easy as a flick of the \ud83e\ude84:\n\n```", "doc_id": "70f5f376-a252-45e4-9ec5-96bdbdb9ab93", "embedding": null, "doc_hash": "d2561dcc28a51af167847c9b2b50284b8b5ea1e591e619e0aeef8f97aac24669", "extra_info": {"file_path": "docs/api/quick-start/api-py.md", "file_name": "api-py.md"}, "node_info": {"start": 0, "end": 3078, "_node_type": "1"}, "relationships": {"1": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389", "3": "db20b10a-2cb4-4c67-a8d2-6aa6c8be0089"}}, "__type__": "1"}, "db20b10a-2cb4-4c67-a8d2-6aa6c8be0089": {"__data__": {"text": "the Dune API as easy as a flick of the \ud83e\ude84:\n\n``` py\ndef execute_query(query_id, engine=\"medium\"):\n    \"\"\"\n    Takes in the query ID and engine size.\n    Specifying the engine size will change how quickly your query runs. \n    The default is \"medium\" which spends 10 credits, while \"large\" spends 20 credits.\n    Calls the API to execute the query.\n    Returns the execution ID of the instance which is executing the query.\n    \"\"\"\n    \n    url = make_api_url(\"query\", \"execute\", query_id)\n    params = {\n        \"performance\": engine,\n    }\n    response = post(url, headers=HEADER, params=params)\n    execution_id = response.json()['execution_id']\n    \n    return execution_id\n\n\ndef get_query_status(execution_id):\n    \"\"\"\n    Takes in an execution ID.\n    Fetches the status of query execution using the API\n    Returns the status response object\n    \"\"\"\n    \n    url = make_api_url(\"execution\", \"status\", execution_id)\n    response = get(url, headers=HEADER)\n    \n    return response\n\n\ndef get_query_results(execution_id):\n    \"\"\"\n    Takes in an execution ID.\n    Fetches the results returned from the query using the API\n    Returns the results response object\n    \"\"\"\n    \n    url = make_api_url(\"execution\", \"results\", execution_id)\n    response = get(url, headers=HEADER)\n    \n    return response\n\n\ndef cancel_query_execution(execution_id):\n    \"\"\"\n    Takes in an execution ID.\n    Cancels the ongoing execution of the query.\n    Returns the response object.\n    \"\"\"\n    \n    url = make_api_url(\"execution\", \"cancel\", execution_id)\n    response = get(url, headers=HEADER)\n    \n    return response\n```\n\n## Using the Dune API\n\n### Execute a Query\n\nTo [Execute a Query](../api-reference/execute-query-id.md), you can pass any `query_id` from Dune that you want to fetch data from, then pass it to the `execute_query` function.\n\n#### Function Call\n\n``` py\nexecution_id = execute_query(\"1258228\",\"large\")\n```\n\n#### Output\n\nThis function returns an `execution_id` which will look something like the sample output shown here:\n\n``` py\n'01GCQKPC4QZ6Q8645C3JC4WBT1'\n```\n\nThis execution ID is the required input for rest of the API functions.\n\n### Get Query Execution Status\n\nTo get the [Query Execution Status](../api-reference/execution-status.md), take the `execution_id` that was returned from the `execute_query` function in the previous section, then pass it to `get_query_status` function as shown here:\n\n#### Function Call\n\n``` py\nresponse = get_query_status(execution_id)\n```\n#### Output\n\nThe `response` object returned by this function will look something like the example shown here:\n\n``` json\n{'execution_id': '01GCQKPC4QZ6Q8645C3JC4WBT1',\n 'query_id': 1258228,\n 'state': 'QUERY_STATE_COMPLETED',\n 'submitted_at': '2022-09-12T01:05:51.781328Z',\n 'expires_at': '2024-09-11T01:05:51.82013Z',\n", "doc_id": "db20b10a-2cb4-4c67-a8d2-6aa6c8be0089", "embedding": null, "doc_hash": "bcf765127e2efe501583c480d4eae4f766e3de95e6129073f41795e53bab9c92", "extra_info": {"file_path": "docs/api/quick-start/api-py.md", "file_name": "api-py.md"}, "node_info": {"start": 3043, "end": 5840, "_node_type": "1"}, "relationships": {"1": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389", "2": "70f5f376-a252-45e4-9ec5-96bdbdb9ab93", "3": "c66e3977-4027-47c2-b496-e191e996c0f1"}}, "__type__": "1"}, "c66e3977-4027-47c2-b496-e191e996c0f1": {"__data__": {"text": "'2024-09-11T01:05:51.82013Z',\n 'execution_started_at': '2022-09-12T01:05:51.806752Z',\n 'execution_ended_at': '2022-09-12T01:05:51.820127Z',\n 'result_metadata': {'column_names': ['block_time',\n   'token_a_symbol',\n   'token_b_symbol',\n   'token_a_amount',\n   'token_b_amount',\n   'project',\n   'version',\n   'category',\n   'trader_a',\n   'trader_b',\n   'token_a_amount_raw',\n   'token_b_amount_raw',\n   'usd_amount',\n   'token_a_address',\n   'token_b_address',\n   'exchange_contract_address',\n   'tx_hash',\n   'tx_from',\n   'tx_to',\n   'trace_address',\n   'evt_index',\n   'trade_id'],\n  'result_set_bytes': 5048,\n  'total_row_count': 10,\n  'datapoint_count': 220,\n  'pending_time_millis': 25,\n  'execution_time_millis': 13}}\n```\n\nIn most cases, you will primarily be concerned with accessing the `state` property in this JSON object, which in this case is `QUERY_STATE_COMPLETED`.\n\n### Get Query Results\n\nFinally, let's load the results from the now-completed execution of our Query.\n\n#### Function Call\n\n``` py\nresponse = get_query_results(execution_id)\n```\n\nLets wrap the data received from this JSON `response` object up into a neat pandas Dataframe.\n\n``` py\ndata = pd.DataFrame(response.json()['result']['rows'])\n```\n\n#### Output\n\nIf everything worked smoothly, you should see your data in the `data` variable returned by this function:\n\n``` py 0\t2021-05-14T15:17:39+00:00\tDEX\t191\t\\xf82d8ec196fb0d56c6b82a8b1870f09502a49f88\tUniswap\t\\xa2b4c0af19cc16a6cfacce81f192b024d625817d\t7.819632e+11\t781963170639542600000\tKISHU\t\\xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\t...\tWETH\t[]\t1\t\\x75e29a7676717b99da65c6faad2e7644d00e2053\tNone\t\\x75e29a7676717b99da65c6faad2e7644d00e2053\t\\x6bc05c2bc156a60c1cacfc379540ad00b7280796613b...\t\\x7a250d5630b4cf539739df2c5dacb4c659f2488d\t10387.825000\t2", "doc_id": "c66e3977-4027-47c2-b496-e191e996c0f1", "embedding": null, "doc_hash": "cd200042884bca5be080f75bbb3dd0578df076cf4a8cfc1919bc6b072fa6e339", "extra_info": {"file_path": "docs/api/quick-start/api-py.md", "file_name": "api-py.md"}, "node_info": {"start": 5847, "end": 7621, "_node_type": "1"}, "relationships": {"1": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389", "2": "db20b10a-2cb4-4c67-a8d2-6aa6c8be0089", "3": "61d7795d-2a48-4b70-9e2f-d606df97780e"}}, "__type__": "1"}, "61d7795d-2a48-4b70-9e2f-d606df97780e": {"__data__": {"text": "1\t2022-04-06T07:01:37+00:00\tDEX\t11\t\\x6591c4bcd6d7a1eb4e537da8b78676c1576ba244\tUniswap\t\\xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48\t1.007936e+04\t10079361085\tUSDC\t\\x0391d2021f89dc339f60fff84546ea23e337750f\t...\tBOND\t[]\t1\t\\x0000006daea1723962647b7e189d311d757fb793\tNone\t\\x0000495194ec698fcf89ccf8abb445daf01db497\t\\x8b962e59ca9f1d91e465a7af289b4b4c9c7c64c6d30d...\t\\x0000006daea1723962647b7e189d311d757fb793\t10093.794730\t2 2\t2022-04-06T07:10:12+00:00\tDEX\t438\t\\xa25b34d2ec38e338bde108c8c4040be88945d024\tUniswap\t\\xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\t1.015798e-01\t101579832516438100\tWETH\t\\x8020734a29ee290fb81992874bd1de01a16c4204\t...\tNone\t[]\t1\t\\x68b3465833fb72a70ecdf485e0e4c7bd8665fc45\tNone\t\\xaac6fb32fd0a7a51768bddd4ac2f643445bd01af\t\\x8bbaff042cea60af88fac791c4d20f84ed7d21601c41...\t\\x68b3465833fb72a70ecdf485e0e4c7bd8665fc45\t342.732387\t2 3\t2022-04-06T07:10:12+00:00\tDEX\t339\t\\x8ef79d6c328c25da633559c20c75f638a4863462\tUniswap\t\\xa71d0588eaf47f12b13cf8ec750430d21df04974\t1.058343e+09\t1058343424775444053499052032.0\tQOM\t\\xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\t...\tWETH\t[]\t1\t\\x7540000cab63979795c7d4b326cadbb00ed24a04\tNone\t\\x7540000cab63979795c7d4b326cadbb00ed24a04\t\\x8bea318de386a65ac1c0c88f13e39654c3d4ec53a412...\t\\x68b3465833fb72a70ecdf485e0e4c7bd8665fc45\t263.520686\t2", "doc_id": "61d7795d-2a48-4b70-9e2f-d606df97780e", "embedding": null, "doc_hash": "5705ee9616e5a5f0b0a3450375096fa2e2d1caee8eaaba7d60c2e7c128ad49d6", "extra_info": {"file_path": "docs/api/quick-start/api-py.md", "file_name": "api-py.md"}, "node_info": {"start": 7652, "end": 8919, "_node_type": "1"}, "relationships": {"1": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389", "2": "c66e3977-4027-47c2-b496-e191e996c0f1", "3": "743f3699-bbe4-4ac1-9a73-08f3cefef767"}}, "__type__": "1"}, "743f3699-bbe4-4ac1-9a73-08f3cefef767": {"__data__": {"text": "4\t2022-04-06T07:15:58+00:00\tDEX\t149\t\\x9c84f58bb51fabd18698efe95f5bab4f33e96e8f\tUniswap\t\\xb620be8a1949aa9532e6a3510132864ef9bc3f82\tNaN\t21168910617154070511616.0\tNone\t\\xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\t...\tWETH\t[]\t1\t\\xdf29ee8f6d1b407808eb0270f5b128dc28303684\tNone\t\\xdf29ee8f6d1b407808eb0270f5b128dc28303684\t\\x8bf5a55a772b3c3423ee628bd459655a1d7bd09a5c69...\t\\xdef171fe48cf0115b1d80b88dc8eab59176fee57\t675.194000\t2 5\t2022-04-06T07:03:20+00:00\tDEX\t266\t\\x847e0b52589c9e6fa2dcc42b8ffb34ec924d4cf8\tUniswap\t\\xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\t8.903535e-04\t890353516515079\tWETH\t\\x9cf77be84214beb066f26a4ea1c38ddcc2afbcf7\t...\tNone\t[]\t1\t\\x7a250d5630b4cf539739df2c5dacb4c659f2488d\tNone\t\\xf2d229cc832661de2aa56249c5b7991006868522\t\\x8c00c8c20b1f3f1b447c579165c2759c688981dbc408...\t\\x1b2cf79d0a3622f25fbe10e968b3b25a348e008b\t3.004792\t2 6\t2021-05-17T16:04:09+00:00\tDEX\t88\t\\x0d4a11d5eeaac28ec3f61d100daf4d40471f1852\tUniswap\t\\xdac17f958d2ee523a2206206994597c13d831ec7\t1.003227e+02\t100322742\tUSDT\t\\xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\t...\tWETH\t[]\t1\t\\x773dd321873fe70553acc295b1b49a104d968cc8\tNone\t\\x7af55e2ab6e74f338d674537958ad236d17ab3ac\t\\x6bc07c4f53719ad8d1a0f5f99d2db3699fa9dce888e3...\t\\x8df6084e3b84a65ab9dd2325b5422e5debd8944a\t100.372301\t2", "doc_id": "743f3699-bbe4-4ac1-9a73-08f3cefef767", "embedding": null, "doc_hash": "34b88031226c96ed7d120d231860e9bca9450603dce5696774f853b7a1516303", "extra_info": {"file_path": "docs/api/quick-start/api-py.md", "file_name": "api-py.md"}, "node_info": {"start": 8920, "end": 10165, "_node_type": "1"}, "relationships": {"1": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389", "2": "61d7795d-2a48-4b70-9e2f-d606df97780e", "3": "9ef186eb-cf32-4e7e-92ed-3d98ecc0f9d3"}}, "__type__": "1"}, "9ef186eb-cf32-4e7e-92ed-3d98ecc0f9d3": {"__data__": {"text": "7\t2022-04-06T07:24:39+00:00\tDEX\t219\t\\xaa51ea59c985a92ce881517a8896931d4a86e9e3\tUniswap\t\\xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\t3.214029e-01\t321402936315917950\tWETH\t\\x4846b0cce69121e4d25b6efe7738eaf27bca7e7f\t...\tNone\t[]\t1\t\\x7a250d5630b4cf539739df2c5dacb4c659f2488d\tNone\t\\xa053dbafba05e307a7bddede09c7feb235dc34b1\t\\x8c86abc9c4eaff2b8de48351360781bc153cd16fa108...\t\\x68b3465833fb72a70ecdf485e0e4c7bd8665fc45\t1084.606349\t2 8\t2021-05-17T16:04:09+00:00\tDEX\t91\t\\x773dd321873fe70553acc295b1b49a104d968cc8\tUniswap\t\\x95ad61b0a150d79219dcf64e1e6cc01f0b64c4ce\t6.477303e+06\t6477302710423104532774912.0\tSHIB\t\\xdac17f958d2ee523a2206206994597c13d831ec7\t...\tUSDT\t[]\t1\t\\x8df6084e3b84a65ab9dd2325b5422e5debd8944a\tNone\t\\x7af55e2ab6e74f338d674537958ad236d17ab3ac\t\\x6bc07c4f53719ad8d1a0f5f99d2db3699fa9dce888e3...\t\\x8df6084e3b84a65ab9dd2325b5422e5debd8944a\t103.636843\t2 9\t2022-04-06T07:24:39+00:00\tDEX\t234\t\\xaa51ea59c985a92ce881517a8896931d4a86e9e3\tUniswap\t\\xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\t1.127058e-01\t112705776325968480\tWETH\t\\x4846b0cce69121e4d25b6efe7738eaf27bca7e7f\t...\tNone\t[]\t1\t\\x68b3465833fb72a70ecdf485e0e4c7bd8665fc45\tNone\t\\xa053dbafba05e307a7bddede09c7feb235dc34b1\t\\x8c86abc9c4eaff2b8de48351360781bc153cd16fa108...\t\\x68b3465833fb72a70ecdf485e0e4c7bd8665fc45\t380.336913\t2 ```  So you now have data from your Dune query.\n\nIn a table.\n\nIn Python. \n\n\ud83e\uddd9\ud83e\ude84\n\n### Cancel Query Execution\n\nSome queries can take a long time to execute (minutes).\n\nDepending on your workflow, you may want to interrupt execution at times. Here's how to do that:\n\n```py\nresponse = cancel_query_execution(execution_id)\n```\n\nWhen you have a running Query and call this function, you'll get a response object returned to you confirming the cancellation of query execution.\n\n## Parameterized Queries\n\nOnly one step changes when you are working with parameterized queries - you need to pass query parameters to the execution endpoint of our API. There is no change to working with rest of the endpoints after this step.\n\nSo let's define a function `execute_query_with_params`", "doc_id": "9ef186eb-cf32-4e7e-92ed-3d98ecc0f9d3", "embedding": null, "doc_hash": "d95a10041bec78c2f6a0b1a2d19ef947ff51833f45c7e6382b593847e1d91d94", "extra_info": {"file_path": "docs/api/quick-start/api-py.md", "file_name": "api-py.md"}, "node_info": {"start": 10166, "end": 12206, "_node_type": "1"}, "relationships": {"1": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389", "2": "743f3699-bbe4-4ac1-9a73-08f3cefef767", "3": "37d0b15e-a7ba-4f3b-86ef-fa9a9a8248b3"}}, "__type__": "1"}, "37d0b15e-a7ba-4f3b-86ef-fa9a9a8248b3": {"__data__": {"text": "this step.\n\nSo let's define a function `execute_query_with_params` to call the execute endpoint for parameterized queries:\n\n```py\ndef execute_query_with_params(query_id, param_dict):\n    \"\"\"\n    Takes in the query ID. And a dictionary containing parameter values.\n    Calls the API to execute the query.\n    Returns the execution ID of the instance which is executing the query.\n    \"\"\"\n    \n    url = make_api_url(\"query\", \"execute\", query_id)\n    response = post(url, headers=HEADER, json={\"query_parameters\" : param_dict})\n    execution_id = response.json()['execution_id']\n    \n    return execution_id\n```\n\n#### Create a Dictionary of parameters\nFor our example, we're creating a dictionary with just one key, the `wallet_address`, for use in a query that returns the total amount spent on gas from a given `wallet_address`:\n\n```py\nparameters = {\"wallet_address\" : \"0xb10f35351ff21bb81dc02d4fd901ac5ae34e8dc4\"}\n```\n\n#### Pass the parameters dictionary to the execution endpoint\nNow let's make use of the function that we just defined to achieve this:\n\n```py\nexecution_id = execute_query_with_params(\"638435\", parameters)\n```\n\nAnd that is it!\n\nOnce you get the `execution_id` from this POST endpoint, you can use it with all the GET endpoints of the API, just like you would with a simple query without parameters.\n\n!!! Complete-Code\n    The complete code for this tutorial is available on [this link](https://github.com/SusmeetJain/dune_api_python).\n", "doc_id": "37d0b15e-a7ba-4f3b-86ef-fa9a9a8248b3", "embedding": null, "doc_hash": "ceec4d9e569f18527c310089ffae9e80ecc0c892f0be5c3fdeac0bf18b36b7c3", "extra_info": {"file_path": "docs/api/quick-start/api-py.md", "file_name": "api-py.md"}, "node_info": {"start": 12140, "end": 13594, "_node_type": "1"}, "relationships": {"1": "81d66ca829f3f244a5f8fceb32fe05ec6b10a389", "2": "9ef186eb-cf32-4e7e-92ed-3d98ecc0f9d3"}}, "__type__": "1"}, "519d0f3f-8c1c-45e0-8b5b-7985829bdcf6": {"__data__": {"text": "---\ntitle: Community Clients\ndescription: Here's a list of Dune API clients built by our magnificent community!\n---\n\nOur community once again comes through for the win with the below API clients.\n\nIf you've built your own let us know about it in our [#dune-api Discord Channel](https://discord.com/channels/757637422384283659/1019910980634939433)!\n\n!!! warning \"Disclaimer\"\n    While we love that our community has taken the lead, these clients are not directly maintained by the Dune team.\n\n## Cow Protocol Python Client\n\nBuilt by [@bh2smith](https://dune.com/bh2smith) and the team at [Cow Protocol](https://dune.com/cowprotocol), you can find this client on [PyPi](https://pypi.org/project/dune-client/).\n\nGet started quickly with a simple pip install command:\n\n```\npip install dune-client\n```\n\nAnd if you want to learn more about how it's built and works, check out the client's [GitHub page here](https://github.com/cowprotocol/dune-client).\n\n## Cow Protocol Typescript Client\n\n[@bh2smith](https://dune.com/bh2smith) also built a [Node.js client you can find here](https://www.npmjs.com/package/@cowprotocol/ts-dune-client).\n\nInstall it like this:\n\n```\nyarn add @cowprotocol/ts-dune-client\n```\n\n## Dune Go Client\n\nDune team member [@theedgeofrage](https://dune.com/theedgeofrage) built [a Go client you can find on GitHub here](https://github.com/duneanalytics/duneapi-client-go/).\n\n[There's also more advanced documentation here](https://pkg.go.dev/github.com/duneanalytics/duneapi-client-go).\n\n## Dune Ruby client\n\n[@shellandbull](https://github.com/shellandbull) built the Ruby client, available in [RubyGems](https://rubygems.org/gems/dune)\n\nTo install add the following line to your `Gemfile`\n\n```ruby\ngem \"dune\"\n```\n\nThen run `$ bundle install` from your terminal\n", "doc_id": "519d0f3f-8c1c-45e0-8b5b-7985829bdcf6", "embedding": null, "doc_hash": "baef80ceb536fe216328820d160f137e82c5b914d5a3a5d0b8c4e555fde20afd", "extra_info": {"file_path": "docs/api/quick-start/community-clients.md", "file_name": "community-clients.md"}, "node_info": {"start": 0, "end": 1775, "_node_type": "1"}, "relationships": {"1": "65788ed3a52740a5d20a43ca5641bf4038899151"}}, "__type__": "1"}, "8fd7274f-8d46-4cd6-973e-9a975d17b8c9": {"__data__": {"text": "---\ntitle: API Quick Start \ndescription: Get started with our API fast using these quick start guides.\n---\n\n## Language Specific API Quickstart Guides\n\nGet started with our API in a few lines of code using these quick start guides:\n\n<div class=\"cards grid\" markdown>\n- [Python](../quick-start/api-py.md)\n- [Javascript](../quick-start/api-js.md)\n</div>\n\nYou should check out our [community API clients (sdks)](../quick-start/community-clients.md) as well.\n\nFor building a simple data ingestion pipeline, see [using Python and Celery](https://adamparrish.xyz/downstream-data-extract-transform-load).\n## API-ready Queries\n\nHere we have four queries, you can use the query ID from the URL in any of the [API guides](../quick-start/index.md). Or, you can fork the query and change it however you like - then use that new query ID in the API.\n\n**Get the ERC20 balances for a given address**\n\nThe query ID is [1616880](https://dune.com/queries/1616880).\n\n| Parameters | Description | Valid Choices |\n| -----------| ---------- | ---------- |\n| `address` | The address that you would like to get balances for | must be a valid EVM address |\n| `blocknumber` | The cutoff block for checking balances | 0 if you want most recent block, otherwise any blocknumber that has been processed will work (~3 minute/15 block delay) |\n| `chain` | The EVM chain you'd like to check balances for | `ethereum`, `polygon`, `bnb`, `optimism`, `arbitrum`, `avalanche_c`, `gnosis` |\n| `dust` | Keep or remove dust tokens (worth less than $0.01) | `keep` or `remove` |\n\nOutput columns\n\n| Output Column | Description | \n| ------------- | ----------- |\n| `symbol` | the token symbol, if we have it |\n| `notional_value` | the notional amount of tokens held, rounded 5 decimals |\n| `total_value` | the $USD value of tokens held, rounded 3 decimals |\n| `token_price` | the $USD price of the token |\n\n**Get all the holders and their balances for a given ERC20 address**\n\nThe query ID is [1618116](https://dune.com/queries/1618116).\n\n| Parameters | Description | Valid Choices |\n| -----------| ---------- | ---------- |\n| `address` | The ERC20 token address you would like to get holders of | must be a valid EVM address |\n| `blocknumber` | The cutoff block for checking balances | 0 if you want most recent block, otherwise any blocknumber that has been processed will work (~3 minute/15 block delay) |\n| `chain` | The EVM chain you'd like to check balances for | `ethereum`, `polygon`, `bnb`, `optimism`, `arbitrum`, `avalanche_c`, `gnosis` |\n\nOutput columns\n\n| Output Column | Description | \n| ------------- | ----------- |\n| `holder` | the address of the holder |\n| `holder_ens` | the ens of the holder address, if any |\n| `notional_value` | the notional amount of tokens held, rounded 5 decimals |\n| `total_value` | the $USD value of tokens held, rounded 3 decimals |\n| `token_price` | the $USD price of the token |\n\n**Get the NFT balances for a given address**\n\nThe query ID is [1617158](https://dune.com/queries/1617158).\n\n| Parameters | Description | Valid Choices |\n| -----------| ---------- | ---------- |\n| `address` | The address that you would like to get balances for | must be a valid EVM address |\n| `blocknumber` | The cutoff block for checking balances | 0 if you want most recent block, otherwise any blocknumber that has been processed will work (~3 minute/15 block delay) |\n| `chain` | The", "doc_id": "8fd7274f-8d46-4cd6-973e-9a975d17b8c9", "embedding": null, "doc_hash": "bfb87658ec11be93e7cdfa9195a50f670e0fbc3d292a8bf42cabede115b37447", "extra_info": {"file_path": "docs/api/quick-start/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 3373, "_node_type": "1"}, "relationships": {"1": "8dc010af0db2fcc9db9f9c23db6ed3a2f5644e39", "3": "bdf217ca-d262-4c92-8357-92adaf1e493b"}}, "__type__": "1"}, "bdf217ca-d262-4c92-8357-92adaf1e493b": {"__data__": {"text": "will work (~3 minute/15 block delay) |\n| `chain` | The EVM chain you'd like to check balances for | `ethereum`, `polygon`, `bnb`, `optimism`, `arbitrum`, `avalanche_c`, `gnosis` |\n\nOutput columns\n\n| Output Column | Description | \n| ------------- | ----------- |\n| `symbol` | the symbol of the NFT, if we have it |\n| `name` | the name of the NFT, if we have it |\n| `category`| the category of the NFT, if we have it |\n| `token_id` | the token_id of the NFT |\n| `contract_address` | the contract_address of the NFT |\n| `acquired_how` | was it `minted` or `transfered/bought` |\n| `acquired_on_block_number` | the block_number that the NFT was received on |\n\n**Get all the holders and their balances for a given NFT address**\n\nThe query ID is [1618122](https://dune.com/queries/1618122).\n\n| Parameters | Description | Valid Choices |\n| -----------| ---------- | ---------- |\n| `address` | The NFT address that you would like to holders of | must be a valid EVM address |\n| `blocknumber` | The cutoff block for checking balances | 0 if you want most recent block, otherwise any blocknumber that has been processed will work (~3 minute/15 block delay) |\n| `chain` | The EVM chain you'd like to check balances for | `ethereum`, `polygon`, `bnb`, `optimism`, `arbitrum`, `avalanche_c`, `gnosis` |\n\nOutput columns\n\n| Output Column | Description | \n| ------------- | ----------- |\n| `holder` | the address of the holder |\n| `holder_ens` | the ens of the holder address, if any |\n| `tokens_held` | how many NFTs from this contract is held |\n| `token_ids` | an array of all the token ids held |", "doc_id": "bdf217ca-d262-4c92-8357-92adaf1e493b", "embedding": null, "doc_hash": "d510eb3f628393d99221e42182baf4d9a9cc7b1be79cf32640c52547c992184b", "extra_info": {"file_path": "docs/api/quick-start/index.md", "file_name": "index.md"}, "node_info": {"start": 3319, "end": 4901, "_node_type": "1"}, "relationships": {"1": "8dc010af0db2fcc9db9f9c23db6ed3a2f5644e39", "2": "8fd7274f-8d46-4cd6-973e-9a975d17b8c9"}}, "__type__": "1"}, "b9bbb261-4cb7-4b7d-a5fb-4489f077c5c8": {"__data__": {"text": "---\ntitle: Write API\ndescription: The Dune CSV Upload API allows developers to upload CSV files to a specific table in the Dune database.\n---\n\n# Dune CSV Upload API\n\n\nThe Dune CSV Upload API allows you to upload CSV files in the Dune database. This API streamlines the process of importing data into the Dune platform and makes allows you to import off-chain data into Dune with ease. You can simply use your usual API key to authenticate with the API and upload your CSV file.\n\nCurrently, the API only supports uploading CSV files with a maximum size of 200 MB. The API will return an error if the file size exceeds this limit. \n\nFor now, all files will be stored in the ``dunecat`` schema in the Dune database. In the future, we will allow users to specify the schema where the data should be stored. The table name must be specified in the request payload.\n\n```sql\nSelect * from dunecat.example_table\n```\n\n**All Data uploaded via this API is public and can be accessed by anyone.**\n\n## How to use the API\n\nHere are the key details you need to know to use the API.\n\n### Authentication\n\nTo authenticate with the API, you must include your API key in the request headers. The header should look like this: \n\n``X-Dune-Api-Key : <your-api-key>``\n\n### Endpoint\n\nThe API endpoint for uploading a CSV file is:\n\n```\nPOST https://api.dune.com/api/v1/table/upload/csv\n```\n\n### Request Parameters\n\nThe request payload should be a JSON object containing the following fields:\n\n- `table_name`: (string) The target table in the database where the CSV data should be uploaded.\n- `description`: (string, optional) A brief description of the uploaded data. Will be displayed in the Dune UI in the future.\n- `data`: (string) The content of the CSV file, passed as a string.\n\n### Example Request\n\n```json\n{\n    \"table_name\": \"example_table\",\n    \"description\": \"Sample data for testing\",\n    \"data\": \"column1,column2\\nvalue1,value2\\nvalue3,value4\"\n}\n```\n\n### Response\n\nThe API will respond with a status code indicating the result of the upload. A successful upload will return a 200 status code. The response body may contain additional information about the result of the request.\n\n### Example Usage\n\nYou can test the API with this google colab notebook: \n\n<div class=\"cards grid\" markdown>\n- [:octicons-arrow-right-24: Google Colab Notebook](https://colab.research.google.com/drive/1dJ9xTT5UfyylIUbMg9r-6FSeMD37HoZN?usp=sharing)\n</div>\n\nAlternatively, you can use the following Python code to do the same locally:\n\n```py\n# This example demonstrates how to use the new API to upload a CSV file\nimport os\nimport json\nimport requests\n\napi_key = '<YOUR_API_KEY>'\ncsv_file_path = '<CSV_FILE_PATH>'\n\nurl = 'https://api.dune.com/api/v1/table/upload/csv'\n\nwith open(csv_file_path) as open_file:\n    data = open_file.read()\n    \n    headers = {'X-Dune-Api-Key': api_key}\n\n    payload = {\n        \"table_name\": \"example_table\",\n        \"description\": \"test_description\",\n        \"data\": str(data)\n    }\n    \n    response = requests.post(url, data=json.dumps(payload), headers=headers)\n\n    print('Response status code:', response.status_code)\n    print('Response content:',", "doc_id": "b9bbb261-4cb7-4b7d-a5fb-4489f077c5c8", "embedding": null, "doc_hash": "b3f59a6145581aa3daac8f9065d58ef3f23627ccc8ea19214e36807ee667d80b", "extra_info": {"file_path": "docs/api/write-api.md", "file_name": "write-api.md"}, "node_info": {"start": 0, "end": 3149, "_node_type": "1"}, "relationships": {"1": "fb6e1495c297e2c98d22e485362addc5f4086d7b", "3": "50732a05-df51-4e8e-9546-a75340544c1d"}}, "__type__": "1"}, "50732a05-df51-4e8e-9546-a75340544c1d": {"__data__": {"text": "status code:', response.status_code)\n    print('Response content:', response.content)\n\n```\n\n\n## Querying for the data in Dune\n\nOnce the data has been uploaded, you can query it using the following SQL query:\n\n```sql\nSelect * from dunecat.example_table\n```\n\n", "doc_id": "50732a05-df51-4e8e-9546-a75340544c1d", "embedding": null, "doc_hash": "ae98c533a10e9c2a9888e198d4e72e66986e745c52e8cdc51cde2bc0f862baa3", "extra_info": {"file_path": "docs/api/write-api.md", "file_name": "write-api.md"}, "node_info": {"start": 3082, "end": 3339, "_node_type": "1"}, "relationships": {"1": "fb6e1495c297e2c98d22e485362addc5f4086d7b", "2": "b9bbb261-4cb7-4b7d-a5fb-4489f077c5c8"}}, "__type__": "1"}, "a83f8ec6-4060-4fd2-8499-22b0008e8808": {"__data__": {"text": "---\ntitle: Create a Dashboard\n---\n\n**Dashboards are where Dune's content lives and gets discovered.**\n\nDashboards on Dune consist of widgets. Widgets can either be Visualizations or Text. It is also possible to embed images or GIFs inside of the text widget.\n\nYou can freely resize every widget to match the layout you want to create.\n\n## Creating a Dashboard\n\n\n\n<div style=\"position: relative; padding-bottom: calc(66.66666666666666% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/xTAXmlo0nCL0FOn38hW9?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Creating a dashboard\"></iframe></div>\n\n\n**To create a dashboard on Dune:**\n\n1. Use the create menu and pick \"New Dashboard\"\n2. Give your Dashboard a name\n3. Click on \"Save and Open\"\n4. You are now inside of your Dashboard\n5. Enter the edit mode by clicking on the \"Edit\" button in the top right corner\n6. Add widgets by clicking on the \"Add Widget\" button in the top right corner\n7. Pick the widget you want to add\n8. You can now resize the widget by dragging the bottom right corner\n9. You can also move the widget by dragging it around\n10. Click on the \"Save\" button in the top right corner to save your changes\n\nThe initial name that you give to your Dashboard will also be the URL slug. You can't change the URL slug afterwards, so be mindful of the name you choose. Changing the Dashboard's display name is always possible though.\n\n## Add Widgets from the Query Editor\n\nYou can add widgets directly from the Query Editor.\n\n<div style=\"position: relative; padding-bottom: calc(56.99999999999999% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/tcRqeUZ7qVNahQImdVsw?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Rocket Pool Minipools by ETH Bond vs. Time\"></iframe></div>\n\n1. Navigate to the query Editor\n2. Pick the Visualization you want to add to your Dashboard\n3. Click on the \"Add to Dashboard\" button\n4. Choose the Dashboard you want to add the Visualization to\n5. The Visualization is now added to your Dashboard\n\nThe widget will be added to the bottom of your Dashboard. You can move it around and resize it as you like.\n\n## Adding Text Widget\n\nYou can add text widgets to your dashboard.\n\nText widgets support a subset of Markdown. You can manipulate text and embed images and GIFs.\n\n### Embedding Images and GIFs\n\nOur text boxes can also be used to embed images or GIFs into your Dashboard.\n\nThe Syntax for embedding images is:\n\n| [Image](https://www.markdownguide.org/basic-syntax/#images-1) | `![alt text](image url)` |\n| ------------------------------------------------------------- | ------------------------ |\n\nSince you can't store images locally on our servers, you need to upload your images somewhere else or find the raw file somewhere on the internet.\n\nIn practice this might look like this:\n\n```markdown\n![text](https://pbs.twimg.com/media/FEWVLQwWUAQcqLY?format=jpg&name=medium)\n```\n\nYou can resize the image by simply resizing the widget it is contained in.\n\nYou can combine images and text in one widget.\n", "doc_id": "a83f8ec6-4060-4fd2-8499-22b0008e8808", "embedding": null, "doc_hash": "445912e51239258f90c197da134c5dec15a2596bf4df59e942d6d6886860453e", "extra_info": {"file_path": "docs/app/dashboards.md", "file_name": "dashboards.md"}, "node_info": {"start": 0, "end": 3309, "_node_type": "1"}, "relationships": {"1": "1ef7f1624e04f49dda014356fec5109184fd5ac9"}}, "__type__": "1"}, "8750ca7f-6588-40b7-9082-5775d7d93f84": {"__data__": {"text": "---\ntitle: Decoding Contracts\ndescription: Here's everything you need to know about Decoded contracts and how to submit them!\n---\n\n**Dune contains an extensive catalog of Decoded Contracts, brought into the platform through Wizard submissions!**\n\nInstead of working with raw transaction, log, and trace data, contracts are decoded into human-readable tables for each event and function defined in the smart contract's ABI ([Application Binary Interface](https://www.alchemy.com/overviews/what-is-an-abi-of-a-smart-contract-examples-and-usage)).\n\nLearn more about how Decoding works and what Decoded tables are available in the [data tables section](../../tables/decoded/).\n\n## Submitting a new contract for decoding\n\n![type:video](https://www.youtube.com/embed/4v9zEYZvv34)\n\nContracts can be submitted for decoding through:\n\n- [The New contract form](https://dune.com/contracts/new)\n- The [My Creations > Contracts Tab](https://dune.com/browse/contracts/authored)\n\n### 1. Blockchain and address\n\nWe first ask for the contract's address and blockchain. Requesting this data first has two purposes:\n\n1. To enable us to review for potential duplicate contracts and pending submissions.\n2. To automate parts of the submission process where we can.\n\nThe latter is usually accomplished by fetching potentially useful metadata from Dune and other third party sources where relevant.\n\nFor instance, below here's an example of submitting the USDT contract (`0x94b008aA00579c1307B0EF2c499aD98a8ce58e58`) in Optimism:\n\n![Submit smart contract](images/decoding-contracts/submit-smart-contract.png)\n\nIf we can find the contract through a third party source, we will show a green check mark next to the address field.\n\nThis means we were able to fetch information such as the contract's name and ABI (Application Binary Interface).\n\n### 2. Contract details\n\nAfter pressing Next, we ask for other information about the contract that we need in order to decode it:\n\n![Submit smart contract 2](images/decoding-contracts/submit-smart-contract-2.png)\n\nIf we found the contract through other third party sources, you will only have to fill in the project name.\n\nWe have some naming conventions on that, partly due to our technical setup and also to make finding data more predictable.\n\n**Project Names Rules**\n\n- All lowercase\n- No spaces (underscore \"_\" if needed)\n- Added \"_v2\" or other version names at the end if applicable\n\neg `augur`, `tornado_cash`, `uniswap_v2`\n\nOnce you submit it, you are done! The contract will be stored in our queue, which we manually review for quality assurance purposes.\n\n!!! note\n    \n    Submission are usully processed within a few hours on weekdays.\n\n### Advanced options\n\nIn some instances, Dune can automatically detect and index multiple contract addresses under the same submission. This is useful for examples such as AMM pools where there often exists one contract instance per pair.\n\nWe have two strategies for detecting other contracts for decoding:\n\n1. **Bytecode match.** We use the bytecode of the contract address in the submission to find other matches in the whole chain history.\n2. **Factory instances.** We find all other contracts created by the same address as the one responsible for creating the submitted contract.\n\nIn both cases, we assume that all the contracts found through either method correspond to the same blockchain, project name, contract name and ABI.\n\nIf you want us to index more than one contract, toggle on Advanced options and select \"Yes\" to the first question, \"Are there several instances of this contract?\"\n\nThen, to the second question - \"Is it created by a factory contract?\" - select \"No\" to index all other", "doc_id": "8750ca7f-6588-40b7-9082-5775d7d93f84", "embedding": null, "doc_hash": "37db042ee0506258e86a1c09d71e6115b9293aae5507d214d8896ab491679cea", "extra_info": {"file_path": "docs/app/decoding-contracts.md", "file_name": "decoding-contracts.md"}, "node_info": {"start": 0, "end": 3669, "_node_type": "1"}, "relationships": {"1": "efe2d8928da28dcac2206c5aaabcc0269cd911cd", "3": "2dc178c5-ae63-4b32-837b-9d422ec96e17"}}, "__type__": "1"}, "2dc178c5-ae63-4b32-837b-9d422ec96e17": {"__data__": {"text": "- \"Is it created by a factory contract?\" - select \"No\" to index all other contracts with the same bytecode or \"Yes\" to index all other contracts originating from the same creator:\n\n![new-contract-advanced-options](images/decoding-contracts/new-contract-advanced-options.png)\n\n!!! warning\n\n    Only use these options if you know what you're doing and are familiar with the project's architecture and deployment hierarchy. Incorrectly applying these settings may lead to a rejected submission.\n\n## Tracking your submissions\n\nYou can view your submissions and their processing status at any time by navigating to [My Creations > Contracts](https://dune.com/browse/contracts/authored).\n\nContract submissions are usually processed within a few hours, but some submissions may require additional time. Once a contract has been approved, it may take up to an hour for the data to become available, and up to six hours for historical data to be included.\n\n## Frequently Asked Questions\n\n#### How do I submit contract information manually?\n\n!!! note\n    If the contract being manually submitted is a Proxy contract, we recommend you to move on to the next section.\n\nAlthough we try to fetch contract information such as the ABI, sometimes this information might not be available through our sources.\n\nIn those instances, you will need to manually input the contract's name and its ABI.\n\nIf the contract has been verified by the chain's block explorer, you should be able to find this information there.\n\n#### How do I submit a Proxy contract?\n\nIn order to properly decode transactions towards contracts that fit the [Proxy pattern](https://blog.openzeppelin.com/proxy-patterns/), Dune needs to map the Proxy contract's address with the implementation contract's ABI.\n\nWe avoid monitoring the implementation contract's address because its logic is accessed in transactions via the [`DelegateCall` function](https://medium.com/coinmonks/delegatecall-calling-another-contract-function-in-solidity-b579f804178c).\n\nIf we did monitor the implementation contract's address directly, we would miss out on any event logs in its logic since these are actually fired by the caller (the Proxy in this case) when calling a function through `DelegateCall`.\n\n!!! warning\n    When submitting Proxy-patterned contracts to Dune, you should input the Proxy contract's address and, if you have it, the Implementation contract's ABI.\n\nWhen you submit the Proxy contract's address, we'll attempt to fetch the proxy's contract name and the implementation address it's pointing towards to source the Implementation contract's ABI.\n\nIf we can't find the Implementation contract's ABI, you'll need to find it using the relevant chain's blockchain explorer and input it manually.\n\n\n#### How do I re-submit a contract?\n\nDune assumes each address in the blockchain can map to at most 1 contract. For this reason, submitting a contract with an address that already exists in `[blockchain].contracts` will override it for Decoding purposes.\n\nThis has a couple potential dangerous side effects:\n\n- If the project or contract name has changed, we will generate new tables for all of the contract's methods and events. In turn, previous tables will stop updating, data will be fragmented, and Queries will stop working.\n- If the ABI has changed in a way that modifies an existing table's parameters, Queries that depend on such table might break or become inaccurate.\n\nIf you attempt to submit a contract that already exists, we'll first present a warning note and ask you to confirm you want to proceed:\n\n![new contract resubmission warning](images/decoding-contracts/new-contract-resubmission-warning.png)\n\nThen, at the bottom of the Details page, we'll ask you to explain why you're resubmitting the contract so we can assess whether it's worth overriding the contract's data:\n\n![new contract resubmission", "doc_id": "2dc178c5-ae63-4b32-837b-9d422ec96e17", "embedding": null, "doc_hash": "0216ea45200c0d9930c30d5ed959ea9787f1ebb3e695ad805b34d4456b93b3cf", "extra_info": {"file_path": "docs/app/decoding-contracts.md", "file_name": "decoding-contracts.md"}, "node_info": {"start": 3611, "end": 7476, "_node_type": "1"}, "relationships": {"1": "efe2d8928da28dcac2206c5aaabcc0269cd911cd", "2": "8750ca7f-6588-40b7-9082-5775d7d93f84", "3": "a3bf8534-fa35-4d0b-b07e-3c52d80339bd"}}, "__type__": "1"}, "a3bf8534-fa35-4d0b-b07e-3c52d80339bd": {"__data__": {"text": "it's worth overriding the contract's data:\n\n![new contract resubmission reason](images/decoding-contracts/new-contract-resubmission-reason.png)\n\nIf we believe the risk of accepting a re-submission is higher than the added value, we'll reject your resubmission.\n\nIf you think we're wrong (we're only human!), feel free to reach out in our [#decoding Discord channel](https://discord.com/channels/757637422384283659/850326962152538122) and we'll discuss it further with you!\n\n#### How do I submit Diamond Proxy contracts?\n\nSimilar to vanilla Proxy contracts, [EIP-2535](https://eips.ethereum.org/EIPS/eip-2535) contracts can be supported by passing in the address of the Diamond Proxy as well as **a single ABI representing the totality of all the facets interfaces**.\n\n#### My submission got rejected, why?\n\nIn the interest of data quality, we reject duplicative, incorrect or low quality submissions. To avoid rejection, be sure to submit accurate contract information! \ud83d\ude4f\n\n#### Why am I missing historical data for my contract?\n\nIt may take up to six hours from the time of contract approval for the contract to be fully decoded along with its historical data. If you still can't see the data after this period, please reach out to us through our [#decoding Discord channel](https://discord.com/channels/757637422384283659/850326962152538122).\n\n#### For all other questions:\n\nHead over to the [#decoding Discord channel](https://discord.com/channels/757637422384283659/850326962152538122) and we'll be happy to help!\n", "doc_id": "a3bf8534-fa35-4d0b-b07e-3c52d80339bd", "embedding": null, "doc_hash": "b36326cf339901cfd8acf5623a5b77164600433bc2bdb1461940b05c6b016b5d", "extra_info": {"file_path": "docs/app/decoding-contracts.md", "file_name": "decoding-contracts.md"}, "node_info": {"start": 7464, "end": 8981, "_node_type": "1"}, "relationships": {"1": "efe2d8928da28dcac2206c5aaabcc0269cd911cd", "2": "2dc178c5-ae63-4b32-837b-9d422ec96e17"}}, "__type__": "1"}, "2af4e6b7-3d2f-44ca-84a5-a6fbd5d3bbe1": {"__data__": {"text": "---\ntitle: Creating Embeds\ndescription: Embeds allow you to enjoy beautiful, updating Dune charts across the web!\n---\n\n**Create embeds to display your Dune widgets across the web!**\n\nTo save you from having to take screenshots that might not look so great but will definitely be out of date a few minutes after you take them, we've built a native embed function that works across most web platforms.\n\nYou can generate embed links by clicking on any query title and selecting the embed function in the top right corner.\n\n!!! note\n    The embed button works as a stand alone link and as a way to embed your live graphs into websites/apps. If a Query has no Visualizations, the link will be to the Query Results table. If you have multiple Visualizations, the link will be for whichever Visualization you've selected when you clicked the Embed button.\n\n![generating an embed link](images/embed-link.gif)\n\n## Using Embeds on different platforms\n\nHere are a few examples of how you can use Dune embeds on different platforms.\n\n### Twitter\n\nTwitter renders and updates Dune Visualizations automatically!\n\nSimply paste your embed link and let the magic happen.\n\n![Twitter automatically renders the embed link correctly](images/twitter.gif)\n\n### Discord\n\nDune embeds work very well in Discord, simply drop the embed link in the chat and the corresponding Visualization will be displayed.\n\nThis also lends itself very well to programming a bot to return the corresponding charts on command.\n\n![Discord](images/discord.gif)\n\n### Web Pages\n\nYou can use Dune's embed links to add live Visualizations to any web page using an `iframe`\n\nHere is a code snippet example:\n```html\n<iframe src=\"[your-query's-embed-link]\" height=\"500\" width=\"500\" title=\"[name-of-your-query]\"></iframe>`\n```\nA great showcase for this is the [cryptoart.io](https://cryptoart.io/data) website.\n\n### Mirror.xyz\n\nDune Visualizations can easily be embedded into articles on mirror.xyz. Simply generate an embed link and postfix it with `?display=iframe`\n\n```html\n\nhttps://dune.com/embeds/208941/391702/34ee3319-1cac-40e1-a08d-160bd93693cc?display=iframe`\n```\n### Known Issues\n\nUnfortunately, embeds do not work in a couple of fairly popular web platforms, including:\n\n* Substack\n* Medium\n* GitBook\n\n## Creating Embeds with Parameters\n\nEmbed links also work with parameterized Queries, but it is a bit tricky to get them to work:\n\nThe embed link you generate won't include the necessary parameters yet, even if you ran the query with them.\n\nWe are working on automating this, but for now you'll need to manually prefix the parameter link with the parameters:\n\n`link?[name_of_parameter_1]=[xxxx]&?[name_of_parameter_2]=[yyyy]&[...]`\n\nHere is a working example:\n```\nhttps://dune.com/embeds/118220/238460/aa002dd3-f9e2-4d63-86c8-b765569306c6NFT?address=0xff9c1b15b16263c61d017ee9f65c50e4ae0113d7&rolling_n_trades=500\n```", "doc_id": "2af4e6b7-3d2f-44ca-84a5-a6fbd5d3bbe1", "embedding": null, "doc_hash": "132288fdaa7412d6e5882ca057a1d48eaa7cee0d4cc734e5604e3ef664fe4612", "extra_info": {"file_path": "docs/app/embeds.md", "file_name": "embeds.md"}, "node_info": {"start": 0, "end": 2875, "_node_type": "1"}, "relationships": {"1": "f0ebb4e9a8e3ba41efa0a590709f9def98cb48c5"}}, "__type__": "1"}, "1d5818de-df6a-43e5-b869-386e83fd3415": {"__data__": {"text": "---\ntitle: App Overview\ndescription: Learn more about how the dune.com app works in this section!\n---\n\n**The Dune platform is your key to accessing blockchain data!**  \n\n\n<div class=\"grid cards\" markdown>\n\n-   #### Query Editor\n\n    ---\n\n    The Query Editor is where you can write SQL queries to explore blockchain data. This docs section describes the functional elements of the Query Editor, to learn how to write queries, see [the query section](../query/index.md).  \n    \n    [:octicons-arrow-right-24: Queries](query-editor/index.md)\n\n-   #### Visualizations\n\n    ---\n\n    Visualizations make your data come to life! You can create Visualizations from any results of a query.  \n    \n    [:octicons-arrow-right-24: Visualizations](visualizations/index.md)\n\n-   #### Dashboards\n\n    ---\n\n    Dashboards are a collection of Visualizations and text that you can share with the world. You can create Dashboards out of any Visualizations you have created.  \n    \n    [:octicons-arrow-right-24: Dashboards](dashboards.md)\n\n-   #### Decoding\n\n    ---\n\n    Decoding is a feature that allows you to submit contracts for decoding. This is useful if you want to decode events or transactions that are not decoded already.  \n    \n    [:octicons-arrow-right-24: Decoding](decoding-contracts.md)\n\n-   #### Teams\n\n    ---\n\n    Working with a team? You can create a team and invite your teammates to collaborate on queries, visualizations, and dashboards.  \n    \n    [:octicons-arrow-right-24: Teams](teams.md)\n\n-   #### Embeds\n\n    ---\n\n    Embeds allow you to embed your Visualizations on your website, blog, twitter, or anywhere else you want to share your data.  \n    \n    [:octicons-arrow-right-24: Embeds](embeds.md)\n\n</div>\n\n\n", "doc_id": "1d5818de-df6a-43e5-b869-386e83fd3415", "embedding": null, "doc_hash": "892b1c82e372952455f9c923c5dbfec49e24f7ddab25592848b9b56dbecff241", "extra_info": {"file_path": "docs/app/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 1722, "_node_type": "1"}, "relationships": {"1": "fc98b150ec32caa79b409a81a22df8f1c9d29970"}}, "__type__": "1"}, "f8246d4e-ae76-4c23-9693-2b2818f0863d": {"__data__": {"text": "---\ntitle: Finding Tables\ndescription: The Data Explorer allows you to search for blockchain and other data to use in your Queries. Here's how it works.\n---\n\nThe left sidebar of the query editor is the Data Explorer. It allows you to search for blockchain and other data to use in your queries.\n\nYou can learn about Dune's data tables [in the data tables section](../../data-tables/index.md).\n\n## Browsing data\n\nHere is a simple example of how to use the Data Explorer to find the data you need:\n\n1. Click on one of the categories in the left sidebar to see the tables available in that category.\n2. Filter the tables through the dropdowns in the top right corner.\n3. Check out the table preview to see what data is available in that table.\n4. Click on the arrow next to the table name to include it in your query.\n\n<div style=\"position: relative; padding-bottom: calc(61.916666666666664% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/IWTNiiQ9np1JWSe7FRJs?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Dune\"></iframe></div>\n\n## Finding specific tables\n\nYou can also search for specific tables in the Data Explorer.   \n\n1. Choose the \"decoded projects\" category.\n2. Type the projects name in the search bar.\n3. Choose the project you want to explore.\n4. Type the smart contract name in the search bar.\n5. Choose the smart contract you want to explore.\n\n<div style=\"position: relative; padding-bottom: calc(67.66666666666666% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/I28EsaPHjpRQZPLbLTu2?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Dune\"></iframe></div>\n\n## Finding a smart contract by address\n\nUnfortunately, the Data Explorer does not allow you to search for a smart contract by address. However, you can use [this dashboard](https://dune.com/dune/is-my-contract-decoded-yet-v2) to find the smart contract's name by address. If it doesn't show up, you can submit it for decoding [here](https://dune.com/decoding).\n\n<div style=\"position: relative; padding-bottom: calc(67.66666666666666% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/RJ799xCLgFOc3Vof1quV?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Is My Contract Decoded Yet - Dune Engine V2\"></iframe></div>\n\n\n### Blockchain Icons\n\nSome data sets will have multiple blockchain icons - meaning data from each of those blockchains is available within that data set!\n\n\n| Icon      | Description                          |\n| ----------- | ---------------------------------------- |\n|    ![ethereum icon](images/explorer-labels/ethereum-icon.png)    | Ethereum blockchain Raw Data, Decoded Project, or Spell |\n|![gnosis chain icon](images/explorer-labels/gnosis-chain-icon.png)| Gnosis Chain Raw Data, Decoded Project, or Spell |\n| ![polygon icon](images/explorer-labels/polygon-icon.png) | Polygon blockchain Raw Data, Decoded Project, or Spell |\n| ![optimism", "doc_id": "f8246d4e-ae76-4c23-9693-2b2818f0863d", "embedding": null, "doc_hash": "777935ef09c2508f378b98a04b84396691edbd235867c0d65eb2b8d7c122e096", "extra_info": {"file_path": "docs/app/query-editor/data-explorer.md", "file_name": "data-explorer.md"}, "node_info": {"start": 0, "end": 3310, "_node_type": "1"}, "relationships": {"1": "75fdb7ce0c015bdb6192677d1a04da8080373b32", "3": "d561730d-93ee-4b45-b723-870826b628b4"}}, "__type__": "1"}, "d561730d-93ee-4b45-b723-870826b628b4": {"__data__": {"text": "Polygon blockchain Raw Data, Decoded Project, or Spell |\n| ![optimism icon](images/explorer-labels/optimism-icon.png) | Optimism blockchain Raw Data, Decoded Project, or Spell |\n| ![optimism legacy icon](images/explorer-labels/optimism-legacy-icon.png) | Optimism (legacy) blockchain Raw Data, Decoded Project, or Spell |\n| ![bnb chain icon](images/explorer-labels/bnb-chain-icon.png) | BNB Chain Raw Data, Decoded Project, or Spell |\n| ![solana icon](images/explorer-labels/solana-icon.png) | Solana blockchain Raw Data, Decoded Project, or Spell |\n| ![arbitrum icon](images/explorer-labels/arbitrum-icon.png) | Arbitrum blockchain Raw Data, Decoded Project, or Spell |\n| ![avalanche icon](images/explorer-labels/avalanche-icon.png) | Avalanche C-Chain Raw Data, Decoded Project, or Spell |\n| ![goerli testnet icon](images/explorer-labels/goerli-testnet-icon.png) | Ethereum Goerli Testnet Raw Data, Decoded Project, or Spell |\n| ![fantom icon](images/explorer-labels/fantom-icon.png) | Fantom Raw Data, Decoded Project, or Spell |\n\n### Dataset Icons\n\n| Icon      | Description                          |\n| ----------- | ---------------------------------------- |\n| ![table icon 1](images/explorer-labels/table-icon-1.png)![table icon 2](images/explorer-labels/table-icon-2.png) | Data Table (Raw Data, Spell, or smart contract Event or Function) |\n| ![decoded project icon](images/explorer-labels/decoded-project-icon.png) | Decoded Project (protocol or protocol version eg \"opensea\" or \"aave_v2\") |\n| ![spell icon](images/explorer-labels/spell-icon.png) | Spell set (eg cow_protocol contains \"batches\" and \"solvers\" Spells) |\n| ![community data icon](images/explorer-labels/community-data-icon.png) | Community Data Set |\n\n### Dataset Labels\n\n| Label      | Description                          |\n| ----------- | ---------------------------------------- |\n| `project` | A Spell set for a specific project eg `aave` |\n| `sector` | A Spell set for a sector eg `dex` |\n| `event` | A smart contract event dataset |\n| `function` | A smart contract function dataset |", "doc_id": "d561730d-93ee-4b45-b723-870826b628b4", "embedding": null, "doc_hash": "56892a877a5c3e0f3e5237a8aab39c11a47215c31e0260119f067c5ff2f72e83", "extra_info": {"file_path": "docs/app/query-editor/data-explorer.md", "file_name": "data-explorer.md"}, "node_info": {"start": 3241, "end": 5305, "_node_type": "1"}, "relationships": {"1": "75fdb7ce0c015bdb6192677d1a04da8080373b32", "2": "f8246d4e-ae76-4c23-9693-2b2818f0863d"}}, "__type__": "1"}, "b37e8d45-bcf3-4bcf-999c-d5f3647c1f3e": {"__data__": {"text": "---\ntitle: Query Editor\ndescription: Learn more about how Dune's Query Editor works here!\n---\n\nLearn more about how Dune's Query Editor works:\n\n<div class=\"grid cards\" markdown>\n\n-   #### Writing Queries\n\n    ---\n\n    The Query Editor is where you work your Dune by inputting SQL code and running it.  \n    \n    [:octicons-arrow-right-24: Writing Queries](query-window.md)\n\n-   #### Finding Tables\n\n    ---\n\n    The Data Explorer empowers you to search for blockchain and other data to use in your queries.  \n    \n    [:octicons-arrow-right-24: Finding Tables](data-explorer.md)\n\n-   #### Access the Version History\n\n    ---\n\n    Version History allows you to see the history of changes made to your queries.  \n    \n    [:octicons-arrow-right-24: Version History](version-history.md)\n\n-   #### Scheduling Queries\n\n    ---\n\n    Query Scheduler allows you to reliably execute queries in a defined schedule.\n    \n    [:octicons-arrow-right-24: Scheduling Queries](query-scheduler.md)\n</div>\n\n\n", "doc_id": "b37e8d45-bcf3-4bcf-999c-d5f3647c1f3e", "embedding": null, "doc_hash": "abaae3ee7a2b475b3c423794a6c113ab2fd8e79367f28e387982b8dccfc6bb46", "extra_info": {"file_path": "docs/app/query-editor/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 990, "_node_type": "1"}, "relationships": {"1": "6e8399335ad01ebf5bc8c610ad9a8cd928437f60"}}, "__type__": "1"}, "1f92112a-651d-40fc-9066-389909366c25": {"__data__": {"text": "---\ntitle: Scheduling Queries\ndescription: Learn how to leverage the power of query scheduling for a more reliable and up-to-date dashboard display!\n---\n\n**Query Scheduling [allows you to schedule a query](query-scheduler.md#why-schedule-a-query) to run at a specific time and frequency.**\n\nQueries on Dune usually execute when a user triggers an [automatic or interactive execution](query-scheduler.md#when-does-dune-execute-queries). This means that if you have a dashboard that is not frequently viewed, the data displayed on the dashboard may be outdated and execution of the queries will only be triggered once a user views the dashboard. Especially for dashboards that contain resource-intensive queries, this can lead to long loading times for the viewer.\n\nTo keep your dashboard up-to-date and to ensure that your queries are executed reliably and in a timely manner, you can schedule them to run at a specific time and frequency. Scheduled queries can be run on medium and large query engines, which will require credits. Credit costs are the same as any other query execution on Dune, you will pay 10 credits for a medium tier execution and 20 credits for a large tier execution.\n\n### How to Schedule a Query\n\n<div style=\"position: relative; padding-bottom: calc(50.67708333333333% + 41px); height: 0; width: 100%\"><iframe src=\"https://demo.arcade.software/HDqYf2VdwfwMdHFzKh6u?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Query Scheduler V2\"></iframe></div>\n\n\n1. Start by clicking the scheduler (clock) icon located at the bottom of the query editor, to the left of the \"Run\" button\n2. A dialog will prompt you to set a refresh schedule and an execution tier. Please note that scheduled queries can only be run on medium and large query engines, which will require credits.\n3. The dialog will display an estimated monthly credit consumption for this query scheduling, along with a monthly quota. These values will adjust based on the frequency and execution tier you select.\n4. Save the schedule\n5. Your query will execute once to start the schedule, and then will execute according to the schedule you set.\n\n!!! warning\n    - Query scheduling is currently not available for queries with parameters.\n    - The query schedule is removed when the queries are archived or when the ownership changes (e.g., when a query is migrated).\n    - There are no notifications available for scheduled query failures as of now. Rest assured, these failures do not result in any charges to your account.\n#### Adjusting or Cancelling a Query Schedule\n\nIf you need to modify or cancel a query schedule, click on the scheduler icon to open the scheduling dialog. Make changes as needed or click \"Stop\" to cancel the schedule.\n\n![](images/query-scheduler/schedule_query_cancel.gif)\n\n### Why Schedule a Query? \n\nScheduling queries are useful for two reasons:\n\n1. **Increase the execution frequency of your queries**\n2. **Guarantee that resource-intensive queries are executed reliably**\n3. **Maintain fresh data & reliable uptime for your queries and dashboards**\n\n\n#### When does Dune execute queries? \nBefore we dive into the details, let's first take a look at when queries are executed on Dune:\n\n- **Interactive executions** are manually triggered by a user clicking the \"Run\" button in the query editor page or refreshing an entire dashboard. Interactive executions can be routed via the community, medium, or large cluster, depending on the query engine selected.  \n\n- **Automatic", "doc_id": "1f92112a-651d-40fc-9066-389909366c25", "embedding": null, "doc_hash": "0259f7e1f12df9b9103284bf7e4dcd1674dfd2b4ed4e58e380993e94ef638e6b", "extra_info": {"file_path": "docs/app/query-editor/query-scheduler.md", "file_name": "query-scheduler.md"}, "node_info": {"start": 0, "end": 3625, "_node_type": "1"}, "relationships": {"1": "be9bc7a8dc64606386116f4514bd22682be4921d", "3": "57846725-b06b-4935-90bd-e6c67a549c26"}}, "__type__": "1"}, "57846725-b06b-4935-90bd-e6c67a549c26": {"__data__": {"text": "or large cluster, depending on the query engine selected.  \n\n- **Automatic executions** are triggered whenever any user on Dune encounters a widget on a dashboard and the widget's underlying query results are \"expired\". As of now, query results are set to expire every 6 hours, although this is subject to change. These automatic executions are always routed via the community cluster.\n\n- **Scheduled executions** are triggered at a specific time and frequency. Scheduled executions can be routed via the medium or large cluster, depending on the execution tier selected.\n\n\n\n#### 1. Increase the execution frequency of your queries\n\nTo bypass the usual 6-hour expiration time of query results, you can schedule your queries to run at a higher frequency. This will ensure that your dashboard displays the most up-to-date data. \n\n#### 2. Guarantee that resource-intensive queries are executed reliably\n\nAll automatic query executions are routed via the community cluster. This can lead to very long loading times for the viewer if the query is resource-intensive and the community cluster is busy. In the worst case, the query may even time out.\n\nIf you schedule your queries instead of relying on automatic executions, you can choose a higher execution tier, which will ensure that your queries are executed reliably and in a timely manner.\n\n### Additional Info\n\u2795 We plan to extend the functionality of query scheduling with webhooks, alerts, and the ability to update materialized views. We are also working on a allowing you to schedule a whole dashboard at once. Stay tuned for updates!\n\n\ud83d\udcad Have an idea for additional features for scheduled queries? Please [submit them here](https://feedback.dune.com/)! We value your input and are regularly implementing improvements based on user feedback.\n", "doc_id": "57846725-b06b-4935-90bd-e6c67a549c26", "embedding": null, "doc_hash": "e084c09cf1571acb6e4ceb0f9141582d6d0bbf75ca37f4f29c1896309184ba13", "extra_info": {"file_path": "docs/app/query-editor/query-scheduler.md", "file_name": "query-scheduler.md"}, "node_info": {"start": 3551, "end": 5346, "_node_type": "1"}, "relationships": {"1": "be9bc7a8dc64606386116f4514bd22682be4921d", "2": "1f92112a-651d-40fc-9066-389909366c25"}}, "__type__": "1"}, "b3be340a-d2b5-4fe8-b375-1c661132b8cb": {"__data__": {"text": "---\ntitle: Writing Queries\ndescription: The query editor allows you to query blockchain data using DuneSQL.\n---\n\nThe Query Editor is where you construct your queries. You'll probably spend most of your time here.\n\n![Query editor](images/query-window/query-window.png)\n\nTo learn more about how to write queries, check out the [query documentation](../../query/index.md).\n\n## Understanding the query editor\n\nThe Query editor is pretty straightforward. It's a text editor where you can write SQL code.\n\nThe editor has a few features that make your life easier:\n\n- [Autocomplete](#autocomplete)\n- [Run selection](#run-selection)\n- [Explain Query](#explain-query)\n- [Parameters](#parameters)\n\n\n### Autocomplete\n\nThe autocomplete feature will bring up DuneSQL keywords, as well as tables and aliases you've already included in your Query.\nYou can always bring up the autocomplete menu by pressing `ctrl/cmd + space`.\n\nTurn it on/off in the settings.\n\n### Run selection\n\nTo save yourself time while testing and debugging your Queries, you can run just a part of your Query.\n\nTo do this, highlight a part of your Query. You'll then see the <span class=\"fk-btn-1\">Run</span> button turn into a <span class=\"fk-btn-1\">Run selection</span> button.\n\n<div style=\"position: relative; padding-bottom: calc(67.66666666666666% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/Jb2fyuNXBUSLAcMyAOsH?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Dune\"></iframe></div>\n\n\n### Parameters\n\nParameters allow you to implement variables in certain parts of your Query code. This is useful if you want to create a Query that you can reuse with different parameters. \n\nTo use parameters:\n\n1. choose the spot in your Query where you want to implement a parameter\n2. click on the add parameter button or type `{{new_parameter_name}}``\n3. open the parameter options \n4. configure your parameter's name, type, and default value\n\nParameters can be text, numbers,a date or a list of values.\n\nIf you want to use the same parameter between different queries on a dashboard, make sure to use exactly the same settings for the parameter in each query. The parameter will then be shared between the queries and only turn up once in the dashboard's parameter menu.\n\n\n<div style=\"position: relative; padding-bottom: calc(50.67708333333333% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/wEVEG2p4ns4oXV5LSpJ3?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Net flow of stake ETH last 7 days\"></iframe></div>\n\n\n### Explain Query\n\nThe explain query feature utilizes ChatGPT4 to explain your query in plain English. It's a great way to get a quick overview of what your query does.\n\nSimply click the explain query button to see a GPT4 generated explanation of the query.\n\n![Explain query](images/query-window/explain-query.jpeg)\n\n\n### Shortcuts\n\nHere are a handful of shortcuts to make crafting Queries easier:\n\n| Shortcut      | Action                         |\n| ------------- | ------------------------------ |\n| ctrl + enter  | execute the Query              |\n| ctrl + # or / | comments out the selected code", "doc_id": "b3be340a-d2b5-4fe8-b375-1c661132b8cb", "embedding": null, "doc_hash": "551d3897ef6c229d18ab2d86ceace870de941e9ef07ee0460cb046b7f4a792ad", "extra_info": {"file_path": "docs/app/query-editor/query-window.md", "file_name": "query-window.md"}, "node_info": {"start": 0, "end": 3391, "_node_type": "1"}, "relationships": {"1": "12dbbe33d490e31bbf50851055623592349db141", "3": "c07ac0ae-0067-4d4d-842b-fa15ae190b68"}}, "__type__": "1"}, "c07ac0ae-0067-4d4d-842b-fa15ae190b68": {"__data__": {"text": "      |\n| ctrl + # or / | comments out the selected code |\n| ctrl + space  | brings up a list of keywords   |\n| crtl + z      | undoes your last changes       |\n| ctrl + y      | redoes your last changes       |\n| ctrl + f      | search for keywords            |\n| ctrl + h      | search and replace keywords    |\n\n_These shortcuts work on US/UK Keyboards and might vary based on the language setting on your device._\n\n## Query results\n\nThe Query results are displayed in a table below the Query editor.\n\nYou can sort the results by clicking on the column headers. Click once to sort ascending, click again to sort descending.\nResults are paginated, so you can click through the pages to see more results. Each page shows 25 results.\n\nYou can full text search the results by using the search bar below the results table.\n\nYou can format the results according to the rules laid out in the [tables section](/visualizations/tables) of the documentation.\n\n<div style=\"position: relative; padding-bottom: calc(50.67708333333333% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/FrOeNaAh5HBsESAvGUGm?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Net flow of stake ETH last 7 days\"></iframe></div>\n\n", "doc_id": "c07ac0ae-0067-4d4d-842b-fa15ae190b68", "embedding": null, "doc_hash": "66bbc641c69a6914e729f7578f144a1ce8b7d5e4adb15392a35ab252b044f12e", "extra_info": {"file_path": "docs/app/query-editor/query-window.md", "file_name": "query-window.md"}, "node_info": {"start": 3335, "end": 4689, "_node_type": "1"}, "relationships": {"1": "12dbbe33d490e31bbf50851055623592349db141", "2": "b3be340a-d2b5-4fe8-b375-1c661132b8cb"}}, "__type__": "1"}, "902c7cc8-ab57-420e-bc5b-6d83e2d9748f": {"__data__": {"text": "---\ntitle: Access the Version History\ndescription: Queries now have version history, where you can compare and revert to previous query versions.\n---\n\nAll queries now come with version history, where you can compare and revert to previous query versions seamlessly. **You can access version history by clicking the \"clock\" icon on the top left of the query editor.**\n\n!!!History Length\n    Everyone gets 30 days by default, you can upgrade your plan for longer history access. \n\n### Start of a new version\n\nThe first time you save a query (whether it is forked or freshly created), there will be an intial commit to the query history. If you've forked the query, you won't be able to access the original query's edit history - it starts anew for you.\n\n![](images/version-history/version_start.PNG)\n\n### Saving and naming versions\n\nYou can save a new version at any time by running your query. If you leave the page without saving/running, the new version will be lost!\n\n![](images/version-history/version_saved.PNG)\n\nYou can then edit the metadata of the saved version to make it easier to find in the future. \n\n![](images/version-history/simplified_query.gif)\n\n### Comparing and reverting versions\n\nHere's the main feature: you can now easily compare diffs with previous versions, and then revert if you want to. **The reverted query is saved as a new version in the query history.**\n\n![](images/version-history/compare_query.gif)", "doc_id": "902c7cc8-ab57-420e-bc5b-6d83e2d9748f", "embedding": null, "doc_hash": "ca4c3fe00bd22ebab7bbe44ecc79c5b767b86ed7c8addc34ef567a1118a45f71", "extra_info": {"file_path": "docs/app/query-editor/version-history.md", "file_name": "version-history.md"}, "node_info": {"start": 0, "end": 1431, "_node_type": "1"}, "relationships": {"1": "e603e7e87a17aeb00f17727731f1dbfb611eb121"}}, "__type__": "1"}, "b19fe1a0-d685-4692-8f4a-2542490a5f91": {"__data__": {"text": "---\ntitle: Work with your Team\ndescription: Dune Teams are shared workspaces for Wizards to collaborate within.\n---\n\n**Dune Teams are shared workspaces for Wizards to collaborate within.**\n\n## Why Teams?\n\nCreating a Team has several benefits:\n\n1. **Collaborate on the same content.** Teams make it easy for multiple Wizards to work on shared Queries and Dashboards.\n2. **Shared access to paid features.** All Team members can spend credits and access paid features like private Queries and Dashboards.\n3. **A new Team profile.** Showcase all of your Team\u2019s work in one place.\n4. **User roles.** Onboard Team members as viewers, editors or admins.\n\n### Creating a Team\n\nHead over to [**Settings > Teams**](https://dune.com/settings/teams) to create your Team.\n\n### Adding users\n\nYou can invite other Dune Wizards to join your Team in the People section of your Team\u2019s Settings page. When you invite someone you'll need to input their Dune Username.\n\nYou'll also need to assign them one of the following **Roles**:\n\n- \ud83d\udc40 **Viewer:** can see the Team\u2019s content through My Creations and will be listed as a Team member in the Team page. Can also spend credits.\n- \u270f\ufe0f **Editor:** in addition to the above, they can create and edit Queries under the Team\u2019s domain.\n- \u2699\ufe0f **Admin:** in addition to the above, they can manage the Team and its content.\n\n!!! info\n    When you invite a Wizard to join your team we'll email them a link to join. They can also directly go to [Settings > Teams](https://dune.com/settings/teams) and accept their invite there.\n\n### Team content\n\nTeam Queries and Dashboards are created the same way they are for individual accounts. The context you are in determines whether you are creating content for your personal account or for your Team. You can always change the ownership of a Query or Dashboard in their Settings page.\n\n![Team content](images/teams/teams-1.png)\n\n!!! warning\n    Once you transfer content to a Team, you will only be able to transfer it out of the Team if you are an Admin. If you accidentally transfer content to a Team you will have to ask the Team's Admin to transfer it back to you.\n\n\n## Switching Contexts \n\nOnce you are member of a team, you can switch between your personal context and your Team context. Accordingly, the \"my creations\" page will show your personal creations or your team's creations.   \nAdditionally, all queries and dashboards created in the team context will be owned by the team and not by you personally.\n\n<p align=\"center\">\n  <img src=\"../images/context-switcher.jpeg\" alt=\"The context Switcher\" title=\"Context Switcher\" style=\"width: 30%;\" /><br />\n</p>\n\nThe context predicates which credit balance you are spending from. If you are in your personal context, you will spend your personal credits. If you are in your Team's context, you will spend your Team's credits.  \nYou can spend the credits of your team on any content, regardless of whether it is owned by your personal account, your team or another Wizard. \n\nYou can edit the content of your team, regardless of whether you are in the personal or team context.\nIn the [Version History](../app/query-editor/version-history.md) edits you make will be attributed to your personal account, even if you are in your Team's context.\n\n### FAQ\n\n??? question \"Can I have private content?\"\n\n    Private dashboards and queries are available for the team or personal account they are in.\n\n??? question \"How do I edit my role?\"\n\n    You have to ask one of your team admins. If you're an admin, you will still have to ask another admin or upgrade someone else to the admin role. That's to ensure every team always has at least an admin.\n\n??? question \"Can I remove people from my Team?\"\n\n    Yes, you can remove", "doc_id": "b19fe1a0-d685-4692-8f4a-2542490a5f91", "embedding": null, "doc_hash": "2a36ed56caec1f1f005782e9e33574a8314668d61ff12af501b43fbe84b64d21", "extra_info": {"file_path": "docs/app/teams.md", "file_name": "teams.md"}, "node_info": {"start": 0, "end": 3725, "_node_type": "1"}, "relationships": {"1": "5ae1301cc542880d92f78213d959b10a0a2868e7", "3": "05078c76-7257-4dd9-90b8-06c2f41c65ed"}}, "__type__": "1"}, "05078c76-7257-4dd9-90b8-06c2f41c65ed": {"__data__": {"text": "question \"Can I remove people from my Team?\"\n\n    Yes, you can remove people from your Team in the People section of your Team\u2019s Settings page.\n\n??? question \"Can I transfer content to another Team?\"\n\n    Yes, you can transfer content to another Team in the Settings page of the Query or Dashboard you want to transfer.\n\n??? question \"Can I transfer content to another Wizard?\"\n\n    Yes, you can transfer content to another Wizard in the Settings page of the Query or Dashboard you want to transfer.\n    This will only work if the other Wizard is a member of your Team. If they are not, you will have to invite them to your Team first.\n\n??? question \"Can I transfer content to my personal account?\"\n\n    Yes, you can transfer content to your personal account in the Settings page of the Query or Dashboard you want to transfer.\n\n**I have feedback, how do I reach out?**\n\nCome join our [#general-feedback Discord channel](https://discord.com/channels/757637422384283659/1012706316755664926) and we'll be glad to help \ud83d\ude47\u200d\u2642\ufe0f\n", "doc_id": "05078c76-7257-4dd9-90b8-06c2f41c65ed", "embedding": null, "doc_hash": "5e7a417e0667fedb0acb1eafb9dfcabadff115689215550dca9cc2f9666088b5", "extra_info": {"file_path": "docs/app/teams.md", "file_name": "teams.md"}, "node_info": {"start": 3656, "end": 4677, "_node_type": "1"}, "relationships": {"1": "5ae1301cc542880d92f78213d959b10a0a2868e7", "2": "b19fe1a0-d685-4692-8f4a-2542490a5f91"}}, "__type__": "1"}, "e1b52bc8-dde9-4cea-8133-5a6107a3b7db": {"__data__": {"text": "---\ntitle: Create Graphs\ndescription: Charts are good for condensing data points into a Visualization. Learn how to make them here!\n---\n\n**Visualizations make your data come to life! You can create Visualizations from any results of a query.**\n\nGraphs are great for condensing data points into a Visualization.\n\nWith Dune, you can create the following types of graphs:\n\n=== \"Bar charts\"\n\n    ![bar chart example](images/charts-graphs/bar-chart-example.png)\n\n=== \"Area charts\"\n\n    ![area chart example](images/charts-graphs/area-chart.png)\n\n=== \"Scatter charts\"\n\n    ![scatter chart example](images/charts-graphs/scatter-chart-example.png)\n\n=== \"Line charts\"\n\n    ![line chart example](images/charts-graphs/line-chart-example.png)\n\n=== \"Pie charts\"\n\n    ![pie chart example](images/charts-graphs/pie-chart-example.png)\n\n=== \"Mixed graphs\"\n\n    ![mixed graph example](images/charts-graphs/mixed-graph-example.png)\n\n    You can mix all of these graph types together in one Visualization, as long as your base graph isn't a Pie chart.\n\nAll graph Visualizations share a common set of editing options, see the tabs below for how to configure each.\n\n![all visualization configuration options](images/charts-graphs/all-visualization-configuration-options.png)\n\n## Visualization Configuration Options\n\n=== \"Chart options\"\n\n    This section allows you to define how to display your data.\n\n    ![see explanations below](images/charts-graphs/graphs-4.png)\n\n    **Title**\n\n    * The title will appear in all instances of this graph prominently at the top.\n    * The graph will always keep the name of the Query, even if you edit this.\n\n    **Show chart legend**\n\n    * Ticking this box will enable or disable the legend for the chart.\n\n    **Enable stacking**\n\n    * If applicable, ticking this box will stack the chart values on top of each other based on the x-axis values.\n    * If this is not turned on, the values will be plotted individually on the y-axis.\n    * The calculation underpinning this will always group the value corresponding to one value on the x-axis. Make sure your data is clean in able for this to work (avoid gaps in your data).\n\n    **Normalize to percentage data**\n\n    * This will normalize the chart to display percentage values of the chosen data table.\n    * The calculation underpinning this will always group the value corresponding to one value on the x-axis. Make sure your data is clean in able for this to work (avoid gaps in your data).\n\n    **Show data labels**\n\n    * Ticking this box leads to the display of the individual datapoints inside of the graph.\n    * This only makes sense in cases where you have few datapoints that are spread out far enough from each other to not overlap.\n\n=== \"Result data\"\n\n    Here you can pick the data points that are to be displayed.\n\n    ![see explanations below](images/charts-graphs/graphs-5.png)\n\n    You can choose one **x-axis** and multiple **y-axis.**\n\n    Alternatively, you can also choose one data series on the y-axis and choose to group it by a different column of your table (as shown in the example above).\n\n=== \"X-axis options\"\n\n    Using these options you can influence how your x-axis data gets displayed.\n\n    ![see explanations below](images/charts-graphs/graphs-6.png)\n\n    **Axis title**\n\n    * This field allows you to specify a title for your", "doc_id": "e1b52bc8-dde9-4cea-8133-5a6107a3b7db", "embedding": null, "doc_hash": "019b41358ca9ddddc3b92c9cd4e3a059afaa7cce149dc25abe5033cb67022635", "extra_info": {"file_path": "docs/app/visualizations/charts-graphs.md", "file_name": "charts-graphs.md"}, "node_info": {"start": 0, "end": 3330, "_node_type": "1"}, "relationships": {"1": "9f8de3b5c2fb0d2f94ff7a4f3f5f2c33255ff8cc", "3": "0bdb0904-80b6-4b63-bbdd-0b9242191e87"}}, "__type__": "1"}, "0bdb0904-80b6-4b63-bbdd-0b9242191e87": {"__data__": {"text": "title**\n\n    * This field allows you to specify a title for your x-axis.\n\n    **Sort Values**\n\n    * by ticking this box you can specify if you want the values in your chart to be ordered.\n    * If your x-axis is a time series, this will automatically happen.\n\n    **Reverse value**\n\n    * Ticking this box will reverse the order of the values on the x-axis.\n\n    **Logarithmic**\n\n    * Ticking this box will make your x-axis values display \\_\\_ logarithmically.\n\n=== \"Y-axis options\"\n\n    With these options you can influence how your x-axis data gets displayed.\n\n    ![see explanations below](images/charts-graphs/graphs-7.png)\n\n    **Axis title**\n\n    * This field allows you to specify a title for your y-axis.\n\n    **Logarithmic**\n\n    * Ticking this box will make your x-axis values display \\_\\_ logarithmically.\n\n    **Enable right y-axis**\n\n    * Ticking this box will enable an additional y-axis that you can plot values on.\n    * You can choose in the [chart series section](charts-graphs.md#ordering-your-series) what you want to be displayed on the left and right axis.\n\n=== \"Series options\"\n\n    ![](images/charts-graphs/graphs-9.png)\n\n    In this section of the Visualization editor you can finalize your graph.\n\n    * You can rename the \"series\" by simply clicking into the field.\n    * You can change the chart type by clicking into the dropdown.\n    * You can change the colors by clicking into the color box.\n    * Finally you can also change the order of the series.\n\n    **Picking Colors**\n\n    You can pick colors with your browser native color selector.\n\n    This might look slightly different for you depending on which browser you use.\n\n    ![Choose any color you want!](images/charts-graphs/graphs-color.gif)\n\n=== \"Pie options\"\n    \n    ![pie options](images/charts-graphs/pie-options.png)\n    \n    **Label format**\n\n    * This field allows you to define the [tick format](#xy-axis-tick-and-label-formats) of the data labels in your pie chart.\n\n***\n\n## X/Y-axis Tick and Label formats\n\n![](images/charts-graphs/graphs-8.png)\n\nTick formats change how numeric values and axis labels in your graphs are displayed.\n\nHere's how to format them:\n\n| Starting Value        | Tick/Label format | Output          | Description                                                                                                                                           |\n| ------------ | ----------- | --------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 1256784.3745 | `[blank]`  | 1256784.3745000 | Displays the number 7 decimal precision.                                                                        ", "doc_id": "0bdb0904-80b6-4b63-bbdd-0b9242191e87", "embedding": null, "doc_hash": "82d5cd28f5ce61d2af5cd971c18de1dbc409f53dbce3b20a0b69867e039be0e6", "extra_info": {"file_path": "docs/app/visualizations/charts-graphs.md", "file_name": "charts-graphs.md"}, "node_info": {"start": 3281, "end": 6023, "_node_type": "1"}, "relationships": {"1": "9f8de3b5c2fb0d2f94ff7a4f3f5f2c33255ff8cc", "2": "e1b52bc8-dde9-4cea-8133-5a6107a3b7db", "3": "aa3b2ddf-596b-4f7f-83cb-10ea1c0de835"}}, "__type__": "1"}, "aa3b2ddf-596b-4f7f-83cb-10ea1c0de835": {"__data__": {"text": "                                                           |\n| 1256784.3745 | `0`           | 1256784         | Displays only the integer.                                                                                                                            |\n| 1256784.3745 | `0,0`         | 1,256,784       | Only displays the integer with comma separation.                                                                                                      |\n| 1256784.3745 | `0,0.00`      | 1,256,784.38    | Displays the number with [x] decimal precision, where [x] is the number of `0` you add after the decimal point.                                                                |\n| 1256784.3745 | `0.0a`     | 1.2M            | <p>Displays the number with [x] precision and a letter based on the number's 1e[y] power (eg \"m\" for million, \"b\" for billion)  |\n| 1256784.3745 | `$0.0a`    | $1.2M           | Adds a \"\\$\" to the number. Works with all formats above though use of the `a` suffix is recommended. Currently the only \"\\$\" is the only supported currency symbol.                                                                                      |", "doc_id": "aa3b2ddf-596b-4f7f-83cb-10ea1c0de835", "embedding": null, "doc_hash": "7bd3d8d891293b766e3f64ec430c267d1fd8c627917b4ffda9721a5c8c136f14", "extra_info": {"file_path": "docs/app/visualizations/charts-graphs.md", "file_name": "charts-graphs.md"}, "node_info": {"start": 6054, "end": 7225, "_node_type": "1"}, "relationships": {"1": "9f8de3b5c2fb0d2f94ff7a4f3f5f2c33255ff8cc", "2": "0bdb0904-80b6-4b63-bbdd-0b9242191e87"}}, "__type__": "1"}, "a6850047-8ac0-4c91-b2ad-da55471ef0bf": {"__data__": {"text": "---\ntitle: Create counters\ndescription: Counters give you a way to display a single number in a prominent way.\n---\n\n**Counters give you a way to display a single number in a prominent way.**\n\n## Counters\n\nCounters are a great way to provide your audience with immediate \"on a glance\" stats.\n\n![\"on a glance\" stats in https://dune.com/0xBoxer/NFT](images/other-visualizations/counters-1.png)\n\n### Configuring your Counter\n\n![Counters 2](images/other-visualizations/counters-2.png)\n\n#### Counter options\n\nIn this section you can define what kind of data the counter should display:\n\n=== \"Title\"\n\n    * The Title will appear in all instances of this graph prominently at the top\n    * If left blank the Query name will be the only thing that is left standing\n\n=== \"Column\"\n\n    * In this field you can define which column the counter should show.\n\n=== \"Row\"\n\n    * This field can be used to define which row of the underlying data table you want displayed e.g. row 1\n    * Usually this requires you to sort or limit your Query results in order for row 1 to show the wanted results.\n\n***\n\n#### Formatting\n\nThis section is where you can adjust how your numerical data is displayed.\n\n=== \"Prefix\"\n\n    * This field allows you to define a prefix for your counter value.\n    * e.g.: `$`, `\u20ac`, `\u039e`, `\u0e3f`\n\n=== \"Suffix\"\n\n    * This field allows you to define a suffix for your counter value.\n\n=== \"Label\"\n\n    * This field allows you to define a label for your counter value.\n    * The label will appear beneath the counter value as text.\n\n=== \"Decimals\"\n\n    * In this field you can choose how many decimals you want displayed for your counter\n\n***\n\n![label](images/other-visualizations/counters-label-1.png)\n\n", "doc_id": "a6850047-8ac0-4c91-b2ad-da55471ef0bf", "embedding": null, "doc_hash": "32740d7b628a0ea24b7e5dc2e926d0fcc04f2aa870c7b473b3a92f7583d20428", "extra_info": {"file_path": "docs/app/visualizations/counters.md", "file_name": "counters.md"}, "node_info": {"start": 0, "end": 1699, "_node_type": "1"}, "relationships": {"1": "c54cdf811912bf0d1b093377bb878115a1c7559a"}}, "__type__": "1"}, "fee71c90-2d4d-4f64-8dcf-651544d1bb04": {"__data__": {"text": "---\ntitle: Visualizations\ndescription: Learn more about how to make visualizations here!\n---\n\n**Dune offers you several way to display your data.**\n  \n  \n\n<div class=\"grid cards\" markdown>\n\n-   #### Charts & Graphs\n\n    ---\n\n    Create Charts & Graphs to visualize your data.  \n    \n    [:octicons-arrow-right-24: Charts & Graphs](charts-graphs.md)\n\n-   #### Tables\n\n    ---\n\n    Learn how to change the appearance of your tables. \n    \n    [:octicons-arrow-right-24: Tables](tables.md)\n\n-   #### Counters\n\n    ---\n\n    Show off specific data points with counters. \n    \n    [:octicons-arrow-right-24: Counters](counters.md)\n</div>\n\n", "doc_id": "fee71c90-2d4d-4f64-8dcf-651544d1bb04", "embedding": null, "doc_hash": "a9f7d657d7ee95e78bae3065711e05b54614ea870e2f19dee06a5602de062809", "extra_info": {"file_path": "docs/app/visualizations/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 633, "_node_type": "1"}, "relationships": {"1": "b6dde3875b506f0d450a3f8b9a50728329973410"}}, "__type__": "1"}, "693b903e-6743-4d1d-be52-9ea9ce5c8d40": {"__data__": {"text": "---\ntitle: Formatting Tables\ndescription: Tables are a way to display your data in a tabular format.\n---\n\n**Tables are the default Visualization whenever you create and run a Query.**\n\n![query results table example](images/other-visualizations/query-results-table-example.png)\n\nYou can also make more Tables to display your data differently using the <span class=\"fk-btn-2\">New visualization</span> button and drop down menu:\n\n![new table visualization](images/other-visualizations/new-table-visualization.png)\n\n### Configuring your Table\n\n![table configuration options](images/other-visualizations/table-configuration-options.png)\n\n#### Table options\n\n**Title**\n\nThe Title appears at the top of your Table.\n\nLeaving default value (`Table`) or making this blank makes your Table title the same as your Query's title/name.\n\nAdding any other value to this field will add that value first, followed by your Query Name:\n\n![table title example](images/other-visualizations/table-title-example.png)\n\nNote: the default value for \"Query Results\" is treated like an added value.\n\n#### \"Column [x]:\" options\n\nYou can configure the following options for each column in your Table\n\n=== \"Title\"\n\n    The Title appears at the top of your Table.\n\n    Leaving this blank makes your column title the same as its Dune database name.\n\n=== \"Align\"\n\n    This changes the text alignment for the column data and title.\n\n=== \"Format\"\n\n    Allows you to adjust the numerical format of your data following the [X/Y-axis Tick and Label formats here](charts-graphs.md#xy-axis-tick-and-label-formats).\n\n=== \"Hide Column\"\n\n    Hides this column from your table.\n\n***\n\n#### Numerical Column options\n\nColumns that return numerical data have these additional options:\n\n=== \"Type\"\n\n    - `Normal` simply displays the column's numerical data.\n    - `Progress bar` shows the column's numerical data with a progress bar visual that is \"full\" for the column's highest value and \"nearly empty\" for the column's lowest value, with the rest of the data ranging in between:\n\n    ![progress bar example](images/other-visualizations/progress-bar-example.gif)\n\n=== \"Colored Values\"\n\n    Check these boxes to color <span style=\"color:var(--success-green)\">Positive Values Green</span> and <span style=\"color:var(--danger-red)\">Negative Values Red</span>.\n\n    ![colored values example](images/other-visualizations/colored-values-example.jpeg)\n\n", "doc_id": "693b903e-6743-4d1d-be52-9ea9ce5c8d40", "embedding": null, "doc_hash": "65ded9c1c49b1a4a1f591c076a7f3961eb81a7cb7c990dc9e086304826ef4c3f", "extra_info": {"file_path": "docs/app/visualizations/tables.md", "file_name": "tables.md"}, "node_info": {"start": 0, "end": 2398, "_node_type": "1"}, "relationships": {"1": "e0cf334a6611aab79be64eada67f526c545e65dd"}}, "__type__": "1"}, "9afd63ca-98e6-49e7-ae49-7466ac597092": {"__data__": {"text": "# Arbitrages\n\n## **flashbots.arbitrages**\n\nThis table contains records with additional information about each arbitrage trade.\n\nQuery examples can be found here: [Total Arb Protocols](https://dune.com/queries/626076/1167481)\n\n| **Column name**        | **Type**  | **Description**                               |\n| ---------------------- | --------- | --------------------------------------------- |\n| block\\_number          | bigint    | Block number                                  |\n| account\\_address       | string    | Address of the searcher                       |\n| created\\_at            | string    | Time of the record creation                   |\n| end\\_amount            | bigint    | Available amount after the arbitrage          |\n| error                  | string    | Available amount after the arbitrage          |\n| id                     | string    | Internal id of the arbitrage                  |\n| profit\\_amount         | bigint    | Profit amount after the arbitrage             |\n| profit\\_token\\_address | string    | Address of the profit asset                   |\n| protocols              | string    | List of protocols involved in the transaction |\n| start\\_amount          | bigint    | Available amount before the arbitrage         |\n| transaction\\_hash      | string    | Hash of the transaction                       |\n| timestamp              | timestamp | Timestamp of the latest update of the file    |\n", "doc_id": "9afd63ca-98e6-49e7-ae49-7466ac597092", "embedding": null, "doc_hash": "924ca130c45803cd36e55af8cebb2a68a07aca731f7b2aeb4ffbff7f8061ad91", "extra_info": {"file_path": "docs/data-tables/community/flashbots/arbitrages.md", "file_name": "arbitrages.md"}, "node_info": {"start": 0, "end": 1444, "_node_type": "1"}, "relationships": {"1": "02de8b5c5cf82beb550cb7373a766ec393999aa4"}}, "__type__": "1"}, "20f0d466-9944-49e2-aff3-674d6f167b52": {"__data__": {"text": "---\ndescription: >-\n  Flashbots is a research and development organization formed with the goal of\n  making sure MEV incentives do not become opaque and undemocratic.\n---\n\n# Flashbots\n\n**Note:** mev-inspect-py, Flashbots\u2019 open source engine for generating MEV data, is used to power dashboards such as mev-explore and Dune\u2019s Flashbots integration. We\u2019re always looking to improve, fix bugs, cover edge cases, and add protocol coverage to the best of our ability with the help of our community and contributors. We encourage researchers and developers to report and help correct any found bugs, or implement any new features! Feel free to consult the documentation and join the Flashbots discord for more information and updates on our data and mev-inspect.\n\n**Docs:** [https://docs.flashbots.net/](https://docs.flashbots.net)\n\n**Discord:** [https://discord.gg/7hvTycdNcK](https://discord.gg/7hvTycdNcK)\n\nData available:\n\n<div class=\"grid cards\" markdown>\n\n- #### arbitrages\n\n  ---\n\n  Arbitrage opportunities found by mev-inspect-py.\n\n  [:octicons-arrow-right-24: Arbitrages](arbitrages.md)\n\n- #### liquidations\n\n  ---\n\n  Liquidations found by mev-inspect-py.\n\n  [:octicons-arrow-right-24: Liquidations](liquidations.md)\n\n- #### sandwiched_swaps\n\n  ---\n\n  Sandwiched swaps found by mev-inspect-py.\n\n  [:octicons-arrow-right-24: Sandwiched Swaps](sandwiched-swaps.md)\n\n- #### sandwiches \n\n  ---\n\n  Sandwiches found by mev-inspect-py.\n\n  [:octicons-arrow-right-24: Sandwiches](sandwiches.md)\n\n\n- #### mev_summary\n\n  ---\n\n  Summary of MEV found by mev-inspect-py.\n\n  [:octicons-arrow-right-24: MEV Summary](mev_summary.md)\n\n  ", "doc_id": "20f0d466-9944-49e2-aff3-674d6f167b52", "embedding": null, "doc_hash": "a53e8ca3f61fe23da1b345395a6e0c952c477a7315301e58d4ba647bae5af6f8", "extra_info": {"file_path": "docs/data-tables/community/flashbots/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 1622, "_node_type": "1"}, "relationships": {"1": "b04767a5b3481e7dc5d3fd5a34d3b27a19875aab"}}, "__type__": "1"}, "b040e289-cec8-4900-a28e-3e6073f6d396": {"__data__": {"text": "# Liquidations\n\n## **flashbots.liquidations**\n\nLiquidation is another MEV strategy. This table contains details related to executed liquidations.\n\nQuery examples can be found here: [Liquidations by Protocol](https://dune.com/queries/625715/1166880)\n\n| **Column name**          | **Type**  | **Description**                                                                                                     |\n| ------------------------ | --------- | ------------------------------------------------------------------------------------------------------------------- |\n| created\\_at              | string    | Time of the records creation                                                                                        |\n| transaction\\_hash        | string    | Transaction hash                                                                                                    |\n| trace\\_address           | string    | Trace pattern related to the position of the transaction in the chain of all transactions related to the MEV trade. |\n| debt\\_token\\_address     | string    | Underlying token address of the debt to pay                                                                         |\n| received\\_amount         | bigint    | Amount received from the liquidation                                                                                |\n| protocol                 | string    | Protocol name                                                                                                       |\n| liquidated\\_user         | string    | Address of the liquidated user                                                                                      |\n| liquidator\\_user         | string    | Address of the liquidator user               ", "doc_id": "b040e289-cec8-4900-a28e-3e6073f6d396", "embedding": null, "doc_hash": "8bcd149d1b0f673613b232f08162225c05fe0134b909fce022450ad87f6f7545", "extra_info": {"file_path": "docs/data-tables/community/flashbots/liquidations.md", "file_name": "liquidations.md"}, "node_info": {"start": 0, "end": 1767, "_node_type": "1"}, "relationships": {"1": "82a6b008f7988e12a413c401a38b423aed1b854b", "3": "554b3218-f5e6-4611-9edc-55a30c8cd66f"}}, "__type__": "1"}, "554b3218-f5e6-4611-9edc-55a30c8cd66f": {"__data__": {"text": "of the liquidator user                                                                                      |\n| received\\_token\\_address | string    | Address of the received asset                                                                                       |\n| block\\_number            | bigint    | Block number                                                                                                        |\n| debt\\_purchase\\_amount   | bigint    | Amount of purchased debt                                                                                            |\n| timestamp                | timestamp | Timestamp of the latest update of the file                                                                          |\n", "doc_id": "554b3218-f5e6-4611-9edc-55a30c8cd66f", "embedding": null, "doc_hash": "fc404009245f21e8e170a1f51ca959e642f863ecfeecea80193080b690a4fcef", "extra_info": {"file_path": "docs/data-tables/community/flashbots/liquidations.md", "file_name": "liquidations.md"}, "node_info": {"start": 1730, "end": 2476, "_node_type": "1"}, "relationships": {"1": "82a6b008f7988e12a413c401a38b423aed1b854b", "2": "b040e289-cec8-4900-a28e-3e6073f6d396"}}, "__type__": "1"}, "cadc3249-2231-48bf-b80d-451402044792": {"__data__": {"text": "# MEV Summary\n\n## **flashbots.mev_summary**\n\nThis table contains summary of all the classified transactions\n\nQuery examples can be found here: [Miner Revenue from Liquidations and Arbitrages](https://dune.com/queries/625974/1167301)\n\n| **Column name**                      | **Type**  | **Description**                                        |\n| ------------------------------------ | --------- | ------------------------------------------------------ |\n| block\\_timestamp                     | timestamp | Block timestamp                                        |\n| block\\_number                        | bigint    | Block number                                           |\n| base\\_fee\\_per\\_gas                  | bigint    | Base fee per gas                                       |\n| coinbase\\_transfer                   | bigint    | Direct transfer to miner\u2019s address                     |\n| error                                | string    | Error if exists                                        |\n| gas\\_price                           | bigint    | Price of the gas                                       |\n| gas\\_price\\_with\\_coinbase\\_transfer | bigint    | Amount of gas spent + direct transfer to miner address |\n| gas\\_used                            | bigint    | Amount of gas used                                     |\n| gross\\_profit\\_usd                   | double    | Total profit from the transaction in usd               |\n| miner\\_address                       | string    | Address of the miner                                   |\n| miner\\_payment\\_usd                  | double    | Payment received by the miner in usd                   |\n| protocol                             | string    | Main interacted protocol            ", "doc_id": "cadc3249-2231-48bf-b80d-451402044792", "embedding": null, "doc_hash": "8df86f7caf4debfbada6a2c9ae2929269118b6ae9e84575837eebc460d4d27a9", "extra_info": {"file_path": "docs/data-tables/community/flashbots/mev_summary.md", "file_name": "mev_summary.md"}, "node_info": {"start": 0, "end": 1753, "_node_type": "1"}, "relationships": {"1": "98e09188b958147c3d6bc7ea404bf3cd9b4c4df1", "3": "33a1322f-d516-4332-b2e3-43449d291066"}}, "__type__": "1"}, "33a1322f-d516-4332-b2e3-43449d291066": {"__data__": {"text": "  | Main interacted protocol                               |\n| protocols                            | string    | List of protocols involved in the transaction          |\n| transaction\\_hash                    | string    | Hash of the transaction                                |\n| type                                 | string    | Type of the MEV (e.g. arbitrage)                       |\n| timestamp                            | timestamp | Timestamp of the latest update of the file             |\n", "doc_id": "33a1322f-d516-4332-b2e3-43449d291066", "embedding": null, "doc_hash": "4f64c4a6cef82dfb78fc0adb55685a55e8f181dfad9b70c277c89ea7632e588c", "extra_info": {"file_path": "docs/data-tables/community/flashbots/mev_summary.md", "file_name": "mev_summary.md"}, "node_info": {"start": 1713, "end": 2214, "_node_type": "1"}, "relationships": {"1": "98e09188b958147c3d6bc7ea404bf3cd9b4c4df1", "2": "cadc3249-2231-48bf-b80d-451402044792"}}, "__type__": "1"}, "f273704c-11d1-4a41-807f-0e66d7072d80": {"__data__": {"text": "# Sandwiched Swaps\n\n## **flashbots.sandwiched\\_swaps**\n\nThe sandwiched\\_swaps table contains additional data about one or more swaps that were sandwiched with a corresponding sandwich in the database.\n\nQuery examples can be found here:\n\n| **Column name**   | **Type**  | **Description**                                                                                             |\n| ----------------- | --------- | ----------------------------------------------------------------------------------------------------------- |\n| created\\_at       | string    | Time of the records creation                                                                                |\n| block\\_number     | bigint    | Block number                                                                                                |\n| sandwich\\_id      | string    | Internal id of the sandwiched swap                                                                          |\n| trace\\_address    | string    | Trace pattern related to the position of the swap in the chain of all swaps related to the arbitrage trade. |\n| transaction\\_hash | string    | Transaction hash                                                                                            |\n| timestamp         | timestamp | Timestamp of the latest update of the file                                                                  |\n", "doc_id": "f273704c-11d1-4a41-807f-0e66d7072d80", "embedding": null, "doc_hash": "54f0e9d0844badcdf72de64bb4170103b0b3d2ee90874c24b50cddc1d5cfa667", "extra_info": {"file_path": "docs/data-tables/community/flashbots/sandwiched-swaps.md", "file_name": "sandwiched-swaps.md"}, "node_info": {"start": 0, "end": 1389, "_node_type": "1"}, "relationships": {"1": "20215a3c1c7147517a946a03fe51e5b219211688"}}, "__type__": "1"}, "afd26714-7d65-4168-bd98-0f4794f08e36": {"__data__": {"text": "# Sandwiches\n\n## **sandwiches**\n\nThis table contains detailed information about executed sandwiches\n\n| **Column name**                   | **Type**  | **Description**                                                 |\n| --------------------------------- | --------- | --------------------------------------------------------------- |\n| created\\_at                       | datetime  | Time of the records creation                                    |\n| block\\_number                     | bigint    | Block number                                                    |\n| backrun\\_swap\\_trace\\_address     | string    | address of the swap in the backrun transaction                  |\n| backrun\\_swap\\_transaction\\_hash  | string    | transaction\\_hash of backrun transaction of specified sandwich  |\n| frontrun\\_swap\\_trace\\_address    | string    | address of the swap in the frontrun transaction                 |\n| frontrun\\_swap\\_transaction\\_hash | string    | transaction\\_hash of frontrun transaction of specified sandwich |\n| id                                | string    | Internal id of the sandwich                                     |\n| profit\\_amount                    | bigint    | Profit amount after the arbitrage                               |\n| profit\\_token\\_address            | string    | Address of the profit asset                                     |\n| sandwicher\\_address               | string    | Address of the sandwicher                                       |\n| timestamp                         | timestamp | Timestamp of the latest update of the file                      |\n\n## \\*\\*\\*\\*\n", "doc_id": "afd26714-7d65-4168-bd98-0f4794f08e36", "embedding": null, "doc_hash": "44ccaaa7c2666f89c200063b58822a7d4ab01e158331b0f73b9f85ffa73e96e3", "extra_info": {"file_path": "docs/data-tables/community/flashbots/sandwiches.md", "file_name": "sandwiches.md"}, "node_info": {"start": 0, "end": 1622, "_node_type": "1"}, "relationships": {"1": "2ae98d5f1e2d0b0467799fcb1fc9bd4b794803d7"}}, "__type__": "1"}, "854c7191-ebb6-4594-be0c-b6e66a741a74": {"__data__": {"text": "---\ntitle: Community\ndescription: This section contains data that has been submitted and hosted on Dune by 3rd party data providers\n---\n\n!!! note\n    Community is only available on V2 Engine.\n\nWhile Blockchain data is cool on it's own and we do our best to prepare, standardize and work with that data, sometimes a bit of off-chain data or augmented on-chain data is needed as well. Therefore, we are starting to partner with selected organizations that stream their data directly to Dune.\n\nWe are still building out the infrastructure for this endeavor and can therefore not support more datasets at the current moment.\n\n<div class=\"cards grid\" markdown>\n- [Flashbots](flashbots/index.md)\n- [Reservoir](reservoir/index.md)\n</div>\n", "doc_id": "854c7191-ebb6-4594-be0c-b6e66a741a74", "embedding": null, "doc_hash": "c6a9f39c0bbb2f73bf94679c8634b6d82ae8e577e43a753e6cfe502f3f5935f5", "extra_info": {"file_path": "docs/data-tables/community/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 731, "_node_type": "1"}, "relationships": {"1": "37ee1ab8a924f48d373c8d3915cf04d056a9ac2a"}}, "__type__": "1"}, "5c8059f1-1401-4f54-ac6b-1301b07d4d2d": {"__data__": {"text": "# Ask Events\n\n## **reservoir.ask\\_events**\n\nThis table contains records with information about each ask change.\n\nQuery examples can be found here:\n\n[https://dune.com/queries/1302858/2232178](https://dune.com/queries/1302858/2232178)\n\n[https://dune.com/queries/1302863/2232189](https://dune.com/queries/1302863/2232189)\n\n| **Column name**     | **Type**   | **Description**                                                                                                 |\n|---------------------|------------|-----------------------------------------------------------------------------------------------------------------|\n| id                  | bigint     | Internal event id                                                                                               |\n| kind                | string     | Event type (new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, reprice) |\n| contract            | string     | Contract address                                                                                                |\n| token\\_id           | string     | Id of the token in the collection                                                                               |\n| order\\_id           | string     | Associated ask id                                                                                               |\n| maker               | string     | Associated ask maker wallet address                                                                             |\n| price               | decimal    | Associated ask price (native currency)                                                                       ", "doc_id": "5c8059f1-1401-4f54-ac6b-1301b07d4d2d", "embedding": null, "doc_hash": "4ccf18d79776c5de5058bfed99af1dc91e96f9e5332858a6f0c7c527e1d4d8db", "extra_info": {"file_path": "docs/data-tables/community/reservoir/ask-events.md", "file_name": "ask-events.md"}, "node_info": {"start": 0, "end": 1674, "_node_type": "1"}, "relationships": {"1": "53dd871c76c7b89720ebfb5b249ebe8bdb0f69e8", "3": "1279dbd0-37cb-4f67-949b-7dab1b7ca70d"}}, "__type__": "1"}, "1279dbd0-37cb-4f67-949b-7dab1b7ca70d": {"__data__": {"text": "                      |\n| quantity\\_remaining | bigint     | Associated ask tokens remaining                                                                                 |\n| valid\\_from         | bigint     | Associated ask validity start                                                                                   |\n| valid\\_until        | bigint     | Associated ask validity expiration                                                                              |\n| source              | string     | Source of the order (e.g. opensea.io)                                                                           |\n| tx\\_hash            | string     | Associated transaction hash                                                                                     |\n| tx\\_timestamp       | bigint     | Associated transaction timestamp                                                                                |\n| created\\_at         | timestamp  | Timestamp the event was recorded                                                                                |\n", "doc_id": "1279dbd0-37cb-4f67-949b-7dab1b7ca70d", "embedding": null, "doc_hash": "f20ca9a28141c6d11d281db3586a700c5fdc10efec0f75ce80623d1cdc2960da", "extra_info": {"file_path": "docs/data-tables/community/reservoir/ask-events.md", "file_name": "ask-events.md"}, "node_info": {"start": 1655, "end": 2736, "_node_type": "1"}, "relationships": {"1": "53dd871c76c7b89720ebfb5b249ebe8bdb0f69e8", "2": "5c8059f1-1401-4f54-ac6b-1301b07d4d2d"}}, "__type__": "1"}, "a2fc14f8-20f2-48ba-bac4-db154a32aba5": {"__data__": {"text": "# Asks\n\n## **reservoir.asks**\n\nThis table contains records with information about each listing.\n\nQuery examples can be found here:\n\n[https://dune.com/queries/1302885/2232229](https://dune.com/queries/1302885/2232229)\n\n[https://dune.com/queries/1302904/2232257](https://dune.com/queries/1302904/2232257)\n\n| **Column name**     | **Type**  | **Description**                              |\n|---------------------|-----------|----------------------------------------------|\n| id                  | string    | Internal order id                            |\n| kind                | string    | Protocol name (e.g. seaport)                 |\n| status              | string    | Order status (active, inactive)              |\n| contract            | string    | Contract address                             |\n| token\\_id           | string    | Id of the token in the collection            |\n| maker               | string    | Maker wallet address                         |\n| taker               | string    | Taker wallet address                         |\n| price               | decimal   | The current price (native currency)          |\n| start\\_price        | bigint    | Start Listing price (for dutch auctions)     |\n| end\\_price          | bigint    | End Listing price (for dutch auctions)       |\n| currency\\_address   | string    | Currency address                             |\n| currency\\_symbol    | string    | Currency symbol                              |\n| currency\\_price     | decimal   | Currency price                               |\n| dynamic             | boolean   | Is dutch auction?                            |\n| quantity            | bigint    | Amount of tokens that is listed              |\n| quantity\\_filled    | bigint    | Amount of tokens that was filled             |\n| quantity\\_remaining | bigint    | Amount of tokens remaining                   |\n| valid\\_from         | bigint    | Listing start time    ", "doc_id": "a2fc14f8-20f2-48ba-bac4-db154a32aba5", "embedding": null, "doc_hash": "5ce9f1163ef198c5ac967972cb1fb87f4580384772dcafc5042ea54271a93877", "extra_info": {"file_path": "docs/data-tables/community/reservoir/asks.md", "file_name": "asks.md"}, "node_info": {"start": 0, "end": 1939, "_node_type": "1"}, "relationships": {"1": "289fdcc7bb684cb250ebb6c44e8e64e8240df2c5", "3": "49d365f1-e2f0-4f56-8c0f-9db721174c8a"}}, "__type__": "1"}, "49d365f1-e2f0-4f56-8c0f-9db721174c8a": {"__data__": {"text": "     | bigint    | Listing start time                           |\n| valid\\_until        | bigint    | Listing end time                             |\n| nonce               | string    | The order nonce of the maker                 |\n| source              | string    | Source of the listing (e.g. opensea.io)      |\n| fee\\_bps            | bigint    | Listing fee                                  |\n| expiration          | bigint    | Associated transaction hash                  |\n| raw\\_data           | string    | Raw order data (format will vary per source) |\n| created\\_at         | timestamp | Timestamp the listing was created            |\n| updated\\_at         | timestamp | Timestamp the listing was updated            |\n", "doc_id": "49d365f1-e2f0-4f56-8c0f-9db721174c8a", "embedding": null, "doc_hash": "d254b68fa8b99dc6a853555132addca17bc9eebbe67b2dad71c613ac8e5aac89", "extra_info": {"file_path": "docs/data-tables/community/reservoir/asks.md", "file_name": "asks.md"}, "node_info": {"start": 1898, "end": 2628, "_node_type": "1"}, "relationships": {"1": "289fdcc7bb684cb250ebb6c44e8e64e8240df2c5", "2": "a2fc14f8-20f2-48ba-bac4-db154a32aba5"}}, "__type__": "1"}, "89f93007-789a-4127-bbd3-0e154e59ae15": {"__data__": {"text": "# Attribute Keys\n\n## **reservoir.attribute\\_keys**\n\nThis table contains records with information about each attribute key.\n\nQuery examples can be found here:\n\n[https://dune.com/queries/1302930/2232305](https://dune.com/queries/1302930/2232305)\n\n| **Column name** | **Type**  | **Description**                          |\n|-----------------|-----------|------------------------------------------|\n| id              | string    | Internal attribute key id                |\n| collection\\_id  | string    | Associated collection id                 |\n| key             | string    | The name of the attribute                |\n| kind            | string    | Value type (string, number, date, range) |\n| rank            | string    | Sort order                               |\n| created\\_at     | timestamp | Timestamp the attribute key was created  |\n| updated\\_at     | timestamp | Timestamp the attribute key was updated  |\n", "doc_id": "89f93007-789a-4127-bbd3-0e154e59ae15", "embedding": null, "doc_hash": "be661d53365754d70ddc48f21e8df8059fd302e259adf5948a7e894a11e3c871", "extra_info": {"file_path": "docs/data-tables/community/reservoir/attribute-keys.md", "file_name": "attribute-keys.md"}, "node_info": {"start": 0, "end": 920, "_node_type": "1"}, "relationships": {"1": "931ad55b2927da963c205adc9283abdccc064f0c"}}, "__type__": "1"}, "541b6c04-b8f0-4cf6-bd3b-ecd0242f5e60": {"__data__": {"text": "# Attributes\n\n## **reservoir.attributes**\n\nThis table contains records with information about each attribute.\n\nQuery examples can be found here:\n\n[https://dune.com/queries/1302927/2232298](https://dune.com/queries/1302927/2232298)\n\n[https://dune.com/queries/1302966/2232361](https://dune.com/queries/1302966/2232361)\n\n| **Column name**    | **Type**  | **Description**                                            |\n|--------------------|-----------|------------------------------------------------------------|\n| id                 | bigint    | Internal attribute id                                      |\n| attribute\\_key\\_id | bigint    | Internal attribute key id                                  |\n| value              | string    | Attribute value                                            |\n| token\\_count       | bigint    | Amount of tokens that have the attribute                   |\n| on\\_sale\\_count    | bigint    | Amount of tokens that have the attribute which are on sale |\n| floor\\_sell\\_value | decimal   | Current floor ask price                                    |\n| sell\\_updated\\_at  | timestamp | Timestamp the floor sale was last updated                  |\n| collection\\_id     | string    | Associated collection id                                   |\n| kind               | string    | Value type (string, number, date, range)                   |\n| key                | string    | Associated key name                                        |\n| created\\_at        | timestamp | Timestamp the attribute was created                        |\n| updated\\_at        | timestamp | Timestamp the attribute was updated                        |\n", "doc_id": "541b6c04-b8f0-4cf6-bd3b-ecd0242f5e60", "embedding": null, "doc_hash": "92bd7fe5c77e677cdaac09b54493095372d4f312f2b5c5224082bacfea12d63c", "extra_info": {"file_path": "docs/data-tables/community/reservoir/attributes.md", "file_name": "attributes.md"}, "node_info": {"start": 0, "end": 1662, "_node_type": "1"}, "relationships": {"1": "2a6f7d19dc780c431987c6ecf37dcc6ad21ac4b6"}}, "__type__": "1"}, "8053d478-544d-438c-a923-753619cf6bc2": {"__data__": {"text": "# Bid Events\n\n## **reservoir.bid\\_events**\n\nThis table contains records with information about each bid change.\n\nQuery examples can be found here: [TBD](TBD)\n\n| **Column name**     | **Type**  | **Description**                                                                                                 |\n| ------------------- | --------- | --------------------------------------------------------------------------------------------------------------- |\n| id                  | string    | Internal event id                                                                                               |\n| kind                | string    | Event type (new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, reprice) |\n| status              | string    | Event status (active, expired)                                                                                  |\n| contract            | string    | Contract address                                                                                                |\n| token\\_set\\_id      | string    | Id of the token set                                                                                             |\n| order\\_id           | string    | Associated bid id                                                                                               |\n| maker               | string    | Associated bid maker wallet address                                                                             |\n| price               | string    | Associated bid price (native currency)                          ", "doc_id": "8053d478-544d-438c-a923-753619cf6bc2", "embedding": null, "doc_hash": "2fd9e3a1ea43a01a35663035627ab0b3da2b3969cf8dae3b1444d18aa94fe35e", "extra_info": {"file_path": "docs/data-tables/community/reservoir/bid-events.md", "file_name": "bid-events.md"}, "node_info": {"start": 0, "end": 1609, "_node_type": "1"}, "relationships": {"1": "e39e6325eee6099ae006fe360d3deabc3ecb97ec", "3": "dd514643-e072-463f-8241-aa6879f935f2"}}, "__type__": "1"}, "dd514643-e072-463f-8241-aa6879f935f2": {"__data__": {"text": "                                                                   |\n| value               | string    | Associated bid value (native currency)                                                                          |\n| quantity\\_remaining | bigint    | Associated bid tokens remaining                                                                                 |\n| valid\\_from         | bigint    | Associated bid validity start                                                                                   |\n| valid\\_until        | bigint    | Associated bid validity expiration                                                                              |\n| source              | string    | Source of the order (e.g. opensea.io)                                                                           |\n| tx\\_hash            | string    | Associated transaction hash                                                                                     |\n| tx\\_timestamp       | bigint    | Associated transaction timestamp                                                                                |\n| created\\_at         | timestamp | Timestamp the event was recorded                                                                                |\n", "doc_id": "dd514643-e072-463f-8241-aa6879f935f2", "embedding": null, "doc_hash": "ab1fa00502de44dc26f6ddf55ca25b85d0b84ffd570880f9e1d714f6940d74c5", "extra_info": {"file_path": "docs/data-tables/community/reservoir/bid-events.md", "file_name": "bid-events.md"}, "node_info": {"start": 1590, "end": 2859, "_node_type": "1"}, "relationships": {"1": "e39e6325eee6099ae006fe360d3deabc3ecb97ec", "2": "8053d478-544d-438c-a923-753619cf6bc2"}}, "__type__": "1"}, "4a3d6c75-2992-4386-9e85-a113c95eb4cc": {"__data__": {"text": "# Bids\n\n## **reservoir.bids**\n\nThis table contains records with information about each bid.\n\nQuery examples can be found here: [TBD](TBD)\n\n| **Column name**     | **Type**  | **Description**                              |\n| ------------------- | --------- | -------------------------------------------- |\n| id                  | string    | Internal order id                            |\n| kind                | string    | Protocol name (e.g. seaport)                 |\n| status              | string    | Order status (active, inactive)              |\n| contract            | string    | Contract address                             |\n| token\\_set\\_id      | string    | Id of the token set                          |\n| maker               | string    | Maker wallet address                         |\n| taker               | string    | Taker wallet address                         |\n| price               | string    | The current price (native currency)          |\n| value               | string    | The current value (native currency)          |\n| currency\\_address   | string    | Currency address                             |\n| currency\\_symbol    | string    | Currency symbol                              |\n| currency\\_price     | string    | Currency price                               |\n| quantity            | bigint    | Amount of tokens that is listed              |\n| quantity\\_filled    | bigint    | Amount of tokens that was filled             |\n| quantity\\_remaining | bigint    | Amount of tokens remaining                   |\n| valid\\_from         | bigint    | Listing start time                           |\n| valid\\_until        | bigint    | Listing end time                             |\n| nonce               | bigint    | The order nonce of the maker                 |\n| source              | string    | Source of the", "doc_id": "4a3d6c75-2992-4386-9e85-a113c95eb4cc", "embedding": null, "doc_hash": "5830c6cc831d7092044af0d6cc05a7f0acf318e09c9f77811a459d96506bfff1", "extra_info": {"file_path": "docs/data-tables/community/reservoir/bids.md", "file_name": "bids.md"}, "node_info": {"start": 0, "end": 1848, "_node_type": "1"}, "relationships": {"1": "e193f392c8bf7ebbb52bce2abb2f050810796ba4", "3": "8702ae4e-4d6f-4132-b6a7-fb60864c10fc"}}, "__type__": "1"}, "8702ae4e-4d6f-4132-b6a7-fb60864c10fc": {"__data__": {"text": "           | string    | Source of the listing (e.g. opensea.io)      |\n| fee\\_bps            | bigint    | Listing fee                                  |\n| expiration          | bigint    | Associated transaction hash                  |\n| raw\\_data           | string    | Raw order data (format will vary per source) |\n| created\\_at         | timestamp | Timestamp the listing was created            |\n| updated\\_at         | timestamp | Timestamp the listing was updated            |\n", "doc_id": "8702ae4e-4d6f-4132-b6a7-fb60864c10fc", "embedding": null, "doc_hash": "f23773a6ebfb0341c2df6222aa727c155c8cfbde3a77a23bf9e9407706885aba", "extra_info": {"file_path": "docs/data-tables/community/reservoir/bids.md", "file_name": "bids.md"}, "node_info": {"start": 1810, "end": 2297, "_node_type": "1"}, "relationships": {"1": "e193f392c8bf7ebbb52bce2abb2f050810796ba4", "2": "4a3d6c75-2992-4386-9e85-a113c95eb4cc"}}, "__type__": "1"}, "3c14273b-380d-4fe1-babd-c1078638dd16": {"__data__": {"text": "# Collection Floor Ask Events\n\n## **reservoir.collection\\_floor\\_ask\\_events**\n\nThis table contains records with information about each collection floor ask change.\n\nQuery examples can be found here:\n\n[https://dune.com/queries/1302799/2232083](https://dune.com/queries/1302799/2232083)\n\n[https://dune.com/queries/1302841/2232151](https://dune.com/queries/1302841/2232151)\n\n| **Column name** | **Type**  | **Description**                                                                                                 |\n|-----------------|-----------|-----------------------------------------------------------------------------------------------------------------|\n| id              | bigint    | Internal event id                                                                                               |\n| kind            | string    | Event type (new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, reprice) |\n| collection\\_id  | string    | Collection id                                                                                                   |\n| contract        | string    | Contract address                                                                                                |\n| token\\_id       | string    | Id of the token in the collection                                                                               |\n| order\\_id       | string    | Associated ask id                                                                                               |\n| maker           | string    | Associated ask maker wallet address                                                                             |\n| price ", "doc_id": "3c14273b-380d-4fe1-babd-c1078638dd16", "embedding": null, "doc_hash": "687c83c3acbea7f2553956665900a962f923a1a74895a7ccceb3b512e29ea478", "extra_info": {"file_path": "docs/data-tables/community/reservoir/collection-floor-ask-events.md", "file_name": "collection-floor-ask-events.md"}, "node_info": {"start": 0, "end": 1695, "_node_type": "1"}, "relationships": {"1": "12b396288e590ffc0362e7d51ba2bf194980cf88", "3": "c10d08d1-558b-4ed9-8c0e-c1e64ea2d08d"}}, "__type__": "1"}, "c10d08d1-558b-4ed9-8c0e-c1e64ea2d08d": {"__data__": {"text": "               |\n| price           | decimal   | Associated ask price (native currency)                                                                          |\n| previous\\_price | decimal   | previous floor ask price (native currency)                                                                      |\n| valid\\_until    | bigint    | Associated ask validity expiration                                                                              |\n| source          | string    | Source of the order (e.g. opensea.io)                                                                           |\n| tx\\_hash        | string    | Associated transaction hash                                                                                     |\n| tx\\_timestamp   | bigint    | Associated transaction timestamp                                                                                |\n| created\\_at     | timestamp | Timestamp the event was recorded                                                                                |\n", "doc_id": "c10d08d1-558b-4ed9-8c0e-c1e64ea2d08d", "embedding": null, "doc_hash": "b6bd39b4cf2ce9fecbf28819ad24527b2d5525766909d80a29f6121ab9e5aa9c", "extra_info": {"file_path": "docs/data-tables/community/reservoir/collection-floor-ask-events.md", "file_name": "collection-floor-ask-events.md"}, "node_info": {"start": 1670, "end": 2709, "_node_type": "1"}, "relationships": {"1": "12b396288e590ffc0362e7d51ba2bf194980cf88", "2": "3c14273b-380d-4fe1-babd-c1078638dd16"}}, "__type__": "1"}, "5dc29253-a690-4b39-ba33-f11a5a8dbbb4": {"__data__": {"text": "# Collection Top Bid Events\n\n## **reservoir.collection\\_top\\_bid\\_events**\n\nThis table contains records with information about each collection top bid change.\n\nQuery examples can be found here: [TBD](TBD)\n\n| **Column name** | **Type**  | **Description**                                                                                                 |\n|-----------------|-----------|-----------------------------------------------------------------------------------------------------------------|\n| id              | string    | Internal event id                                                                                               |\n| kind            | string    | Event type (new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, reprice) |\n| collection\\_id  | string    | Collection id                                                                                                   |\n| contract        | string    | Contract address                                                                                                |\n| token\\_id       | string    | Id of the token in the collection                                                                               |\n| order\\_id       | string    | Associated bid id                                                                                               |\n| maker           | string    | Associated bid maker wallet address                                                                             |\n| price           | string    | Associated bid price (native currency)                                                  ", "doc_id": "5dc29253-a690-4b39-ba33-f11a5a8dbbb4", "embedding": null, "doc_hash": "647ddff9d27afeb19e4d8624ccd942ea955df14e5ae6ee1b28d80805dcf9aeda", "extra_info": {"file_path": "docs/data-tables/community/reservoir/collection-top-bid-events.md", "file_name": "collection-top-bid-events.md"}, "node_info": {"start": 0, "end": 1640, "_node_type": "1"}, "relationships": {"1": "3b7d233595bfeff028b98d61a84fe66cdeae663c", "3": "66ec64ae-11f6-48a1-a238-672c41ac062c"}}, "__type__": "1"}, "66ec64ae-11f6-48a1-a238-672c41ac062c": {"__data__": {"text": "                                           |\n| previous\\_price | decimal   | previous top bid price (native currency)                                                                        |\n| valid\\_until    | bigint    | Associated bid validity expiration                                                                              |\n| source          | string    | Source of the order (e.g. opensea.io)                                                                           |\n| tx\\_hash        | string    | Associated transaction hash                                                                                     |\n| tx\\_timestamp   | bigint    | Associated transaction timestamp                                                                                |\n| created\\_at     | timestamp | Timestamp the event was recorded                                                                                |\n", "doc_id": "66ec64ae-11f6-48a1-a238-672c41ac062c", "embedding": null, "doc_hash": "126801669e52bcc4571de62a475a71960e51c7a8c9880e88ee838392eda232f4", "extra_info": {"file_path": "docs/data-tables/community/reservoir/collection-top-bid-events.md", "file_name": "collection-top-bid-events.md"}, "node_info": {"start": 1621, "end": 2542, "_node_type": "1"}, "relationships": {"1": "3b7d233595bfeff028b98d61a84fe66cdeae663c", "2": "5dc29253-a690-4b39-ba33-f11a5a8dbbb4"}}, "__type__": "1"}, "f74e5e13-75f3-4481-9898-eae14123c143": {"__data__": {"text": "# Collections\n\n## **reservoir.collections**\n\nThis table contains records with information about each NFT collection.\n\nQuery examples can be found here:\n\n[https://dune.com/queries/1302781/2232054](https://dune.com/queries/1302781/2232054)\n\n[https://dune.com/queries/1302788/2232065](https://dune.com/queries/1302788/2232065)\n\n| **Column name**            | **Type**  | **Description**                             |\n|----------------------------|-----------|---------------------------------------------|\n| id                         | string    | Internal collection id                      |\n| slug                       | string    | Collection slug                             |\n| name                       | string    | Collection name                             |\n| description                | string    | Collection description                      |\n| token\\_count               | bigint    | Id of the token in the collection           |\n| contract                   | string    | Contract address                            |\n| day1\\_rank                 | bigint    | Ranking in the previous day                 |\n| day7\\_rank                 | bigint    | Ranking in the previous 7 days              |\n| day30\\_rank                | bigint    | Ranking in the previous 30 days             |\n| all\\_time\\_rank            | bigint    | All time ranking                            |\n| day1\\_volume               | decimal   | Trade volume in the previous day            |\n| day7\\_volume               | decimal   | Trade volume in the previous 7 days         |\n| day30\\_volume              | decimal   | Trade volume in the previous 30 days        |\n| all\\_time\\_volume          | decimal   | All time trade volume                       |\n| day1\\_volume\\_change       | double    | Trade volume change in the previous day     |\n| day7\\_volume\\_change       | double    | Trade volume change in the previous 7 days  |\n| day30\\_volume\\_change", "doc_id": "f74e5e13-75f3-4481-9898-eae14123c143", "embedding": null, "doc_hash": "1f3a77be702b8b17ef6936ab5ba469c9ce5ef076e7bd8db8b7e2d221bb76034b", "extra_info": {"file_path": "docs/data-tables/community/reservoir/collections.md", "file_name": "collections.md"}, "node_info": {"start": 0, "end": 1950, "_node_type": "1"}, "relationships": {"1": "6944cccd045271bb98ad1db1f322bc71b7a63115", "3": "fb750b13-8f7e-442f-9660-575bb7200a71"}}, "__type__": "1"}, "fb750b13-8f7e-442f-9660-575bb7200a71": {"__data__": {"text": "volume change in the previous 7 days  |\n| day30\\_volume\\_change      | double    | Trade volume change in the previous 30 days |\n| floor\\ask\\_value           | decimal   | Current floor sale price (native currency)  |\n| day1\\_floor\\_sale\\_value   | decimal   | Floor sale price in the previous day        |\n| day7\\_floor\\_sale\\_value   | decimal   | Floor sale price 7 days ago                 |\n| day30\\_floor\\_sale\\_value  | decimal   | Floor sale price 30 days ago                |\n| day1\\_floor\\_sale\\_change  | double    | Floor sale price change from previous day   |\n| day7\\_floor\\_sale\\_change  | double    | Floor sale price change from 7 days ago     |\n| day30\\_floor\\_sale\\_change | double    | Floor sale price change from 30 days ago    |\n| created\\_at                | timestamp | Timestamp the collection was created        |\n| updated\\_at                | timestamp | Timestamp the collection was updated        |                                                               |\n", "doc_id": "fb750b13-8f7e-442f-9660-575bb7200a71", "embedding": null, "doc_hash": "4f2ecf72e4cc7d0284290ef87e2276a4b8bc8b9efe85fd0f4c1e5ba80755c9fb", "extra_info": {"file_path": "docs/data-tables/community/reservoir/collections.md", "file_name": "collections.md"}, "node_info": {"start": 1887, "end": 2881, "_node_type": "1"}, "relationships": {"1": "6944cccd045271bb98ad1db1f322bc71b7a63115", "2": "f74e5e13-75f3-4481-9898-eae14123c143"}}, "__type__": "1"}, "8c5abd63-edd2-4b05-95d9-809d33f1a84f": {"__data__": {"text": "---\ntitle: Reservoir\ndescription: Reservoir is enabling the next generation of NFT products and liquidity sources through open-source, on-chain NFT order aggregation.\n---\n\n# Reservoir\n\n**Dashboard:** [https://dune.com/reservoir0x/reservoir-dune-docs-dashboard](https://dune.com/reservoir0x/reservoir-dune-docs-dashboard)\n\n**Docs:** [https://docs.reservoir.tools/docs](https://docs.reservoir.tools/docs)\n\n**Discord:** [https://discord.gg/jbEUwrVx](https://discord.gg/jbEUwrVx)\n\n\nData available:\n\n<div class=\"cards grid\" markdown>\n\n-   #### [Ask Events](ask-events.md)\n\n    Information about Ask events in a marketplace.\n  \n    [:octicons-arrow-right-24: Ask Events](ask-events.md)\n\n-   #### [Bid Events](bid-events.md)\n\n    Information about Bid events in a marketplace.\n  \n    [:octicons-arrow-right-24: Bid Events](bid-events.md)\n\n-   #### [Collections](collections.md)\n\n    Information about NFT collections.\n  \n    [:octicons-arrow-right-24: Collections](collections.md)\n\n-   #### [Token Floor Ask Events](token-floor-ask-events.md)\n\n    Information about Token Floor Ask events in a marketplace.\n  \n    [:octicons-arrow-right-24: Token Floor Ask Events](token-floor-ask-events.md)\n\n-   #### [Asks](asks.md)\n\n    Information about Asks in a marketplace.\n  \n    [:octicons-arrow-right-24: Asks](asks.md)\n\n-   #### [Bids](bids.md)\n\n    Information about Bids in a marketplace.\n  \n    [:octicons-arrow-right-24: Bids](bids.md)\n\n-   #### [Tokens](tokens.md)\n\n    Information about ERC-721 tokens.\n  \n    [:octicons-arrow-right-24: Tokens](tokens.md)\n\n-   #### [Attribute Keys](attribute-keys.md)\n\n    List of attributes or characteristics of a token.\n  \n    [:octicons-arrow-right-24: Attribute Keys](attribute-keys.md)\n\n-   #### [Collection Floor Ask Events](collection-floor-ask-events.md)\n\n    Information about Collection Floor Ask events in a marketplace.\n  \n    [:octicons-arrow-right-24: Collection Floor Ask Events](collection-floor-ask-events.md)\n\n-   #### [Sales](sales.md)\n\n    Information about sales in a marketplace.\n  \n    [:octicons-arrow-right-24: Sales](sales.md)\n\n-   #### [Attributes](attributes.md)\n\n    Information about token attributes.\n  \n    [:octicons-arrow-right-24: Attributes](attributes.md)\n\n-   #### [Collection Top Bid Events](collection-top-bid-events.md)\n\n    Information about Collection Top Bid events in a marketplace.\n  \n    [:octicons-arrow-right-24: Collection Top Bid Events](collection-top-bid-events.md)\n\n-   #### [Token Attributes](token-attributes.md)\n\n    Information about token attributes and characteristics.\n  \n    [:octicons-arrow-right-24: Token Attributes](token-attributes.md)\n\n</div>\n\n", "doc_id": "8c5abd63-edd2-4b05-95d9-809d33f1a84f", "embedding": null, "doc_hash": "2f4c23a90dc205f66a858909dc347e52a76ea9e71b3dc00cc6cd4d7e9f1e9ac1", "extra_info": {"file_path": "docs/data-tables/community/reservoir/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 2640, "_node_type": "1"}, "relationships": {"1": "e360a49dd06db3a0d936fecb9de73d34719da9d2"}}, "__type__": "1"}, "e16a6454-c0d0-42e2-837e-ba24f94d19b7": {"__data__": {"text": "# Sales\n\n## **reservoir.sales**\n\nThis table contains records with information about each sale.\n\nQuery examples can be found here:\n\n[https://dune.com/queries/1302771/2232036](https://dune.com/queries/1302771/2232036)\n\n[https://dune.com/queries/1302775/2232040](https://dune.com/queries/1302775/2232040)\n\n| **Column name**      | **Type**  | **Description**                                   |\n|----------------------|-----------|---------------------------------------------------|\n| id                   | string    | Internal sale id                                  |\n| contract             | string    | Contract address                                  |\n| token\\_id            | string    | Id of the token in the collection                 |\n| order\\_id            | string    | Associated order id                               |\n| order\\_kind          | string    | Protocol name (e.g. seaport)                      |\n| order\\_side          | string    | Order type (ask / bid)                            |\n| order\\_source        | string    | Source of the listing (e.g. opensea.io)           |\n| from                 | string    | Maker wallet address                              |\n| to                   | string    | Taker wallet address                              |\n| price                | decimal   | Sale price (native currency)                      |\n| usd\\_price           | string    | Sale price in USD                                 |\n| currency\\_address    | string    | The currency address used for this sale           |\n| currency\\_symbol     | string    | The currency symbol used for this sale            |\n| currency\\_price      | decimal   | Sale price                                        |\n| amount               | string    | Amount of tokens sold                             |\n| fill\\_source   ", "doc_id": "e16a6454-c0d0-42e2-837e-ba24f94d19b7", "embedding": null, "doc_hash": "a2ce2975a9b1170d36c93385689e77f5f52c491e50b292b6b082a0cfd78d5ef5", "extra_info": {"file_path": "docs/data-tables/community/reservoir/sales.md", "file_name": "sales.md"}, "node_info": {"start": 0, "end": 1833, "_node_type": "1"}, "relationships": {"1": "0651df3c0cc49a752054e4604f91e922493abae2", "3": "e9acfd82-4baf-4e66-9ef6-1d3e1dfde643"}}, "__type__": "1"}, "e9acfd82-4baf-4e66-9ef6-1d3e1dfde643": {"__data__": {"text": "          |\n| fill\\_source         | string    | Where the order was filled                        |\n| aggregator\\_source   | string    | aggregator source (e.g. reservoir)                |\n| wash\\_trading\\_score | int       | Internal wash trading score (based on past sales) |\n| is\\_primary          | boolean   | Is paid mint?                                     |\n| tx\\_hash             | string    | Associated transaction hash                       |\n| tx\\_log\\_index       | int       | Associated transaction log index                  |\n| tx\\_batch\\_index     | int       | Associated transaction batch index                |\n| tx\\_timestamp        | bigint    | Associated transaction timestamp                  |\n| created\\_at          | timestamp | Timestamp the sale was recorded                   |\n| updated\\_at          | timestamp | Timestamp the sale was updated                    |                                                               |\n", "doc_id": "e9acfd82-4baf-4e66-9ef6-1d3e1dfde643", "embedding": null, "doc_hash": "113c011cf303f74081c25123e9dac3037fb62a283d370994f00e2639fe4c435e", "extra_info": {"file_path": "docs/data-tables/community/reservoir/sales.md", "file_name": "sales.md"}, "node_info": {"start": 1804, "end": 2770, "_node_type": "1"}, "relationships": {"1": "0651df3c0cc49a752054e4604f91e922493abae2", "2": "e16a6454-c0d0-42e2-837e-ba24f94d19b7"}}, "__type__": "1"}, "45c832d7-e5e6-4592-9b1a-ded4634ea5bb": {"__data__": {"text": "# Token Attributes\n\n## **reservoir.token\\_attributes**\n\nThis table contains records with information about each NFT token attribute.\n\nQuery examples can be found here:\n\n[https://dune.com/queries/1302940/2232326](https://dune.com/queries/1302940/2232326)\n\n| **Column name** | **Type**  | **Description**                           |\n|-----------------|-----------|-------------------------------------------|\n| id              | bigint    | Internal token attribute id               |\n| contract        | string    | Contract address                          |\n| token\\_id       | string    | Id of the token in the collection         |\n| attribute\\_id   | bigint    | Internal attribute id                     |\n| collection\\_id  | string    | Internal collection id                    |\n| key             | string    | Attribute name                            |\n| value           | string    | Attribute value                           |\n| created\\_at     | timestamp | Timestamp the token attribute was created |\n| updated\\_at     | timestamp | Timestamp the token attribute was updated |                                                               |\n", "doc_id": "45c832d7-e5e6-4592-9b1a-ded4634ea5bb", "embedding": null, "doc_hash": "0c646c10651bbec4e2fabe2d3b043724e4a0fe82bf4b6d369eba4c637e1359a2", "extra_info": {"file_path": "docs/data-tables/community/reservoir/token-attributes.md", "file_name": "token-attributes.md"}, "node_info": {"start": 0, "end": 1155, "_node_type": "1"}, "relationships": {"1": "9624e926c5a83e17eb6fe1fe7a2ffaf0e8a714bb"}}, "__type__": "1"}, "52cd6ab5-df3f-403d-88a0-4e2ff6566230": {"__data__": {"text": "# Token Floor Ask Events\n\n## **reservoir.token\\_floor\\_ask\\_events**\n\nThis table contains records with information about each NFT token floor ask change.\n\nQuery examples can be found here:\n\n[https://dune.com/queries/1302852/2232169](https://dune.com/queries/1302852/2232169)\n\n[https://dune.com/queries/1302854/2232173](https://dune.com/queries/1302854/2232173)\n\n| **Column name** | **Type**  | **Description**                                                                                                 |\n|-----------------|-----------|-----------------------------------------------------------------------------------------------------------------|\n| id              | bigint    | Internal token attribute id                                                                                     |\n| kind            | string    | Event type (new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, reprice) |\n| contract        | string    | Contract address                                                                                                |\n| token\\_id       | string    | Id of the token in the collection                                                                               |\n| order\\_id       | string    | Associated Ask id                                                                                               |\n| maker           | string    | Associated Ask maker wallet address                                                                             |\n| price           | decimal   | Associated ask price (native currency)                                                                          |\n| previous\\_price | decimal   | Associated ask price (native currency)     ", "doc_id": "52cd6ab5-df3f-403d-88a0-4e2ff6566230", "embedding": null, "doc_hash": "aab9c900364384f18646f9daf5c220f301c9a1d8f73dae5d748a373b0c1f21c5", "extra_info": {"file_path": "docs/data-tables/community/reservoir/token-floor-ask-events.md", "file_name": "token-floor-ask-events.md"}, "node_info": {"start": 0, "end": 1751, "_node_type": "1"}, "relationships": {"1": "370c8923e15916e05edcb8e1a1879cbc37601680", "3": "a64b5701-3647-4d70-9cdd-6fccf7d7025b"}}, "__type__": "1"}, "a64b5701-3647-4d70-9cdd-6fccf7d7025b": {"__data__": {"text": "| decimal   | Associated ask price (native currency)                                                                          |\n| nonce           | string    | The order nonce of the maker                                                                                    |\n| valid\\_from     | bigint    | Associated ask validity start                                                                                   |\n| valid\\_until    | bigint    | Associated ask validity expiration                                                                              |\n| source          | string    | Source of the order (e.g. opensea.io)                                                                           |\n| tx\\_hash        | string    | Associated transaction hash                                                                                     |\n| tx\\_timestamp   | bigint    | Associated transaction timestamp                                                                                |   \n| created\\_at     | timestamp | Timestamp the event was recorded                                                                                |\n", "doc_id": "a64b5701-3647-4d70-9cdd-6fccf7d7025b", "embedding": null, "doc_hash": "a641113bd79bd97e0091d6bbd0a7f27ac9bee35dc7e169054fe6c5a56f44bd9a", "extra_info": {"file_path": "docs/data-tables/community/reservoir/token-floor-ask-events.md", "file_name": "token-floor-ask-events.md"}, "node_info": {"start": 1694, "end": 2847, "_node_type": "1"}, "relationships": {"1": "370c8923e15916e05edcb8e1a1879cbc37601680", "2": "52cd6ab5-df3f-403d-88a0-4e2ff6566230"}}, "__type__": "1"}, "094ea4bd-b58b-4ad3-a0b1-6b46e21693a6": {"__data__": {"text": "# Tokens\n\n## **reservoir.tokens**\n\nThis table contains records with information about each NFT token.\n\nQuery examples can be found here:\n\n[https://dune.com/queries/1303052/2232521](https://dune.com/queries/1303052/2232521)\n\n[https://dune.com/queries/1303064/2232571](https://dune.com/queries/1303064/2232571)\n\n| **Column name**         | **Type**  | **Description**                    |\n|-------------------------|-----------|------------------------------------|\n| id                      | string    | Internal token id                  |\n| contract                | string    | Contract address                   |\n| token\\_id               | string    | Id of the token in the collection  |\n| name                    | string    | NFT name                           |\n| description             | string    | NFT description                    |                                                                                         |\n| collection\\_id          | string    | Associated Collection id           |\n| owner                   | string    | Owner wallet address               |\n| floor\\_ask\\_id          | string    | Floor ask id                       |\n| floor\\_ask\\_value       | bigint    | Floor ask value                    |\n| floor\\_ask\\_maker       | string    | Floor ask maker wallet address     |\n| floor\\_ask\\_valid\\_from | bigint    | Floor ask Listing start time       |\n| floor\\_ask\\_valid\\_to   | bigint    | Floor ask Listing end time         |\n| floor\\_ask\\_source      | string    | Floor ask source (e.g. opensea.io) |\n| last\\_sale\\_value       | bigint    | Associated transaction timestamp   |   \n| last\\_sale\\_timestamp   | bigint    | Associated transaction timestamp   |   \n| created\\_at             | timestamp | Timestamp the token was created    |\n| updated\\_at             | timestamp | Timestamp the token was updated    |                                                           ", "doc_id": "094ea4bd-b58b-4ad3-a0b1-6b46e21693a6", "embedding": null, "doc_hash": "6132b2a7fd2b340b39d896befc824bb660da7c7db30da8ee05dd8c5adbbc05b9", "extra_info": {"file_path": "docs/data-tables/community/reservoir/tokens.md", "file_name": "tokens.md"}, "node_info": {"start": 0, "end": 1927, "_node_type": "1"}, "relationships": {"1": "67fb5f46a65071875838118624d06d4ed15a010c", "3": "5f2b026e-2155-45d9-a336-1b0dac2b671c"}}, "__type__": "1"}, "5f2b026e-2155-45d9-a336-1b0dac2b671c": {"__data__": {"text": "                                  |\n", "doc_id": "5f2b026e-2155-45d9-a336-1b0dac2b671c", "embedding": null, "doc_hash": "ae7f0eb181e7eb8facda027727047a189cb48e985bf3a66a1d87f34bf68ab893", "extra_info": {"file_path": "docs/data-tables/community/reservoir/tokens.md", "file_name": "tokens.md"}, "node_info": {"start": 1908, "end": 1944, "_node_type": "1"}, "relationships": {"1": "67fb5f46a65071875838118624d06d4ed15a010c", "2": "094ea4bd-b58b-4ad3-a0b1-6b46e21693a6"}}, "__type__": "1"}, "d1b62e87-c568-4ffc-996c-a53396b512a2": {"__data__": {"text": "---\ntitle: Call Tables\ndescription: On Dune, we parse all message calls and transactions made to smart contracts in their own tables.\n---\n\nSmart contracts generally have functions that are able to be called by either an externally owned account(EOA) or other smart contracts. Functions can be anything from a simple state read and return to changing multiple states and invoking message calls to other smart contracts.\n\nOn Dune, we parse all message calls and transactions made to smart contracts in their own tables. The tables are then accordingly named:\n\n=== \"V2 Engine (Spark SQL)\"\n\n    `[projectname_blockchain].contractName_call_functionName`\n\n=== \"V1 Engine (PosgreSQL)\"\n\n    `[projectname].\"contractName_call_functionName\"`\n\nThis is either done on an individual contract level like for the uniswap v3 factory, or a class of contracts like the uniswap v3 pairs.\n\nFor example, when a uniswap v3 pool gets created via the [uniswap v3 factory](https://etherscan.io/address/0x1f98431c8ad98523631ae4a59f267346ea31f984#code) (on Ethereum) function `createPool`, Dune will record that transaction in the table:\n\n=== \"V2 Engine (Spark SQL)\"\n\n    `uniswap_v3_ethereum.Factory_call_createPool`\n\n    ![type:video](https://dune.com/embeds/1616145/2679669/79f2a210-959d-4308-9dc3-7578cc898e9d)\n\n=== \"V1 Engine (PosgreSQL)\"\n\n    [`uniswap_v3.\"Factory_call_createPool\"`]\n    \n    ![type:video](https://dune.com/embeds/1616134/2679651/af9175b5-e1a8-4f25-a275-7bcfbe5edb4c)\n\nThis will happen whether this was done by an externally owned account (EOA) through a transaction or a smart contract by the means of a message call.\n\n## Multiple Instances\n\nFor a contract where multiple instances exist, we will decode all calls to all instances of this smart contract into one table. If there is a transaction calling the `swap` function of any instance of a [Uniswap v3 pair](https://etherscan.io/address/0x8f8ef111b67c04eb1641f5ff19ee54cda062f163#writeContract) contract, we will collect this data in the table:\n\n=== \"V2 Engine (Spark SQL)\"\n    \n    `uniswap_v3_ethereum.Pair_call_swap`\n\n    ![type:video](https://dune.com/embeds/1616219/2679778/548764d6-179d-4fe3-8a23-1f3107f0e918)\n\n=== \"V1 Engine (PosgreSQL)\"\n\n    `uniswap_v3.\"Pair_call_swap\"`\n\n    ![type:video](https://dune.com/embeds/1616221/2679780/3e5e3cb5-2186-474d-b7b5-4c06a3b394ce)\n\n## Common misconceptions\n\nOne thing to keep in mind here is that [web3.js](https://web3js.readthedocs.io), [web3.py](https://web3py.readthedocs.io/en/stable) and all other methods of (locally) calling a `pure`, `read`, or `constant` function do not broadcast or publish anything on the blockchain and are therefore not recorded in Dune.\n\nHowever, if one of these functions is invoked by another smart contract in the context of a transaction, this will be broadcast on the chain and therefore accessible in", "doc_id": "d1b62e87-c568-4ffc-996c-a53396b512a2", "embedding": null, "doc_hash": "c8c76ccd58416dbd4f1b10c4538dbba1fef82449c3113cd236dc25e0c235cf4a", "extra_info": {"file_path": "docs/data-tables/decoded/evm/call-tables.md", "file_name": "call-tables.md"}, "node_info": {"start": 0, "end": 2837, "_node_type": "1"}, "relationships": {"1": "8ac25b1c3280d05c59576e696bcd034c11ad1635", "3": "a5035c45-c2f8-429f-b5ac-cdae104270fc"}}, "__type__": "1"}, "a5035c45-c2f8-429f-b5ac-cdae104270fc": {"__data__": {"text": "the context of a transaction, this will be broadcast on the chain and therefore accessible in Dune.\n\nIn short: **State data stored in the memory of a smart contract is not available on Dune!**\n\nA good example of this is the function `decimals` of the [erc20 token contract](https://etherscan.io/token/0x1f9840a85d5af5bf1d1762f925bdaddc4201f984#readContract) `Uni` which is a `constant` state variable that is able to be accessed through an automatically created \"[getter function](https://docs.soliditylang.org/en/v0.7.4/contracts.html#getter-functions)\". Should a smart contract invoke this function in the context of transaction, this message call will be recorded in the Dune table [`uniswap.\"UNI_call_decimals\"`](https://dune.com/queries/741354).\n\nThis is in contrast to anyone calling this function locally using web3.py/web3.js or using the Etherscan frontend to access this state. These local calls are not recorded in Dune.\n\n## Further Reading\n\n<div class=\"cards grid\" markdown>\n- [What is the difference between a transaction and a call?](https://ethereum.stackexchange.com/questions/765/what-is-the-difference-between-a-transaction-and-a-call)\n- [Soliditylang.org documentation](https://docs.soliditylang.org/en/v0.8.13/contracts.html#function-visibility)\n- [How Calldata is Encoded](https://degatchi.com/articles/reading-raw-evm-calldata)\n</div>", "doc_id": "a5035c45-c2f8-429f-b5ac-cdae104270fc", "embedding": null, "doc_hash": "405bb8de3c253f2ace7f58fcd18034103c7deaf8c7f3b3edee89ce4e042942d8", "extra_info": {"file_path": "docs/data-tables/decoded/evm/call-tables.md", "file_name": "call-tables.md"}, "node_info": {"start": 2744, "end": 4100, "_node_type": "1"}, "relationships": {"1": "8ac25b1c3280d05c59576e696bcd034c11ad1635", "2": "d1b62e87-c568-4ffc-996c-a53396b512a2"}}, "__type__": "1"}, "4b95ea82-1432-450f-89c7-c63ed469e0c5": {"__data__": {"text": "---\ntitle: Event Logs\ndescription: Smart Contracts emit event logs when certain predefined actions are completed\n---\n\nSmart Contracts emit **event logs** when certain predefined actions are completed. The structure published in these logs is predefined by the developer of the smart contract, the content is dynamically created during the transaction.\n\nLogs are useful for monitoring, alerting and in general keeping track of what happens inside of a smart contract. Logs are your best friend as a data analyst since they reliably present you with data that is intended to be analyzed post factum. If you ever want to see which logs _can_ be emitted by a smart contract, you can simply search for the keyword `emit` in the source code of the smart contract.\n\nWe will decode all event logs for smart contracts into tables named accordingly to this schema: \n\n=== \"V2 Engine (Spark SQL)\"\n\n    `[projectname_blockchain].[contractName]_evt_[eventName]`\n\n=== \"V1 Engine (PosgreSQL)\"\n\n    `[projectname].\"[contractName]_evt_[eventName]\"`\n\nLet's stay in the context of the [uniswap v3 factory](https://etherscan.io/address/0x1f98431c8ad98523631ae4a59f267346ea31f984#code) and look at the event that gets emitted upon the creation of a new pool. The event is called `PoolCreated` and gets emitted every time somebody successfully deployed a new Uniswap V3 pool by calling the function `createPool`. The event will readily give us information like the tokens in the pool, the fee tier of this pool and the tick spacing. In Etherscan, you can easily look at the event logs of transaction by opening the [logs tab](https://etherscan.io/tx/0xdeb368592f3de0f2840754bce61d2c3f29cdb3407c63c699052e68a854c71eaa#eventlog). In Dune, this particular event will be stored in the table:\n\n=== \"V2 Engine (Spark SQL)\"\n\n    `uniswap_v3_ethereum.Factory_evt_PoolCreated`\n\n    ![type:video](https://dune.com/embeds/1616189/2679743/677e99ea-ff65-4ae1-8efd-4f1ffedb1a7e)\n\n=== \"V1 Engine (PosgreSQL)\"\n\n    `uniswap_v3.\"Factory_evt_PoolCreated\"`\n    \n    ![type:video](https://dune.com/embeds/1616199/2679754/0a6da377-6ab2-4bba-8e85-36df09cbd470)\n\n## Multiple Instances\n\nIf there is multiple instances of a contract we will collect all event logs across all instances of this smart contract in one table. For example, all uniswap v3 pool `swap` events (on ethereum) are stored in the table:\n\n=== \"V2 Engine (Spark SQL)\"\n    \n    `uniswap_v3_ethereum.Pair_evt_Swap`\n\n    ![type:video](https://dune.com/embeds/1616209/2679768/9e48417a-165e-40db-90a4-508b96b2bcdf)\n\n=== \"V1 Engine (PosgreSQL)\"\n\n    `uniswap_v3.\"Pair_evt_Swap\"`\n    \n    ![type:video](https://dune.com/embeds/1616210/2679769/673e672a-b406-49e2-bc68-c566cd8f0b20)\n\n \n The column `contract_address` indicates as to which smart contract emitted this event.\n\n## Further Reading\n\n<div class=\"cards grid\" markdown>\n- [Understanding event", "doc_id": "4b95ea82-1432-450f-89c7-c63ed469e0c5", "embedding": null, "doc_hash": "41bd2181770efea35f5f29f96c69817c8d5ed285b493ff6e387b7711adf8a0c0", "extra_info": {"file_path": "docs/data-tables/decoded/evm/event-logs.md", "file_name": "event-logs.md"}, "node_info": {"start": 0, "end": 2863, "_node_type": "1"}, "relationships": {"1": "3bbfb8391058b4049afe30bcaa711ab70c115862", "3": "f23b28b3-5c9b-4320-b9fd-f0f96646de5e"}}, "__type__": "1"}, "f23b28b3-5c9b-4320-b9fd-f0f96646de5e": {"__data__": {"text": "Further Reading\n\n<div class=\"cards grid\" markdown>\n- [Understanding event logs on the Ethereum blockchain](https://medium.com/mycrypto/understanding-event-logs-on-the-ethereum-blockchain-f4ae7ba50378)\n- [Everything You Ever Wanted to Know About Events and Logs on Ethereum](https://medium.com/linum-labs/everything-you-ever-wanted-to-know-about-events-and-logs-on-ethereum-fec84ea7d0a5)\n</div>", "doc_id": "f23b28b3-5c9b-4320-b9fd-f0f96646de5e", "embedding": null, "doc_hash": "a4a456e811e473f19357079f89393cd5b4e82d0157aa9ff2dfbf173be0fddc42", "extra_info": {"file_path": "docs/data-tables/decoded/evm/event-logs.md", "file_name": "event-logs.md"}, "node_info": {"start": 2790, "end": 3183, "_node_type": "1"}, "relationships": {"1": "3bbfb8391058b4049afe30bcaa711ab70c115862", "2": "4b95ea82-1432-450f-89c7-c63ed469e0c5"}}, "__type__": "1"}, "e826487b-6088-4659-b119-450fcd0ddc72": {"__data__": {"text": "---\ntitle: Decoded Tables (EVM)\ndescription: Instead of working with the transactions, logs, and traces in their raw states, on Dune we decode smart contract activity into nice human-readable tables.\n---\n\nTo make it easier to work with smart contracts, Dune also provides decoded data as individual, human readable tables. We use the ABI for smart contracts and the interface standard for standardized token smart contracts (ERC20, ERC721 etc.). We've indexed over 280k contracts as of writing, and you can [submit new contracts](../../../app/decoding-contracts.md).\n\nInstead of working with the transactions, logs, and traces in their raw states, on Dune we decode smart contract activity into nice human-readable tables.\n\nWe create tables for each event and function defined in the smart contract's ABI(Application Binary Interface). Subsequently, every event, message call or transaction made to that contract is decoded and inserted as a row into these tables.\n\nThe tables are named accordingly:\n\n**events:** `[projectname_blockchain].contractName_evt_eventName`\n\n**function calls:** `[projectname_blockchain].contractName_call_eventName`\n\nAs an example, decoded data for the `swap`-event of the Uniswap V2 pair contract on Ethereum is found in the table `uniswap_v2_ethereum.Pair_evt_Swap`.\n\n![type:video](https://dune.com/embeds/1616367/2680001/f9d16ba2-9f69-4b84-acaa-6dff2e2de9bd)\n\nIf a contract has multiple instances, we will decode all of them into the same table, you will be able to identify the specific smart contract using the `contract_address` column. You can find unique contract names/addresses using the `labels.contracts` table.\n\nSince all chain's data resides in one database, but the multichain world is a reality, contracts on Dune have a meta attribute that describes which blockchain this specific table is pulling the data from.\n\n**Read more about the difference between calls and events here:**\n\n<div class=\"grid cards\" markdown>\n\n-   #### Call tables\n\n    ---\n\n    Call tables provide a way to see all method calls that were made by contracts on the blockchain.\n\n    [:octicons-arrow-right-24: Call tables](call-tables.md)\n\n-   #### Event logs\n\n    ---\n\n    Event logs are data that gets generated by smart contracts.\n\n    [:octicons-arrow-right-24: Event logs](event-logs.md)\n\n</div>\n\n\n## Which contracts have decoded data?\n\nYou can check if contracts are already decoded by querying `[blockchain].contracts` tables through our database or use [this dashboard](https://dune.com/dune/is-my-contract-decoded-yet-v2).\n\n```sql\nSelect * from ethereum.contracts --you can change ethereum.contracts to the e.g. optimism.contracts\nwhere address = '0x429881672b9ae42b8eba0e26cd9c73711b891ca5'\n```\n\n![type:video](https://dune.com/embeds/1616434/2680124/eefc0eb8-e335-4a56-86ca-1e4dac39d2d8)\n\nIf the contract is not in our database yet, you can submit them here: \n\n<div class=\"cards grid\" markdown>\n- [dune.com/contracts/new](https://dune.com/contracts/new).\n</div>\n\nIf you want to submit several contracts at the same time, there is also the possibility of submitting a batch of contracts. To do so, please use [this", "doc_id": "e826487b-6088-4659-b119-450fcd0ddc72", "embedding": null, "doc_hash": "ec5366975febb3889301418b401b0f27e77dd3ca23ded983fa6f39d4060a644d", "extra_info": {"file_path": "docs/data-tables/decoded/evm/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 3137, "_node_type": "1"}, "relationships": {"1": "ed15f18ac6d87a916a49197c931e955d77bef99f", "3": "6eabf164-4859-4803-9e08-3848f21425ca"}}, "__type__": "1"}, "6eabf164-4859-4803-9e08-3848f21425ca": {"__data__": {"text": "the possibility of submitting a batch of contracts. To do so, please use [this CSV](https://gist.github.com/antonio-mendes/c6a43c22862581674c11462cae230e23) as a template and fill it in with the appropriate information for the contracts you want to decode. Afterwards send the CSV to decoding@dune.com.\n\nIt usually takes about 24 hours to initially decode smart contracts, and you can check to see if your contract has been decoded yet here:\n\n<div class=\"cards grid\" markdown>\n- [Is my Contract decoded yet?](https://dune.com/0xBoxer/Is-my-Contract-decoded-yet)\n</div>\n\nOnce a contract has been added to our Decoded Contracts system, you can check this dashboard to see the current delays between block published to decoded data ready for querying:\n\n<div class=\"cards grid\" markdown>\n- [Dune Meta Monitoring](https://dune.com/dune/Meta-Monitoring)\n</div>\n\nRead more about submitting contracts for decoding in this section:\n\n<div class=\"cards grid\" markdown>\n- [Adding new contracts](../../../app/decoding-contracts.md)\n</div>\n\n## How does decoding work?\n\nSmart Contracts on any EVM blockchain are mostly written in high level languages like [Solidity](https://docs.soliditylang.org/en/v0.8.2) or [Vyper](https://vyper.readthedocs.io/en/stable).\n\nIn order for them to be able to be deployed to an EVM execution environment, they need to be compiled to EVM executable bytecode. Once deployed, the bytecode gets associated to an address on the respective chain and is permanently stored in this chain's state storage.\n\nTo be able to interact with this smart contract, which is now just bytecode, we need a guide to be able to call the functions which are defined in the high-level languages. This translation of names and arguments into byte representation is done using an **Application Binary Interface (ABI)**.\n\nThe ABI documents names, types, and arguments precisely which allows us to interact with the smart contract using a somewhat human readable format. The ABI can be compiled using the high level language source code.\n\n**The ABI is used to call a smart contract or interpret the data it emits.**\n\n![source: https://hackernoon.com/hn-images/1\\*Sz1a7G2pQ62UnkHoieve4w.jpeg](../../images/decoding.png)\n\n### An Example\n\nWe are going to look at an event log of an ERC20 transfer event from the [smart contract](https://etherscan.io/token/0x429881672B9AE42b8EbA0E26cD9C73711b891Ca5#readContract) that represents the $PICKLE token.\n\nOn [Etherscan](https://etherscan.io/tx/0x2bb7c8283b782355875fa37d05e4bd962519ea294678a3dcf2fdffbbd0761bc5#eventlog) the undecoded event looks like this:\n\n![](../../images/etherscan.png)\n\nIf we query for this transaction in the `ethereum.logs` table in the Dune database, we will receive the same encoded bytecode as our result dataset.\n\n```sql\n    Select *\nfrom ethereum.logs\nwhere tx_hash = '0x2bb7c8283b782355875fa37d05e4bd962519ea294678a3dcf2fdffbbd0761bc5'\n```\n\n**Result:**\n\n![type:video](https://dune.com/embeds/1616458/2680156/af81457b-c5f0-453e-a468-48875e043949)\n\n**Now this is not at all helpful to analyze", "doc_id": "6eabf164-4859-4803-9e08-3848f21425ca", "embedding": null, "doc_hash": "7d8a28a8bf0a9100ac9704508557a68c4f02ee7bcb48c73f6ee0e51f13e32851", "extra_info": {"file_path": "docs/data-tables/decoded/evm/index.md", "file_name": "index.md"}, "node_info": {"start": 3073, "end": 6123, "_node_type": "1"}, "relationships": {"1": "ed15f18ac6d87a916a49197c931e955d77bef99f", "2": "e826487b-6088-4659-b119-450fcd0ddc72", "3": "2d08803e-0110-4ed1-a2f9-9053d30947e4"}}, "__type__": "1"}, "2d08803e-0110-4ed1-a2f9-9053d30947e4": {"__data__": {"text": "this is not at all helpful to analyze data.**\n\nUsing the contract's ABI we can convert this encoded bytecode to decoded data.\n\nThe event log we are looking at here is from the $PICKLE ERC20 token `transfer` event log.\n\nSince this table is decoded on Dune, we can query the table in Dune to receive the decoded information: \n\n```sql\nSELECT *\nFROM pickle_finance_ethereum.PickleToken_evt_Transfer\nWHERE evt_tx_hash = '0x2bb7c8283b782355875fa37d05e4bd962519ea294678a3dcf2fdffbbd0761bc5'\n```\n\n**Result:**\n\n![type:video](https://dune.com/embeds/1616496/2680220/8bb05bb4-f820-4f00-aa38-67bc16278460)\n\n**Now this is actually useful for analyzing this transaction!**\n\nHow exactly does this work?\n\nSince we know which event we are looking at here, we can simply convert the encoded bytecode to decoded data by decoding the bytecode according to it's datatype.\n\nThe structure for the `Transfer` event log of an ERC20 token will always be:\n\n```solidity\nTransfer(address from, address to, uint256 value)\n```\n\nThis basically tells us that topic2 and topic3 are of the type `address`(32bytes) and are respectively the sender and recipient of the token transfer. An event log only has 3 indexed fields, so the `data` field is used to store the information about how much units of the token have been moved in this transaction. This field is called `value`.\n\nSince `topic1` always is just the Keccak-256 hash of the signature of the event, we are left with decoding `topic2`, `topic3` and `data`.\n\nIn this case, they map out like this:\n\n| raw data field | decoded data description | raw data | decoded data |\n| -------------- | ------------------------ | -------- | ------------ |\n| topic1 | keccak256(\"Transfer(address,address,uint256)\") | 0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef | not needed, this table only contains event logs from the `transfer` event log |\n| topic2 | from | 0x00000000000000000000000075e89d5979e4f6fba9f97c104c2f0afb3f1dcb88 | 0x75e89d5979e4f6fba9f97c104c2f0afb3f1dcb88 |\n| topic3 | to | 0x00000000000000000000000087d9da48db6e1f925cb67d3b7d2a292846c24cf7 | 0x87d9da48db6e1f925cb67d3b7d2a292846c24cf7 |\n| data | value | 0x00000000000000000000000000000000000000000000001a894d51f85cb08000 | 489509000000000000000 |\n\n**In summary:**\n\nWe can use the contracts ABI to go from encoded bytecode to decoded data. This helps you run analysis fast and efficient as the decoded data is easy to work with.\n\n## How do I understand decoded data?\n\nDecoded data is the high level programming language representation of two pieces of software talking to each other via the blockchain.\n\nIt's not always easy for a human to understand what exactly is going on in these interactions, but most of the time, looking at column names and the data that is transmitted within them should help you to understand what is happening within that specific log or call.\n\nIf you are not able to make sense of the data by just searching the tables, it usually helps to look at single transactions using the transaction hash and Etherscan.\n\nFurthermore, actually going into the smart contracts code (our favorite way to do this is [DethCode](https://etherscan.deth.net)) to read the comments or the actual logic can", "doc_id": "2d08803e-0110-4ed1-a2f9-9053d30947e4", "embedding": null, "doc_hash": "0cbfcf64e956669adae32d523cdd259ea1ecb207034407687b8cc8a6c10b3509", "extra_info": {"file_path": "docs/data-tables/decoded/evm/index.md", "file_name": "index.md"}, "node_info": {"start": 6159, "end": 9371, "_node_type": "1"}, "relationships": {"1": "ed15f18ac6d87a916a49197c931e955d77bef99f", "2": "6eabf164-4859-4803-9e08-3848f21425ca", "3": "3a94ec9b-c779-4c1d-aaf3-01dc71515bf5"}}, "__type__": "1"}, "3a94ec9b-c779-4c1d-aaf3-01dc71515bf5": {"__data__": {"text": "to read the comments or the actual logic can help to understand the smart contract's emitted data.\n\nIf that also doesn't lead to satisfactory results, scouring the relevant docs and GitHub of the project can lead you to the desired answers. Furthermore, talking to the developers and core community of a project can also help you to get an understanding of the smart contracts.\n\n**In Summary**:\n\nWorking with decoded data allows you deep access to information stored on the blockchain and is very information rich, but understanding that data sometimes takes a bit of effort on your side since you are interacting with the data of the contract in a direct way.\n\n## Which tables should I use?\n\n**Events** are designed to be analyzed and stored on the blockchain to allow backward looking analysis of what is happening, **transactions** and **message calls** are made to pass information between smart contracts.\n\nTherefore, in most cases the easiest and most accessible way to analyze various things happening on the blockchain is by looking at events.\n\nHowever, there is some cases where the emitted events miss some crucial information or there is just no events that get emitted. In these cases you might have to fall back to transaction and message calls (found in call tables).\n\nCases where no event gets emitted get rarer over time as developers now mostly understand that events are important enough to be emitted, but they still exist. In some cases, it might make sense to combine the decoded data with [raw data](../../raw/index.md) in order to get metadata about the transaction or dive even deeper.\n\n## Queries to explore decoded Contracts\n\n### See all projects we have decoded data for\n\n```sql\nSELECT DISTINCT namespace FROM [blockchain].contracts; --change [blockchain] the chain you're interested in e.g. ethereum.contracts\n```\n\n**Example:**\n\n![type:video](https://dune.com/embeds/1616581/2680356/94b49bf5-9acc-4522-b5cc-3edf55d7f2a4)\n\n### Check for multiple instances of a contract\n\nIf you are working with an event or call table directly you can see if there are several instances of that contract with this query.\n\n```sql\nSELECT DISTINCT contract_address \nFROM [projectname_blockchain].[contractName]_evt_[eventName]; --change [projectname_blockchain] to the project name and blockchain you're interested in,[contractName] and [eventName] to the specific contract  e.g. uniswap_v2_ethereum.Factory_evt_PairCreated\n```\n    \n**Example:**\n\n![type:video](https://dune.com/embeds/1616645/2680450/cac9c9c8-3ab1-40d2-afdc-7f6c05628430)", "doc_id": "3a94ec9b-c779-4c1d-aaf3-01dc71515bf5", "embedding": null, "doc_hash": "342edb1b658c7307e7f747b2057302d0cea29ff0c2b14012c6eadfca61e60b9b", "extra_info": {"file_path": "docs/data-tables/decoded/evm/index.md", "file_name": "index.md"}, "node_info": {"start": 9357, "end": 11902, "_node_type": "1"}, "relationships": {"1": "ed15f18ac6d87a916a49197c931e955d77bef99f", "2": "2d08803e-0110-4ed1-a2f9-9053d30947e4"}}, "__type__": "1"}, "064bc582-56a7-4eac-b273-f2c34ffc0f32": {"__data__": {"text": "---\ntitle: Decoded Tables\ndescription: Instead of working with the transactions, logs, and traces in their raw states, on Dune we decode smart contract activity into nice human-readable tables.\n---\n\n\n\n**To make it easier to work with smart contracts and programs, Dune has decoded data from all transactions (all functions and logs) into human readable tables. This means you don't need to work with any of the raw data from the blockchain!**\n\n!!! suggestion \"Consider using spellbook tables first\"\n    We highly recommend you use spellbook tables first, as many decoded tables have been further abstracted into tables like [`nft.trades`](../spellbook/top-tables/nft.trades.md) and [`dex.trades`](../spellbook/top-tables/dex.trades.md)\n\n## EVM decoded tables\n\nWe support [decoded tables for Ethereum based chains (EVM)](evm/index.md) like Ethereum, Optimism, Arbitrum.\n\nThere are two types of EVM decoded tables, one that decodes functions and one that decodes event logs. \n<div class=\"cards grid\" markdown>\n\n-   #### [Call Tables](evm/call-tables.md)\n\n    ---\n\n    These are decoded from traces, which contain every function call within a transaction (i.e. between contracts).\n  \n    [:octicons-arrow-right-24: Call Tables](evm/call-tables.md)\n\n-   #### [Event Log Tables](evm/event-logs.md)\n\n    ---\n\n    These are decoded from event logs, which are data points emitted during a function call.\n  \n    [:octicons-arrow-right-24: Event Log Tables](evm/event-logs.md)\n\n</div>\n\n\n## Solana decoded tables\n\nWe also support [decoded tables on Solana](solana/idl-tables.md), for any program (Candy Machine, Whirlpool, Jupiter, SPL Token, System Program, Pyth, and many more).\n\n<div class=\"cards grid\" markdown>\n\n-   #### [IDL Tables](solana/idl-tables.md)\n\n    These are decoded from `instruction_calls`, so all function calls at the first instruction level (not inner instructions) are decoded.\n  \n    [:octicons-arrow-right-24: IDL Tables](solana/idl-tables.md)\n</div>", "doc_id": "064bc582-56a7-4eac-b273-f2c34ffc0f32", "embedding": null, "doc_hash": "3f279d37ad9273aabc64493d4923f49e518f69f2f5c97acd8884dc99180fad42", "extra_info": {"file_path": "docs/data-tables/decoded/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 1964, "_node_type": "1"}, "relationships": {"1": "d4a21cab679cd538a27b55474d5e5acfdc44b848"}}, "__type__": "1"}, "64809586-c097-44c3-8194-c55ff1b5ec96": {"__data__": {"text": "---\ntitle: IDL Decoded Tables\ndescription: Table Schemas\n---\n\n!!! info \"Submissions\"\n    You can submit any program for decoding that has a public IDL or github repo (anchor and native are both supported) like [this one](https://solscan.io/account/JUP4Fb2cqiRUcaTHdrPC8h2gNsA2ETXiPDD33WcGuJB#anchorProgramIDL). You can submit to [this form](https://forms.gle/tbHZ6ZeEke5qwVjcA).\n\nDecoded tables inherit all of the columns from [`instruction_calls`](../../raw/solana/instruction-calls.md), so you can refer there for most of the types. We only add columns for each argument in the function call `data` and each account that was required to be in `account_arguments`. **These only decode from instructions, and not inner instructions.**\n\n## Example IDL Decoded Walkthrough\n\nUsing an IDL, we decode the function data arguments and the required account arguments. Let's look at an example using Whirlpool - normally you can find the IDL [on Solscan](https://solscan.io/account/whirLbMiicVdio4qvUfM5KAg6Ct8VwpYzGff3uctyCc#anchorProgramIDL), but this time we had to dig [into the project repo](https://github.com/orca-so/whirlpools/blob/main/sdk/src/artifacts/whirlpool.json). IDLs are like ABIs on Ethereum, except they are created from the [Anchor lang](https://www.anchor-lang.com/) project instead of natively from every program.\n\n[Here's a transaction](https://solscan.io/tx/TGDKvM2E8mWYcsG2JBnb9axFcyEcKqs7yZLyayCmrV8p8SSdA8r9SLEC7EHQ4mcXQXpczEyaCBXvnmEi9yoKVJ9) of a pool (a trading pair) being initialzed.\n\nYou can see that the instruction data is decoded in \"Bumps\", \"TickSpacing\", and \"InitialSqrtPrice\" on the explorer. We have the same thing in a SQL table! You can also see all the account names are labelled clearly as well with an `account_` prefix. Raw table inherited columns like `tx_id`, `block_time`, `tx_index` get a `call_` prefix.\n\nThe main thing to note is that we've exploded outer and inner instructions, where the index will match what you see on explorers. This example call is at the outer instruction level, so the inner instruction index is null. For Whirlpool swaps, often times it will happen in inner_instructions so then the top level outer instruction is inherited into the `call_outer_instruction_index` and the inner index is `call_inner_instruction_index` (same idea with the `call_outer_executing_account` and `call_inner_executing_acount`)\n\n![type:video](https://dune.com/embeds/2352049/3851391)\n\nTry it out for yourself in [this query](https://dune.com/embeds/2352049/3851391) below:\n\n```\nSELECT * FROM whirlpool_solana.whirlpool_call_initializePool\nWHERE call_tx_id = 'TGDKvM2E8mWYcsG2JBnb9axFcyEcKqs7yZLyayCmrV8p8SSdA8r9SLEC7EHQ4mcXQXpczEyaCBXvnmEi9yoKVJ9'\n```\n\nThe table name follows the pattern `<namespace>_solana.<programName>_call_<instructionName>`. We already have many of the top projects decoded, so go play around!\n", "doc_id": "64809586-c097-44c3-8194-c55ff1b5ec96", "embedding": null, "doc_hash": "20934fce9fa3d29271f955293631cc84e45ae77272f315644e994763b015b049", "extra_info": {"file_path": "docs/data-tables/decoded/solana/idl-tables.md", "file_name": "idl-tables.md"}, "node_info": {"start": 0, "end": 2863, "_node_type": "1"}, "relationships": {"1": "9fc9b94a80404af3d46f3ac3c761a5f8df00a645"}}, "__type__": "1"}, "7da876af-eabb-4f89-b033-69c12c012f20": {"__data__": {"text": "---\ntitle: Tables and Chains Overview\n---\n\n## The Four Kinds of Tables\n\nDune ingests data from [node providers](https://www.quicknode.com/case-study/dune-analytics) to directly fill our **raw tables** for each chain. This data is then decoded using contract ABIs to provide easier to work with **decoded tables**. Then we create abstracted tables that standardize and aggregate the data (from all other tables) - giving you the easiest to work with **spell tables**. \n\nWe also ingest data from **community providers** like [Reservoir](community/reservoir/index.md) and [Flashbots](community/flashbots/index.md), which you can think of as spell level abstractions.\n\n!!! suggestion \"Easy Tables\"\n    We highly recommend you use spellbook and decoded tables first, and then if you can't find the data you want try raw tables.\n\nIn each section below, you'll find details on how the tables are created and some table definitions/descriptions.\n\n<div class=\"cards grid\" markdown>\n\n\n-   #### [Raw data](raw/index.md)\n\n    ---\n  \n    Unedited, raw and encoded blockchain data.\n  \n    [:octicons-arrow-right-24: Raw data](raw/index.md)\n\n-   #### [Decoded data](decoded/index.md)\n\n    ---\n  \n    View the decoded calls and events made to smart contracts. This data is still unedited.\n  \n    [:octicons-arrow-right-24: Decoded data](decoded/index.md)\n\n-   #### [Spellbook](spellbook/index.md)\n\n    ---\n\n    Easy to work with aggregated tables that are maintained by Dune and our community.\n  \n    [:octicons-arrow-right-24: Spellbook](spellbook/index.md)\n\n-   #### [Community](community/index.md)\n\n    ---\n  \n    Enhanced tables that combine onchain and offchain data together.\n  \n    [:octicons-arrow-right-24: Community](community/index.md)\n\n</div>\n\n## Available Chains\n\nHere are the chains we have available to Query in Dune.\n\n**Non-EVM Chains**\n\n- Solana\n\n- Bitcoin\n\n**EVM Chains**\n\n- Ethereum Mainnet\n\n- Gnosis (previously xDai)\n  \n- Polygon (POS)\n  \n- Optimism\n  \n- BNB (Binance Smart Chain)\n  \n- Arbitrum\n  \n- Avalanche (c-chain)\n  \n- Goerli (Ethereum)\n  \n- Fantom\n\n### Non-EVM Chains\n#### Solana\n\nSolana is a non-EVM blockchain that aims to have high transaction speeds without sacrificing decentralization. The chain employs a bunch of novel approaches, including the \u201cproof of history\u201d mechanism, which is why you'll find their data is quite different from EVM chains.\n\n[You can learn to get started with Solana data analysis here](https://web3datadegens.substack.com/p/starter-guide-to-solana-data-analysis)\n\n#### Bitcoin\n\nThe original blockchain launched by Satoshi in 2009, using a UTXO and ledger structure. You can get started with Bitcoin analysis using [this guide](https://web3datadegens.substack.com/p/how-to-analyze-bitcoin-data-with)\n\n### EVM Chains\n#### Ethereum Mainnet\n\nEthereum was first launched in 2015 and is the original Blockchain that innovated and implemented the Ethereum Virtual Machine. Ethereum to this day remains a \"truly\" decentralized platform with many node operators all over the world securing the Blockchain. Ethereum is maintained and developed by independent developers all over the world.\n\nYou can get started with EVM data analysis", "doc_id": "7da876af-eabb-4f89-b033-69c12c012f20", "embedding": null, "doc_hash": "49549c88f409ba69d21fc085e7c727994bd49fa27b00bd1dabf7db021c070876", "extra_info": {"file_path": "docs/data-tables/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 3167, "_node_type": "1"}, "relationships": {"1": "c184523682f190fefdd4ceb314550e8cd2fb5648", "3": "3183cef5-7201-42fc-811c-22387e99f946"}}, "__type__": "1"}, "3183cef5-7201-42fc-811c-22387e99f946": {"__data__": {"text": "by independent developers all over the world.\n\nYou can get started with EVM data analysis [with this guide](https://web3datadegens.substack.com/p/a-basic-wizard-guide-to-dune-sql).\n\n<div class=\"cards grid\" markdown>\n- [Ethereum Developer Docs](https://ethereum.org/en/developers/docs)\n</div>\n\n#### Gnosis Chain (xDai)\n\nGnosis Chain is the predecessor of xDAI. It's a unique system in which the native fee currency is a bridged version of the stablecoin $DAI. The chain uses a unique dual-token model; $xDai is a stable token used for transactions, payments, and fees; Proof of Stake protection will be provided by $GNO with the consensus-layer Gnosis Beacon Chain.\n\nGnosis Chain is yet to complete it's transition to an open proof of stake system, in the meanwhile the chain is being maintained by the POSDAO. You can read more about this transitional state [here](https://developers.gnosischain.com/for-validators/consensus).\n\nGnosis Chain will continue xDai\u2019s intent to follow the Ethereum roadmap as closely as possible. Future goals include:\n\n* Offer the highest degree of compatibility between Gnosis Chain and Ethereum\n* Set up a Gnosis Beacon Chain (in preparation of a later merge)\n* Develop over time a role similar to what Kusama is to Polkadot\n\nGnosis Chain follows all standards and upgrades of Ethereum Mainnet, querying on Dune is exactly the same.\n\n#### Polygon POS\n\nPolygon(formerly MATIC) is an Ethereum sidechain hosted and maintained by by Polygon Technology. Polygon PoS is a solution that achieves transaction speed and cost savings by utilizing a POS network. Polygon node requirements are significantly higher than Mainnet requirements as Polygon has a higher gas limit and shorter block time. \n\nYou can read more about Polygon and their approach to scaling an EVM in their [documentation](https://docs.polygon.technology).\n\nPolygon follows all the rules of ETH mainnet and querying on Dune works exactly the same.\n\n#### Optimism\n\nOptimism is a Layer 2 Optimistic Rollup network designed to utilize the strong security guarantees of Ethereum while reducing its cost and latency. Optimism processes transactions outside of Ethereum Mainnet, reducing congestion on the base layer and improving scalability. For a Deep Dive into Optimism, we recommend reading through their [Documentation](https://community.optimism.io/docs/how-optimism-works).\n\nOptimism differs in it's EVM implementation in the calculation of gas costs, since it also needs to pay for L1 resources.\n\n!!! warning \"Optimism Regenesis\"\n    We've included Optimism's OVM 1.0 base tables (blocks, logs, traces, transactions) in Dune V2, which can be found in the `optimism_legacy_ovm1` database. Data from these tables are labeled \"Optimism (Legacy)\" in the dropdown menu and use this icon: \n    \n    ![optimism legacy icon](../app/query-editor/images/explorer-labels/optimism-legacy-icon.png)\n\n    These tables are no longer updated as Optimism made significant changes with their [OVM 2.0 update](https://twitter.com/optimismFND/status/1458953238867165192).\n\n    Data for the current version of Optimism's blockchain (November 11th, 2021 to present), is contained in the `optimism` database, are labeled \"Optimism\" in the dropdown menu, and use this icon:\n    \n    ![optimism icon](../app/query-editor/images/explorer-labels/optimism-icon.png)\n#### BNB Chain (BSC)\n\nBNB Chain(formerly Binance Smart Chain, BSC) is an instance of the Ethereum Virtual Machine built and maintained by", "doc_id": "3183cef5-7201-42fc-811c-22387e99f946", "embedding": null, "doc_hash": "192c49c32fbbf60958152242c039d2d51343fb25e21f7073615b31325812b4d9", "extra_info": {"file_path": "docs/data-tables/index.md", "file_name": "index.md"}, "node_info": {"start": 3092, "end": 6560, "_node_type": "1"}, "relationships": {"1": "c184523682f190fefdd4ceb314550e8cd2fb5648", "2": "7da876af-eabb-4f89-b033-69c12c012f20", "3": "14b9cea9-28cf-4846-9ec4-d17880048ce2"}}, "__type__": "1"}, "14b9cea9-28cf-4846-9ec4-d17880048ce2": {"__data__": {"text": "Chain, BSC) is an instance of the Ethereum Virtual Machine built and maintained by a team from the popular Crypto Exchange [Binance](https://binance.com). BNB Chain follows most of the rules of Ethereum Mainnet, but has not implemented EIP1559. Instead it relies on [BEP-95](https://github.com/bnb-chain/BEPs/blob/master/BEP95.md) to burn fees that accrue during usage of the platform. Furthermore, the gas limit per block is set to 100 mio, enabling more transactions to be processed in a given block. Transactions fees are paid in $BNB instead of $ETH.\n\nYou can read more about BNB Chain in [the documentation](https://docs.bnbchain.org/docs/bnbIntro).\n\nOn Dune, that means that the gas fields for EIP1559 transactions stay empty, everything else is the same.\n\n<div class=\"cards grid\" markdown>\n- [BNB Chain Documentation](https://docs.bnbchain.org/docs/bnbIntro)\n</div>\n\n#### Arbitrum\n\nArbitrum is an optimistic rollup that settles it's transactions on Ethereum Mainnet. You can read all about Arbitrum's approach to scaling and building a rollup [in their docs](https://developer.offchainlabs.com/docs/inside\\_arbitrum).\n\nArbitrum's execution environment differs from the Mainnet EVM implementation in it's calculation of gas costs. Since Arbitrum is an optimistic rollup that publishes it's transaction on Ethereum Mainnet, the gas calculations have to account for additional factors.\n\n#### Avalanche (C-Chain)\n\nC-Chain is an instance of the Ethereum Virtual Machine powered by the Avalanche network. It follows the rules of Ethereum Mainnet and only differs in it's consensus mechanism, all other technical specification are exactly the same. Gas is paid in $AVAX instead of $ETH.\n\nYou can read more about Avalanche Network and C-Chain [in this article](https://learn.figment.io/protocols/avalanche).\n\nWorking with the C-Chain on Dune works exactly like querying Ethereum mainnet data. Only `avalanche_c.blocks` has slightly different properties as Avalanche C-Chain is already in a proof of stake(POS) consensus algorithm.\n\n#### Ethereum's Goerli Testnet\n\nCreated in September 2018 during ETHBerlin, [Goerli Testnet](https://goerli.net/) was the first proof-of-authority cross-client testnet, synching Parity Ethereum, Geth, Nethermind, Hyperledger Besu (formerly Pantheon), and EthereumJS.\n\nThis is the perfect solution for dapp developers looking to get stats before you launch on mainnet!\n\n#### Fantom\n\n[Fantom](https://fantom.foundation/) is a layer 1 blockchain offering smart contract functionality.\n\nIt uses a Directed Acyclic Graph, which involves the seamless interaction of nodes in the network to ensure fast and secure transactions.\n", "doc_id": "14b9cea9-28cf-4846-9ec4-d17880048ce2", "embedding": null, "doc_hash": "21b28cb164a8ba6f5d64e85c8ff5f0a034644c463cd25ba6264aad4bfff40252", "extra_info": {"file_path": "docs/data-tables/index.md", "file_name": "index.md"}, "node_info": {"start": 6554, "end": 9206, "_node_type": "1"}, "relationships": {"1": "c184523682f190fefdd4ceb314550e8cd2fb5648", "2": "3183cef5-7201-42fc-811c-22387e99f946"}}, "__type__": "1"}, "76c81058-80ac-43d9-81a7-d98d3f356e7b": {"__data__": {"text": "# Blocks\n\n## `bitcoin.blocks`\n\n|Column name        |Column type  |Description                                                                                                                          |\n|-------------------|---------|-----------------------------------------------------------------------------------------------------------------------------------------|\n|time               |timestamp|The block time                                                                                                                           |\n|height             |bigint   |The block number                                                                                                                         |\n|date               |date     |The block date                                                                                                                           |\n|hash               |string   |The block hash                                                                                                                           |\n|transaction_count  |int      |The number of transactions in the block                                                                                                  |\n|size               |bigint   |The size of the block                                                                                                ", "doc_id": "76c81058-80ac-43d9-81a7-d98d3f356e7b", "embedding": null, "doc_hash": "7881808ad84e75ac41b05d55b2d83468b6187d1cfed08b4d7a9cafabe86f7024", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/blocks.md", "file_name": "blocks.md"}, "node_info": {"start": 0, "end": 1369, "_node_type": "1"}, "relationships": {"1": "a64c22f8cf2a4269a785f12ef963236cd939ee16", "3": "03cfe848-fdc8-426f-bffd-3e369a87706b"}}, "__type__": "1"}, "03cfe848-fdc8-426f-bffd-3e369a87706b": {"__data__": {"text": "                                       |\n|mint_reward        |double   |The output paid out to the miner for minting the block                                                                                   |\n|total_fees         |double   |The fees paid out to the miner from transaction users. Each transaction's fee is what's left of output after input is subtracted from it.|\n|total_reward       |double   |The static reward given to the miner. It is the sum of the outputs in the coinbase transaction (the first transaction).                  |\n|stripped_size      |bigint   |The size of the block excluding witness data                                                                                             |\n|weight             |bigint   |The block weight as defined in BIP 141                                                                                                   |\n|chainwork          |string   |The expected number of hashes required to produce the current chain                                                                      |\n|difficulty         |string   |The estimated amount of work done to find this block relative to the estimated amount of work done to find block 0                       |\n|merkle_root        |string   |The root node of a Merkle tree, where leaves are transaction hashes                                                                      |\n|nonce              |string   |The number of transactions made by the sender prior to this one                                                                          |\n|coinbase           |string   |The data specified in the coinbase transaction of the block                                                              ", "doc_id": "03cfe848-fdc8-426f-bffd-3e369a87706b", "embedding": null, "doc_hash": "48542e8ec8af090475cb63ef2b3646b8481989be818a5fb308bd467567f2fa4f", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/blocks.md", "file_name": "blocks.md"}, "node_info": {"start": 1370, "end": 3093, "_node_type": "1"}, "relationships": {"1": "a64c22f8cf2a4269a785f12ef963236cd939ee16", "2": "76c81058-80ac-43d9-81a7-d98d3f356e7b", "3": "7deb9cbf-533e-4c40-86da-4dbfdcbf6fd7"}}, "__type__": "1"}, "7deb9cbf-533e-4c40-86da-4dbfdcbf6fd7": {"__data__": {"text": "                                   |\n|previous_block_hash|string   |The hash of the previous block                                                                                                           |\n|bits               |string   |The difficulty threshold specified in block header                                                                                       |\n", "doc_id": "7deb9cbf-533e-4c40-86da-4dbfdcbf6fd7", "embedding": null, "doc_hash": "715ee20cef0cf5ba608dfecb581634f685f2c1a09755a45f1d11bfbc83d8dc6e", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/blocks.md", "file_name": "blocks.md"}, "node_info": {"start": 3074, "end": 3451, "_node_type": "1"}, "relationships": {"1": "a64c22f8cf2a4269a785f12ef963236cd939ee16", "2": "03cfe848-fdc8-426f-bffd-3e369a87706b"}}, "__type__": "1"}, "fd3dbbc0-894c-46f5-8802-096b46cf7264": {"__data__": {"text": "---\ntitle: Bitcoin Overview\ndescription: As a non-EVM chain, Bitcoin raw data looks quite different from other chains. Learn more about Bitcoin's data in these pages.\n---\n\n**Raw tables provide you raw, unfiltered and unedited data.**\n\nRaw data tables are very useful to get raw scripts, inputs, and outputs from transactions.\n\nBitcoin uses a UTXO transaction model, and has a heavy focus on signatures and scripts for \"locking\" and \"unlocking\" tokens. They are also most well known for being tied to a 21 million token supply, and halvenings. For a full guide on all Bitcoin concepts, [check out this one](https://web3datadegens.substack.com/p/how-to-analyze-bitcoin-data-with).\n\n## Data Available\n\n<div class=\"grid cards\" markdown>\n\n-   #### Blocks\n\n    ---\n\n    Blocks are the base unit that all transactions fit into.  \n    \n    [:octicons-arrow-right-24: Blocks](blocks.md)\n\n-   #### Transactions\n\n    ---\n\n    Transactions contain all spent inputs and created outputs from a UTXO transaction.  \n    \n    [:octicons-arrow-right-24: Transactions](transactions.md)\n\n-   #### Outputs\n\n    ---\n\n    Just the outputs, unnested.  \n    \n    [:octicons-arrow-right-24: Outputs](outputs.md)\n\n-   #### Inputs\n\n    ---\n\n    Just the inputs, unnested.\n\n    [:octicons-arrow-right-24: Inputs](inputs.md)\n</div>\n\n", "doc_id": "fd3dbbc0-894c-46f5-8802-096b46cf7264", "embedding": null, "doc_hash": "728ba38b3a79a86f6e3e554103db50fffb17b724b354ab78cbafe86354687a15", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 1303, "_node_type": "1"}, "relationships": {"1": "46d72f633611ea3d8528ad61981d9057ad748792"}}, "__type__": "1"}, "7955af9e-815e-4466-b428-f08ba067ff7a": {"__data__": {"text": "# Inputs\n\n## `bitcoin.inputs`\n\n|Column name        |Type  |Description                                                                                                                              |\n|-------------------|------|-----------------------------------------------------------------------------------------------------------------------------------------|\n|block_time         |timestamp|The block time                                                                                                                           |\n|block_date         |date  |The block date                                                                                                                           |\n|block_height       |bigint|The block number                                                                                                                         |\n|index              |int   |The index of the input                                                                                                                   |\n|block_hash         |bigint|The block hash of the output                                                                                                             |\n|tx_id              |string|The transaction id that this input was used                                                                                             ", "doc_id": "7955af9e-815e-4466-b428-f08ba067ff7a", "embedding": null, "doc_hash": "f1662153d134f61abb1ef9431c389d16e48fb983573735ab0af331daaff53899", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/inputs.md", "file_name": "inputs.md"}, "node_info": {"start": 0, "end": 1367, "_node_type": "1"}, "relationships": {"1": "5c689c9c40fef2d51e1273867b9f8f2dbf57dd77", "3": "8f333e4d-44c3-4e6f-b2fc-30368d0cfed8"}}, "__type__": "1"}, "8f333e4d-44c3-4e6f-b2fc-30368d0cfed8": {"__data__": {"text": "                    |\n|spent_block_height |bigint|The block height of the output                                                                                                           |\n|spent_tx_id        |string|The transaction id of the output                                                                                                         |\n|spent_output_number|bigint|The output number                                                                                                                        |\n|value              |double|The number of Satoshis attached to this input                                                                                            |\n|address            |string|The address that owned/owns the output used as input                                                                                     |\n|type               |string|The address type of the input                                                                                                            |\n|coinbase           |string|This input was the coinbase input in the transaction                                                                                     |\n|is_coinbase        |boolean|True if coinbase is not null, else false                                                                          ", "doc_id": "8f333e4d-44c3-4e6f-b2fc-30368d0cfed8", "embedding": null, "doc_hash": "58b5d6cc61d64868e63838afec4a813432b46544b5e640ced7ce9ee48ab62e08", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/inputs.md", "file_name": "inputs.md"}, "node_info": {"start": 1368, "end": 2702, "_node_type": "1"}, "relationships": {"1": "5c689c9c40fef2d51e1273867b9f8f2dbf57dd77", "2": "7955af9e-815e-4466-b428-f08ba067ff7a", "3": "733d348f-c230-4e91-acdb-f51d889dd601"}}, "__type__": "1"}, "733d348f-c230-4e91-acdb-f51d889dd601": {"__data__": {"text": "                                          |\n|script_asm         |string|Symbolic representation of the bitcoin's script language op-codes                                                                        |\n|script_hex         |string|Hexadecimal representation of the bitcoin's script language op-codes                                                                     |\n|script_desc        |string|The description                                                                                                                          |\n|script_signature_asm|string|Symbolic representation of the bitcoin's script language op-codes                                                                        |\n|script_signature_hex|string|Hexadecimal representation of the bitcoin's script language op-codes                                                                     |\n|sequence           |bigint|A number intended to allow unconfirmed time-locked transactions to be updated before being finalized; not currently used except to disable locktime in a transaction|\n|witness_data       |array&lt;string&gt;|Witness data                                                                                                                             |\n", "doc_id": "733d348f-c230-4e91-acdb-f51d889dd601", "embedding": null, "doc_hash": "19a2d8dd0d04a00ce27d75bcb813df4c234e0571592c1d808c41cd51f6e8af75", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/inputs.md", "file_name": "inputs.md"}, "node_info": {"start": 2683, "end": 3938, "_node_type": "1"}, "relationships": {"1": "5c689c9c40fef2d51e1273867b9f8f2dbf57dd77", "2": "8f333e4d-44c3-4e6f-b2fc-30368d0cfed8"}}, "__type__": "1"}, "5915644c-4f41-41c0-a7f5-891f5bdd6318": {"__data__": {"text": "# Outputs\n\n## `bitcoin.outputs`\n\n|Column name        |Type  |Description                                                                                                                              |\n|-------------------|------|-----------------------------------------------------------------------------------------------------------------------------------------|\n|block_time         |timestamp|The block time                                                                                                                           |\n|block_date         |date  |The block date                                                                                                                           |\n|block_height       |bigint|The block number                                                                                                                         |\n|block_hash         |string|The block hash                                                                                                                           |\n|tx_id              |string|The id (hash) of the transaction this is from                                                                                            |\n|index              |int   |0-indexed number of an output within a transaction. Used by inputs to identify outputs.                                                  |\n|value              |double|The number of Satoshis attached to this output             ", "doc_id": "5915644c-4f41-41c0-a7f5-891f5bdd6318", "embedding": null, "doc_hash": "47ba8c9c7a4a416310c273ff78a95b746d9bee37149a3f3255291246caf05bdc", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/outputs.md", "file_name": "outputs.md"}, "node_info": {"start": 0, "end": 1459, "_node_type": "1"}, "relationships": {"1": "98836337801044fe47e1f9675805d35799fe40c7", "3": "9b7ee9a7-ab2d-48c5-941f-90e821ef792d"}}, "__type__": "1"}, "9b7ee9a7-ab2d-48c5-941f-90e821ef792d": {"__data__": {"text": "attached to this output                                                                                           |\n|script_asm         |string|Symbolic representation of the bitcoin's script language op-codes                                                                        |\n|script_hex         |string|Hexadecimal representation of the bitcoin's script language op-codes                                                                     |\n|address            |string|The address that owns this output                                                                                                        |\n|type               |string|The address type of the output                                                                                                           |\n", "doc_id": "9b7ee9a7-ab2d-48c5-941f-90e821ef792d", "embedding": null, "doc_hash": "192a3f2d396bd24919005c763af6f434a992362be6c83b39f47987f7bf0f7368", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/outputs.md", "file_name": "outputs.md"}, "node_info": {"start": 1423, "end": 2207, "_node_type": "1"}, "relationships": {"1": "98836337801044fe47e1f9675805d35799fe40c7", "2": "5915644c-4f41-41c0-a7f5-891f5bdd6318"}}, "__type__": "1"}, "53f65dde-c43c-47df-9b81-8e17db2fb70f": {"__data__": {"text": "# Transactions\n\n## `bitcoin.transactions`\n\n|Column name        |Type  |Description                                                                                                                              |\n|-------------------|------|-----------------------------------------------------------------------------------------------------------------------------------------|\n|block_time         |timestamp|The block time                                                                                                                           |\n|block_date         |date  |The block date                                                                                                                           |\n|block_height       |bigint|The block number                                                                                                                         |\n|block_hash         |string|The hash of the block that contains this transaction                                                                                     |\n|index              |int   |The number of the transaction in the block.                                                                                              |\n|id                 |string|The id (hash) of this transaction                                                                                                        |\n|input_value        |double|Total value of inputs in the transaction        ", "doc_id": "53f65dde-c43c-47df-9b81-8e17db2fb70f", "embedding": null, "doc_hash": "610c4244fa1f2e6d04b0fbf685eb75e18162b2e54449beddefdd666471e8aa8e", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 0, "end": 1458, "_node_type": "1"}, "relationships": {"1": "460797ef1dd00cc2de7eebf75c628486a95f868f", "3": "9666ebfc-0745-49f2-a45d-d62236189929"}}, "__type__": "1"}, "9666ebfc-0745-49f2-a45d-d62236189929": {"__data__": {"text": "|double|Total value of inputs in the transaction                                                                                                 |\n|output_value       |double|Total value of outputs in the transaction                                                                                                |\n|fee                |double|The transaction fee paid to the miner. = output_value - input_value                                                                      |\n|input_count        |int   |The number of inputs in the transaction                                                                                                  |\n|output_count       |int   |The number of outputs in the transaction                                                                                                 |\n|size               |bigint|The size of this transaction in bytes                                                                                                    |\n|virtual_size       |bigint|The virtual transaction size (differs from size for witness transactions)                                                                |\n|is_coinbase        |boolean|The transaction is a coinbase transaction, which is the first transaction in a block                                                     |\n|coinbase           |string|If the transaction is a coinbase transaction, contains the coinbase data. Otherwise, null.                                               |\n|input          ", "doc_id": "9666ebfc-0745-49f2-a45d-d62236189929", "embedding": null, "doc_hash": "0225a707e3730ea4511fd4ffc3a658b6801723d4a61eda59127dd3117d4a5710", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 1417, "end": 2917, "_node_type": "1"}, "relationships": {"1": "460797ef1dd00cc2de7eebf75c628486a95f868f", "2": "53f65dde-c43c-47df-9b81-8e17db2fb70f", "3": "22ddc996-f92b-4b11-9c62-85a3bf248ece"}}, "__type__": "1"}, "22ddc996-f92b-4b11-9c62-85a3bf248ece": {"__data__": {"text": "      |\n|input              |struct|Transaction inputs                                                                                                                       |\n|output             |struct|Transaction outputs. See outputs table.                                                                                                  |\n|lock_time          |bigint|Earliest time that miners can include the transaction in their hashing of the Merkle root to attach it in the latest block of the blockchain|\n|hex                |string|The transaction encoded as hexadecimal                                                                                                   |\n\n### Struct definitions\n\nWithin several of these columns is a data type of STRUCT which allows for representing nested hierarchical data and has key-value pairs. It's similar to a dictionary in python and can be used to group fields together to make them more accessible.\n\nNote that you can work with these columns with the syntax `input[1].witness_data[2]` or `input[3].script_pub_key.address` depending on lengths of arrays within each value. It is an `array(row(map))` type, and while it looks like just an array in the returned table - it is more than that!\n\n**input**\n\n| Field   | Data type | Description  |\n|-------------------|------|-----------------------------------------------------------------------------------------------------------------------------------------|\n|value        |double|The number of Satoshis attached to this output                                                                                           |\n|height       |bigint|The height of the output                                                                                                                 |\n|tx_id        |string|The transaction id of the output that is here used as input                                                                             ", "doc_id": "22ddc996-f92b-4b11-9c62-85a3bf248ece", "embedding": null, "doc_hash": "a045e92430759b68198a6563d4db8bbac5ab4b715b39dd7a3916cbcbd559face", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 2952, "end": 4891, "_node_type": "1"}, "relationships": {"1": "460797ef1dd00cc2de7eebf75c628486a95f868f", "2": "9666ebfc-0745-49f2-a45d-d62236189929", "3": "c3e89e0c-d6bd-4fe9-a98d-8198a8e1fd9f"}}, "__type__": "1"}, "c3e89e0c-d6bd-4fe9-a98d-8198a8e1fd9f": {"__data__": {"text": "                    |\n|output_number|bigint|The number (index) of the output in transaction `tx_id`'s outputs                                                                        |\n|coinbase     |string|The data specified in this transaction, if it was a coinbase transaction                                                                 |\n|sequence     |bigint|Sequence number                                                                                                                          |\n|witness_data |array<string>|Array of hex encoded witness data                                                                                                        |\n|script_signature|struct|The script signature                                                                                                                     |\n|script_pub_key|struct|The script public key                                                                                                                    |\n\n***\n\n**input.script_signature**\n\n| Field   | Data type | Description  |\n|---------|-----------|--------------|\n|hex|string|The transaction's script operations, in hex                                                                                              |\n|asm|string|The transaction's script operations, in symbolic representation                                                                          |\n\n***\n\n**input.script_pub_key**\n\n| Field   | Data type", "doc_id": "c3e89e0c-d6bd-4fe9-a98d-8198a8e1fd9f", "embedding": null, "doc_hash": "d242ae3e859cf55ae837d13d4991feea37f287cf86dd532b06c203774917c9fc", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 4900, "end": 6366, "_node_type": "1"}, "relationships": {"1": "460797ef1dd00cc2de7eebf75c628486a95f868f", "2": "22ddc996-f92b-4b11-9c62-85a3bf248ece", "3": "f574a492-08a8-44f2-89b5-ba22876e1aa5"}}, "__type__": "1"}, "f574a492-08a8-44f2-89b5-ba22876e1aa5": {"__data__": {"text": "Field   | Data type | Description  |\n|---------|-----------|--------------|\n|asm|string|The transaction's script operations, in symbolic representation                                                                          |\n|desc|string|The transaction's script operations, in symbolic representation                                                                          |\n|address|string|The transaction's script operations, in symbolic representation                                                                          |\n|hex|string|The transaction's script operations, in hex                                                                                              |\n|type|string|The address type of the output                                                                                                           |\n\n***\n\n**output**\n\n| Field   | Data type | Description  |\n|-------------------|------|-----------------------------------------------------------------------------------------------------------------------------------------|\n|index       |bigint|0-indexed number of an output within a transaction used by a later transaction to refer to that specific output                          |\n|value       |double|The number of Satoshis attached to this output                                                                                           |\n|script_pub_key|struct|The public key                                                                                                                           |\n\n***\n\n**output.script_pub_key**\n\n| Field   | Data type | Description  |\n| ------- | --------- | -------------|\n|asm|string|The transaction's script operations, in symbolic representation                                                                 ", "doc_id": "f574a492-08a8-44f2-89b5-ba22876e1aa5", "embedding": null, "doc_hash": "3adbf0526544ec6723f550305a1c2b60b27295fc0f4bc8959015876d55b83b23", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 6353, "end": 8147, "_node_type": "1"}, "relationships": {"1": "460797ef1dd00cc2de7eebf75c628486a95f868f", "2": "c3e89e0c-d6bd-4fe9-a98d-8198a8e1fd9f", "3": "4c153586-19d9-44df-87ba-d1e4bd8dcbde"}}, "__type__": "1"}, "4c153586-19d9-44df-87ba-d1e4bd8dcbde": {"__data__": {"text": "                            |\n|hex|string|The transaction's script operations, in hex                                                                                              |\n|address|string|The address the BTC came from                                                                                                            |\n|type|string|The address type of the output                                                                                                           |\n", "doc_id": "4c153586-19d9-44df-87ba-d1e4bd8dcbde", "embedding": null, "doc_hash": "2cbc31c2f00591b4e0f6729f7bc9e59f2f76466a22bf546b20a80ba7a2ced896", "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 8142, "end": 8630, "_node_type": "1"}, "relationships": {"1": "460797ef1dd00cc2de7eebf75c628486a95f868f", "2": "f574a492-08a8-44f2-89b5-ba22876e1aa5"}}, "__type__": "1"}, "f26f48b4-e594-4019-809b-806b8ea6b149": {"__data__": {"text": "---\ntitle: Blocks\ndescription: Blocks are the building blocks of blockchains and rollups.\n---\n\nBlocks are the building blocks of blockchains and rollups. A block contains transactions which will alter the state of an EVM system incrementally. Transaction within a block can only be executed one after the other, not in parallel.\n\nThese tables are useful for identifying block activity and transaction changes over time.\n\n## Tables\n\n=== \"V2 Engine (Spark SQL)\"\n\n    | Chain             | Table                | Notes                                                 |\n    | ----------------  | -------------------- | ----------------------------------------------------- |\n    | Ethereum Mainnet  | `ethereum.blocks`    |                                                       |\n    | Gnosis Chain      | `gnosis.blocks`      | Does not contain `nonce`                              |\n    | Polygon           | `polygon.blocks`     |                                                       |\n    | Optimism          | `optimism.blocks`    | Does not contain `miner` `nonce` `base_fee_per_gas`   |\n    | Optimism (legacy) | `optimism_legacy_ovm1.blocks` | Does not contain `miner` `nonce` `base_fee_per_gas` |\n    | BNB Chain         | `bnb.blocks`         | Does not contain `base_fee_per_gas`                   |\n    | Arbitrum          | `arbitrum.blocks`    | Does not contain `miner` `difficulty` `total_difficulty` `nonce` `size` `base_fee_per_gas` |\n    | Avalanche C-Chain  | `avalanche_c.blocks` | Does not contain `miner` `difficulty`                 |\n    \n\n=== \"V1 Engine (PosgreSQL)\"\n\n    | Chain                | Table             | Notes                                               |\n    | -------------------  | ----------------- | --------------------------------------------------- |\n    | Ethereum Mainnet     | `ethereum.blocks` |                                                     |\n    | Gnosis Chain (xDai)  | `xdai.blocks`     | Does not contain `nonce`                            |\n    | Polygon              | `polygon.blocks` ", "doc_id": "f26f48b4-e594-4019-809b-806b8ea6b149", "embedding": null, "doc_hash": "68f0cfd81baa5e0ee479db798dbde1ef41b477ae0c2236fa432783b8c571d250", "extra_info": {"file_path": "docs/data-tables/raw/evm/blocks.md", "file_name": "blocks.md"}, "node_info": {"start": 0, "end": 2049, "_node_type": "1"}, "relationships": {"1": "7d1af784439981fa4387d660eaf2c2d0f3d1973d", "3": "06121cdf-c16a-49ba-a0ae-b221f343e48c"}}, "__type__": "1"}, "06121cdf-c16a-49ba-a0ae-b221f343e48c": {"__data__": {"text": "            | `polygon.blocks`  |                                                     |\n    | Optimism (OVM 1 & 2) | `optimism.blocks` | Does not contain `miner` `nonce` `base_fee_per_gas` |\n    | BNB Chain (BSC)      | `bsc.blocks`      | Does not contain `base_fee_per_gas`                 |\n\n## Column Data\n\n### Example\n\n![type:video](https://dune.com/embeds/1513349/2544895/3a7395c7-0555-4cc4-a563-78c24a9bacbd)\n\n### Description\n\n| Column name           |   Data type    |    Description                                     |\n| --------------------- | :------------: | ------------------------------------------------- |\n| `time`                | _timestamptz_  | The time when the block was mined                 |\n| `number`              | _numeric_      | The length of the blockchain in blocks            |\n| `hash`                | _bytea_        | A unique identifier for that block                |\n| `parent hash`         | _bytea_        | The unique identifier for the prior block         |\n| `gas_limit`           | _numeric_      | The gas limit of the current block                |\n| `gas_used`            | _numeric_      | The gas used in this block                        |\n| `miner`               | _bytea_        | The address of the miner                          |\n| `difficulty`          | _numeric_      | The effort required to mine the block             |\n| `total_difficulty`    | _numeric_      | Total difficulty of the chain until this block    |\n| `nonce`               | _bytea_        | The block nonce is used to demonstrate the proof of work during mining |\n| `size`                | _numeric_      | This block's size in bytes (limited by gas limit) |\n| `base_fee_per_gas`    | _numeric_      | This block's base fee (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |", "doc_id": "06121cdf-c16a-49ba-a0ae-b221f343e48c", "embedding": null, "doc_hash": "17be6cd4577ab3e06af4918a87c55cb92b630451bc9404e540a9e3739d75bb8e", "extra_info": {"file_path": "docs/data-tables/raw/evm/blocks.md", "file_name": "blocks.md"}, "node_info": {"start": 2018, "end": 3842, "_node_type": "1"}, "relationships": {"1": "7d1af784439981fa4387d660eaf2c2d0f3d1973d", "2": "f26f48b4-e594-4019-809b-806b8ea6b149"}}, "__type__": "1"}, "6c861a1c-8acf-4aaf-8243-2a7208ebfb52": {"__data__": {"text": "---\ntitle: Event Logs\ndescription: Event Logs tables store all logs data that gets generated by smart contracts.\n---\n\nEvent Logs tables store all logs data that gets generated by smart contracts.\n\nThis can be useful for querying contracts that are not yet decoded or are not able to be decoded since the code of the smart contract is not public.\n\nLogs are an elegant way to store tiny amounts of data on EVM blockchains for a small amount of gas. Specifically, event logs are useful to let other people know something has happened without them having to query contracts individually.\n\nFor more on this topic read [this article](https://medium.com/mycrypto/understanding-event-logs-on-the-ethereum-blockchain-f4ae7ba50378).\n\n!!!note\n    Our topic index counts from 1, so `topic0` shows up as `topic1`, `topic1` shows up as `topic2` and so on.\n\n## Tables\n\n=== \"V2 Engine (Spark SQL)\"\n\n    |   Chain           |   Table             | Notes |\n    | ----------------  | ------------------- | ----- |\n    | Ethereum Mainnet  | `ethereum.logs`     |       |\n    | Gnosis Chain      | `gnosis.logs`       |       |\n    | Polygon           | `polygon.logs`      |       |\n    | Optimism          | `optimism.logs`     |       |\n    | Optimism (legacy) | `optimism_legacy_ovm1.logs` |       |\n    | BNB Chain         | `bnb.logs`          |       |\n    | Arbitrum          | `arbitrum.logs`     |       |\n    | Avalanche C-Chain  | `avalanche_c.logs` |       |\n    \n\n=== \"V1 Engine (PosgreSQL)\"\n\n    |   Chain              |   Table         | Notes |\n    | -------------------  | --------------- | ----- |\n    | Ethereum Mainnet     | `ethereum.logs` |       |\n    | Gnosis Chain (xDai)  | `xdai.logs`     |       |\n    | Polygon              | `polygon.logs`  |       |\n    | Optimism (OVM 1 & 2) | `optimism.logs` |       |\n    | BNB Chain (BSC)      | `bsc.logs`      |       |\n\n## Column Data\n\n### Example\n\n![type:video](https://dune.com/embeds/1582190/2633928/337cdc5f-d449-4de6-a845-dd5d55173776)\n\n### Description\n\n|   Column name      |   Data type     |    Description   |\n| ------------------ | :------------: | -------------------------------------------------------------- |\n| `contract_address` | _bytea_        | The address of the contract that emitted the log               |\n| `topic1`           |", "doc_id": "6c861a1c-8acf-4aaf-8243-2a7208ebfb52", "embedding": null, "doc_hash": "b4d17c62e629a99f40876987629d27a0c796fa63bebd62bfefc9804f2b5f1148", "extra_info": {"file_path": "docs/data-tables/raw/evm/event-logs.md", "file_name": "event-logs.md"}, "node_info": {"start": 0, "end": 2303, "_node_type": "1"}, "relationships": {"1": "1e0cc5749df2e5e1cf7a2ea52d712364e36f2ec6", "3": "c1ebf3ed-884d-48fd-a6a3-a0934dbef765"}}, "__type__": "1"}, "c1ebf3ed-884d-48fd-a6a3-a0934dbef765": {"__data__": {"text": "  |\n| `topic1`           | _bytea_        | keccak256 hash of a flattened event declaration string         |\n| `topic2`           | _bytea_        | Second indexed `topic` of the event                            |\n| `topic3`           | _bytea_        | Third indexed `topic` of the event                             |\n| `topic4`           | _bytea_        | Fourth indexed `topic` of the event                            |\n| `data`             | _bytea_        | Unindexed data containing further information on the event     |\n| `tx_hash`          | _bytea_        | The transaction hash of the transaction that produced this log |\n| `block_hash`       | _bytea_        | A unique identifier for that block                             |\n| `block_number`     | _int8_         | The length of the blockchain in blocks                         |\n| `block_time`       | _timestamptz_  | The time when the block was mined that includes this log       |\n| `index`            | _numeric_      | This logs index position in the block (cumulative amount of logs ordered by execution) |\n| `tx_index`         | _numeric_      | The index position of the transaction in this block (cumulative amount of transactions ordered by execution) |", "doc_id": "c1ebf3ed-884d-48fd-a6a3-a0934dbef765", "embedding": null, "doc_hash": "6b6b54a171b407cb4d8993ce9bc7906381b108828b2bd49ecd225c8fe0b1e291", "extra_info": {"file_path": "docs/data-tables/raw/evm/event-logs.md", "file_name": "event-logs.md"}, "node_info": {"start": 2277, "end": 3505, "_node_type": "1"}, "relationships": {"1": "1e0cc5749df2e5e1cf7a2ea52d712364e36f2ec6", "2": "6c861a1c-8acf-4aaf-8243-2a7208ebfb52"}}, "__type__": "1"}, "47680fc0-fa44-4ce3-9a59-e7aa5540931c": {"__data__": {"text": "---\ntitle: EVM Overview\n---\n\n**Raw tables provide you raw, unfiltered and unedited data.**\n\nThis allows you to query for any transaction, block, event log or trace across the blockchains Dune supports.  Raw data tables are very useful to get meta information about the blockchain, a transaction, traces or certain events.\n\nHowever, queries that have been written using raw data tables are notoriously hard to understand and audit due to the nature of the the encoded data commonly found in these tables. Furthermore, the raw data tables have a very large number of rows and hence can be slow to query. Most of the time you are better off [submitting contracts for decoding](../../../app/decoding-contracts.md) and working with [decoded data](../../decoded/index.md).\n\n## EVM Raw Table Data\n\nEthereum Virtual Machine (EVM) powers all chains in Dune except Solana and Bitcoin - meaning they share the base structure for underlying data.\n\n<div class=\"grid cards\" markdown>\n\n-   #### Traces\n\n    ---\n\n    Blocks are the base unit that all transactions fit into.\n\n    [:octicons-arrow-right-24: Blocks](blocks.md)\n\n-   #### Event Logs\n\n    Event Logs are data that gets generated by smart contracts.\n\n    [:octicons-arrow-right-24: Event Logs](event-logs.md)\n\n-   #### Traces\n\n    ---\n\n    Traces contain information about the execution of smaller atomic actions generated by transactions.\n\n    [:octicons-arrow-right-24: Traces](traces.md)\n\n-   #### Transactions  \n    \n    ---  \n    \n    Transactions are cryptographically signed instructions from accounts.  \n      \n    [:octicons-arrow-right-24: Transactions](transactions.md)\n\n</div>\n", "doc_id": "47680fc0-fa44-4ce3-9a59-e7aa5540931c", "embedding": null, "doc_hash": "27d7ba01c1448f90f85141b3f24484c4c76b0c698828551717bc856fc0b09f96", "extra_info": {"file_path": "docs/data-tables/raw/evm/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 1634, "_node_type": "1"}, "relationships": {"1": "fd71e1bfe6e282bf0326070e42576b034847f203"}}, "__type__": "1"}, "01f07a90-184d-4356-aca9-06f1708545dd": {"__data__": {"text": "---\ntitle: Traces\ndescription: Traces tables contain information about the execution of smaller atomic actions generated by transactions.\n---\n\nTransactions can trigger smaller atomic actions that modify the internal state of an Ethereum Virtual Machine. Information about the execution of these actions is logged and can be found stored as an EVM execution trace, or just a _trace_. In Etherscan these are referred to as \"internal transactions\".\n\nRead more [here](https://medium.com/chainalysis/ethereum-traces-not-transactions-3f0533d26aa).\n\n## Tables\n\n=== \"V2 Engine (Spark SQL)\"\n\n    |   Chain           |   Table               | Notes |\n    | ----------------  | --------------------- | ----- |\n    | Ethereum Mainnet  | `ethereum.traces`     | `value` measured in `wei` |\n    | Gnosis Chain      | `gnosis.traces`       | `value` measured in `wei` |\n    | Polygon           | `polygon.traces`      | `value` measured in `wei`, does not contain `gas` |\n    | Optimism          | `optimism.traces`     | `value` measured in `wei` |\n    | Optimism (legacy) | `optimism_legacy_ovm1.traces` | `value` measured in `wei` |\n    | BNB Chain         | `bnb.traces`          | `value` measured in `wei` |\n    | Arbitrum          | `arbitrum.traces`     | `value` measured in `ArbGas`, does not contain `gas` |\n    | Avalanche C-Chain  | `avalanche_c.traces` | `value` measured in `nanoavax` |\n\n=== \"V1 Engine (PosgreSQL)\"\n\n    |   Chain              |   Table           |   Notes   |\n    | -------------------  | ----------------- | --------- |\n    | Ethereum Mainnet     | `ethereum.traces` | `value` measured in `wei`  |\n    | Gnosis Chain (xDai)  | `xdai.traces`     | `value` measured in `wei` |\n    | Polygon              | `polygon.traces`  | `value` measured in `wei`  |\n    | Optimism (OVM 1 & 2) | `optimism.traces` | `value` measured in `wei`  |\n    | BNB Chain (BSC)      | `bsc.traces`      | `value` measured in `wei`  |\n\n## Column Data\n\n### Example\n\n![type:video](https://dune.com/embeds/1582215/2633989/e683cb9b-9074-43d3-b1b4-cf9940786b2c)\n\n### Description\n\n|   Column name    |   Data type    |   Description                                                            |\n| --------------------- | :------------: | ------------------------------------------------------------------ |\n| `block_time`     | _timestamptz_ | The time when the block was mined                 ", "doc_id": "01f07a90-184d-4356-aca9-06f1708545dd", "embedding": null, "doc_hash": "d4d8240f55aee5589433b43b7f64b6bfc28abc58739e6dfb41847a8a658e3102", "extra_info": {"file_path": "docs/data-tables/raw/evm/traces.md", "file_name": "traces.md"}, "node_info": {"start": 0, "end": 2380, "_node_type": "1"}, "relationships": {"1": "a3cd7362b146852b1c8e39b11f0ab90571b01186", "3": "22304e58-2267-4292-a3ea-4630e87bcf4d"}}, "__type__": "1"}, "22304e58-2267-4292-a3ea-4630e87bcf4d": {"__data__": {"text": "was mined                                        |\n| `block_number`   | _int8_        | The length of the blockchain in blocks                                   |\n| `value`          | _numeric_     | The amount of `[chain_gas_token]` sent in this transaction               |\n| `gas`            | _numeric_     | Gas provided with the message call                                       |\n| `gas_used`       | _numeric_     | The gas consumed by the transaction in `wei`                            |\n| `block_hash`     | _bytea_       | A unique identifier for that block                                       |\n| `success`        | _boolean_     | A true/false value that shows if the trace action succeeded              |\n| `tx_index`       | _numeric_     | The position of the transaction in a block                               |\n| `sub_traces`     | _numeric_     | Number of children of a trace                                            |\n| `error`          |  _text_       | The error message the EVM throws if the execution of one of a contract's instructions fails. [See a list of unique Ethereum Errors this past week here](https://dune.com/queries/1582755). |\n| `tx_success`     | _boolean_     | A true/false value that indicates if the transaction succeeded           |\n| `tx_hash`        | _bytea_       | The transaction hash of the event                                        |\n| `from`           | _bytea_       | Address of the sender                                                    |\n| `to`             | _bytea_       | Address of the receiver. `null` when its a contract creation transaction |\n| `trace_address`  | _array_       | Address of the trace within the call graph forest. E.g., [0, 2, 1] is the parent of [0, 2, 1, 0] |\n| `type`           | _text_        | Can be `reward`, `create`, `call` or `suicide`. Describes the type of action taken in this trace.", "doc_id": "22304e58-2267-4292-a3ea-4630e87bcf4d", "embedding": null, "doc_hash": "a0b2642904fa476943ce7b5bb47d93db09d0055086418e441aad6a89915d5eab", "extra_info": {"file_path": "docs/data-tables/raw/evm/traces.md", "file_name": "traces.md"}, "node_info": {"start": 2373, "end": 4263, "_node_type": "1"}, "relationships": {"1": "a3cd7362b146852b1c8e39b11f0ab90571b01186", "2": "01f07a90-184d-4356-aca9-06f1708545dd", "3": "853dbd37-d6f1-4a7c-931c-fca8cace01c2"}}, "__type__": "1"}, "853dbd37-d6f1-4a7c-931c-fca8cace01c2": {"__data__": {"text": "`call` or `suicide`. Describes the type of action taken in this trace. | \n|`address`         | _bytea_       | The contract that is called when the type is `suicide` or `create`       |\n| `code`           | _bytea_       | The bytecode to deploy a new contract, only contains data when type is `create`. |\n| `call_type`      | _bytea_       | Can be `staticcall`, `delegatecall` or `call`. Learn more [here](https://medium.com/coinmonks/delegatecall-calling-another-contract-function-in-solidity-b579f804178c) |\n| `input`          | _bytea_       | The bytecode of the call that is made to another smart contract          |\n| `output`         | _bytea_       | The bytecode answer the smart contract that was called gives back        |\n| `refund_address` | _bytea_       | Only contains data if `type` was `suicide`. Specifies where to send the outstanding BNB balance. |\n\n## Gas used in `.traces`\n\nThe `gas_used` column in the `.traces` tables is a bit hard to understand, so here is some pointers:\n\n- The `gas_used` of a trace will always include the gas consumed by the trace and all it's subtraces.\n- The `gas_used` of the initial call will not contain the cost of making the call in the first place\n- You need to add 21000 gas units + the cost of sending zero + non zero bytes to the `gas_used` value of the top trace to arrive at the \"true\" `gas_used` value.\n- For more reading on this please refer to this [StackExchange entry](https://ethereum.stackexchange.com/questions/31443/what-do-the-response-values-of-a-parity-trace-transaction-call-actually-repres)\n- [Here's an example query doing this in Dune](https://dune.com/queries/895857)\n\n## Creation Traces\n\n\n### Tables\n\n|   Chain           |   Table               | Notes |\n| ----------------  | --------------------- | ----- |\n| Ethereum Mainnet  | `ethereum.creation_traces`     |  |\n| Gnosis Chain      | `gnosis.creation_traces`       |  |\n| Polygon           | `polygon.creation_traces`      |  |\n| Optimism          | `optimism.creation_traces`     |  |\n| Optimism (legacy) | `optimism_legacy_ovm1.creation_traces` |  |\n| BNB Chain         | `bnb.creation_traces`          |  |\n| Solana            | `solana.creation_traces`       |  |\n| Arbitrum          | `arbitrum.creation_traces`     |  |\n| Avalanche C-Chain  | `avalanche_c.creation_traces` |  |\n\n### Example\n\n![type:video](https://dune.com/embeds/1612273/2673868/6953efb3-bb8a-40c8-9e1b-a455dd7b0ae6)\n\n### Description\n\nTransactions can trigger smaller atomic actions that modify the internal state of an Ethereum Virtual Machine.", "doc_id": "853dbd37-d6f1-4a7c-931c-fca8cace01c2", "embedding": null, "doc_hash": "06a3c9f228a9b3988d2602ff90d3e9c0a68787ecb3f29e10eafdb29f4bfbe77c", "extra_info": {"file_path": "docs/data-tables/raw/evm/traces.md", "file_name": "traces.md"}, "node_info": {"start": 4213, "end": 6765, "_node_type": "1"}, "relationships": {"1": "a3cd7362b146852b1c8e39b11f0ab90571b01186", "2": "22304e58-2267-4292-a3ea-4630e87bcf4d", "3": "2a250e28-5ef0-4329-8dfb-6f402694dd09"}}, "__type__": "1"}, "2a250e28-5ef0-4329-8dfb-6f402694dd09": {"__data__": {"text": "can trigger smaller atomic actions that modify the internal state of an Ethereum Virtual Machine. \n\nOne type of trace, `create`, is used to create a smart contract then transfer ether to it.\n\nRead more [here](https://medium.com/chainalysis/ethereum-traces-not-transactions-3f0533d26aa).\n\n|   Column name  |   Data type   | Description |\n| -------------- | :-----------: | --------------- |\n| `block_time`   | _timestamptz_ | The time when the block was mined |\n| `block_number` | _long_        | The length of the blockchain in blocks |\n| `tx_hash`      | _string_      | The transaction hash of the event |\n| `address`      | _string_      | The address of the created contract |\n| `from`         | _string_      | Address of the contract that generated the `create` trace |\n| `code`         | _string_      | The function executed |", "doc_id": "2a250e28-5ef0-4329-8dfb-6f402694dd09", "embedding": null, "doc_hash": "a074e051c2781a0314194769aaebdb3d8bd3a62093a43801870ee8e7197e9490", "extra_info": {"file_path": "docs/data-tables/raw/evm/traces.md", "file_name": "traces.md"}, "node_info": {"start": 6727, "end": 7561, "_node_type": "1"}, "relationships": {"1": "a3cd7362b146852b1c8e39b11f0ab90571b01186", "2": "853dbd37-d6f1-4a7c-931c-fca8cace01c2"}}, "__type__": "1"}, "62c37351-a198-4c61-a644-0d021f1b481b": {"__data__": {"text": "---\ntitle: Transactions\ndescription: Transactions are cryptographically signed instructions from accounts.\n---\n\nTransactions are cryptographically signed instructions from accounts. An account will initiate a transaction to update the state of the Ethereum network. Transactions will always originate from externally owned accounts, a smart contract can not initiate a transaction.\n\nTransactions need to be broadcast to the whole network. Any node can broadcast a request for a transaction to be executed on the EVM; after this happens, a miner will execute the transaction and propagate the resulting state change to the rest of the network.\n\nRead more in the official Ethereum documentation [here](https://ethereum.org/en/developers/docs/transactions).\n\n## Tables\n\n=== \"V2 Engine (Spark SQL)\"\n\n    |   Chain           |   Table               | Notes |\n    | ----------------  | --------------------- | ----- |\n    | Ethereum Mainnet  | `ethereum.transactions`     |  |\n    | Gnosis Chain      | `gnosis.transactions`       |  |\n    | Polygon           | `polygon.transactions`      |  |\n    | Optimism          | `optimism.transactions`     | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n    | Optimism (legacy) | `optimism_legacy_ovm1.transactions` | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n    | BNB Chain         | `bnb.transactions`          | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n    | Arbitrum          | `arbitrum.transactions`     | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy`. Gas is measured in `ArbGas` instead of `wei` |\n    | Avalanche C-Chain  | `avalanche_c.transactions` | Does not contain. Gas is measured in `nanoavax` instead of `wei` |\n\n=== \"V1 Engine (PosgreSQL)\"\n\n    |   Chain              |   Table                 |   Notes   |\n    | -------------------  | ----------------------- | --------- |\n    | Ethereum Mainnet     | `ethereum.transactions` |           |\n    | Gnosis Chain (xDai)  | `xdai.transactions`     |           |\n    | Polygon              | `polygon.transactions`  |           |\n    | Optimism (OVM 1 & 2) | `optimism.transactions` | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`,", "doc_id": "62c37351-a198-4c61-a644-0d021f1b481b", "embedding": null, "doc_hash": "f9b5996dc56a5752226bd347d6f6161564bcd5e05c46b4068902341dacaf1fa1", "extra_info": {"file_path": "docs/data-tables/raw/evm/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 0, "end": 2594, "_node_type": "1"}, "relationships": {"1": "1cb7db9df2541410c506b5bb60849d2f2d0f7d32", "3": "bbd9b67d-6800-43f0-a1c3-f303b0b13044"}}, "__type__": "1"}, "bbd9b67d-6800-43f0-a1c3-f303b0b13044": {"__data__": {"text": "`max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n    | BNB Chain (BSC)      | `bsc.transactions`      | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n\n## Column Data\n\n### Example\n\n![type:video](https://dune.com/embeds/1582277/2634087/017d7f95-4cef-46f6-8637-7077ce9f5536)\n\n### Description\n\n|  Column  **            |  Data type   |  Description                                                   |\n| -------------------------- | :-----------: | ---------------------------------------------------------------- |\n| `block_time`               | _timestamptz_ | The time when the block was mined that includes this transaction |\n| `block_number`             | _int8_        | The length of the blockchain in blocks                     |\n| `value`                      | _numeric_     | The amount of `[chain_gas_token]` sent in this transaction in `wei`. Note that ERC20 tokens do not show up here |\n| `gas_limit`                | _numeric_     | The gas limit in `wei` (ArbGas for Arbitrum) |\n| `gas_price`                | _numeric_     | The gas price in `wei`                                    |\n| `gas_used`                 | _numeric_     | The gas consumed by the transaction in `wei`              |\n| `max_fee_per_gas`          | _numeric_     | The maximum fee per gas the transaction sender is willing to pay total (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |\n| `max_priority_fee_per_gas` | _numeric_     | Maximum fee per gas the transaction sender is willing to give to miners to incentivize them to include their transaction (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |\n| `priority_fee_per_gas`     | _numeric_     | The priority fee paid out to the miner for this transaction (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |\n| `nonce`                    | _numeric_     | The transaction nonce, unique to that wallet               |\n| `index`                    | _numeric_     | The transactions index position in the block               |\n| `success`       ", "doc_id": "bbd9b67d-6800-43f0-a1c3-f303b0b13044", "embedding": null, "doc_hash": "38e9d0b84decee6ba1bdd0a30f95c1ca03196e563d48913b9871f94ae98ed919", "extra_info": {"file_path": "docs/data-tables/raw/evm/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 2550, "end": 4742, "_node_type": "1"}, "relationships": {"1": "1cb7db9df2541410c506b5bb60849d2f2d0f7d32", "2": "62c37351-a198-4c61-a644-0d021f1b481b", "3": "ba9606d9-5384-476d-9a55-1b342d8ab0fe"}}, "__type__": "1"}, "ba9606d9-5384-476d-9a55-1b342d8ab0fe": {"__data__": {"text": "       |\n| `success`                  | _boolean_     | A true/false value that shows if the transaction succeeded |\n| `from`                     | _bytea_       | Address of the sender                                      |\n| `to`                       | _bytea_       | Address of the receiver. `null` when its a contract creation transaction |\n| `block_hash`               | _bytea_       | A unique identifier for that block                         |\n| `data`                     | _bytea_       | Can either be empty, a hex encoded message or instructions for a smart contract call |\n| `hash`                     | _bytea_       | The hash of the transaction                                |\n| `type`                     | _text_        | The type of the transaction: `Legacy`, `AccessList`, or `DynamicFee` |\n| `access_list`              | _jsonb_       | A list of addresses and storage keys the transaction intends to access. See [EIP2930](https://eips.ethereum.org/EIPS/eip-2930). Applicable if the transaction is of type `AccessList` or `DynamicFee` |\n| `effective_gas_price` | _numeric_      | [Arbitrum and Avalanche C-Chain only] The gas price this transaction paid in `wei` (Arbitrum) or `nanoavax` (Avalanche) |\n| `gas_used_for_l1` | _numeric_ | [Arbitrum only] The gas consumed by the L1 resources used for this transaction in ArbGas |\n| `l1_gas_used` | _numeric_ | [Optimism only] The costs to send the input `calldata` to L1 |\n| `l1_gas_price` | _numeric_ | [Optimism only] The gas price on L1 |\n| `l1_fee` | _numeric_ | [Optimism only] The amount in wei paid on L1  |\n| `l1_fee_scalar` | _numeric_ | [Optimism only] Variable parameter that makes sure that gas costs on L1 get covered + profits |\n| `l1_block_number` | _numeric_ | [Optimism only] The block_number of the block in which this transaction got batch settled on L1 |\n| `l1_timestamp` | _numeric_ | [Optimism only] The timestamp of the block in which this transaction got batch settled on L1 |\n| `l1_tx_origin` | _numeric_ | [Optimism only] ?? |", "doc_id": "ba9606d9-5384-476d-9a55-1b342d8ab0fe", "embedding": null, "doc_hash": "3f91fb29ba9ba1e48f4c13a360e89742a491026d3cc379e0b477938e6372cfd0", "extra_info": {"file_path": "docs/data-tables/raw/evm/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 4760, "end": 6784, "_node_type": "1"}, "relationships": {"1": "1cb7db9df2541410c506b5bb60849d2f2d0f7d32", "2": "bbd9b67d-6800-43f0-a1c3-f303b0b13044"}}, "__type__": "1"}, "29e8792f-68ea-433a-9737-983c1767998b": {"__data__": {"text": "---\ntitle: Withdrawals\ndescription: The withdrawal table stores information about withdrawals made on the Ethereum beacon chain, including the block time, block number, index, validator index, amount, address, withdrawals root, and block hash.\n---\n!!! warning\n    This table is only relevant of Ethereum mainnet and does not exist for other EVM chains on Dune.\n\n\n!!!note\n    Dune does not have beacon chain data yet. This table introduces the action of withdrawing from the beacon chain only.  \n\n\nThe [Ethereum Improvement Proposal (EIP) 4895](https://eips.ethereum.org/EIPS/eip-4895) introduces a system-level \"operation\" to support validator withdrawals that are \"pushed\" from the beacon chain to the EVM.\n\n Withdrawals are represented as a new type of object in the execution payload, called an \"operation\", that cleanly separates this \"system-level\" operation from regular transactions. Withdrawals provide key information from the consensus layer such as a monotonically increasing index, validator index, recipient address, and the amount of ether given in Gwei.\n\n Using this table you can observe beacon chain withdrawals.\n\n### How to work with this table\n\nIn order to connect deposits and withdrawals, we must identify the ``validator_index`` of unique depositors. Since Dune doesn't have beacon chain data yet, we have to rely on a workaround using a query to obtain a list of valid and active deposits from the Ethereum deposit contract.\n\nThis [query](https://dune.com/queries/2364548) returns a list of valid and active deposits, which we can use to identify the ``validator_index`` of unique depositors. We can use this query to match the ``validator_index`` of depositors with the ``validator_index`` of withdrawers in the withdrawals table.\n\nThe Query is manually maintained and therefore may not always be up to date, but most historical data is available.  \n\n[LINK TO QUERY](https://dune.com/queries/2364548)  \n\nUsing this query, we can for example take a look at how the exodus of Kraken's ETH staking pools from the beacon chain is going:\n\n![type:video](https://dune.com/embeds/2370313/3886141)\n\n\nWe hope to integrate beacon chain data in the future, which will streamline the process of connecting deposits and withdrawals, and eliminate the need for the aforementioned workaround.\n\n\n## Column Data\n\n### Example\n\n![type:video](https://dune.com/embeds/2363408/3873540)\n\n### Description\n\n| Column Name       | Datatype | Description                                                             |\n|-------------------|----------|-------------------------------------------------------------------------|\n| block_time        | timestamp | The time the block was created                                          |\n| block_number      | bigint    | The number of the block in the blockchain                               |\n| index             | bigint    | a monotonically increasing index, starting from 0, as a value that increments by 1 per withdrawal to uniquely identify each withdrawal|\n| validator_index   | bigint    | the validator_index of the validator, as a uint64 value, on the consensus layer the withdrawal corresponds to|\n| amount            | bigint   ", "doc_id": "29e8792f-68ea-433a-9737-983c1767998b", "embedding": null, "doc_hash": "72d9f5d3feab7e4d4515640eccf29dcf416a4138f69a23299f2ffcdbff136694", "extra_info": {"file_path": "docs/data-tables/raw/evm/withdrawals.md", "file_name": "withdrawals.md"}, "node_info": {"start": 0, "end": 3181, "_node_type": "1"}, "relationships": {"1": "221ca909151ea84cfde102e709e67e090f0b60da", "3": "b811a527-a404-4cce-812b-a27c32c606ef"}}, "__type__": "1"}, "b811a527-a404-4cce-812b-a27c32c606ef": {"__data__": {"text": "amount            | bigint    | a nonzero amount of ether given in Gwei (1e9 wei)                        |\n| address           | varbinary | a recipient for the withdrawn ether. Note that depositor and recipient address are not neccesarily the same|\n| withdrawals_root  | varbinary | the 32 byte root of the trie committing to the list of withdrawals provided in a given execution payload|\n| block_hash        | varbinary | The hash of the block                                                    |\n", "doc_id": "b811a527-a404-4cce-812b-a27c32c606ef", "embedding": null, "doc_hash": "406473e17a105bb9664a30ab648c6f7674bf360a5136b0c5c96171a65d1b1148", "extra_info": {"file_path": "docs/data-tables/raw/evm/withdrawals.md", "file_name": "withdrawals.md"}, "node_info": {"start": 3152, "end": 3651, "_node_type": "1"}, "relationships": {"1": "221ca909151ea84cfde102e709e67e090f0b60da", "2": "29e8792f-68ea-433a-9737-983c1767998b"}}, "__type__": "1"}, "90fef2e3-98d4-43d5-8777-193e134da1ad": {"__data__": {"text": "---\ntitle: Raw Tables Overview\n---\n\n**Raw tables provide you raw, unfiltered and unedited data.**\n\nThis allows you to query for any transaction, block, event log or trace across the blockchains Dune supports.  Raw data tables are very useful to get meta information about the blockchain, a transaction, traces or certain events.\n\nHowever, queries that have been written using raw data tables are notoriously hard to understand and audit due to the nature of the the encoded data commonly found in these tables. Furthermore, the raw data tables have a very large number of rows and hence can be slow to query. Most of the time you are better off [submitting contracts for decoding](../../app/decoding-contracts.md) and working with [decoded data](../decoded/index.md).\n\n## EVM Raw Table Data\n\nEthereum Virtual Machine (EVM) powers all chains in Dune except Solana and Bitcoin - meaning they share the base structure for underlying data. For a full written guide on getting started, [check out this one](https://web3datadegens.substack.com/p/a-basic-wizard-guide-to-dune-sql).\n\n<div class=\"grid cards\" markdown>\n\n-   #### Traces\n\n    ---\n\n    Blocks are the base unit that all transactions fit into.\n\n    [:octicons-arrow-right-24: Blocks](evm/blocks.md)\n\n-   #### Event Logs\n\n    Event Logs are data that gets generated by smart contracts.\n\n    [:octicons-arrow-right-24: Event Logs](evm/event-logs.md)\n\n-   #### Traces\n\n    ---\n\n    Traces contain information about the execution of smaller atomic actions generated by transactions.\n\n    [:octicons-arrow-right-24: Traces](evm/traces.md)\n\n-   #### Transactions  \n    \n    ---  \n    \n    Transactions are cryptographically signed instructions from accounts.  \n    [:octicons-arrow-right-24: Transactions](evm/transactions.md)\n\n</div>\n\n## Bitcoin Raw Table Data\n\nBitcoin data follows a UTXO model. For a full written guide on getting started, [check out this one](https://web3datadegens.substack.com/p/how-to-analyze-bitcoin-data-with).\n\n<div class=\"grid cards\" markdown>\n\n-   #### Blocks\n\n    ---\n\n    Blocks are the base unit that all transactions fit into.  \n    [:octicons-arrow-right-24: Blocks](bitcoin/blocks.md)\n\n-   #### Transactions\n\n    ---\n\n    Transactions contain all spent inputs and created outputs from a UTXO transaction.  \n    [:octicons-arrow-right-24: Transactions](bitcoin/transactions.md)\n\n-   #### Outputs\n\n    ---\n\n    Just the outputs, unnested.  \n    [:octicons-arrow-right-24: Outputs](bitcoin/outputs.md)\n\n-   #### Inputs\n\n    ---\n\n    Just the inputs, unnested.  \n    [:octicons-arrow-right-24: Inputs](bitcoin/inputs.md)\n</div>\n\n## Solana Raw Table Data\n\nSolana data follows an instruction/program based model. You initiate a set of instruction calls (instead of just a single call), and those will set off a bunch of inner instruction calls during execution.. For a full written guide on getting started, [check out this one](https://web3datadegens.substack.com/p/how-to-analyze-bitcoin-data-with).\n\n<div class=\"grid cards\" markdown>\n\n-   #### Account Activity\n\n    ---\n\n    This table contains information from the transactions table focused on account usage.\n\n   ", "doc_id": "90fef2e3-98d4-43d5-8777-193e134da1ad", "embedding": null, "doc_hash": "c3be743b62775cae166ea913bb40c5b53860421a2885a162c6ff14b7b896356d", "extra_info": {"file_path": "docs/data-tables/raw/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 3145, "_node_type": "1"}, "relationships": {"1": "513f7e01ad1d2a060f4b3fc64d0a0768b3292171", "3": "26ff6998-e343-4710-989d-b6004c159320"}}, "__type__": "1"}, "26ff6998-e343-4710-989d-b6004c159320": {"__data__": {"text": " This table contains information from the transactions table focused on account usage.\n\n    [:octicons-arrow-right-24: Account Activity](solana/account-activity.md)\n\n-   #### Blocks\n\n    ---\n\n    Blocks are the base unit that all transactions fit into.\n\n    [:octicons-arrow-right-24: Blocks](solana/blocks.md)\n\n-   #### Rewards\n\n    ---\n\n    This table contains data about rewards paid out on Solana.\n\n    [:octicons-arrow-right-24: Rewards](solana/rewards.md)\n\n-   #### Transactions\n\n    ---\n\n    Transactions are cryptographically signed instructions from accounts.\n\n    [:octicons-arrow-right-24: Transactions](solana/transactions.md)\n\n-   #### Instruction Calls\n\n    ---\n\n    Transactions are unnested here such that each instruction gets its own row.\n    \n    [:octicons-arrow-right-24: Instruction Calls](solana/instruction-calls.md)\n\n-   #### Vote Transactions\n\n    ---\n\n    This table contains the full set of vote transactions that are submitted by validators to vote on a block.\n\n    [:octicons-arrow-right-24: Vote Transactions](solana/vote-transactions.md)\n</div>\n", "doc_id": "26ff6998-e343-4710-989d-b6004c159320", "embedding": null, "doc_hash": "7ff47d50036d2dca5449d991307ab7eb7e57491007e3cebc3562e037e46a4b97", "extra_info": {"file_path": "docs/data-tables/raw/index.md", "file_name": "index.md"}, "node_info": {"start": 3054, "end": 4131, "_node_type": "1"}, "relationships": {"1": "513f7e01ad1d2a060f4b3fc64d0a0768b3292171", "2": "90fef2e3-98d4-43d5-8777-193e134da1ad"}}, "__type__": "1"}, "2e2de33b-4989-4684-8161-a325cacf504e": {"__data__": {"text": "# Account activity\n\n## Solana.account\\_activity\n\nThis table contains information from the transactions table focused on account usage. Each row contains all information about an account's usage in a transaction.\n\n| Column Name                | Column Type | Description                                                      |\n| -------------------------- | ----------- | ---------------------------------------------------------------- |\n| block\\_slot                | bigint      | The slot of the block this transaction was in.                   |\n| block\\_hash                | string      | The hash of the block this transaction was in                    |\n| block\\_time                | timestamp   | The timestamp that this account usage occurred                   |\n| block\\_date                | date        | The date this account usage occurred                             |\n| address                    | string      | The address of the account, also referred to as public key       |\n| tx\\_index                  | int         | The index of this transaction in the block                       |\n| tx\\_id                     | string      | The ID of the transaction in which this account usage occurred   |\n| tx\\_success                | boolean     | The transaction succeeded and was committed                      |\n| signed                     | boolean     | This account signed this transaction                             |\n| writeable                  | boolean     | This account was granted read-write access in this transaction   |\n| pre\\_balance               | bigint      | The balance of this account before the transaction was processed |\n| pre\\_token\\_balance    | decimal     | The token balance before the transaction was processed           |\n| post\\_balance              | bigint      | The balance of this account after the transaction was processed  |\n| post\\_token\\_balance   | decimal     | The token balance after the transaction was processed            |\n| balance\\_change            | bigint      | The balance change that occurred as part of the transaction      |\n| token\\_balance\\_change | decimal     | The balance change that occurred as part of the transaction      |\n| token\\_mint\\_address | string     | The address the associated token address is minting from (i.e. the", "doc_id": "2e2de33b-4989-4684-8161-a325cacf504e", "embedding": null, "doc_hash": "180807e4738d1b9db4c428351ec5f607f8335cdb16f7a9c563d6fc449864109a", "extra_info": {"file_path": "docs/data-tables/raw/solana/account-activity.md", "file_name": "account-activity.md"}, "node_info": {"start": 0, "end": 2321, "_node_type": "1"}, "relationships": {"1": "eb99779273e4d5e649ce7ed9a6bb892b66f7ba64", "3": "532ff16d-3776-42c0-a119-93f6f898b8d0"}}, "__type__": "1"}, "532ff16d-3776-42c0-a119-93f6f898b8d0": {"__data__": {"text": "   | The address the associated token address is minting from (i.e. the actual token address)    |\n| token\\_owner\\_address | string     | The address that owns this token address    |\n", "doc_id": "532ff16d-3776-42c0-a119-93f6f898b8d0", "embedding": null, "doc_hash": "6ffbaee7db19384a4aa298edf55ca639bbd2ad6126badb11301d653370007339", "extra_info": {"file_path": "docs/data-tables/raw/solana/account-activity.md", "file_name": "account-activity.md"}, "node_info": {"start": 2250, "end": 2434, "_node_type": "1"}, "relationships": {"1": "eb99779273e4d5e649ce7ed9a6bb892b66f7ba64", "2": "2e2de33b-4989-4684-8161-a325cacf504e"}}, "__type__": "1"}, "d37305b4-20fb-40cc-b88f-47509b714a15": {"__data__": {"text": "# Blocks\n\n## Solana.blocks\n\nThis table contains the block data within Solana\u2019s blockchain. It can be used to identify block activity and transaction changes over time.\n\n![type:video](https://dune.com/embeds/1582515/2634478/fae7d1bb-b0c0-46b6-abc3-3da1c918233e)\n\n| Column Name               | Data Type     | Description                                         |\n| :-----------------------: | :-----------: | --------------------------------------------------- |\n| `hash`                    | _string_      | string The hash of this block, base-58 encoded      |\n| `height`                  | _bigint_      | The number of blocks beneath this block             |\n| `slot`                    | _bigint_      | This block\u2019s slot index in the ledger               |\n| `time`                    | _timestamp_   | The (estimated) time this block was produced        |\n| `date`                    | _date_        | Used to partition by                                |\n| `parent_slot`             | _bigint_      | The slot index of this block's parent               |\n| `previous_block___hash`   | _string_      | The hash of this block's parent, base-58 encoded    |\n| `total_transactions`      | _bigint_      | The total number of transactions in this block      |\n| `successful_transactions` | _bigint_      | The number of successful transactions in this block |\n| `failed_transactions`     | _bigint_      | The number of failed transactions in this block     |\n\nSolana Query examples can be found here: [Solana blocks over time](https://dune.xyz/queries/389979) and [Transactions per day](https://dune.xyz/queries/390045)", "doc_id": "d37305b4-20fb-40cc-b88f-47509b714a15", "embedding": null, "doc_hash": "3bab7a6f6a430f98cee88568c18d46bc68e8d90afcf01c29c5bdfc6549c0945c", "extra_info": {"file_path": "docs/data-tables/raw/solana/blocks.md", "file_name": "blocks.md"}, "node_info": {"start": 0, "end": 1622, "_node_type": "1"}, "relationships": {"1": "56919e8e56101797085f0ac142cb1e86d3dfefc6"}}, "__type__": "1"}, "97dbe69d-8295-40af-af47-950c84aa10bc": {"__data__": {"text": "---\ntitle: Solana Overview\ndescription: As a non-EVM chain, Solana Raw data looks quite different from other chains. Learn more about Solana's data in these pages.\n---\n\n**Raw tables provide you raw, unfiltered and unedited data.**\n\nRaw data tables are very useful to get transactions, pre and post balances, and instructions data. As a non-EVM chain, Solana Raw data looks quite different from other chains (largely due to it's account structure). You can learn to get started with Solana analysis [in this guide](https://web3datadegens.substack.com/p/starter-guide-to-solana-data-analysis).\n\nHowever, queries that have been written using raw data tables are notoriously hard to understand and audit due to the nature of the the encoded data commonly found in these tables. Furthermore, the raw data tables have a very large number of rows and hence can be slow to query. Most of the time you are better off working with [decoded data](../../decoded/solana/idl-tables.md).\n\n## Data Available\n\n<div class=\"grid cards\" markdown>\n\n-   #### Account Activity\n\n    ---\n\n    This table contains information from the transactions table focused on account usage.\n\n    [:octicons-arrow-right-24: Account Activity](account-activity.md)\n\n-   #### Blocks\n\n    ---\n\n    Blocks are the base unit that all transactions fit into.\n\n    [:octicons-arrow-right-24: Blocks](blocks.md)\n\n-   #### Rewards\n\n    ---\n\n    This table contains data about rewards paid out on Solana.\n\n    [:octicons-arrow-right-24: Rewards](rewards.md)\n\n-   #### Transactions\n\n    ---\n\n    Transactions are cryptographically signed instructions from accounts.\n\n    [:octicons-arrow-right-24: Transactions](transactions.md)\n\n-   #### Instruction Calls\n\n    ---\n\n    Transactions are unnested here such that each instruction gets its own row.\n    \n    [:octicons-arrow-right-24: Instruction Calls](instruction-calls.md)\n\n-   #### Vote Transactions\n\n    ---\n\n    This table contains the full set of vote transactions that are submitted by validators to vote on a block.\n\n    [:octicons-arrow-right-24: Vote Transactions](vote-transactions.md)\n</div>\n\n\n", "doc_id": "97dbe69d-8295-40af-af47-950c84aa10bc", "embedding": null, "doc_hash": "016032f541a03952f34b641d455eac75664ec6864ff8e3b841fbe2fd750ea268", "extra_info": {"file_path": "docs/data-tables/raw/solana/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 2104, "_node_type": "1"}, "relationships": {"1": "b4ad10650e8eac5e709c087fa3b569ea10ef018a"}}, "__type__": "1"}, "143ee9d7-38be-4782-a5b7-e318cd9f72ae": {"__data__": {"text": "# Instruction Calls\n\nThis is an unnested table of [`solana.transactions`](transactions.md). There can be multiple instructions in a transaction, so having an exploded view here will make it a little easier to work with the data. **This table mainly exists as the base for [Solana decoded tables](../../decoded/solana/idl-tables.md) though, which you should be using instead.**\n\nHere is the schema:\n\n| Column Name               | Data Type     | Description                                         |\n| ------------------- | --------------- | ------------------------------------ |\n| block_slot | bigint | This block\u2019s slot index in the ledger |\n| block_date | date | Event date |\n| block_time | timestamp(3) with time zone | Event time |\n| block_hash | varchar | The hash of this block, base-58 encoded\n| index | integer | the order of the instruction in the original instructions of the transaction |\n| tx_index | integer | Index into the block\u2019s transactions |\n| outer_instruction_index | integer | Index of the instruction in `instructions`. Starts from 1 |\n| inner_instruction_index | integer | Index of the instruction in `inner_instructions`. Starts from 1 |\n| outer_executing_account | varchar | The account key of the program that executed this instruction at the outer level |\n| inner_executing_account | varchar | The account key of the program that executed this instruction at the inner level (sometimes null) |\n| executing_account | varchar | coalesce of the inner_executing_account and outer_executing_account. The account key of the program that executed this instruction |\n| data | varbinary | Program input data in a base-58 string |\n| is_inner | boolean | marks if a row is an inner instruction or not |\n| account_arguments | array(varchar) | Ordered list of accounts to pass to the program |\n| inner_instructions | array(row(data varchar, executing_account varchar, account_arguments array(varchar))) | see breakout below |\n| tx_signer | varchar | The address that initiates the transaction and pays the transaction fee |\n| tx_id | varchar | the first signature in the transaction |\n| tx_success | boolean |The transaction was valid and thus committed. |\n| log_messages | array<string> | The log messages emitted by the transaction |\n\n**inner\\_instructions**\n\n| Field              | Data type      | Description                                                    |\n| ------------------ | -------------- | -------------------------------------------------------------- |\n| account\\_arguments | array&lt;string&gt; | Ordered list of accounts to pass to the program                |\n| data               | string         | Program input data in a base-58 string                         |\n| executing\\_account | string         | The account key of the program that executed this instruction. |\n", "doc_id": "143ee9d7-38be-4782-a5b7-e318cd9f72ae", "embedding": null, "doc_hash": "32076b982185d4e09a3c85da4422496ee4a7ea52ee250707d40965e03a992aff", "extra_info": {"file_path": "docs/data-tables/raw/solana/instruction-calls.md", "file_name": "instruction-calls.md"}, "node_info": {"start": 0, "end": 2808, "_node_type": "1"}, "relationships": {"1": "d57c71b5ef37f03cfcff7ef6f2775a8d517a145a"}}, "__type__": "1"}, "4cef0b77-f8aa-41a6-a7ea-8f7795bdad5e": {"__data__": {"text": "# Rewards\n\n## Solana.rewards\n\nThis table contains data about rewards paid out on Solana. One block may contain zero or more rewards, and each row corresponds to one reward.\n\nAn example query can be found here: [Solana rewards fee per day](https://dune.xyz/queries/391421/747012)\n\n| Column Name   | Column Type | Description                                                                                       |\n| ------------- | ----------- | ------------------------------------------------------------------------------------------------- |\n| block\\_slot   | bigint      | This block\u2019s slot index in the ledger                                                             |\n| block\\_hash   | string      | The hash of this block, base-58 encoded                                                           |\n| block\\_time   | timestamp   | The (estimated) time this block was produced                                                      |\n| block\\_date   | date        | Event date                                                                                        |\n| commission    | string      | Vote account commission when the reward was credited, only present for voting and staking rewards |\n| lamports      | bigint      | Number of reward lamports credited or debited by the account                                      |\n| pre\\_balance  | bigint      | Account balance in lamports before the reward was applied                                         |\n| post\\_balance | bigint      | Account balance in lamports after the reward was applied                                          |\n| recipient     | string      | The public key, as base-58 encoded string, of the account that received the reward                |\n| reward\\_type  | string      | Type of reward: \"fee\", \"rent\", \"voting\", \"staking\"                                                |\n", "doc_id": "4cef0b77-f8aa-41a6-a7ea-8f7795bdad5e", "embedding": null, "doc_hash": "fee5a80dfb72546c6a6aa6f2f1ccd7845fa053c985ce5c254b0913c0cbff7a6e", "extra_info": {"file_path": "docs/data-tables/raw/solana/rewards.md", "file_name": "rewards.md"}, "node_info": {"start": 0, "end": 1864, "_node_type": "1"}, "relationships": {"1": "066d1391242cf88445c8d7eb218fdd8306eee8a8"}}, "__type__": "1"}, "c86fa5d8-ecba-4e2b-92c3-ff7e75678280": {"__data__": {"text": "# Transactions\n\n## Solana.transactions\n\nThis table contains the transaction data within Solana\u2019s blockchain. Most of the relevant data related to account, protocol, and program activity is available in this table.\n\nQuery examples can be found here: [NFT transactions of popular programs past 7 days](https://dune.xyz/queries/390720/745376) and [drift-protocol overview](https://dune.xyz/bigz/drift-\\(solana\\))\n\n| Column Name                      | Column Type                   | Description                                                                                                                                                                                                                           |\n| -------------------------------- | ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| block\\_slot                      | bigint                        | This block\u2019s slot index in the ledger                                                                                                                                                                                                 |\n| block\\_time                      | timestamp                     | The (estimated) time this block was produced                                                                                                                                                                                          |\n| block\\_date                      | date                          | Event date                             ", "doc_id": "c86fa5d8-ecba-4e2b-92c3-ff7e75678280", "embedding": null, "doc_hash": "4f63012d6efbf36d9465d1809f2d9fa46e9391d1964493c784a66eb14c305b8a", "extra_info": {"file_path": "docs/data-tables/raw/solana/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 0, "end": 1723, "_node_type": "1"}, "relationships": {"1": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7", "3": "e732f692-cd36-4f56-b895-b30fec0e963e"}}, "__type__": "1"}, "e732f692-cd36-4f56-b895-b30fec0e963e": {"__data__": {"text": "                                                                                                                                                                                                                  |\n| index                            | bigint                        | Index into the block\u2019s transactions                                                                                                                                                                                                   |\n| fee                              | bigint                        | Fee this transaction was charged, as paid by first account                                                                                                                                                                            |\n| block\\_hash                      | string                        | The hash of this block, base-58 encoded                                                                                                                                                                                               |\n| error                    ", "doc_id": "e732f692-cd36-4f56-b895-b30fec0e963e", "embedding": null, "doc_hash": "8d8ceb07a18fa9ea721127d71a77b8a79954e3b28b6d70bda0bfc5eb2bced9dd", "extra_info": {"file_path": "docs/data-tables/raw/solana/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 1724, "end": 2866, "_node_type": "1"}, "relationships": {"1": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7", "2": "c86fa5d8-ecba-4e2b-92c3-ff7e75678280", "3": "748eae3f-125c-4029-a851-fd809d2c6697"}}, "__type__": "1"}, "748eae3f-125c-4029-a851-fd809d2c6697": {"__data__": {"text": "                           | STRUCT error                  | NULL if success is true.                                                                                                                                                                                                              |\n| required\\_signatures             | bigint                        | The total number of signatures required to make the transaction valid.                                                                                                                                                                |\n| readonly\\_signed\\_accounts   | bigint                        | The last readonly\\_signed\\_accounts of the signed keys are read-only accounts.                                                                                                                                                        |\n| readonly\\_unsigned\\_accounts | bigint                        | The last readonly\\_unsigned\\_accounts of the unsigned keys are read-only accounts.                                                                                                                                                    |\n| id                               | string                        | The first signature in the transaction                         ", "doc_id": "748eae3f-125c-4029-a851-fd809d2c6697", "embedding": null, "doc_hash": "28caa6fe119ea0f2f0450c8334fc1525fd6bd140b0812805b27f6198e0aa68f4", "extra_info": {"file_path": "docs/data-tables/raw/solana/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 2867, "end": 4187, "_node_type": "1"}, "relationships": {"1": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7", "2": "e732f692-cd36-4f56-b895-b30fec0e963e", "3": "57e41555-12f3-4770-82d9-f0aad1b6412a"}}, "__type__": "1"}, "57e41555-12f3-4770-82d9-f0aad1b6412a": {"__data__": {"text": "                                                                                                                                                                                          |\n| success                          | boolean                       | The transaction was valid and thus committed.                                                                                                                                                                                         |\n| recent\\_block\\_hash          | string                        | The hash of a recent block in the ledger, used to prevent transaction duplication and to give transactions lifetimes                                                                                                                  |\n| instructions                     | array&lt;STRUCT instructions&gt;   | Instructions to execute (in order)                                                                                                                                                                                                    |\n| accountKeys                      | array&lt;string&gt;                | The account keys used in the transaction                                                                       ", "doc_id": "57e41555-12f3-4770-82d9-f0aad1b6412a", "embedding": null, "doc_hash": "8ea76972df8bc9166199591357c3667ba62f8959dcf73e42050614d01bf1edcc", "extra_info": {"file_path": "docs/data-tables/raw/solana/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 4188, "end": 5465, "_node_type": "1"}, "relationships": {"1": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7", "2": "748eae3f-125c-4029-a851-fd809d2c6697", "3": "c3916487-3131-4d50-adf5-9fa53486bf77"}}, "__type__": "1"}, "c3916487-3131-4d50-adf5-9fa53486bf77": {"__data__": {"text": "                                                                                                                                          |\n| log\\_messages                    | array&lt;string&gt;                | The log messages emitted by the transaction                                                                                                                                                                                           |\n| pre\\_balances                    | array&lt;bigint&gt;                | Array of account balances before the transaction was processed. The i-th balance is the balance of the i-th account key in account\\_keys                                                                                              |\n| post\\_balances                   | array&lt;bigint&gt;                | Array of account balances after the transaction was processed. The i-th balance is the balance of the i-th account key in account\\_keys                                                                                               |\n| pre\\_token\\_balance              | array&lt;STRUCT token\\_balance&gt; | List of [token balances](https://docs.solana.com/developing/clients/jsonrpc-api#token-balances-structure) from before the transaction was processed or omitted if token balance recording was not yet enabled during this transaction |\n| post\\_token\\_balance             | array&lt;STRUCT token\\_balance&gt; | List of [token balances](https://docs.solana.com/developing/clients/jsonrpc-api#token-balances-structure) from after the transaction was processed or omitted if token balance recording was not yet enabled during this transaction  |\n| signatures                       | array&lt;string&gt;                | A list of", "doc_id": "c3916487-3131-4d50-adf5-9fa53486bf77", "embedding": null, "doc_hash": "245d95c71c85c59df071bfeba7bd1da8a923f70439b60ebb7c559bd11876a142", "extra_info": {"file_path": "docs/data-tables/raw/solana/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 5466, "end": 7219, "_node_type": "1"}, "relationships": {"1": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7", "2": "57e41555-12f3-4770-82d9-f0aad1b6412a", "3": "afaca212-91ca-4b9a-98bf-fab669e3328d"}}, "__type__": "1"}, "afaca212-91ca-4b9a-98bf-fab669e3328d": {"__data__": {"text": "               | A list of base-58 encoded signatures applied to the transaction. Always of length numRequiredSignatures                                                                                                                               |\n| signer                           | string                        | The initial value from the account\\_keys array that initiates the transaction and pays the transaction fee                                                                                                                            |\n\n### Struct definitions\n\nWithin several of these columns is a data type of STRUCT which allows for representing nested hierarchical data and has key-value pairs. It's similar to a dictionary in python and can be used to group fields together to make them more accessible.\n\nAn example of how these can be used to extract data: [# of Solana instructions by day for DEXes](https://dune.xyz/queries/416358/794290)\n\n**token\\_balance**\n\n| Field   | Data type | Description                                                                                                                                                                  |\n| ------- | --------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| account | string    | The account key of the account that the token balance is provided for.                                                                                                       |\n| mint    | string    | Public key of the token\u2019s mint. This is an account that stores metadata about the token: The supply, number of decimals, and various authorities with control over the mint. |\n| amount  | Decimal   | Derived from the token balance's raw amount (ui\\_token\\_amount.amount) and the number of decimals (ui\\_token\\_amount.decimals)                                               |\n\n***\n\n**instructions**\n\n| Field               | Data type          ", "doc_id": "afaca212-91ca-4b9a-98bf-fab669e3328d", "embedding": null, "doc_hash": "758c09a77d28e1473552880c7a960283d536310a50f1c7f48e528397bfc472eb", "extra_info": {"file_path": "docs/data-tables/raw/solana/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 7212, "end": 9255, "_node_type": "1"}, "relationships": {"1": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7", "2": "c3916487-3131-4d50-adf5-9fa53486bf77", "3": "6e708be5-e0aa-4428-8549-d8152a28cf43"}}, "__type__": "1"}, "6e708be5-e0aa-4428-8549-d8152a28cf43": {"__data__": {"text": "       | Data type                          | Description                                                    |\n| ------------------- | ---------------------------------- | -------------------------------------------------------------- |\n| account\\_arguments  | array&lt;string&gt;                     | Ordered list of accounts to pass to the program                |\n| data                | string                             | Program input data in a base-58 string                         |\n| executing\\_account  | string                             | The account key of the program that executed this instruction. |\n| inner\\_instructions | array&lt;STRUCT inner\\_instructions&gt; | The instructions invoked by this instruction.                  |\n\n***\n\n**inner\\_instructions**\n\n| Field              | Data type      | Description                                                    |\n| ------------------ | -------------- | -------------------------------------------------------------- |\n| account\\_arguments | array&lt;string&gt; | Ordered list of accounts to pass to the program                |\n| data               | string         | Program input data in a base-58 string                         |\n| executing\\_account | string         | The account key of the program that executed this instruction. |\n\n***\n\n**error**\n\n| Field                  | Data type | Description                        |\n| ---------------------- | --------- | ---------------------------------- |\n| **instruction\\_index** | int       | The instruction number that failed |\n| message                | string    | The error message                  |\n\n##\n", "doc_id": "6e708be5-e0aa-4428-8549-d8152a28cf43", "embedding": null, "doc_hash": "9aab10a545ef1be1e500b8904786408f6d70ef8c572fd63c31399ae18e411ccc", "extra_info": {"file_path": "docs/data-tables/raw/solana/transactions.md", "file_name": "transactions.md"}, "node_info": {"start": 9235, "end": 10872, "_node_type": "1"}, "relationships": {"1": "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7", "2": "afaca212-91ca-4b9a-98bf-fab669e3328d"}}, "__type__": "1"}, "278dc771-dfcf-4ca3-a5de-b7f2a6b78e8b": {"__data__": {"text": "# Vote Transactions\n\n## Solana.vote\\_transactions\n\nThis table contains the full set of vote transactions that are submitted by validators to vote on a block. It can be joined with the non-vote transactions table above to get a full breakdown of all transactions. It has the same schema as the main transactions table.\n\nAn example query that demonstrates that is available here: [Solana transactions past 30 days](https://dune.xyz/queries/389976/743760)\n\n| Column Name                      | Column Type                   | Description                                                                                                                                                                                                                           |\n| -------------------------------- | ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| block\\_slot                      | bigint                        | This block\u2019s slot index in the ledger                                                                                                                                                                                                 |\n| block\\_time                      | timestamp                     | The (estimated) time this block was produced                                                                                                                                                                                          |\n| block\\_date                      | date                          | Event date                          ", "doc_id": "278dc771-dfcf-4ca3-a5de-b7f2a6b78e8b", "embedding": null, "doc_hash": "5a9175c3086611c275b060d4e490829372c8ed20817cb08056a1f4b4f8fca1af", "extra_info": {"file_path": "docs/data-tables/raw/solana/vote-transactions.md", "file_name": "vote-transactions.md"}, "node_info": {"start": 0, "end": 1763, "_node_type": "1"}, "relationships": {"1": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5", "3": "9e035d68-9ea5-45a7-b068-b60a772d41f6"}}, "__type__": "1"}, "9e035d68-9ea5-45a7-b068-b60a772d41f6": {"__data__": {"text": "                                                                                                                                                                                                                     |\n| index                            | bigint                        | Index into the block\u2019s transactions                                                                                                                                                                                                   |\n| fee                              | bigint                        | Fee this transaction was charged, as paid by first account                                                                                                                                                                            |\n| block\\_hash                      | string                        | The hash of this block, base-58 encoded                                                                                                                                                                                               |\n| error            ", "doc_id": "9e035d68-9ea5-45a7-b068-b60a772d41f6", "embedding": null, "doc_hash": "4a2b47769c74329c744b26632af9e7c90a04d0a0e7f24cf0d10e3bae886df92a", "extra_info": {"file_path": "docs/data-tables/raw/solana/vote-transactions.md", "file_name": "vote-transactions.md"}, "node_info": {"start": 1764, "end": 2901, "_node_type": "1"}, "relationships": {"1": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5", "2": "278dc771-dfcf-4ca3-a5de-b7f2a6b78e8b", "3": "3342e4f8-6172-42e5-bf5f-9af21d06d8f7"}}, "__type__": "1"}, "3342e4f8-6172-42e5-bf5f-9af21d06d8f7": {"__data__": {"text": "    |\n| error                            | STRUCT error                  | NULL if success is true.                                                                                                                                                                                                              |\n| required\\_signatures             | bigint                        | The total number of signatures required to make the transaction valid.                                                                                                                                                                |\n| readonly\\_signed\\_\\_\\_accounts   | bigint                        | The last readonly\\_signed\\_accounts of the signed keys are read-only accounts.                                                                                                                                                        |\n| readonly\\_unsigned\\_\\_\\_accounts | bigint                        | The last readonly\\_unsigned\\_accounts of the unsigned keys are read-only accounts.                                                                                                                                                    |\n| id                               | string                        | The first signature in the transaction    ", "doc_id": "3342e4f8-6172-42e5-bf5f-9af21d06d8f7", "embedding": null, "doc_hash": "7e2f2b19393f1eb0664df95fa396ed76980f20d4397446b625bb0cd0bd569cca", "extra_info": {"file_path": "docs/data-tables/raw/solana/vote-transactions.md", "file_name": "vote-transactions.md"}, "node_info": {"start": 2894, "end": 4215, "_node_type": "1"}, "relationships": {"1": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5", "2": "9e035d68-9ea5-45a7-b068-b60a772d41f6", "3": "90849325-0bc1-4513-8447-9828f136d15e"}}, "__type__": "1"}, "90849325-0bc1-4513-8447-9828f136d15e": {"__data__": {"text": "       | The first signature in the transaction                                                                                                                                                                                                |\n| success                          | boolean                       | The transaction was valid and thus committed.                                                                                                                                                                                         |\n| recent\\_block\\_\\_\\_hash          | string                        | The hash of a recent block in the ledger, used to prevent transaction duplication and to give transactions lifetimes                                                                                                                  |\n| instructions                     | array&lt;STRUCT instructions&gt;   | Instructions to execute (in order)                                                                                                                                                                                                    |\n| accountKeys                      | array&lt;string&gt;                | The account keys used in the transaction                                         ", "doc_id": "90849325-0bc1-4513-8447-9828f136d15e", "embedding": null, "doc_hash": "8f888ec749175fb96e0295af83790090786f23ffce6dabfffe104955b5dfa37c", "extra_info": {"file_path": "docs/data-tables/raw/solana/vote-transactions.md", "file_name": "vote-transactions.md"}, "node_info": {"start": 4190, "end": 5494, "_node_type": "1"}, "relationships": {"1": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5", "2": "3342e4f8-6172-42e5-bf5f-9af21d06d8f7", "3": "40e1be1d-46ef-423c-94a3-78b9a259608a"}}, "__type__": "1"}, "40e1be1d-46ef-423c-94a3-78b9a259608a": {"__data__": {"text": "                                                                                                                                                                        |\n| log\\_messages                    | array&lt;string&gt;                | The log messages emitted by the transaction                                                                                                                                                                                           |\n| pre\\_balances                    | array&lt;bigint&gt;                | Array of account balances before the transaction was processed. The i-th balance is the balance of the i-th account key in account\\_keys                                                                                              |\n| post\\_balances                   | array&lt;bigint&gt;                | Array of account balances after the transaction was processed. The i-th balance is the balance of the i-th account key in account\\_keys                                                                                               |\n| pre\\_token\\_balance              | array&lt;STRUCT token\\_balance&gt; | List of [token balances](https://docs.solana.com/developing/clients/jsonrpc-api#token-balances-structure) from before the transaction was processed or omitted if token balance recording was not yet enabled during this transaction |\n| post\\_token\\_balance             | array&lt;STRUCT token\\_balance&gt; | List of [token balances](https://docs.solana.com/developing/clients/jsonrpc-api#token-balances-structure) from after the transaction was processed or omitted if token balance recording was not yet enabled during this transaction  |\n| signatures                ", "doc_id": "40e1be1d-46ef-423c-94a3-78b9a259608a", "embedding": null, "doc_hash": "60578e3378f7fad133ff4c1ac130fa6939166ea501e6e050a0dd046cda68ca30", "extra_info": {"file_path": "docs/data-tables/raw/solana/vote-transactions.md", "file_name": "vote-transactions.md"}, "node_info": {"start": 5529, "end": 7257, "_node_type": "1"}, "relationships": {"1": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5", "2": "90849325-0bc1-4513-8447-9828f136d15e", "3": "250b3bb1-506b-4362-9929-e6833bb0120a"}}, "__type__": "1"}, "250b3bb1-506b-4362-9929-e6833bb0120a": {"__data__": {"text": "signatures                       | array&lt;string&gt;                | A list of base-58 encoded signatures applied to the transaction. Always of length numRequiredSignatures                                                                                                                               |\n| signer                           | string                        | The initial value from the account\\_keys array that initiates the transaction and pays the transaction fee                                                                                                                            |\n", "doc_id": "250b3bb1-506b-4362-9929-e6833bb0120a", "embedding": null, "doc_hash": "dd2b3b8698bc7637ddcf8ac2ae73037458d0b3af616891ec17c445980535698f", "extra_info": {"file_path": "docs/data-tables/raw/solana/vote-transactions.md", "file_name": "vote-transactions.md"}, "node_info": {"start": 7231, "end": 7836, "_node_type": "1"}, "relationships": {"1": "0d64e4202485d0f5aa45c05ef5e329a651e33cf5", "2": "40e1be1d-46ef-423c-94a3-78b9a259608a"}}, "__type__": "1"}, "8d10a680-acc6-41de-9572-045e687528e5": {"__data__": {"text": "---\ntitle: 1. \ud83d\udcbb Local Setup\ndescription: Heres what you need to do to set up your computer to work on Spellbook.\n---\n\nTo get started, you\u2019ll need to install:\n\n* [VSCode](https://code.visualstudio.com/) (any IDE will work but this is what we use)\n* [Python 3.9](https://realpython.com/installing-python/) (you need this exact version of Python and distutils installed; if you have trouble ask for help in our [#spellbook Discord channel!](https://discord.com/channels/757637422384283659/999683200563564655))\n* [pip](https://pip.pypa.io/en/stable/installation/)\n* [pipenv](https://pypi.org/project/pipenv/)\n* [git and GitHub](https://docs.github.com/en/get-started/quickstart/set-up-git) (including authentication)\n\nAfter that, you\u2019ll also need to:\n\n* Make a [fork](https://docs.github.com/en/get-started/quickstart/fork-a-repo) of the [spellbook repo](https://github.com/duneanalytics/spellbook). Including cloning locally and adding an upstream. \n* Review Github\u2019s [instructions](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request-from-a-fork) on how to make a pull request from a fork. \n\nHere\u2019s a quick video showing how to make a fork of the Spellbook repo:\n\n![type:video](https://drive.google.com/file/d/1wGGhgwUsersdvqq4YpDWRMRSgqd8l8Qd/preview)\n\nEssentially you:\n\n1. Go to the Spellbook repository and click the fork button at the top.\n2. Copy the HTTPS URL of your fork\n3. Open the folder that you\u2019d like to store Spellbook in inside of VS Code\n4. Open a terminal in VS code and enter `git clone [paste your URL here]`\n\nOnce you hit enter, you\u2019ll start downloading Spellbook, it\u2019ll take a few minutes.\n\n## Setting up Spellbook dbt\n\nOnce you have a local copy of your Spellbook fork, it\u2019s time to set up Spellbook dbt!\n\nIf it isn\u2019t already, open your local copy of your Spellbook fork in VSCode, then open a terminal and enter `pipenv install`.\n\nThis will install the packages necessary to run Spellbook on your computer.\n\nOnce that installation is complete, run `pipenv shell` to activate your virtual environment.\n\nThen `dbt init` to initialize dbt.\n\nEnter the value 1 to select Trino as shown below:\n\n```\nRunning with dbt=1.4.6\nSetting up your profile.\nWhich database would you like to use?\n[1] trino\n\n(Don't see the one you want? https://docs.getdbt.com/docs/available-adapters)\n\nEnter a number: 1\n```\n\nThis will create a template for the profiles.yml file. After you hit enter, you'll be prompted with the location of this file. \n\n```   \nProfile spellbook written to /Users/{your_user}/.dbt/profiles.yml using target's sample configuration. Once updated, you'll be able to start developing with dbt.  \n```\n\nOpen the file with `open /Users/{your_user}/.dbt/profiles.yml` and change the following lines:\n\nBefore editing:\n```\nspellbook:\n  outputs:\n\n    dev:\n      type: trino\n  ", "doc_id": "8d10a680-acc6-41de-9572-045e687528e5", "embedding": null, "doc_hash": "329b511d26702b42843e7a17ab0956569b340b71b32743ff271a4aedc8b1c4b5", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/1-do-some-prerequisites and-set-up-Spellbook-dbt.md", "file_name": "1-do-some-prerequisites and-set-up-Spellbook-dbt.md"}, "node_info": {"start": 0, "end": 2882, "_node_type": "1"}, "relationships": {"1": "06c0b39d09ed42720b55d3bbe0dbaf4ac24e8a38", "3": "e32797e1-c383-44f7-b5b8-b224348fd87e"}}, "__type__": "1"}, "e32797e1-c383-44f7-b5b8-b224348fd87e": {"__data__": {"text": "   dev:\n      type: trino\n      method: none  # optional, one of {none | ldap | kerberos}\n      user: [dev_user]\n      password: [password]  # required if method is ldap or kerberos\n      database: [database name]\n      host: [hostname]\n      port: [port number]\n      schema: [dev_schema]\n      threads: [1 or more]\n\n    prod:\n      type: trino\n      method: none  # optional, one of {none | ldap | kerberos}\n      user: [prod_user]\n      password: [prod_password]  # required if method is ldap or kerberos\n      database: [database name]\n      host: [hostname]\n      port: [port number]\n      schema: [prod_schema]\n      threads: [1 or more]\n\n  target: dev\n```\n\nAfter editing:\n```\nspellbook:\n  outputs:\n    dev:\n      type: trino\n      method: none\n      user: x\n      password: x\n      database: tpch\n      host: localhost\n      port: 8080\n      schema: wizard\n      threads: 1\n      http_scheme: http\n  target: dev\n```\n\nThis will not connect to the Dune database but you have access to some dbt actions.\n\n**Selecting schema `wizard` is important. This indicates you are an external contributor.**\n\nWith this configuration saved, run `dbt deps` to install dependencies.\n\nNext, we need to set up a Trino server. We will use Docker to do this. If you do not have Docker installed, you can download it [here](https://www.docker.com/products/docker-desktop).\n\nThen, we will follow the Trino Docker setup outlined [here](https://trino.io/docs/414/installation/containers.html):\n\nRun:\n\n```console\ndocker run --name trino -d -p 8080:8080 trinodb/trino:414\n```\nThe first time you run this command, it will take a few moments to download the image. On subsequent runs, this will be much faster.\n\nIf you see an error like the one below. Make sure Docker is running by opening the application. You should see the docker whale logo in your menu bar.\n\n```console\ndocker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.\nSee 'docker run --help'.\n``` \n\nYou can check the status of the container with:\n\n```console\ndocker ps\n```\n\nYou should see something like this if it succeeded: \n\n```console\nCONTAINER ID   IMAGE               COMMAND                  CREATED              STATUS                        PORTS                    NAMES\n7fb5aa1f12cb   trinodb/trino:414   \"/usr/lib/trino/bin/\u2026\"   About a minute ago   Up About a minute (healthy)  ", "doc_id": "e32797e1-c383-44f7-b5b8-b224348fd87e", "embedding": null, "doc_hash": "3956918990189e63ece047854c6dc7e76dc1aaec2dde6df7a84f97cc85dc6cdd", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/1-do-some-prerequisites and-set-up-Spellbook-dbt.md", "file_name": "1-do-some-prerequisites and-set-up-Spellbook-dbt.md"}, "node_info": {"start": 2867, "end": 5250, "_node_type": "1"}, "relationships": {"1": "06c0b39d09ed42720b55d3bbe0dbaf4ac24e8a38", "2": "8d10a680-acc6-41de-9572-045e687528e5", "3": "8fa4d92f-fb35-4c30-9319-eb77734dfdbe"}}, "__type__": "1"}, "8fa4d92f-fb35-4c30-9319-eb77734dfdbe": {"__data__": {"text": "  About a minute ago   Up About a minute (healthy)   0.0.0.0:8080->8080/tcp   trino\n\n```\n\nStart the Trino server with: \n\n```console\ndocker start trino\n```\n\nWhen you are done developing, run `docker stop trino` to stop the server.\n\nFinally, run `dbt compile`.\n\nIf that runs correctly your terminal should end with \u201cdone\u201d and you should see the \u201ctarget\u201d folder in your sidebar\n\n![target folder success](images/target-folder-success.jpg)\n\nLastly, run `git checkout -b workshop` to create a new, locally stored branch called \u201cworkshop\u201d for doing the practice work in this guide.\n\nFinally, run `git push -u origin workshop` to add or \u201cpush\u201d your local \u201cworkshop\u201d branch to your remote GitHub repository so we can eventually make our Spellbook pull request.", "doc_id": "8fa4d92f-fb35-4c30-9319-eb77734dfdbe", "embedding": null, "doc_hash": "cb8b646ffc7216a437fd4127546b084bfcf0de3ed9b80e93de810ba3c2a5a03b", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/1-do-some-prerequisites and-set-up-Spellbook-dbt.md", "file_name": "1-do-some-prerequisites and-set-up-Spellbook-dbt.md"}, "node_info": {"start": 5214, "end": 5965, "_node_type": "1"}, "relationships": {"1": "06c0b39d09ed42720b55d3bbe0dbaf4ac24e8a38", "2": "e32797e1-c383-44f7-b5b8-b224348fd87e"}}, "__type__": "1"}, "803f4148-56ab-43bd-ab3c-f1d462b909c4": {"__data__": {"text": "---\ntitle: 2. \ud83d\udee3\ufe0f File Structure\ndescription: Next, let\u2019s check for an existing folder for our project and create one if it doesn\u2019t exist.\n---\n\nNext, let\u2019s check for an existing folder for our project and create one if it doesn\u2019t exist.\n\nAll Spells are stored in the `/spellbook/models` directory by project name, then blockchain network.\n\nNames are all lower case and words are separated by `_`\n\nEg `/spellbook/models/[project_name]/[blockchain_name]`\n\nSo in our Keep3r network example, the folder will be `/spellbook/models/keep3r_network/ethereum`\n\nSince this folder already exists (because we\u2019ve done this before :), in this case, we\u2019ll just build in there.\n\nIf the project didn\u2019t exist, we\u2019d create that folder with the name of the blockchain it\u2019s on; if the project folder exists but we\u2019re creating a Spell for a new blockchain (e.g. that project just added Polygon support), then we\u2019d create a folder for the new blockchain.\n\nWith our folder structure in place, we\u2019ll need to create 3 files:\n\n1. A `.sql` file where our Spell\u2019s logic will go.\n2. A `_schema.yml` where I define my spell\u2019s purpose and add generic tests, descriptions, metadata, etc.\n3. A `_sources.yml` with any project-specific table dependencies.\n\n![spell folder file structure](images/spell-folder-file-structure.jpg)\n\nSpells files are named like this:\n\n* `[project_name]_[blockchain]_schema.yml` for schema files.\n* `[project_name]_[blockchain]_sources.yml` for sources files.\n* `[project_name]_[blockchain]_[spell_name].sql` for the Spell\u2019s SQL files.\n\nIn this specific v1 migration example, we\u2019ll also need to create 3 additional `.sql` files that `keep3r_network_ethereum_view_job_log.sql` depends on.\n\nThese are `keep3r_network_ethereum_view_job_liquidity_log.sql`,  `keep3r_network_ethereum_view_job_credits_log.sql`, and `keep3r_network_ethereum_view_job_migrations.sql`\n\nHow did we know we needed these?\n\nLooking at the original `view_job_log.sql` V1 Abstraction, we see two `FROM` statements:\n\n```sql\n\nFROM\n\n        keep3r_network.view_job_liquidity_log\n\n```\n\n```sql\n\nFROM\n\n        keep3r_network.view_job_credits_log\n\n```\n\nWhen we look at the V1 Keep3r network folder, we see that these two files are there - meaning they are also abstractions that need to be converted into Spells.\n\n![keep3r other abstractions to translate](images/keep3r-other-abstractions-to-translate.png)\n\nWe also need to do a recursive check to see if those abstractions depend on any other abstractions that have yet to be migrated to Spells.\n\nTo do this, we open those two abstractions and search for `FROM` statements.\n\nHere we find a couple of tables referenced that include \u201c_evt_\u201d, which is a naming convention for [Decoded Event tables](../../decoded/evm/event-logs.md).\n\nYou\u2019ll find other Raw and Decoded data table naming conventions in our [Tables documentation here](../../../index.md).", "doc_id": "803f4148-56ab-43bd-ab3c-f1d462b909c4", "embedding": null, "doc_hash": "3af88de9774312a2455efd91220a828ca4b3ddab2d1fb081a377e9348fa10453", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/2-set-up-your-file-structure-for-SQL-schema-and-source-files.md", "file_name": "2-set-up-your-file-structure-for-SQL-schema-and-source-files.md"}, "node_info": {"start": 0, "end": 2854, "_node_type": "1"}, "relationships": {"1": "f043f3380d1f2e3bdb20217f6665d1cf95860ab8", "3": "e960c0c7-a8a3-4093-989c-23dee3b19f66"}}, "__type__": "1"}, "e960c0c7-a8a3-4093-989c-23dee3b19f66": {"__data__": {"text": "naming conventions in our [Tables documentation here](../../../index.md). \n\nV1 abstractions are named like so:\n\n`[project_name].[abstraction_name]`\n\nAnd when we search both of the abstractions referenced in `view_job_log.sq` we also find a reference to `keep3r_network_ethereum_view_job_migrations` so that must also become a Spell.", "doc_id": "e960c0c7-a8a3-4093-989c-23dee3b19f66", "embedding": null, "doc_hash": "235eceb6223cd942d63b5c88692d7bf4396895425540954255ec64c99d084b7c", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/2-set-up-your-file-structure-for-SQL-schema-and-source-files.md", "file_name": "2-set-up-your-file-structure-for-SQL-schema-and-source-files.md"}, "node_info": {"start": 2781, "end": 3113, "_node_type": "1"}, "relationships": {"1": "f043f3380d1f2e3bdb20217f6665d1cf95860ab8", "2": "803f4148-56ab-43bd-ab3c-f1d462b909c4"}}, "__type__": "1"}, "f6ab8d66-b8d4-4268-953b-d29ac73ffd01": {"__data__": {"text": "---\ntitle: 3. \ud83d\udcd9 Define Sources.yml\ndescription: With our file structure setup, let\u2019s complete our `_sources.yml` file.\n---\n\nWith our file structure setup, let\u2019s complete our `_sources.yml` file.\n\nHere\u2019s how these files are formatted:\n\n```sls\n\nversion: 2 # Spells all have \u201cversion: 2\u201d as that\u2019s the version of our engine they use.\n\nsources:\n\n  - name: [project_name]_[blockchain]\n\n    description: [one line description] # right arrow > allows us to make a multi-line description\n\n    tables:\n\n      - name: [source_table_1]\n\n      - name: [source_table_2]\n\n      - name: [source_table_3]\n\n```\n\nWhat sources do we need to name?\n\nTo find this, we again go through each of the V1 abstractions that we\u2019re migrating, search for `FROM` statements, and this time we\u2019re looking for all tables mentioned that *are not* abstractions.\n\nIn our Keep3r example, doing that for our main abstraction and its dependencies:\n\n* `keep3r_network.view_job_log`\n* `keep3r_network.view_job_liquidity_log`\n* `keep3r_network.view_job_credits_log`\n* `keep3r_network_ethereum_view_job_migrations`\n\nWe end up with a `keep3r_network_ethereum_sources.yml` file that looks like this:\n\n```sls\n\nversion: 2\n\nsources:\n\n  - name: keep3r_network_ethereum\n\n    description: >\n\n      Decoded events for [keep3r.network](https://keep3r.network/), a marketplace for posting and accepting jobs to help run decentralized infrastructure.\n\n      The scope of Keep3r Network is not to manage the jobs themselves, but to allow contracts to register as jobs for keepers, and keepers to register themselves as available to perform jobs. A \"keeper\" is a term used to refer to an external person and/or team that executes a job.\n\n      See their [docs](https://docs.keep3r.network/) for more.\n\n    tables:\n\n      - name: Keep3r_evt_LiquidityAddition\n\n      - name: Keep3r_v2_evt_LiquidityAddition\n\n      - name: Keep3r_evt_LiquidityWithdrawal\n\n      - name: Keep3r_v2_evt_LiquidityWithdrawal\n\n      - name: Keep3r_evt_JobMigrationSuccessful\n\n      - name: Keep3r_v2_evt_JobMigrationSuccessful\n\n      - name: Keep3r_evt_KeeperWork\n\n      - name: Keep3r_v2_evt_KeeperWork\n\n      - name: Keep3r_evt_LiquidityCreditsReward\n\n      - name: Keep3r_v2_evt_LiquidityCreditsReward\n\n```", "doc_id": "f6ab8d66-b8d4-4268-953b-d29ac73ffd01", "embedding": null, "doc_hash": "1efe6ba643472ed8e16c98115b51e8a418464853d8d373bb063f8207b45715fd", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/3-identify-and-define-sources.md", "file_name": "3-identify-and-define-sources.md"}, "node_info": {"start": 0, "end": 2224, "_node_type": "1"}, "relationships": {"1": "0ee3e4c07af94ede0ae8cecd50917977db44d7e8"}}, "__type__": "1"}, "f754d93d-64c7-424c-b9c3-f656cff42e51": {"__data__": {"text": "---\ntitle: 4. \ud83e\uddea Define Schema/Test\ndescription: Next, we define what success means for our Spell in two ways.\n---\n\nNext, we define what success means for our Spell in two ways:\n\n1. A schema of columns to output.\n2. A unit test to ensure accurate data is being outputted to those columns.\n\n## Defining schema\n\nFirst, we start by defining our model\u2019s schema - what columns should be outputted for each of the .sql files in our Spell.\n\nOur `_schema.yml` files are structured like this:\n\n```sls\n\nversion: 2\n\nmodels:\n\n  - name: [model_name]\n\n    meta:\n\n      blockchain: [blockchain_name]\n\n      project: [project_name]\n\n      contributors: [your_name]\n\n    config:\n\n      tags: [\"[blockchain]\", \"[project_name]\", \"[other_relevant_tags]\"]\n\n    description: [description]\n\n    columns:\n\n      - &[column_name]\n\n        name: [column_name]\n\n        description: \"[description]\"\n\n        tests:\n\n          - [generic_test_criteria]\n\n  - name: [model_name_2]\n\n    meta:\n\n      blockchain: [blockchain_name]\n\n      project: [project_name]\n\n      contributors: [your_name]\n\n    config:\n\n      tags: [\"[blockchain]\", \"[project_name]\", \"[other_relevant_tags]\"]\n\n    description: [description]\n\n    columns:\n\n      - *[previously_definied_column]\n\n```\n\n!!! note\n    \u201c&\u201d is used for the first definition of a column and \u201c*\u201d thereafter will lead to a column with the same name in a different model inheriting the same name, description, and generic tests.\n\nEach of the SQL files we created in our fourth step is a model here, with each of the columns we want to output named and described along with a mention of any generic tests that they should be checked against.\n\n[Check out the Keep3r Spell schema here for what that looks like when finished in our example](https://github.com/duneanalytics/spellbook/blob/b9260a03351e562448c5c9e62529da7b2d94ca59/models/keep3r_network/ethereum/keep3r_network_ethereum_schema.yml).\n\n## Set up unit test seed file structure\n\nWith our schema set up, we\u2019re ready to define our [Unit Tests](https://en.wikipedia.org/wiki/Unit_testing) - which will help us ensure our Spells work as intended.\n\nThis starts with setting up a seed file structure.\n\nIn dbt, [seed files are CSVs](https://docs.getdbt.com/docs/build/seeds) that we use to store reference data we can use in our Spells and unit tests; in this case, we\u2019ll use it to store some data we can use to validate our Spell is WAI.\n\nNavigating to the `/seeds` folder, just like we do for new projects, we\u2019ll create a `/[project_name]/[blockchain]` subfolder.\n\nSo in our Keep3r example `/seeds/keep3r_network/ethereum`\n\nWith that in place, we need to create a CSV file with a descriptive name using this format:\n\n`[project_name]_[blockchain]_[spell_name]_test_data.csv`\n\nSo in our", "doc_id": "f754d93d-64c7-424c-b9c3-f656cff42e51", "embedding": null, "doc_hash": "7128ad23418249f10849da5573aaf0633acf91e144595af1bbd96a93b59f8164", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/4-define-expectations-with-schema-and-tests.md", "file_name": "4-define-expectations-with-schema-and-tests.md"}, "node_info": {"start": 0, "end": 2747, "_node_type": "1"}, "relationships": {"1": "a21fee5e6788aef76f96cfd5e128ec3b8be3caf7", "3": "425e6521-cb82-4b62-9f2a-b14a778a969d"}}, "__type__": "1"}, "425e6521-cb82-4b62-9f2a-b14a778a969d": {"__data__": {"text": "in our example:\n\n`keep3r_network_ethereum_view_job_log_test_data.csv`\n\n## Finding expected values for unit tests\n\nOur unit tests will be run against a list of expected values, essentially we want to check to make sure our Spell delivers the results it should.\n\nWhat results should we expect?\n\nTo figure that out we\u2019ll need to learn a bit more about Keep3r network by reading through their website, docs, Medium blog, asking in their discord, etc.\n\nFor our example, the important thing to know is that Keep3r network is a marketplace for posting and accepting jobs to help run decentralized infrastructure.\n\nJobs on the Keep3r network are smart contracts that need Keepers to do something outside of their internal logic. Doing these tasks results in the Keeper being rewarded.\n\nBased on this understanding we can write a test where, given a transaction hash, we can see the amount that was awarded for the job, the keeper who received it, and which token they were paid in.\n\nSo in our CSV file, we start by defining the columns we\u2019ll have test data to validate against, in this case: `tx_hash`, `amount`, ` keeper`, and `token`.\n\nNext, we\u2019ll find a few specific transactions, 3 is enough, and add the actual data that should be in each of those columns.\n\nThe result is something like this:\n\n```csv\n\ntx_hash,amount,keeper,token\n\n0xca1ee6de6d2a776afda7d6ab6bc489d4554f69777725db58591a7ac0ef533c96,0.11,0x9429cd74a3984396f3117d51cde46ea8e0e21487,0x1cEB5cB57C4D4E2b2433641b95Dd330A33185A44\n\n0xdd59724ee9a1f151706bc182be810483a35b36c2a82485469245887742996313,0.13,0xfb20864791b7dd70542dae2f4907ef0535a68cdc,0x1cEB5cB57C4D4E2b2433641b95Dd330A33185A44\n\n0xa8c8383254bd4cda949de1e847f8ae0d7f765053ddeeca11a159ad8191d8cc85,0.35,0xfb20864791b7dd70542dae2f4907ef0535a68cdc,0x1cEB5cB57C4D4E2b2433641b95Dd330A33185A44\n\n```\n\n## Writing unit tests\n\nNow that we have expected results to test against, we can write our unit test!\n\nFirst, as you might expect, we create a folder structure in the `/tests` folder, as well as a SQL file for our test.\n\nSame naming conventions as before for the folders, for our SQL file we\u2019ll name it `[project_name]_[spell_name]_test.sql`\n\nSo:\n\n`/keep3r_network/ethereum/keep3r_network_view_job_log_test.sql`\n\n![keep3r test file](images/keep3r-test-file.jpg)\n\nTo write our unit test, we\u2019re going to check to ensure the results from the Spell we\u2019ll (finally) define in the next step matches the real-world results we added to our expected values seed file.\n\nTo do this, we\u2019ll define a [Common Table Expression](https://learnsql.com/blog/cte-with-examples/) (CTE) called `unit_test`, joining our test and actual results data, and comparing that data returning errors if they don\u2019t match.\n\nHere\u2019s what the unit test for this example looks like, with comments explaining what\u2019s", "doc_id": "425e6521-cb82-4b62-9f2a-b14a778a969d", "embedding": null, "doc_hash": "eed5fce32db27cd88b20580365161ef38c496bf704ff56e3d7f7022f29aac4fc", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/4-define-expectations-with-schema-and-tests.md", "file_name": "4-define-expectations-with-schema-and-tests.md"}, "node_info": {"start": 2743, "end": 5529, "_node_type": "1"}, "relationships": {"1": "a21fee5e6788aef76f96cfd5e128ec3b8be3caf7", "2": "f754d93d-64c7-424c-b9c3-f656cff42e51", "3": "1c725a50-f148-437d-a78d-60e09043751b"}}, "__type__": "1"}, "1c725a50-f148-437d-a78d-60e09043751b": {"__data__": {"text": "what the unit test for this example looks like, with comments explaining what\u2019s going on:\n\n```sql\n\n-- CTEs are created using WITH statements\n\nWITH unit_test AS (\n\n    -- Here we compare test data to actual data, returning TRUE if it matches and FALSE if not; ROUND and LOWER ensure we don\u2019t get false errors due to formatting differences.\n\n    SELECT\n\n        CASE\n\n            WHEN test.amount = ROUND(\n\n                actual.amount,\n\n                2\n\n            ) THEN TRUE\n\n            ELSE FALSE\n\n        END AS amount_test,\n\n        CASE\n\n            WHEN LOWER(\n\n                test.keeper\n\n            ) = LOWER(\n\n                actual.keeper\n\n            ) THEN TRUE\n\n            ELSE FALSE\n\n        END AS keeper_test,\n\n        CASE\n\n            WHEN LOWER(\n\n                test.token\n\n            ) = LOWER(\n\n                actual.token\n\n            ) THEN TRUE\n\n            ELSE FALSE\n\n        END AS token_test\n\n   /* Here we JOIN our actual and test data on tx_hash. Note for \u201cactual\u201d we reference our actual Spell model file, and our test data file for \u201ctest.\u201d The {{}} is JINJA templating we\u2019ll cover later. */\n\n    FROM\n\n        {{ ref('keep3r_network_ethereum_view_job_log') }} AS actual\n\n        INNER JOIN {{ ref('keep3r_network_ethereum_view_job_log_test_data') }} AS test\n\n        ON LOWER(\n\n            actual.tx_hash\n\n        ) = LOWER(\n\n            test.tx_hash\n\n        )\n\n)\n\n-- Loading all columns from unit_test, we return any FALSE results\n\nSELECT\n\n    *\n\nFROM\n\n    unit_test\n\nWHERE\n\n    amount_test = FALSE\n\n    OR keeper_test = FALSE\n\n    OR token_test = FALSE\n\n```", "doc_id": "1c725a50-f148-437d-a78d-60e09043751b", "embedding": null, "doc_hash": "f3a227e0ab9504e9d6a01c9af7ab8d8d814c11332ef7fac289064cffe42c4938", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/4-define-expectations-with-schema-and-tests.md", "file_name": "4-define-expectations-with-schema-and-tests.md"}, "node_info": {"start": 5455, "end": 7058, "_node_type": "1"}, "relationships": {"1": "a21fee5e6788aef76f96cfd5e128ec3b8be3caf7", "2": "425e6521-cb82-4b62-9f2a-b14a778a969d"}}, "__type__": "1"}, "1fa2cdc6-b813-4957-a709-ff3cbc08b525": {"__data__": {"text": "---\ntitle: 5. \ud83d\udd8b\ufe0f Write Your Spell\ndescription: Now we\u2019re ready to *officially* start casting our Spell!\n---\n\nNow we\u2019re ready to *officially* start casting our Spell!\n\nWhile our endpoint is `_view_job_log.sql`, we need to start with `_view_job_migrations.sql`.\n\n## `_view_job_migrations.sql`\n\nWhy start here? Because it\u2019s our lowest-level dependency!\n\nRemember `keep3r_network_ethereum_view_job_log.sql` depends on `keep3r_network_ethereum_view_job_liquidity_log.sql` and `keep3r_network_ethereum_view_job_credits_log.sql` - both of which rely on `keep3r_network_ethereum_view_job_migrations.sql`\n\nSo by starting with `_migrations.sql`, we\u2019ll be able to test as we cast our Spell without having anything break because the dependencies aren\u2019t built.\n\nTo migrate from our V1 abstraction, we\u2019ll start by copying the contents of the V1 file (`/spellbook/deprecated-dune-v1-abstractions/ethereum/keep3r_network/view_job_migrations.sql`) to our `keep3r_network_ethereum_view_job_migrations.sql` file:\n\n```sql\n\nCREATE OR REPLACE VIEW keep3r_network.view_job_migrations AS (\n\n    SELECT\n\n        evt_block_time AS timestamp,\n\n        '0x' || encode(evt_tx_hash, 'hex') AS tx_hash,\n\n        evt_index + s.step AS evt_index,\n\n        CASE s.step\n\n        WHEN (0) THEN\n\n            'JobMigrationOut'\n\n        WHEN (1) THEN\n\n            'JobMigrationIn'\n\n        END AS event,\n\n        '0x' || encode(contract_address, 'hex') keep3r,\n\n        '0x' || encode(\n\n            CASE s.step\n\n            WHEN (0) THEN\n\n                m. \"_fromJob\"\n\n            WHEN (1) THEN\n\n                m. \"_toJob\"\n\n            END, 'hex') AS job\n\n    FROM (\n\n        SELECT\n\n            *\n\n        FROM\n\n            keep3r_network. \"Keep3r_evt_JobMigrationSuccessful\"\n\n        UNION\n\n        SELECT\n\n            *\n\n        FROM\n\n            keep3r_network. \"Keep3r_v2_evt_JobMigrationSuccessful\") AS m\n\n        INNER JOIN (\n\n            SELECT\n\n                generate_series(0, 1) AS step) AS s ON TRUE);\n\n```\n\nWe don\u2019t need the `CREATE` or `REPLACE` definition statement, so we\u2019ll just need everything from the first `SELECT` to the last", "doc_id": "1fa2cdc6-b813-4957-a709-ff3cbc08b525", "embedding": null, "doc_hash": "4f4ce36fe99a6096dd19262999c2c5ad97f0c3236802f802321e2fe08f606b23", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/5-write-your-spell-as-SELECT-statement.md", "file_name": "5-write-your-spell-as-SELECT-statement.md"}, "node_info": {"start": 0, "end": 2112, "_node_type": "1"}, "relationships": {"1": "d92e82a6719b8794e1b2d28b212ea63ea03ef218", "3": "2c1b56d2-9571-424e-a805-24f96feffccc"}}, "__type__": "1"}, "2c1b56d2-9571-424e-a805-24f96feffccc": {"__data__": {"text": "definition statement, so we\u2019ll just need everything from the first `SELECT` to the last `TRUE`\n\nThen for our FROM statements, we need to replace the old references with the new syntax and double check we mention these in our  `_sources.yml` file.\n\n```sql\n\n-- Removed CREATE/REPLACE statement\n\nSELECT\n\n    evt_block_time AS timestamp,\n\n    '0x' || encode(evt_tx_hash, 'hex') AS tx_hash,\n\n    evt_index + s.step AS evt_index,\n\n    CASE s.step\n\n    WHEN (0) THEN\n\n        'JobMigrationOut'\n\n    WHEN (1) THEN\n\n        'JobMigrationIn'\n\n    END AS event,\n\n    '0x' || encode(contract_address, 'hex') keep3r,\n\n    '0x' || encode(\n\n        CASE s.step\n\n        WHEN (0) THEN\n\n            m. \"_fromJob\"\n\n        WHEN (1) THEN\n\n            m. \"_toJob\"\n\n        END, 'hex') AS job\n\nFROM (\n\n    SELECT *\n\n    -- Updated the two tables we reference with our new syntax, confirming they\u2019re both in our sources file.\n\n    FROM\n\n            keep3r_network_ethereum.Keep3r_evt_JobMigrationSuccessful\n\n    UNION\n\n    SELECT *\n\n    FROM\n\n        'keep3r_network_ethereum.Keep3r_v2_evt_JobMigrationSuccessful) AS m\n\n    INNER JOIN (\n\n        SELECT\n\n            generate_series(0, 1) AS step) AS s ON TRUE\n\n```\n\nNotice how the old abstraction had a `SELECT *` statement; it\u2019s best practice to only `SELECT` the actual columns we need when performing a `UNION` so that our Spell doesn\u2019t break should one of our reference tables be updated.\n\nLooking above our first `SELECT *` statement we\u2019ll find the specific columns we need, both of our final statements look like this:\n\n```sql\n\nSELECT\n\n    evt_block_time,\n\n    evt_tx_hash,\n\n    evt_index,\n\n    contract_address,\n\n    _fromJob,\n\n    _toJob\n\n```\n\nNext, we need to change our syntax from V1 abstraction style to V2 Spell style, which means a couple of things in this case:\n\n1. We don\u2019t need to `encode` contract addresses (in V1 they were `bytea` format and in V2 they\u2019re `string`)\n2. Column references no longer need double quotes so `m. \"_fromJob\"` -> `m._fromJob`\n\nAfter we\u2019ve done that, let\u2019s copy our SQL to a new Query in dune.com to see if it works.\n\nIf you get any errors, fix them with the help of the error code; while building this example, we got an Undefined function error as `generate_series`, a function used in the V1 abstraction that does not exist in V2.\n\nKnowing that Dune V1 is PostgreSQL and V2 is Spark SQL, in this case by googling \u201cgenerate series Spark SQL\u201d we were able to find this [StackExchange", "doc_id": "2c1b56d2-9571-424e-a805-24f96feffccc", "embedding": null, "doc_hash": "ac848501430c984875100baa682826f6e61b1dd45df67af256830e2bf34b9555", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/5-write-your-spell-as-SELECT-statement.md", "file_name": "5-write-your-spell-as-SELECT-statement.md"}, "node_info": {"start": 2039, "end": 4495, "_node_type": "1"}, "relationships": {"1": "d92e82a6719b8794e1b2d28b212ea63ea03ef218", "2": "1fa2cdc6-b813-4957-a709-ff3cbc08b525", "3": "a3dc409f-41a5-4adb-b7bb-ab5fd4ead5d9"}}, "__type__": "1"}, "a3dc409f-41a5-4adb-b7bb-ab5fd4ead5d9": {"__data__": {"text": "\u201cgenerate series Spark SQL\u201d we were able to find this [StackExchange answer](https://stackoverflow.com/questions/43141671/sparksql-on-pyspark-how-to-generate-time-series) to perform the same transformation using Spark functionality.\n\nIf you\u2019re not so lucky with Google, then ask for help in our [#spellbook Discord channel](https://discord.com/channels/757637422384283659/999683200563564655)!\n\n## `_liquidity_log.sql`, `_credit_log.sql`, and `_log.sql`\n\nThe process is essentially just the same for our other files (modifying the syntax to V2/Spark SQL).\n\nSince `_liquidity_log.sql` and `_credits_log.sql` both depend on `_migrations.sql`, which we just created and haven\u2019t added to the in-production Spellbook yet, we need to copy/paste the logic that we just created as a `WITH` statement.\n\nSo in `_liquidity_log.sql`, we have this reference: `keep3r_network.view_job_migrations migs`\n\nLet\u2019s update that to `keep3r_network.view_job_migrations_temp migs`\n\nThen define `_temp` at the top of our SQL file:\n\n```sql\n\nWITH \n\nkeep3r_network.view_job_migrations_temp as (\n\n-- [insert the _migrations code we just created here]\n\n)\n\n```\n\nThen we can copy/paste our new SQL into dune.com and fix errors just like we did above.\n\n## Replace hard-coded references with JINJA templating\n\nWith our SQL translated from PostgreSQL to Spark and tested individually, we need to add our JINJA templating so that this will all work in production!\n\nFirst, let\u2019s clarify a couple of terms:\n\n* **Sources** are data that\u2019s been added by the Dune team - raw blockchain data, Decoded data, prices, and Community tables - basically anything that\u2019s not a Spell.\n    * With JINJA, references to models are formatted as `{{ source() }}`\n* **Models **are the `SELECT` statements the community have defined in the `.sql` files stored inside of our `spellbook/models` directory.\n    * With JINJA, references models are formatted as `{{ ref() }}`\n\nFor `sources()` references, we first need to pass the name of our `_sources.yml` file, then the name of the source.\n\nSo our V1 abstraction reference `keep3r_network. \"Keep3r_evt_JobMigrationSuccessful\"` becomes `{{ source('keep3r_network_ethereum','Keep3r_evt_JobMigrationSuccessful') }}` where:\n\n* `keep3r_network_ethereum` is the name of our `_sources.yml` *without* the `_sources.yml` part, and\n* 'Keep3r_evt_JobMigrationSuccessful' is the name of a Decoded table that we included in `keep3r_network_ethereum_sources.yml`\n\nFor our `ref()` references, we just need to name the SQL files we created without `.sql`.\n\nSo our V1 abstraction reference `keep3r_network.view_job_liquidity_log` becomes `{{ ref('keep3r_network_ethereum_view_job_liquidity_log') }}`.\n\nOnce you\u2019ve added the JINJA formatting to your references, run `dbt compile` and fix any errors!\n\nAgain, googling \u201cxxx error dbt\u201d or \u201cJINJA\u201d or \u201cSpark SQL\u201d can help with a lot; if our Google overlords fail you hit up the community in our [#spellbook Discord", "doc_id": "a3dc409f-41a5-4adb-b7bb-ab5fd4ead5d9", "embedding": null, "doc_hash": "713081e95b722cb7076c02efcc84ae5c6af851aac441fb48a01c51edc965e5ca", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/5-write-your-spell-as-SELECT-statement.md", "file_name": "5-write-your-spell-as-SELECT-statement.md"}, "node_info": {"start": 4512, "end": 7444, "_node_type": "1"}, "relationships": {"1": "d92e82a6719b8794e1b2d28b212ea63ea03ef218", "2": "2c1b56d2-9571-424e-a805-24f96feffccc", "3": "f0399098-01e3-46d7-b6ac-cec7bfff6215"}}, "__type__": "1"}, "f0399098-01e3-46d7-b6ac-cec7bfff6215": {"__data__": {"text": "if our Google overlords fail you hit up the community in our [#spellbook Discord channel](https://discord.com/channels/757637422384283659/999683200563564655)!", "doc_id": "f0399098-01e3-46d7-b6ac-cec7bfff6215", "embedding": null, "doc_hash": "58da9fd06e4a50677b70318d36fc59edaec3f539416e50f76b53d4362ebd87bf", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/5-write-your-spell-as-SELECT-statement.md", "file_name": "5-write-your-spell-as-SELECT-statement.md"}, "node_info": {"start": 7422, "end": 7580, "_node_type": "1"}, "relationships": {"1": "d92e82a6719b8794e1b2d28b212ea63ea03ef218", "2": "a3dc409f-41a5-4adb-b7bb-ab5fd4ead5d9"}}, "__type__": "1"}, "b833923a-83e9-4f66-b827-bda4969a8438": {"__data__": {"text": "---\ntitle: 6. \ud83c\udfa8 Configure Alias and Materialization\ndescription: With our Spell\u2019s SQL defined, it\u2019s time to configure our aliases.\n---\n\nWith our Spell\u2019s SQL defined, it\u2019s time to configure our aliases so we can refer to these files in other Spells and Queries and how we want dbt to materialize our work.\n\n## Materialize Your Model as a Table\n\nIn dbt, [materializations](https://docs.getdbt.com/docs/build/materializations) are strategies for persisting our data inside of our data lake house.\n\nThere are 4 materialization strategies in dbt:\n\n* `table`\n* `ephemeral`\n* `view`\n* `incremental`\n\nFor Spellbook, we just use `view` and `incremental`.\n\n### Add Your Model as a View\n\n`view` is the default materialization strategy in Spellbook - so we don\u2019t need to specify it as our strategy in the Spells that use it.\n\nThese Spells are rebuilt each time they are run, meaning every time someone queries a `view` Spell, the SQL is run meaning fresh data is gathered according to our Spell\u2019s SQL logic.\n\nBasically, `view` Spells are just stored SQL logic, no additional data is stored as part of the Spell.\n\nThe Pro is that `view` Spells always have fresh data, the Con is that they can take a long time to run if there\u2019s a lot of data involved.\n\n### Add Your Model as an Incremental Table\n\n`incremental` Spells allow dbt to insert or update records in a table according to the logic we define.\n\nThe benefit is that these Spells can run faster, though their data won\u2019t be as fresh as `view` Spells.\n\nTo create an `incremental` Spell, in the Config section of our file we need to include\n\n```sql\n\n-- a statement of which column we should join new data to our existing data each time we increment; in this example, we use block_date and that\u2019s often the best to use\n\npartition_by = ['block_date'],\n\n-- here we specify that this is an incremental Spell\n\nmaterialized = 'incremental',\n\n-- an instruction for how dbt should combine new/old data; use \u2018merge\u2019\n\nincremental_strategy = 'merge',\n\n```\n\nWe also need to add `if` statements to any `FROM` for which we want to increment data.\n\nIn this example, where we `partition_by = ['block_date']`, we\u2019ve added ifs that will refresh data that\u2019s more than a week old:\n\n```sql\n{% if is_incremental() %}\n\n    WHERE evt_block_time >= date_trunc(\"day\", now() - interval '1 week')\n\n{% endif %}\n```\n\n## Configuring aliases and materialization\n\nTo configure your Spell\u2019s alias and materialization, you\u2019ll add this configuration to the top of each of your SQL files.\n\nNote, this assumes we\u2019re using a `view` materialization strategy; see above for how to implement `incremental` strategies.\n\n```sql\n{{ config (\n\n    -- create an alias for your Spell file that will appear in the dune.com UI\n\n    alias = 'job_log',\n\n    -- this further defines how this file is stored and categorized in the UI, starting with what blockchain it\u2019s associated with\n\n    post_hook = '{{ expose_spells(\\'[\"ethereum\"]\\',\n\n\n         -- then we define whether this is a Spell for a specific project or a whole sector\n\n\n        \"project\", \n\n\n         -- next, we name the project/sector\n\n\n            \"Keep3r\",\n\n\n     ", "doc_id": "b833923a-83e9-4f66-b827-bda4969a8438", "embedding": null, "doc_hash": "be18215e0ea85ebff3eb62b46ffca7baadb48155b6ea8d313958b71a01070677", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/6-configure-alias-and-materialization-strategy.md", "file_name": "6-configure-alias-and-materialization-strategy.md"}, "node_info": {"start": 0, "end": 3117, "_node_type": "1"}, "relationships": {"1": "3e2403e32ef0f367e18352da3695a88684dba3f8", "3": "897cb772-962f-464d-b84a-e1e6dd034784"}}, "__type__": "1"}, "897cb772-962f-464d-b84a-e1e6dd034784": {"__data__": {"text": "        \"Keep3r\",\n\n\n         -- lastly, we name the contributors, including ourselves and in this case the creator of the V1 abstraction!\n\n\n             \\'[\"wei3erHase\", \"agaperste\"]\\') }}'\n\n) }}\n```\n\n## Add new models to dbt_project.yml\n\nComing into the final stretch, we need to add our new models to the `dbt_project.yml` file in the Spellbook root folder.\n\nFirst, find these lines:\n\n```sls\n\n# Configuring models\n\n# Full documentation: https://docs.getdbt.com/docs/configuring-models\n\nmodels:\n\n\tspellbook:\n\n```\n\nUnderneath, we specify the project name, schema, and materialization strategy for the project as a whole as well as the specific blockchain(s) that we\u2019ve created Spells for.\n\nFor Keep3r, our entry looks like this:\n\n```sls\n\n   keep3r_network:\n\n      +schema: keep3r_network\n\n      +materialized: view\n\n      ethereum:\n\n        +schema: keep3r_network_ethereum\n\n        +materialized: view\n\n```", "doc_id": "897cb772-962f-464d-b84a-e1e6dd034784", "embedding": null, "doc_hash": "7d02ab1216852d09fde4f7dc3c07db0bb027663523c35493682c87f22b2d3c89", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/6-configure-alias-and-materialization-strategy.md", "file_name": "6-configure-alias-and-materialization-strategy.md"}, "node_info": {"start": 3092, "end": 3999, "_node_type": "1"}, "relationships": {"1": "3e2403e32ef0f367e18352da3695a88684dba3f8", "2": "b833923a-83e9-4f66-b827-bda4969a8438"}}, "__type__": "1"}, "d8c4454d-fd05-4a31-9902-3426c258e8d3": {"__data__": {"text": "---\ntitle: 7. \ud83e\uddd9 Make a Pull Request\ndescription: With all this out of the way, it\u2019s time to submit a PR to the official Spellbook!\n---\n\nWith all this out of the way, it\u2019s time to submit a PR to the official Spellbook!\n\nTo do that, make sure you Commit your local changes to your Spellbook GitHub fork.\n\nThen, head over to your fork on Github, find the \u201cContribute\u201d dropdown towards the top of the page, open that and smash the \u201cOpen pull request button.\u201d\n\n![open pull request button](images/open-pull-request-button.png)\n\nFollow the PR template to make sure all of your checks and tests pass, and then add the `ready-for-review` label once it's all green! If you click into the [\"dbt slim ci (in beta)\"](https://github.com/duneanalytics/spellbook/actions/runs/4763996851/jobs/8468061865) action and go to \"dbt run initial model(s)\", you will see a test_schema model built for any schemas you changed that creates a temporary table like this `test_schema.git_5d780b2f_tokens_ethereum_erc20`. You can query this table in the Dune interface (only under Spark SQL for now).\n\nNone of us are perfect, so pretty much all of us get comments from the Team for things we need to fix or improve with our Spells before they\u2019ll approve the pull request.\n\nOnce you\u2019ve addressed all the comments, your Spell will be approved and you\u2019ll be one of the select few Dune Archwizards! \ud83e\uddd9 You will earn a git POAP for your work.", "doc_id": "d8c4454d-fd05-4a31-9902-3426c258e8d3", "embedding": null, "doc_hash": "afdfebffe2d3db38b5d8f1130e064d341d814cfd172926b78e78ab48fadbf814", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/7-make-a-pull-request-get-merged-become-an-archwizard.md", "file_name": "7-make-a-pull-request-get-merged-become-an-archwizard.md"}, "node_info": {"start": 0, "end": 1405, "_node_type": "1"}, "relationships": {"1": "cefef4718b805070345764e7a6bb54afe738f236"}}, "__type__": "1"}, "3fee16fb-0df8-46da-91e8-56b07412c687": {"__data__": {"text": "---\ntitle: Daily Aggregation\n---\n\nThis sums all transfers for the day. This table is materialized as an incrementally loaded table updated every 15 minutes because the next step includes a slower \\`[window](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-window.html)\\` function to capture a rolling sum.\n\nThere are a few novel components to make this Spell incremental:\n\nThe `<div data-gb-custom-block data-tag=\"if\"> </div>` JINJA block allows us to add an arbitrary filter when running in \u201cincremental\u201d mode. Incremental mode is default and a full refresh is denoted by a command line arg to completely recreate the table.\n\nHere we use this block to filter for all data timestamped in the last two days. We are running this model every fifteen minutes, but we allow a look back of 2 days to account for data arriving late from the blockchain.\n\nDoes that create duplicates? It would, but we are also using a \u201c`merge`\u201d incremental\\_strategy. Merge strategies require a unique key and deduplicate the table upon each update. You\u2019ll see above in the transfers view, we created our own `'unique_transfer_id'` by coalescing several transfer features together that we utilize here.\n\nYou\u2019ll also note that this is the first use of \u201crefs\u201d in this spellset. A ref, like `{{ ref('tokens_ethereum_erc20') }}` is simply a reference to another model in the DBT project. It doesn\u2019t matter what the name of the view or table is. The ref references the name of the file itself. That means, we can\u2019t have duplicate file names.\n\n[transfers\\_ethereum\\_erc20\\_agg\\_day.sql](https://github.com/duneanalytics/spellbook/blob/master/spellbook/models/transfers/ethereum/erc20/transfers\\_ethereum\\_erc20\\_agg\\_day.sql)\n\n```sql\n{{ config(\n       alias ='erc20_agg_day',\n       materialized ='incremental',\n       file_format ='delta',\n       incremental_strategy='merge',\n       unique_key='unique_transfer_id'\n       )\n}}\n\nselect\n   'ethereum' as blockchain,\n   date_trunc('day', tr.evt_block_time) as day,\n   tr.wallet_address,\n   tr.token_address,\n   t.symbol,\n   sum(tr.amount_raw) as amount_raw,\n   sum(tr.amount_raw / power(10, t.decimals)) as amount,\n   unique_tx_id || '-' || wallet_address || '-' || token_address || '-' || sum(tr.amount_raw)::string as unique_transfer_id\nfrom {{ ref('transfers_ethereum_erc20') }} tr\nleft join {{ ref('tokens_ethereum_erc20') }} t on t.contract_address = tr.token_address\n\n{% raw %}\n{% if is_incremental() %}\n-- this filter will only be applied on an incremental run\nwhere date_trunc('day', tr.evt_block_time) > now() - interval 2 days\n{% endif %}\n{% endraw %}\ngroup by\n   date_trunc('day', tr.evt_block_time), tr.wallet_address, tr.token_address,", "doc_id": "3fee16fb-0df8-46da-91e8-56b07412c687", "embedding": null, "doc_hash": "7672cd7b5c526d5ce6426e2a1e4e8125f91dfbd367073435bf87329a13b4685f", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/daily-aggregation.md", "file_name": "daily-aggregation.md"}, "node_info": {"start": 0, "end": 2680, "_node_type": "1"}, "relationships": {"1": "2168413a22fcc28b3ee9b9ae6ce4c2c77266e951", "3": "98880794-3419-4e65-b782-cc284bac55ef"}}, "__type__": "1"}, "98880794-3419-4e65-b782-cc284bac55ef": {"__data__": {"text": "tr.wallet_address, tr.token_address, t.symbol,unique_tx_id\n```\n\n[transfers\\_ethereum\\_schema.yml](https://github.com/duneanalytics/spellbook/blob/master/spellbook/models/transfers/ethereum/transfers\\_ethereum\\_schema.yml)\n\n```yaml\n  - name: transfers_ethereum_erc20_agg_hour\n    meta:\n      blockchain: ethereum\n      sector: transfers\n      project: erc20\n      contibutors: soispoke, dot2dotseurat\n    config:\n      tags: ['transfers', 'ethereum', 'erc20', 'agg_hour', 'soispoke', 'dot2dotseurat']\n    columns:\n      - *blockchain\n      - &hour\n        name: hour\n        description: \"UTC event block time truncated to the hour mark.\"\n      - *wallet_address\n      - *token_address\n      - name: symbol\n        description: \"ERC20 token symbol\"\n      - *amount_raw\n      - name: amount\n        description: \"Raw amount of ERC20 token held *after* taking into account token decimals\"\n      - name: amount_usd\n        description: \"Amount of ERC20 token held in USD (fiat value at time of transaction)\"\n```\n", "doc_id": "98880794-3419-4e65-b782-cc284bac55ef", "embedding": null, "doc_hash": "24bac069288f79aa0873ef5a8c0f246e0870a5b6c2332d2796ab2f1a10bf2f58", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/daily-aggregation.md", "file_name": "daily-aggregation.md"}, "node_info": {"start": 2644, "end": 3652, "_node_type": "1"}, "relationships": {"1": "2168413a22fcc28b3ee9b9ae6ce4c2c77266e951", "2": "3fee16fb-0df8-46da-91e8-56b07412c687"}}, "__type__": "1"}, "c63449e2-18fa-480b-a4ba-6923ac2f3f3a": {"__data__": {"text": "---\ntitle: Final Daily Balance\n---\n\nThis is our final daily Ethereum ERC20 token balances spell. We expand our Spell to cover all days, not just the days with transfer activity. We add price data, we remove known rebase tokens and any tokens that resulted in large negative balances.\n\nThe ref tokens\\_ethereum\\_rebase is a static list of known rebase tokens that we manage. Whereas, the ref `'balances_ethereum_erc20_noncompliant'` is a table we derive from transfers\\_ethereum\\_erc20\\_rolling\\_day. That table looks for unique token\\_addresses with larger negative balances which indicate the contract may not be compliant with ERC20.\n\n[balances\\_ethereum\\_erc20\\_day.sql](https://github.com/duneanalytics/spellbook/blob/master/spellbook/models/balances/ethereum/erc20/balances\\_ethereum\\_erc20\\_day.sql)\n\n```sql\n{{ config(\n       alias='erc20_day'\n       )\n}}\n\nwith\n   days as (\n       select\n           explode(\n               sequence(\n                   to_date('2015-01-01'), date_trunc('day', now()), interval 1 day\n               )\n           ) as day\n   )\n\n, daily_balances as\n(SELECT\n   wallet_address,\n   token_address,\n   amount_raw,\n   amount,\n   day,\n   symbol,\n   lead(day, 1, now()) OVER (PARTITION BY token_address, wallet_address ORDER BY day) AS next_day\n   FROM {{ ref('transfers_ethereum_erc20_rolling_day') }})\n\nSELECT\n   'ethereum' as blockchain,\n   d.day,\n   b.wallet_address,\n   b.token_address,\n   b.amount_raw,\n   b.amount,\n   b.amount * p.price as amount_usd,\n   b.symbol\nFROM daily_balances b\nINNER JOIN days d ON b.day <= d.day AND d.day < b.next_day\nLEFT JOIN {{ source('prices', 'usd') }} p\n   ON p.contract_address = b.token_address\n   AND d.day = p.minute\n   AND p.blockchain = 'ethereum'\n-- Removes rebase tokens from balances\nLEFT JOIN {{ ref('tokens_ethereum_rebase') }}  as r\n   ON b.token_address = r.contract_address\n-- Removes likely non-compliant tokens due to negative balances\nLEFT JOIN {{ ref('balances_ethereum_erc20_noncompliant') }}  as nc\n   ON b.token_address = nc.token_address\nWHERE r.contract_address is null\nand nc.token_address is null\n```\n\n[transfers\\_ethereum\\_schema.yml](https://github.com/duneanalytics/spellbook/blob/master/spellbook/models/transfers/ethereum/transfers\\_ethereum\\_schema.yml)\n\n```yaml\n  - name: balances_ethereum_erc20_day\n    meta:\n      blockchain: ethereum\n      sector: balances\n      project: erc20\n      contibutors: soispoke, dot2dotseurat\n    config:\n      tags: ['balances',", "doc_id": "c63449e2-18fa-480b-a4ba-6923ac2f3f3a", "embedding": null, "doc_hash": "abcc313f265e7db0fb1480d5a29f777e63fb04cda35aa7764c876a263141119c", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/final-day-balance.md", "file_name": "final-day-balance.md"}, "node_info": {"start": 0, "end": 2461, "_node_type": "1"}, "relationships": {"1": "fc66b7490b3ef2a06eab0ee1846e6ff62eca48df", "3": "dde2f544-2a17-4009-ba5f-46181e5043e5"}}, "__type__": "1"}, "dde2f544-2a17-4009-ba5f-46181e5043e5": {"__data__": {"text": "   config:\n      tags: ['balances', 'ethereum', 'erc20', 'day', 'soispoke', 'dot2dotseurat']\n    description: >\n        Daily token balances of ERC20 Ethereum tokens per wallet and contract address pair.\n        Depends on erc20_ethereum_transfers.\n    columns:\n      - *blockchain\n      - &day\n        name: day\n        description: \"UTC event block time truncated to the day mark\"\n      - *wallet_address\n      - *token_address\n      - *amount_raw\n      - *amount\n      - *amount_usd\n      - *symbolyam\n```\n", "doc_id": "dde2f544-2a17-4009-ba5f-46181e5043e5", "embedding": null, "doc_hash": "7d3a30d51248b63743e31f3181c5c488a7265c734e3343295e4943c2f7424a2f", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/final-day-balance.md", "file_name": "final-day-balance.md"}, "node_info": {"start": 2426, "end": 2935, "_node_type": "1"}, "relationships": {"1": "fc66b7490b3ef2a06eab0ee1846e6ff62eca48df", "2": "c63449e2-18fa-480b-a4ba-6923ac2f3f3a"}}, "__type__": "1"}, "66676581-3a48-45ae-b38b-5b0ca6596d5c": {"__data__": {"text": "---\ntitle: Example Spell Models\n---\n\nAs an example, we'll look at ERC-20. [ERC-20](https://ethereum.org/en/developers/docs/standards/tokens/erc-20) tokens are fungible tokens that all follow a contract standard set by the Ethereum Foundation. To track daily balances, we need to first identify the transfers.\n\nThe main base Dune table we\u2019ll use for this purpose is `erc20_ethereum.evt_Transfer` which you can find via the data explorer.\n![type:video](https://www.loom.com/embed/198148674ded4f5e944f65452852482b)\n\nIn our case, we have broken down the Spell into a more modular series of spells:\n\n- [Reformatted](reformatted.md) transfers\n- [Daily aggregation](daily-aggregation.md) of transfers\n- [Rolling sum](rolling-sum.md) of daily transfers\n- [Final daily balances](final-day-balance.md) for Ethereum ERC20 tokens\n", "doc_id": "66676581-3a48-45ae-b38b-5b0ca6596d5c", "embedding": null, "doc_hash": "cb38c1bbb41498fef2fec283dfd67bc62ce29581c651a4e375d44fa5d0fd672c", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 818, "_node_type": "1"}, "relationships": {"1": "283cccbb1c96b4ef412c449e542b348230110de1"}}, "__type__": "1"}, "0009ad3c-86d1-448b-96bf-f207288296e8": {"__data__": {"text": "---\ntitle: Reformatted Transfers\n---\n\nOur base table records the transfer amount to and from an account. To make it easier to sum of transfers, we munge this into a union of sent txns and received txns.\n\nAdditionally, WETH requires special handling given the additional functions of deposit and withdrawal. This means we need to add `zeroex_ethereum.weth9_evt_deposit` as a source like we did for `erc20_ethereum.evt_transfer` above.\n\nSimilar to a source, the model is defined in a YAML file. This is where things like the description, tests, and metadata are defined. This is also where we track \u201ccontributors\u201d. So make sure you get your clout and add your handle when writing or editing a spell. Then you\u2019ll be credited for your contribution in the [documentation](https://dune.com/spellbook).\n\nIn the JINJA config block, we define that the alias for this view is `erc20`. Without this alias, the table name would default to the file name. The schema name for this view is defined in the [dbt\\_project.yml](https://github.com/duneanalytics/spellbook/blob/master/spellbook/dbt\\_project.yml) file in the root of the Spellbook project. Schema\u2019s are defined there by the directory structure. The name of this view would be transfers\\_ethereum.erc20 given the current structure.\n\nNote: we're generally against using SHOUT CASE, that\u2019s what IDEs are for. Sue us.\n\n[transfers\\_ethereum\\_erc20.sql](https://github.com/duneanalytics/spellbook/blob/master/spellbook/models/transfers/ethereum/erc20/transfers\\_ethereum\\_erc20.sql)\n\n```sql\n{{ config(materialized='view', alias='erc20') }}\n\nwith\n    sent_transfers as (\n        select\n            'send' || '-' || evt_tx_hash || '-' || evt_index || '-' || `to` as unique_tx_id,\n            `to` as wallet_address,\n            contract_address as token_address,\n            evt_block_time,\n            value as amount_raw\n        from\n            {{ source('erc20_ethereum', 'evt_transfer') }}\n    )\n\n    ,\n    received_transfers as (\n        select\n        'receive' || '-' || evt_tx_hash || '-' || evt_index || '-' || `from` as unique_tx_id,\n        `from` as wallet_address,\n        contract_address as token_address,\n        evt_block_time,\n        - value as amount_raw\n        from\n            {{ source('erc20_ethereum', 'evt_transfer') }}\n    )\n\n    ,\n    deposited_weth as (\n        select\n            'deposit' || '-' || evt_tx_hash || '-' || evt_index || '-' || dst as unique_tx_id,\n            dst as wallet_address,\n            contract_address as token_address,\n            evt_block_time,\n            wad as", "doc_id": "0009ad3c-86d1-448b-96bf-f207288296e8", "embedding": null, "doc_hash": "19cd9682764ad7b3df4c5852dca2e5fee536576b7a8d8c8a5cd7b560dc79a603", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/reformatted.md", "file_name": "reformatted.md"}, "node_info": {"start": 0, "end": 2560, "_node_type": "1"}, "relationships": {"1": "c641e41c03008b2290c54aaa4544847d1bd5d8ac", "3": "c565b9de-ddb9-4e36-96d5-c6efc59c9ca6"}}, "__type__": "1"}, "c565b9de-ddb9-4e36-96d5-c6efc59c9ca6": {"__data__": {"text": "           wad as amount_raw\n        from\n            {{ source('zeroex_ethereum', 'weth9_evt_deposit') }}\n    )\n\n    ,\n    withdrawn_weth as (\n        select\n            'withdrawn' || '-' || evt_tx_hash || '-' || evt_index || '-' || src as unique_tx_id,\n            src as wallet_address,\n            contract_address as token_address,\n            evt_block_time,\n            - wad as amount_raw\n        from\n            {{ source('zeroex_ethereum', 'weth9_evt_withdrawal') }}\n    )\n    \nselect unique_tx_id, 'ethereum' as blockchain, wallet_address, token_address, evt_block_time, amount_raw\nfrom sent_transfers\nunion\nselect unique_tx_id, 'ethereum' as blockchain, wallet_address, token_address, evt_block_time, amount_raw\nfrom received_transfers\nunion\nselect unique_tx_id, 'ethereum' as blockchain, wallet_address, token_address, evt_block_time, amount_raw\nfrom deposited_weth\nunion\nselect unique_tx_id, 'ethereum' as blockchain, wallet_address, token_address, evt_block_time, amount_raw\nfrom withdrawn_weth\n```\n\n[transfers\\_ethereum\\_schema.yml](https://github.com/duneanalytics/spellbook/blob/master/spellbook/models/transfers/ethereum/transfers\\_ethereum\\_schema.yml)\n\n```yaml\nmodels:\n - name: transfers_ethereum_erc20\n   meta:\n     blockchain: ethereum\n     sector: transfers\n     project: erc20\n     contibutors: soispoke, dot2dotseurat\n   config:\n     tags: ['transfers', 'ethereum', 'erc20', 'soispoke', 'dot2dotseurat']\n   description: \"ERC20 Token Transfers on Ethereum. This table is updated every 15 minutes.\"\n   columns:\n     - name: unique_transfer_id\n       description: \"Unique transfer ID (used for testing for duplicates)\"\n       tests:\n         - unique\n     - &blockchain\n       name: blockchain\n       description: \"Blockchain\"\n     - &wallet_address\n       name: wallet_address\n       description: \"Wallet address of sender or receiver. If amount is negative, wallet address is the sender's.\"\n     - &token_address\n       name: token_address\n       description: \"Contract address for token\"\n     - &evt_block_time\n       name: evt_block_time\n       description: \"Timestamp for block event time in UTC\"\n     - &amount_raw\n       name: amount_raw\n       description: \"Raw amount of ERC20 token held *before* taking into account token", "doc_id": "c565b9de-ddb9-4e36-96d5-c6efc59c9ca6", "embedding": null, "doc_hash": "ac54f6b00a39e452b39a9c1f2971ede6cc9bb03a9481ec0ac82be302ff4ab86b", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/reformatted.md", "file_name": "reformatted.md"}, "node_info": {"start": 2556, "end": 4812, "_node_type": "1"}, "relationships": {"1": "c641e41c03008b2290c54aaa4544847d1bd5d8ac", "2": "0009ad3c-86d1-448b-96bf-f207288296e8", "3": "d695faf3-3c93-45b6-95f0-42eced039888"}}, "__type__": "1"}, "d695faf3-3c93-45b6-95f0-42eced039888": {"__data__": {"text": "   description: \"Raw amount of ERC20 token held *before* taking into account token decimals\"\n\n```\n\n[dbt\\_project.yml](https://github.com/duneanalytics/spellbook/blob/master/spellbook/dbt\\_project.yml)\n\n```yaml\ntransfers:\n +schema: transfers\n +materialized: view\n ethereum:\n   +schema: transfers_ethereum\n   +materialized: view\n```\n", "doc_id": "d695faf3-3c93-45b6-95f0-42eced039888", "embedding": null, "doc_hash": "fda39011062209a93036756413cf32be7e177a4bca9062e25ae09c576fef6300", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/reformatted.md", "file_name": "reformatted.md"}, "node_info": {"start": 4735, "end": 5066, "_node_type": "1"}, "relationships": {"1": "c641e41c03008b2290c54aaa4544847d1bd5d8ac", "2": "c565b9de-ddb9-4e36-96d5-c6efc59c9ca6"}}, "__type__": "1"}, "65b3424e-539c-458a-bf2a-78dd3c48e473": {"__data__": {"text": "---\ntitle: Rolling Sum of Daily Transfers\n---\n\nThe next step is to apply the rolling sum window function to each daily transfer sum. This is a pretty straightforward query. We\u2019d end here for balances if it was guaranteed that each wallet/contract pair made a transfer every day. But since that\u2019s not the case we\u2019ll finish the Spell in the next model by filling in all the missing days and doing a few more clean up steps.\n\n[transfers\\_ethereum\\_erc20\\_rolling\\_day.sql](https://github.com/duneanalytics/spellbook/blob/master/spellbook/models/transfers/ethereum/erc20/transfers\\_ethereum\\_erc20\\_rolling\\_day.sql)\n\n```sql\n{{ config(\n       alias ='erc20_rolling_day')\n}}\n\n       select\n           'ethereum' as blockchain,\n           day,\n           wallet_address,\n           token_address,\n           symbol,\n           current_timestamp() as last_updated,\n           row_number() over (partition by token_address, wallet_address order by day desc) as recency_index,\n           sum(amount_raw) over (\n               partition by token_address, wallet_address order by day\n           ) as amount_raw,\n           sum(amount) over (\n               partition by token_address, wallet_address order by day\n           ) as amount\n       from {{ ref('transfers_ethereum_erc20_agg_day') }}\n```\n\n[transfers\\_ethereum\\_schema.yml](https://github.com/duneanalytics/spellbook/blob/master/spellbook/models/transfers/ethereum/transfers\\_ethereum\\_schema.yml)\n\n```yaml\n  - name: transfers_ethereum_erc20_rolling_hour\n    meta:\n      blockchain: ethereum\n      sector: transfers\n      project: erc20\n      contibutors: soispoke, dot2dotseurat\n    config:\n      tags: ['transfers', 'ethereum', 'erc20', 'rolling_hour', 'soispoke', 'dot2dotseurat']\n    columns:\n      - *blockchain\n      - *hour\n      - *wallet_address\n      - *token_address\n      - name: symbol\n        description: \"ERC20 token symbol\"\n      - *amount_raw\n      - name: amount\n        description: \"Rolling sum of raw amount of ERC20 token held *after* taking into account token decimals\"\n      - name: amount_usd\n        description: \"Rolling sum of amount of ERC20 token held in USD (fiat value at time of transaction)\"\n      - name: updated_at\n        description: \"UTC timestamp when table was last updated\"\n      - name: recency_index\n        description: \"Index of most recent balance ascending. recency_index=1 is the wallet/contract pair's most recent balance\"\n```\n\n", "doc_id": "65b3424e-539c-458a-bf2a-78dd3c48e473", "embedding": null, "doc_hash": "f91cb594dcbab85c6ddb068ac7a6f8f3be9cc96f5c412a39b80902d38e8fcc85", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/rolling-sum.md", "file_name": "rolling-sum.md"}, "node_info": {"start": 0, "end": 2427, "_node_type": "1"}, "relationships": {"1": "23a3e62f3f2acb009592e6b5b57db1faa03b59d2"}}, "__type__": "1"}, "9dc54506-73e0-4c75-a463-3125a74c1ea3": {"__data__": {"text": "---\ntitle: Understand and Add a Spell\ndescription: Learn how to add a Data Model to the Spellbook\n---\n\n## Understanding Spell Models\n\nIf you are just looking to understand the basic models [from the Github Repo](https://github.com/duneanalytics/spellbook), read through the [example model walkthroughs of transfers and balances of ERC20 tokens](Example%20Spell%20Models/index.md)\n\n## 7 Steps to adding a Spell\n\nLet\u2019s learn how to add a Spell in no time flat - it\u2019s like \ud83d\udcab! By the end of this guide, you\u2019ll have your local environment set up and the knowledge you need to add Spells for yourself or to claim bounties.\n\n7 steps to go:\n\n<div class=\"cards grid\" markdown>\n- [1. \ud83d\udcbb Set Up Spellbook dbt locally](1-do-some-prerequisites%20and-set-up-Spellbook-dbt.md)\n- [2. \ud83d\udee3\ufe0f Set Up Your File Structure for SQL, Schema, and Source Files](2-set-up-your-file-structure-for-SQL-schema-and-source-files.md)\n- [3. \ud83d\udcd9 Identify and Define Sources](3-identify-and-define-sources.md)\n- [4. \ud83e\uddea Define Schema and Tests](4-define-expectations-with-schema-and-tests.md)\n- [5. \ud83d\udd8b\ufe0f Write Your Spell](5-write-your-spell-as-SELECT-statement.md)\n- [6. \ud83c\udfa8 Configure Alias and Materialization](6-configure-alias-and-materialization-strategy.md)\n- [7. \ud83e\uddd9 Make a Pull Request, Become an Archwizard](7-make-a-pull-request-get-merged-become-an-archwizard.md)\n</div>\n\n!!! note \"Spellbook Model Creation Runs on Spark SQL\"\n       Spellbook Spells are available on Dune V2, queryable from both Spark SQL and Dune SQL [V2 Query Engines](/query/index.md). For now, Spells will continue to be written in Spark SQL and querying them with Dune SQL will require small syntax changes. While the changes needed to make Spells Dune SQL native are small, we want to make sure Dune SQL is rock solid before we implement them!\n## Video Guides\n\nIf you\u2019re more of a watcher, check out these video workshops.\n\nIn collaboration with [MetricsDAO](https://metricsdao.xyz/), [@agaperste](https://dune.com/agaperste) showed us how to add a Spell from scratch!\n\n![type:video](https://www.youtube.com/embed/VdTYRxg96-E)\n\nIn this [DuneCon workshop](https://www.youtube.com/playlist?list=PLK3b5d4iK10eVQejE7O1JEwcBMA4uwdSC), Dune Team member Megan Heintz (who came up with the name \"Spellbook\") walks us through Spellbook's infrastructure and how to migrate data to a Spell:\n\n![type:video](https://www.youtube.com/embed/r9pcL7dgaWs)\n\nIn this tutorial, [@ilemi](https://dune.com/ilemi) aka Andrew Hong shows us the main protocol interactions (creating a pair, managing liquidity, swapping through pairs) and how to pull and transform data on Ethereum using.\n\n[Read his guide here](https://ath.mirror.xyz/K-S_Mwhj7osTBqN-AOWbCmfNn9TZViEkzICCmK-oObM) or watch the video below:\n\n![type:video](https://www.youtube.com/embed/7zReSzVdV2s)\n", "doc_id": "9dc54506-73e0-4c75-a463-3125a74c1ea3", "embedding": null, "doc_hash": "172c6a9ddfb9dd3bbcb5fc5e92c45e66bfd737a76a3580a15f4d0958a35d93da", "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 2770, "_node_type": "1"}, "relationships": {"1": "21045d21783395b894914b57930b2f2aa791975b"}}, "__type__": "1"}, "736879d9-b9bb-4566-9ebb-98e72a32451f": {"__data__": {"text": "---\ntitle: Spellbook Tables\ndescription: With the help of the community we construct customs tables which cover the entirety of a type of activity on the blockchain called Spells.\n---\n\n**Spellbook Tables are the easiest way to query blockchain data on Dune**\n\n<div class=\"cards grid\" markdown>\n\n-   #### Github Repo\n\n    The Spellbook GitHub repository can be found here.\n  \n    [:octicons-arrow-right-24: Spellbook Github Repo](https://github.com/duneanalytics/spellbook)\n\n-   #### Model Docs\n\n    Visit the Spellbook Model Docs to see a complete list of Spellbook Spell tables.\n  \n    [:octicons-arrow-right-24: Spellbook Model Docs](https://dune.com/spellbook)\n\n</div>\n\n## Abstraction and Aggregation Tables for Blockchain Data\n\nSpellbook is an open-source [dbt repository](https://docs.getdbt.com/docs/introduction) for creating and maintaining high-level blockchain data tables using SQL and [Jinja templating](https://realpython.com/primer-on-jinja-templating/).\n\n**Spells are custom tables that are built and maintained by Dune and our community.**\n\nIt enables the community to build toward a standardized way to transform data into meaningful abstraction layers. With web3 data, we have a foundational layer of [Raw Data](../raw/index.md) - blockchain transactions, traces, and logs. Spellbook lets us create abstracted data sets, like [dex.trades](https://dune.com/spellbook#!/model/model.spellbook.dex_trades) and [nft.trades](https://dune.com/spellbook#!/model/model.spellbook.nft_trades), which aggregate and organize raw data from multiple sources to make it much easier to query.\n\ndbt natively understands the dependencies between all models. In our old abstractions logic we were managing dependencies manually, which made deploying and maintaining them a mess. With dependency management, we can guarantee that all models are deployed in the correct order.\n\n![Dependency graph created by dbt showing erc20 daily balances dependency tree](images/dbt-erc20-dependency-graph.jpg)\n\nWe hope you are as excited as we are about this tool. You can add a view, seed file (excel/csv), or materialized table (incremental or not) by [contributing to spellbook](contributing/index.md).\n\n## Contributing to Spellbook\n\nIf you'd like to contribute to Dune spells, take a look at [Spellbook](contributing/index.md).\n\nThese enable you to effortlessly aggregate lots of data with as little friction as possible.\n\nTo view available Spells, take a look at our [Spellbook model documentation](https://dune.com/spellbook) and learn how to contribute new Spells [here](contributing/index.md)\n\nOur Spells are managed via the public [Spellbook GitHub repository](https://github.com/duneanalytics/spellbook/). We welcome pull requests!\n\n!!! note \"Spellbook Model Creation Runs on Spark SQL\"\n       Spellbook Spells are available on Dune V2, queryable from both Spark SQL and Dune SQL [V2 Query Engines](/query/index.md). For now, Spells will continue to be written in Spark SQL and querying them with Dune SQL will require small syntax changes. While the changes needed to make Spells Dune SQL native are small, we want to make sure Dune SQL is rock solid before we implement them!\n\n## Why Spellbook?\n\nTo better understand why we use Spellbook, let\u2019s see it in action.\n\nOnce upon a time, crypto Twitter was alight with talk of a new NFT project called Renga.\n\nWhat\u2019s the project about? Is it", "doc_id": "736879d9-b9bb-4566-9ebb-98e72a32451f", "embedding": null, "doc_hash": "d36901fa8de8b9345e081c5acfa39af22c0abb21c67816835008d5e44b125e2a", "extra_info": {"file_path": "docs/data-tables/spellbook/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 3380, "_node_type": "1"}, "relationships": {"1": "eefab96eb5b30e083cfbbf70a8f94370d27df740", "3": "52b32d33-a3f9-4b95-89a6-274b0051d061"}}, "__type__": "1"}, "52b32d33-a3f9-4b95-89a6-274b0051d061": {"__data__": {"text": "NFT project called Renga.\n\nWhat\u2019s the project about? Is it something worth buying as an investment?\n\nIf we want to do some on-chain analysis, we could start by going to OpenSea and finding the Renga collection ([here](https://opensea.io/collection/renga)).\n\n![renga collection opensea](../spellbook/contributing/images/RENGA-Collection-OpenSea.png)\n\n[By viewing an item from this collection](https://opensea.io/assets/ethereum/0x394e3d3044fc89fcdd966d3cb35ac0b32b0cda91/6294), we can get the collection\u2019s contract address as well as the unique ID from its OpenSea URL.\n\n![get renga contract address from url](../spellbook/contributing/images/get-renga-contract-address-from-url.png)\n\nWe can also scroll down and click on a transaction to [view it on the blockchain explorer](https://etherscan.io/tx/0x96f158d75379057d95c1c562b9908603e543feee25a71ac420e21ecf0a0c643c) and get more data like:\n\n* The transaction block and hash\n* The To/From addresses for the transfer\n* How much ETH was transferred\n\nAt a base level, blockchain data is packaged in blocks, which is one form of data we call \u201cRaw\u201d in Dune.\n\nSo from our research, we could build a Query that pulls the data from the block in which this transaction happened.\n\n```sql\n\nSELECT *\n\nFROM ethereum.blocks\n\nWHERE number = 15661624 --the block number we found in etherscan\n\n```\n\nThat returns:\n\n![type:video](https://dune.com/embeds/1645898/2727844/09c37981-3b21-4bfd-85da-c029755af873)\n\nA lot is going on in this block so this isn\u2019t very targeted. Also, the data here isn\u2019t very understandable.\n\nWe could also search for this specific transaction to get closer to our target:\n\n```sql\n\nSELECT *\n\nFROM ethereum.transactions\n\n--the transaction hash we found in etherscan\n\nWHERE where block_number = 15661624 AND hash = '0x96f158d75379057d95c1c562b9908603e543feee25a71ac420e21ecf0a0c643c'\n\n```\n\nWhich gets us:\n\n![type:video](https://dune.com/embeds/1645938/2727926/8a442735-79c7-4903-a525-303c8163d7fd)\n\nSome more interesting info here like `gas_price` and `gas_used` but the juicy stuff is in the `data` column - but to understand that we\u2019d need to reference the contract\u2019s [Application Binary Interface](https://www.quicknode.com/guides/smart-contract-development/what-is-an-abi) ABI.\n\nThankfully, Dune has [Decoded Data](../decoded/index.md), which contains contract data that\u2019s been automatically decoded from the transaction\u2019s raw data using the ABI - the machines save us time.\n\nWith Decoded Data, we can make a Query like this:\n\n```sql\n\nSELECT *\n\n    , concat('0x',substr(get_json_object(offer[0], \"$.token\"),3,40)) as token_contract_address\n\n    , get_json_object(consideration[0], \"$.identifier\") as token_id\n\nFROM seaport_ethereum.Seaport_evt_OrderFulfilled\n\nWHERE evt_tx_hash = lower(\"0x96f158d75379057d95c1c562b9908603e543feee25a71ac420e21ecf0a0c643c\") --sample", "doc_id": "52b32d33-a3f9-4b95-89a6-274b0051d061", "embedding": null, "doc_hash": "b78cf8e29ef7a2563204a29da31992bd6373e696d80951ca6b5dac4ab5e4f01d", "extra_info": {"file_path": "docs/data-tables/spellbook/index.md", "file_name": "index.md"}, "node_info": {"start": 3331, "end": 6153, "_node_type": "1"}, "relationships": {"1": "eefab96eb5b30e083cfbbf70a8f94370d27df740", "2": "736879d9-b9bb-4566-9ebb-98e72a32451f", "3": "2e421799-71d3-4791-99c7-eed2588d0807"}}, "__type__": "1"}, "2e421799-71d3-4791-99c7-eed2588d0807": {"__data__": {"text": "--sample tx\n\n```\n\nWhich would return data like this:\n\n![type:video](https://dune.com/embeds/1345665/2296143/757ed708-17da-4c81-9633-ac19a9d3f3d3)\n\nWhat\u2019s happening here:\n\n* We dug through Dune to find the `seaport_ethereum` contract set and the `Seaport_evt_OrderFulfilled` table which contains the data for our specific transaction. (which takes a lot of time in and of itself).\n* To get closer to something we really want, token contract address and token ID, we had to:\n    * Know to look for the offer column and get the first position in that array\n    * Make it a JSON object, knowing token contracts are 20 bytes which means 40 characters.\n    * And do a similar amount of manual abstraction for the token ID\n\nYet now we still don\u2019t have something interesting like how much money was this NFT sold for.\n\nIf we want to get there, someone has to do this abstraction work.\n\nBut what if, once that work was done the first time, the rest of the community could skip all that noise to get straight to the juicy insights?\n\nWith the [nft.trades](https://dune.com/spellbook#!/model/model.spellbook.nft_trades) Spell, we can do this:\n\n```sql\n\nSELECT\n\n    seller\n\n    , buyer\n\n    , amount_original\n\n    , currency_symbol\n\n    , *\n\nFROM nft.trades\n\nWHERE tx_hash = lower(\"0x96f158d75379057d95c1c562b9908603e543feee25a71ac420e21ecf0a0c643c\") --sample tx\n\n```\n\nWhich returns this:\n\n![type:video](https://dune.com/embeds/1345985/2296638/51cc251d-c1ec-4f71-a269-2b194b25bdac)\n\nAnd right away, with a couple of lines of SQL we can see:\n\n* The seller and buyer wallet addresses\n* The amount that was paid in what cryptocurrency\n* Which blockchain it was on\n\nAnd more!\n\nThis illustrates how on a micro level, for one transaction, a ton of work was saved thanks to the Spell adding done by Wizards who came before us.\n\nThis of course also scales to the macro.\n\nIf we wanted to do a cross-chain NFT marketplace analysis, we might aim to build something like this dashboard:\n\n<div class=\"cards grid\" markdown>\n- [Cross Chain NFT Marketplace Metrics by @agaperste](https://dune.com/agaperste/cross-chain-nft-marketplace-metrics)\n</div>\n\nWith the nft.trades spell, we can see industry-wide stats like:\n\n* Total volume by # of txs and $USD\n* 24-hr volume\n* 24-hour and 7-day growth\n* Market share by marketplace\n* Volume by marketplace\n* Transaction count by marketplace\n\nAnd we can query, visualize, and make a dashboard out of that data all in a couple of hours instead of dozens.\n\nAnd once a new NFT marketplace is launched, anyone in the community who knows how to add a Spell can do the data engineering for that marketplace, submit a Pull Request to Spellbook, and have the entire community benefit from their work.\n\nFor the first time in history, we have access to an open dataset thanks to blockchains.\n\nThanks to Spellbook, we can all build on top of that open data to make it more transparent, accessible, and meaningful together!\n\n\n", "doc_id": "2e421799-71d3-4791-99c7-eed2588d0807", "embedding": null, "doc_hash": "521b287b120336d359df0f4d0011e668687ba4b896f52d09b2115ad7cc6b670d", "extra_info": {"file_path": "docs/data-tables/spellbook/index.md", "file_name": "index.md"}, "node_info": {"start": 6195, "end": 9121, "_node_type": "1"}, "relationships": {"1": "eefab96eb5b30e083cfbbf70a8f94370d27df740", "2": "52b32d33-a3f9-4b95-89a6-274b0051d061"}}, "__type__": "1"}, "cf21b248-0263-4557-ad99-5db6494f6ae2": {"__data__": {"text": "---\ntitle: dex.trades\ndescription: dex.trades aggregates data across multiple DEX platforms into one simple table.\n---\n\nDecentralized exchanges are the beating heart of the DeFi industry. You can swap any native (ETH) or ERC-20 token for any ERC-20 token through the magic of smart contracts.\n\nThe problem here: there are so many decentralized exchanges out there that it's hardly possible for any single person to work with the smart contract data for all of them.\n\nThat's why we created [dex.trades](https://dune.com/spellbook#!/model/model.spellbook.dex_trades).\n\nThis table standardizes and normalizes the trading data across virtually all relevant decentralized exchanges. This in turn allows you to easily query for trading data for your favorite tokens without having to deal with all of the different DEX smart contracts yourself.\n\nThe scripts that generate the table dex.trades can be found in this [public github](https://github.com/duneanalytics/spellbook/tree/main/models/dex) repo.\n\n## Column Data\n\n| Column name | Data type | Description |\n| - | :-: | - |\n| `block_time` | _timestamptz_ | The timestamp of the block that included this transaction |\n| `token_a_symbol` | _varchar_ | The symbol of one of the two tokens that got traded |\n| `token_b_symbol` | _varchar_ | The symbol of one of the two tokens that got traded |\n| `token_a_amount` | _numeric_ | The amount of token A that got traded |\n| `token_b_amount` | _numeric_ | The amount of token B that got traded |\n| `project` | _varchar_ | The dex on which this trade was executed |\n| `version` | _varchar_ | Which version of the dex got used? |\n| `blockchain` | _varchar_ | Which blockchain did this occur on |\n| `taker` | _varbinary_ | Which contract called the dex contract? |\n| `maker` | _varbinary_ | In some special cases there actually is a counter party to transactions, this party will get displayed here if applicable |\n| `token_a_amount_raw` | _numeric_ | The raw amount of token A that got traded |\n| `token_b_amount_raw` | _numeric_ | The raw amount of token B that got traded |\n| `amount_usd` | _numeric_ | The USD value of this trade |\n| `token_a_address` | _varbinary_ | The ERC-20 token contract address of token A |\n| `token_b_address` | _varbinary_ | The ERC-20 token contract address of token B |\n| `exchange_contract_address` | _varbinary_ | The address of the decentralized exchange contract that made this trade possible |\n| `tx_hash` | _varbinary_ | The hash of the transaction that contained this trade |\n| `tx_from` | _varbinary_ | Which address initiated this transaction? |\n| `tx_to` | _varbinary_ | What was the first smart contract that got called during this tx? |\n| `trace_address` | _ARRAY_ | Which position in the graph tree does the execution of the trade have? |\n| `evt_index` | _integer_ | This logs index position in the block (cumulative amount of logs ordered by execution) |\n| `trade_id` | _integer_ | Just for database magic |\n", "doc_id": "cf21b248-0263-4557-ad99-5db6494f6ae2", "embedding": null, "doc_hash": "3c1a398ea118f4155529cb2a79a8cfb32b7cb48409e37ff4b7a9774916269d18", "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/dex.trades.md", "file_name": "dex.trades.md"}, "node_info": {"start": 0, "end": 2938, "_node_type": "1"}, "relationships": {"1": "d6dbc002044115ecc482e398d504f15ac752c9a6"}}, "__type__": "1"}, "2e53f527-e982-4f58-9c6a-bcaa40d19f8e": {"__data__": {"text": "---\ntitle: Top Spellbook Tables\ndescription: Some top spells to get you started\n---\n\nThis section contains some of the most useful spells (abstracted tables) on Dune. You'll likely use these in many of your queries, from beginner to advanced.\n\n<div class=\"cards grid\" markdown>\n- [dex.trades](dex.trades.md): The standardization and aggregation of all Decentralized Exchanges (DEX) across EVM chains.\n- [nft.trades](nft.trades.md): The standardization and aggregation of all NFT marketplaces across chains (EVM + Solana)\n- [labels](labels.md): Labels contain identifiers such as CEX wallets, ENS names, Top 1% NFT Traders, and many more for each address.\n- [tokens](tokens.md): The tokens and transfers tables will be essential to calculating decimals, finding symbols, and tracking balances for ERC20s and NFTs\n- [prices](prices.md): The `prices_usd` tables will help you assign values to volume, TVL, and many more token metrics.\n</div>\n\n## Spell Categories\n\nIn general, there are two types of spell categories. \n### Sector Spells\n\nSector Spells are tables like dex.trades, erc20.stablecoins, lending.borrow, tokens.erc20, etc.\n\nThese Spells take in data from multiple contracts and projects, standardize the data across them and therefore make it very easy to query for this data and compare the metrics of different projects with each other.\n\nTeam Dune and the community are always improving on these sector spells, all new additions to existing ones are always welcome.\n\n### Project Spells\n\nProjects (Opensea, Uniswap, Aave, etc) can assemble their data into one neat table that has all the data they need in one place. To do this, you can construct views or tables in our spells.\n\nThe main advantage here over just constructing a view is that you are able to deal with bigger amounts of data in our Spells since we can run them automatically in the background every few hours.", "doc_id": "2e53f527-e982-4f58-9c6a-bcaa40d19f8e", "embedding": null, "doc_hash": "24e8c11f0dae85fdf3873795ff96f10c4321215c68b46871cefea219f3fbc71c", "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 1882, "_node_type": "1"}, "relationships": {"1": "c2f8dcf099a14b0c2fee340828b861470b856884"}}, "__type__": "1"}, "8945383e-2707-45c1-bfde-2f01e19fef6a": {"__data__": {"text": "---\ntitle: labels\ndescription: Address labels is a feature on Dune where you as a user can add, update and query labels for any address.\n---\n\nBecause of all the open data on blockchain, we can enhance our understanding of any given address by tagging it with different labels. This immediately give any analysis enhanced context. \n\n**labels.addresses** is a spell in Dune that allows you to add static or query labels to enhance your analysis.\n\n## What is a label?\n\nA label is **a piece of metadata about an address**, a tag or metadata if you will. It comes in the form of a key-value pair. The key is the label _type_, and the value the label _name_.\n\nBrowse addresses and and labels at the [**labels page**](https://dune.com/dune/dune-v2-labels) or contribute to the spell [starting with the readme](https://github.com/duneanalytics/spellbook/tree/main/models/labels/addresses).\n\nHere\u2019s a list of label types:\n\n- **Identifiers**: Most static labels should be this label type, as well as common usernames such as Farcaster, ENS, and Lens names. As a rule of thumb, identifiers should usually specify a unique entity name.\n- **Usage**: These are the existing top volume and frequency (or some other percentile-able metric) within a domain and the usage of specific protocols. There must be some sort of ranking/percentile involved!\n- **Personas**: These are for on-chain curated behaviors (like common CT memes) or protocol user tagging. They should be easily understood to non-analysts, though the underlying calculation methods may be more subjective.\n\nTo give a sense of examples, for the \"social\" category you would expect these labels:\n\n- Identifier: Lens username (.lens) ENS reverse resolver (.eth), farcaster (_farcaster)\n- Usage: top holders from ENS\n- Usage: top posters from lens\n- Persona: Lens User, ENS User\n- Persona: Squatter (sitting on dozens of ENS names)\n\n## What labels look like\n\nCheck out [this dashboard](https://dune.com/dune/dune-v2-labels) for examples on what can be created with labels.\n\nThe address `0xD551234Ae421e3BCBA99A0Da6d736074f22192FF` can be labeled like this:\n\n| Type | Name |\n| ----------- | -------- |\n| `cex` | binance |\n\nThe address is controlled by the exchange Binance.\n\nThe address `0xe65040f61701940b62e18da7a53126a58525588b` can be labeled like this:\n\n| label_type | Name |\n| ---------- | ------------ |\n| `persona` | uniswap user |\n| `persona` | dex trader |\n\nThe address in the past interacted with Uniswap.\n\nYou are free to come up with both new types and label names, as labels on Dune are open ended and **crowd sourced**.\n\n## Adding labels\n\nUse Dune queries to label addresses. A very powerful and scalable way to add labels like \u201call these addresses used Uniswap\u201d, and much much more.\n\nPlease see our [GitHub](https://github.com/duneanalytics/spellbook/tree/main/models/labels) for examples of labels created with queries and PR in your own!\n\nExamples of what you can do:\n\n- Label all addresses that used a certain dapp\n- Label all addresses that hold a certain amount of a token\n- Label all addresses that use a dapp more than X times per month\n- Label all addresses that sent money to Binance\n\nYou could also do more novel and involved things around user patterns like who did arbitrage trades or profited from flash loans and so much more.\n\nNote that there might be a few minutes delay from adding the label on", "doc_id": "8945383e-2707-45c1-bfde-2f01e19fef6a", "embedding": null, "doc_hash": "53d1167a436233d4bca2c2dd6711fdff428a614987f09bc1141b87b8d30c03fb", "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/labels.md", "file_name": "labels.md"}, "node_info": {"start": 0, "end": 3370, "_node_type": "1"}, "relationships": {"1": "0beeece78fed944f13822510497b29d6e3f60ea3", "3": "02d9b2c2-3638-4aaf-8c58-a6492d177be7"}}, "__type__": "1"}, "02d9b2c2-3638-4aaf-8c58-a6492d177be7": {"__data__": {"text": "much more.\n\nNote that there might be a few minutes delay from adding the label on [dune.com](http://dune.com) until you can query it in SQL.\n\n## The labels table\n\nLabels are stored in the new `labels.labels` table which has the following schema:\n\n| Column name | Data type | Description |\n| - | :-: | - |\n| `id` | _int_ | incrementing integer |\n| `address` | _varbinary_ | The address of a contract or wallet this label describes |\n| `name` | _varchar_ | label name |\n| `blockchain` | _varchar_ | the blockchain the label is meant for |\n| `author` | _varchar_ | The username of the user who created this label |\n| `source` | _varchar_ | The source of this label, autopopulated by Dune |\n| `updated_at` | _timestamptz_ | The last time this label was changed |\n| `label_type` | _varchar_ | The type of label, defined in the readme |\n| `model_name` | _varchar_ | The name of the label model (filename) |\n\n## Using labels\n\n!!! warning\n    this section is currently under construction, stay tuned!", "doc_id": "02d9b2c2-3638-4aaf-8c58-a6492d177be7", "embedding": null, "doc_hash": "7fb3eb67b434f1fa8bd0d34528250026149669c30d46e2bb9d74d59588b75921", "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/labels.md", "file_name": "labels.md"}, "node_info": {"start": 3289, "end": 4281, "_node_type": "1"}, "relationships": {"1": "0beeece78fed944f13822510497b29d6e3f60ea3", "2": "8945383e-2707-45c1-bfde-2f01e19fef6a"}}, "__type__": "1"}, "3d0d22e2-d02d-4fe4-91a8-68e71a31607d": {"__data__": {"text": "---\ntitle: nft.trades\ndescription: nft.trades is an effort to make NFT trading data easily available to everyone on Dune.\n---\n\n`nft.trades` is an effort to make NFT trading data easily available to everyone on Dune. This table aggregates and standardizes the data between different data platforms and provides auxiliary information and metadata all in one table.\n\nThe culmination of this is a dataset which makes it extremely easy to query for any NFT related trading data across all indexed platforms.\n\nYou can find the specifications for nft.trades on our [Spellbook documentation](https://dune.com/spellbook#!/model/model.spellbook.nft_trades).\n\nSo far we have indexed the data of the following platforms:\n\n- OpenSea\n- Rarible\n- SuperRare\n- CryptoPunks (They get traded in their own contracts)\n- Foundation\n- LooksRare\n\n## How it works\n\n### Single Item Trade\n\nA trade occurs between a `buyer`and a `seller`.\n\nThey exchange an item which is uniquely identified by the combination of `nft_contract_address` and `token_id`. The Buyer will pay the Seller a given `original_amount`of tokens in any given `original_currency`. To make it easier, we have calculated the `usd_amount` that this was worth at the time of the trade for you. Most trades will be done in ETH or WETH, but especially non OpenSea trades often contain other currencies.\n\nThe trade is committed on any of the indexed `platforms`and will be facilitated through a smart contract of those platform's `exchange_contract_address`. Each trade will have metadata like `block_time`, `tx_hash`_,_ `block_number`, `platform version`, `evt_index` etc.\n\nAdditionally, we also provide metadata about the traded NFT. `nft_project_name` and `erc_standard` will help you in analyzing your dataset more easily. `nft_project_name` data gets pulled from the `nft.tokens` [table](https://github.com/duneanalytics/spellbook/blob/master/ethereum/nft/tokens.sql), if your NFT is missing in that table, you are welcome to make a PR to add it.\n\n### Bundle Trade\n\nThere can also be trades in which a single trade transaction contains multiple Items. Each of these Items is uniquely identified through a combination of `nft_contract_address` and `token_id`. Unfortunately, in these trades there is not a clear way to determine a corresponding `usd_amount` for each of the items.\n\nA possible workaround is to divide the number of items by the payment made for the bundle, but this logic very quickly falls apart when Items that are not one in kind/value get sold in a bundle.\n\nWe recommend removing bundle transfers from the dataset that you are working with since it can heavily influence the results in either direction. Note that `token_id` and '`erc_standard` will be null if tokens with different tokens IDs or erc type are transferred within the same transaction.\n\n### Aggregator Trade\n\nThere can also be trades in which a single trade transaction contains multiple items, especially when using NFT aggregator platforms. Our approach is to unravel aggregator trades so that each row correspond to a unique item that was traded, with its associated ID, price, collection, etc.\n\nImportantly, the `trade_type` will be indicated as `Aggregator Trade`, and platform names and address can be found in the `nft.aggregators` [table](https://github.com/duneanalytics/spellbook/blob/master/ethereum/nft/aggregators.sql).\n\nIf your aggregator platform is missing in that table, you are welcome to make a PR to add it.\n\n### Platform and Royalty Fees\n\nIn the most recent version of", "doc_id": "3d0d22e2-d02d-4fe4-91a8-68e71a31607d", "embedding": null, "doc_hash": "792efb28b8d13adef079b226c256d8f6539daa31e0b24167ec3cbc48c536210d", "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/nft.trades.md", "file_name": "nft.trades.md"}, "node_info": {"start": 0, "end": 3513, "_node_type": "1"}, "relationships": {"1": "d109bf6f8b57ebd0329491439a533b66201c9535", "3": "ea70a347-9a43-44b5-8515-3842fe4aa913"}}, "__type__": "1"}, "ea70a347-9a43-44b5-8515-3842fe4aa913": {"__data__": {"text": "add it.\n\n### Platform and Royalty Fees\n\nIn the most recent version of `nft.trades`, information about the amount and percent of royalty fees in the original amount and in USD is available when this information was able to be retrieved.\n\nRoyalty fees are going to the creator, and Platform fees are collected by the NFT platform. Note that royalty fees cannot always be retrieved, and are set to null by default.\n\n## Examples\n\n### Queries\n\n#### All trades for a given NFT\n\n**_SQL_**\n\n```sql\nselect * from nft.trades \n\nwhere nft_contract_address = '\\xb47e3cd837ddf8e4c57f05d70ab865de6e193bbb' --this is the cryptopunks address\n```\n\n**_Results_**\n\n![type:video](https://dune.com/embeds/146090/288199/bc835020-f730-4348-b749-abd94277b0f7)\n\n#### Trades in the last 24 hour on a given platform\n\n**_SQL_**\n\n```sql\nselect date_trunc('day', block_time), usd_amount, nft_contract_address, token_id from nft.trades \n\nwhere platform = 'OpenSea' --only shows trades on given Platform\n\nand block_time > now() - interval '24hours'\n```\n\n**_Results_**\n\n![type:video](https://dune.com/embeds/1622909/2690008/ce6aa75e-b94c-4dcf-a1f0-020d2cb5fa9b)\n\n#### Platform volumes in the last year\n\n**_SQL_**\n\n```sql\nselect  sum(usd_amount), \n        date_trunc('day', block_time) as day, \n        platform \nfrom nft.trades \nwhere block_time > now() - interval '365 days'\ngroup by platform, day\n```\n\n**_Results_**\n\n![type:video](https://dune.com/embeds/146160/288002/cc990e4d-21e8-43a7-9bc3-2357a72be7b0)\n\n### Dashboards\n\n#### That utilize parameters\n\n<div class=\"cards grid\" markdown>\n- [NFT by @0xBoxer](https://dune.com/0xBoxer/NFT)\n- [NFT Sales Overview by Project by @rantum](https://dune.com/rantum/NFT-Sales-Overview-by-Project)\n</div>\n\n#### That look across the entire Ecosystem\n\n<div class=\"cards grid\" markdown>\n- [NFT Collection Dashboard by @rantum](https://dune.com/rantum/NFT-Collection-Dashboard)\n- [NFT by @sealaunch](https://dune.com/sealaunch/NFT)\n</div>\n\n## Column Data\n\n| Column name | Data type | Description |\n| - | :-: | - |\n| `block_time` | _timestamp with time zone_ | When was this trade executed |\n| `block_time` | _varchar_ | NFT project name (e.g. \"the dudes\") |\n| `nft_token_id` | _varchar_ | The token_id that was traded (e.g. 235) |\n| `erc_standard` | _varchar_ | The Token Standard of the traded token `ERC-721` or `ERC-1155` |\n| `platform` | _varchar_ | Which Platform the trade was executed on |\n| `platform_version` | _varchar_ | Which version of this platform was utilized? |\n| `trade_type` | _varchar_ | \"Single Item Sale\" or \"Bundle Sale\" |\n| `number_of_items` | _integer_ | How many NFTs were included in this trade |\n|", "doc_id": "ea70a347-9a43-44b5-8515-3842fe4aa913", "embedding": null, "doc_hash": "f3ec0d4c355e5877195cc81e63eb01871e7b9be818ed50c7fa65912d4bd10962", "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/nft.trades.md", "file_name": "nft.trades.md"}, "node_info": {"start": 3455, "end": 6084, "_node_type": "1"}, "relationships": {"1": "d109bf6f8b57ebd0329491439a533b66201c9535", "2": "3d0d22e2-d02d-4fe4-91a8-68e71a31607d", "3": "3aa20ee2-d4ae-4f34-a70a-cc8f952c3f40"}}, "__type__": "1"}, "3aa20ee2-d4ae-4f34-a70a-cc8f952c3f40": {"__data__": {"text": "| _integer_ | How many NFTs were included in this trade |\n| `category` | _varchar_ | Was this an auction or a direct sale |\n| `evt_type` | _varchar_ | Currently not in use, default 'Trade' |\n| `aggregator` | _varchar_ | Was this trade made using an aggregator (Yes : Name of aggregator, No : Null) |\n| `usd_amount` | _numeric_ | USD value of the trade at time of execution |\n| `seller` | _varbinary_ | Seller of NFTs |\n| `buyer` | _varbinary_ | Buyer of NFTs |\n| `royalty_fees_percent` | _numeric_ | Royalty fees going to the creator (in %) |\n| `original_royalty_fees` | _numeric_ | Royalty fees in the currency used for this trade |\n| `usd_royalty_fees` | _numeric_ | USD value of royalty fees at time of execution |\n| `platform_fees_percent` | _numeric_ | Platform fees (in %) |\n| `original_platform_fees` | _numeric_ | Platform fees in the currency used for this trade |\n| `usd_platform_fees` | _numeric_ | USD value of platform fees at time of execution |\n| `original_currency` | _varchar_ | The Currency used for this trade |\n| `original_currency_contract` | _varbinary_ | The ERC-20 address of the currency used in this trade (does not work with raw ETH) |\n| `currency_contract` | _varbinary_ | The corrected currency contract |\n| `nft_contract_address` | _varbinary_ | The contract address of the NFT traded |\n| `exchange_contract_address` | _varbinary_ | The platform contract that facilitated this trade |\n| `tx_hash` | _varbinary_ | The hash of this transaction |\n| `block_number` | _integer_ | The block_number that this trade was done in |\n| `tx_from` | _varbinary_ | Initiated this transaction |\n| `tx_to` | _varbinary_ | Received this transaction |\n| `trace_address` | _ARRAY_ | n/a |\n| `evt_index` | _integer_ | Event index |\n| `trade_id` | _integer_ | n/a |\n\n## Ser, my platform is not indexed\n\nThe SQL code that processes the data for every market place is open source and available in our [github repository](https://github.com/duneanalytics/spellbook/tree/master/ethereum/nft/trades). Everyone can review the code, make pull requests and submit code to add more marketplaces.\n", "doc_id": "3aa20ee2-d4ae-4f34-a70a-cc8f952c3f40", "embedding": null, "doc_hash": "686987774c64aab1adcc2d17a8e1d7380358b7a813f863e842a0d322eb2f5297", "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/nft.trades.md", "file_name": "nft.trades.md"}, "node_info": {"start": 6084, "end": 8179, "_node_type": "1"}, "relationships": {"1": "d109bf6f8b57ebd0329491439a533b66201c9535", "2": "ea70a347-9a43-44b5-8515-3842fe4aa913"}}, "__type__": "1"}, "60ce5d98-016a-4d00-9298-9194f34006bd": {"__data__": {"text": "---\ntitle: prices\ndescription: These tables allow you to get the price of almost all relevant erc20 tokens.\n---\nWe pull price data from the [coinpaprika](https://coinpaprika.com) API.\n\nThe Price is the volume-weighted price based on real-time market data, translated to USD.\n\n## prices.usd\n\nThis table supports a range of erc20.tokens.\n\n### adding a token to price tracking\n\nIf the token you desire is not listed in here, please make a pull request to our [GitHub repository](https://github.com/duneanalytics/spellbook/blob/main/models/prices/prices_tokens.sql). (For V1 Engine, you can also use the decentralized price feed **dex.view_token_prices.**)\n\n| Column name | Data type | Description |\n| - | :-: | - |\n| `contract_address`| _varbinary_ |string the contract address of the erc20 token |\n| `symbol` | _varchar_ |the identifier of the asset (ticker, cashtag) |\n| `price` | _bigint_ | The price of the asset in any given minute |\n| `minute` | _timestampz_ | The resolution for this table is by minute |\n\nNote that `WETH` can be used for ETH price as it trades at virtually the same price.\n\n## How we get prices from DEXs\n\nWe created a table that creates price feeds based on decentralized exchange trading data. This table covers much more assets than `prices.usd`, since it covers all assets that are traded on any  of the decentralized exchanges that are indexed in `dex.trades`.\n\n**Please keep in mind that this script can generate wrong prices in rare cases.**\n\nThis table is very resource intensive and can therefore only be updated every few hours, please keep that in mind when utilizing it. **** Also the resolution is only hourly, so if you need minutely prices do refer to [`prices.usd`](prices.md).\n\nThis table currently only exists for Ethereum on our old database architecture.\n\nThe logic of how this table works can be accessed in our [public github](https://github.com/duneanalytics/spellbook/tree/master/ethereum/prices) repo.\n\nThis script generates median hourly prices based on data from decentralized exchanges found in `dex.trades`. It will assign asset prices based on a trading pair which has a pricefeed in `prices.usd`.\n\nLet's take the $SPELL/ETH Pool for example.\n\n* $ETH price is contained in `prices.usd`\n* $SPELL price is not contained in `prices.usd`\n\nIn order to get the $SPELL price, the script will dynamically calculate the price of $SPELL based on the price of $ETH that was exchanged for it.\n\ne.g. 5 $ETH were exchanged for 1,086,083 $SPELL.\n\nDex.trades will assign a `usd_amount` to this trade based on the $ETH price data in `prices.usd`.\n\nThat `usd_amount` is $23,498.\n\n`5 * price of ETH (4.699,6) = $23,498`\n\nCalculating the price of $SPELL is now as simple as dividing the amount of tokens exchanged with the `usd_amount` recorded in `dex.trades`.\n\n`$23,498/1,086,083 \u2248 $0,02163`\n\nWe now have successfully calculated the price of 1 $SPELL.\n\nIn order to correct for extreme outliers and in order for this table to be performant the script then aggregates all recorded data into one `median_price` per hour.\n\n### Known issues\n\nIn rare cases this script will generate price feeds that are based on illiquid pairs and therefore report wrong data. This happens when all liquid trading pools of this token", "doc_id": "60ce5d98-016a-4d00-9298-9194f34006bd", "embedding": null, "doc_hash": "e370a914913d986404d74622e24b5f9b50c9e0fd241e0fff4227ad16738a380b", "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/prices.md", "file_name": "prices.md"}, "node_info": {"start": 0, "end": 3245, "_node_type": "1"}, "relationships": {"1": "1c85bc511dc511c37c3ecf59b3dd59f24e415731", "3": "9f5e04f2-bb2b-4998-ae29-e58ecf350e6d"}}, "__type__": "1"}, "9f5e04f2-bb2b-4998-ae29-e58ecf350e6d": {"__data__": {"text": "therefore report wrong data. This happens when all liquid trading pools of this token do not have a price feed in `prices.usd`.\n\nAn example of this would be $PLAY, a metaverse index from PieDAO. The liquid trading pair for this asset is $PLAY/$DOUGH. The \"correct\" price of $PLAY is represented in this pool, but the combination of `dex.trades` and `prices.prices_from_dex_data` are not able to pick up this price.\n\nInstead, `dex.trades` will only have a `usd_amount` for illiquid pairs of this asset. In this case, the $PLAY/$ETH pool has trades once in a while and these will have a `usd_amount` in `dex.trades`. The liquidity of the $PLAY/$ETH pool is very low and it pretty much only consists of arbitrage trades. Therefore, the resulting pricefeed in `prices.prices_from_dex_data` is faulty since it depends on the `usd_amount` in `dex.trades`.\n\nIn order to check for this, you should manually verify the results of `prices.prices_from_dex_data` in order to make sure arbitrage trades do not disturb the price feed constructed. A simple way of validating that the script is working with the right pools is checking the `sample_size` column. If the number seems suspiciously low, the script probably doesn't pick up the right price.\n\nIn cases like this, you have to manually construct a price feed.\n\nWe are always looking to improve this table, if you have any ideas or comments don't hesitate to open a PR or contact us in our Discord.", "doc_id": "9f5e04f2-bb2b-4998-ae29-e58ecf350e6d", "embedding": null, "doc_hash": "a130fc9fab377c076502f89db3941223fcb7f82006b8eb0b53ba8c11839c3aeb", "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/prices.md", "file_name": "prices.md"}, "node_info": {"start": 3160, "end": 4600, "_node_type": "1"}, "relationships": {"1": "1c85bc511dc511c37c3ecf59b3dd59f24e415731", "2": "60ce5d98-016a-4d00-9298-9194f34006bd"}}, "__type__": "1"}, "9f6decb0-2e10-4d40-b469-793011e914fb": {"__data__": {"text": "---\ntitle: tokens\ndescription: token transfers and metadata\n---\n\nYou'll likely be working with tokens that are fungible (erc20) and nonfungible (erc721 and erc1155) a lot in your analysis. There are a couple tables that are must knows for this:\n\n## Metadata tables:\n\n1. [**`tokens.erc20`**](https://spellbook-docs.dune.com/#!/model/model.spellbook.tokens_erc20): contains useful information such as the token `symbol` and the `decimals` for any given `contract_address`, the latter of which is needed to get the actual amount from raw amounts in onchain data.\n\n2. [**`tokens.nft`**](https://spellbook-docs.dune.com/#!/model/model.spellbook.tokens_nft): contains the collection `name` and `symbol` for any given `contract_address`.\n\nThese tables are usually joined on `contract_address` at the end of a query to make everything more human readable.\n\n## Transfer tables:\n\n1. [**`erc20_ethereum.evt_Transfer`**](https://spellbook-docs.dune.com/#!/model/model.spellbook.transfers_ethereum_erc20): all transfer events for every erc20 token. You can find how to get erc20 balances, mints, and burns using [this guide](https://www.youtube.com/watch?v=LT_PB-Fso3M).\n\n2. [**`nft.transfers`**](https://spellbook-docs.dune.com/#!/model/model.spellbook.nft_transfers): all transfer events for every erc721 or erc1155 token. You can learn how to leverage this to find nft balances, transfers, and mints in [this guide](https://web3datadegens.substack.com/p/web3-sql-weekly-3-finding-all-nfts)\n\nIf you're looking for how to calculate native token balances like ethereum (ETH) balances then check out [this guide](https://web3datadegens.substack.com/p/web3-sql-weekly-1-how-to-calculate)\n\n", "doc_id": "9f6decb0-2e10-4d40-b469-793011e914fb", "embedding": null, "doc_hash": "2ed61236472e0361b9e688a3aeef5c9b9fdc0216b501a23b78ac776c712e267a", "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/tokens.md", "file_name": "tokens.md"}, "node_info": {"start": 0, "end": 1674, "_node_type": "1"}, "relationships": {"1": "b9bf45d386b7abfd56184bdf9f902d4080a313ad"}}, "__type__": "1"}, "4c84d6d9-e4dc-4aba-a965-54b66090abc3": {"__data__": {"text": "---\ntitle: Welcome\ndescription: Dune is a web-based platform that allows you to query public blockchain data and aggregate it into beautiful dashboards.\n---\n\n**Dune is a web-based platform that allows you to query public blockchain data and aggregate it into beautiful dashboards.**\n\n!!! type \"Quickstart\"\n    To get started with Dune in 5 minutes, see the [Quickstart](quickstart.md).\n\n\n<p align=\"center\">\n  <img src=\"images/quickstart-cover.jpeg\" alt=\"A beautiful dashboard\" title=\"Dashboard\" /><br />\n  <em>The world's blockchain data at your fingertips!</em>\n</p>\n\n\n\nBlockchains are open and transparent, but each chain is unique\u2014making it difficult to understand, ingest, and aggregate data. Dune gives you the proper tools to analyze cross-chain data for different tokens, wallets, and protocols. You can also easily share your work with the community.\n\n\n### Start building\n\nReady to start building? Once you have an [account](https://dune.com/auth/register) and you\u2019ve reviewed the [Quickstart](quickstart.md), check out these essentials to start using Dune:\n\n\n\n* Use the [Query Editor](/app/query-editor/) to explore data, write queries, and gain mastery\n* Make stunning [visualizations](/app/visualizations/) with graphs, charts, and other unique options\n* Create a [Dashboard](/app/dashboards/) to embed visualizations, graphics, and text to tell compelling stories with your data\n\n\n\n### Learn more\n\nIf you\u2019re new to blockchain or SQL\u2014or want to go deeper on Dune concepts and best practices\u2014check out the following resources:\n\n\n\n* [Dune Official Getting Started Video Series](https://www.youtube.com/watch?v=S-cctFmR828&list=PLK3b5d4iK10ext4v-GBySekaA8-GP8quD&index=1) to learn how data flows and how to navigate the Dune app to get the most out of it\n* [Web3 Analytics Resources](analytics_guidelines.md) to start performing your own analysis, or to find SQL and Blockchain resources for beginners\n* Join our community in [Discord](https://discord.gg/dunecom) to get support through the `#\ud83d\udc25\ufe31beginners` and `#\ud83d\ude4b\ufe31query-questions` channels\n\n\n### Why Dune?\n\nDune\u2014along with our massive community of users and experts\u2014provides powerful tools and analysis of all onchain data. You can find a [dashboard](https://dune.com/browse/dashboards?q=dex&order=favorites&time_range=all) for pretty much anything web3-related, including for EVMs like Ethereum, Polygon, Goerli, and Optimism\u2014and non-EVM chains like Solana and Bitcoin.\n\nExamples of real dashboards:\n\n\n\n* [NFT marketplaces](https://dune.com/hildobby/NFTs)\n* [DEX metrics](https://dune.com/hagaetc/dex-metrics)\n* [Bridges](https://dune.com/eliasimos/Bridge-Away-(from-Ethereum))\n* [DAO Accounting (Maker)](https://dune.com/SebVentures/maker---accounting_1)\n* [Base Chain Metrics](https://dune.com/optimismfnd/Optimism)\n\n\n### Find an expert\n\nThere are many experts in the crypto community who specialize in Dune or have the necessary skills to get up to speed quickly.\n\n<div class=\"cards grid\" markdown>\n\n-   #### Find a Wizard\n\n    A guide on how to find a skilled Dune Freelancer to work with you on your project. \n  \n    [:octicons-arrow-right-24: Find a Wizard](resources/dune-bounties.md)\n\n</div>", "doc_id": "4c84d6d9-e4dc-4aba-a965-54b66090abc3", "embedding": null, "doc_hash": "da2a9c87aa19c983d92a438ab87cadb6381f62a36ad8ff275faa64bc06b71a82", "extra_info": {"file_path": "docs/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 3158, "_node_type": "1"}, "relationships": {"1": "823815552e9904bbecd26edfe8aeb78a9a46ff4a"}}, "__type__": "1"}, "3a3fa97d-ec3c-400c-840f-d7823bc6b16b": {"__data__": {"text": "---\ntitle: Aggregate functions\n---\n\nAggregate functions operate on a set of values to compute a single\nresult.\n\nExcept for `count`, `count_if`, `max_by`, `min_by` and `approx_distinct`, all of these aggregate functions ignore null values and return null for no input rows or when all values are null. For example, `sum` returns null rather than zero and `avg` does not include null values in the count. The `coalesce` function can be used to convert null into zero.\n\n\n## Ordering during aggregation {#aggregate-function-ordering-during-aggregation}\n\nSome aggregate functions such as `array_agg` produce different results depending on the order of input values. This ordering can be specified by writing an `order-by-clause` within the aggregate function:\n\n```sql\n    array_agg(x ORDER BY y DESC)\n    array_agg(x ORDER BY x, y, z)\n```\n## Filtering during aggregation {#aggregate-function-filtering-during-aggregation}\n\nThe `FILTER` keyword can be used to remove rows from aggregation\nprocessing with a condition expressed using a `WHERE` clause. This is\nevaluated for each row before it is used in the aggregation and is\nsupported for all aggregate functions.\n\n```sql\naggregate_function(...) FILTER (WHERE <condition>)\n```\n\nA common and very useful example is to use `FILTER` to remove nulls from\nconsideration when using `array_agg`:\n```sql\n    SELECT array_agg(name) FILTER (WHERE name IS NOT NULL)\n    FROM region;\n```\nAs another example, imagine you want to add a condition on the count for\nIris flowers, modifying the following query:\n```sql\n    SELECT species,\n           count(*) AS count\n    FROM iris\n    GROUP BY species;\n```\n``` text\nspecies    | count\n-----------+-------\nsetosa     |   50\nvirginica  |   50\nversicolor |   50\n```\n\nIf you just use a normal `WHERE` statement you lose information:\n\n    SELECT species,\n        count(*) AS count\n    FROM iris\n    WHERE petal_length_cm > 4\n    GROUP BY species;\n\n``` text\nspecies    | count\n-----------+-------\nvirginica  |   50\nversicolor |   34\n```\n\nUsing a filter you retain all information:\n\n    SELECT species,\n           count(*) FILTER (where petal_length_cm > 4) AS count\n    FROM iris\n    GROUP BY species;\n\n``` text\nspecies    | count\n-----------+-------\nvirginica  |   50\nsetosa     |    0\nversicolor |   34\n```\n\n## General aggregate functions\n\n#### arbitrary()\n**``arbitrary(x)``** &#8594 [same as input]\n\nReturns an arbitrary non-null value of `x`, if one exists.\n\n#### array_agg()\n**``array_agg(x)``** &#8594 [same as input]\n\nReturns an array created from the input `x` elements.\n\n#### avg()\n**``avg(x)``** &#8594 double\n\nReturns the average (arithmetic mean) of all input values.\n\n**``avg(time interval type)``** &#8594 time interval type\n\nReturns the average interval length of all input values.\n\n#### bool_and()\n**``bool_and(boolean)``** &#8594 boolean\n\nReturns `TRUE` if every input value is `TRUE`, otherwise `FALSE`.\n\n#### bool_or()\n**``bool_or(boolean)``** &#8594 boolean\n\nReturns", "doc_id": "3a3fa97d-ec3c-400c-840f-d7823bc6b16b", "embedding": null, "doc_hash": "ae74738ce595b443d140db0ab9cb736f2fd2fc73acae578f2cbd44900bfa9e64", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/aggregate.md", "file_name": "aggregate.md"}, "node_info": {"start": 0, "end": 2959, "_node_type": "1"}, "relationships": {"1": "1c0086e721dbdfb14ccb34937b80956eb381a0e7", "3": "75906804-8f96-4425-ad10-f2d7002b5730"}}, "__type__": "1"}, "75906804-8f96-4425-ad10-f2d7002b5730": {"__data__": {"text": "&#8594 boolean\n\nReturns `TRUE` if any input value is `TRUE`, otherwise `FALSE`.\n\n#### checksum()\n**``checksum(x)``** &#8594 varbinary\n\nReturns an order-insensitive checksum of the given values.\n\n#### count()\n**``count(*)``** &#8594 bigint\n\nReturns the number of input rows.\n\n**``count(x)``** &#8594 bigint\n\nReturns the number of non-null input values.\n\n#### count_if()\n**``count_if(x)``** &#8594 bigint\n\nReturns the number of `TRUE` input values. This function is equivalent to `count(CASE WHEN x THEN 1 END)`.\n\n#### every()\n**``every(boolean)``** &#8594 boolean\n\nThis is an alias for `bool_and`.\n\n#### geometric_mean()\n**``geometric_mean(x)``** &#8594 double\n\nReturns the geometric mean of all input values.\n\n#### listagg()\n**``listagg(x, separator)``** &#8594 varchar\n\nReturns the concatenated input values, separated by the `separator` string.\n\nSynopsis:\n```sql\n    LISTAGG( expression [, separator] [ON OVERFLOW overflow_behaviour])\n        WITHIN GROUP (ORDER BY sort_item, [...])\n```\nIf `separator` is not specified, the empty string will be used as\n`separator`.\n\nIn its simplest form the function looks like:\n```sql\n    SELECT listagg(value, ',') WITHIN GROUP (ORDER BY value) csv_value\n    FROM (VALUES 'a', 'c', 'b') t(value);\n```\nand results in:\n```text\n    csv_value\n    -----------\n    'a,b,c'\n```\nThe overflow behaviour is by default to throw an error in case that the\nlength of the output of the function exceeds `1048576` bytes:\n```sql\n    SELECT listagg(value, ',' ON OVERFLOW ERROR) WITHIN GROUP (ORDER\n    BY value) csv_value\n    FROM (VALUES 'a', 'c', 'b') t(value);\n```\nand results in:\n```text\n    csv_value\n    -----------\n    'a,c,b'\n```\nThe overflow behaviour can also be to truncate the output:\n```sql\n    SELECT listagg(value, ',' ON OVERFLOW TRUNCATE) WITHIN GROUP (ORDER\n    BY value) csv_value\n    FROM (VALUES 'a', 'c', 'b') t(value);\n```\nand results in:\n```text\n    csv_value\n    -----------\n    'a,b'\n```\nThe overflow behaviour can also be to skip the overflowed values:\n```sql\n    SELECT listagg(value, ',' ON OVERFLOW SKIP) WITHIN GROUP (ORDER\n    BY value) csv_value\n```\nThe current implementation of `LISTAGG` function does not support window\nframes.\n\n\n#### max()\n**``max(x)``** &#8594 [same as input]\n\nReturns the maximum value of all input values.\n\n**``max(x, n)``** &#8594 array<[same as x]>\n\nReturns `n` largest values of all input values of `x`.\n\n#### max_by()\n**``max_by(x, y)``** &#8594 [same as x]\n\nReturns the value of `x` associated with the maximum value of `y` over all input values.\n\n**``max_by(x, y, n)``** &#8594 array<[same as x]>\n\nReturns `n` values of `x` associated with the `n` largest of all input values of `y` in descending", "doc_id": "75906804-8f96-4425-ad10-f2d7002b5730", "embedding": null, "doc_hash": "78b3c09c3834cf44f74fecd0d8c9de88fe193e1b9d89148a7f327ae4bd5d93c0", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/aggregate.md", "file_name": "aggregate.md"}, "node_info": {"start": 2938, "end": 5619, "_node_type": "1"}, "relationships": {"1": "1c0086e721dbdfb14ccb34937b80956eb381a0e7", "2": "3a3fa97d-ec3c-400c-840f-d7823bc6b16b", "3": "fa1627f6-6980-4c7c-b3b9-b3a97d4b21f4"}}, "__type__": "1"}, "fa1627f6-6980-4c7c-b3b9-b3a97d4b21f4": {"__data__": {"text": "associated with the `n` largest of all input values of `y` in descending order of `y`.\n\n#### min()\n**``min(x)``** &#8594 [same as input]\n\nReturns the minimum value of all input values.\n\n**``min(x, n)``** &#8594 array<[same as x]>\n\nReturns `n` smallest values of all input values of `x`.\n\n#### min_by()\n**``min_by(x, y)``** &#8594 [same as x]\n\nReturns the value of `x` associated with the minimum value of `y` over all input values.\n\n**``min_by(x, y, n)``** &#8594 array<[same as x]>\n\nReturns `n` values of `x` associated with the `n` smallest of all input values of `y` in ascending order of `y`.\n\n#### sum()\n**``sum(x)``** &#8594 [same as input]\n\nReturns the sum of all input values.\n\n## Bitwise aggregate functions\n\n#### bitwise_and_agg()\n**``bitwise_and_agg(x)``** &#8594 bigint\n\nReturns the bitwise AND of all input values in 2's complement representation.\n\n#### bitwise_or_agg()\n**``bitwise_or_agg(x)``** &#8594 bigint\n\nReturns the bitwise OR of all input values in 2's complement representation.\n\n#### histogram()\n**``histogram(x)``** &#8594 map<K,bigint>\n\nReturns a map containing the count of the number of times each input value occurs.\n\n#### map_agg()\n**``map_agg(key, value)``** &#8594 map<K,V>\n\nReturns a map created from the input `key` / `value` pairs.\n\n#### map_union()\n**``map_union(x(K,V))``** &#8594 map<K,V>\n\nReturns the union of all the input maps. If a key is found in multiple input maps, that key's value in the resulting map comes from an arbitrary input map.\n\n#### map_union_agg()\n**``map_union_agg(x(K,V))``** &#8594 map<K,V>\n\nReturns the union of all the input maps. If a key is found in multiple input maps, that key's value in the resulting map comes from the last input map.\n\n#### multimap_agg()\n**``multimap_agg(key, value)``** &#8594 multimap<K,V>\n\nReturns a multimap created from the input `key` / `value` pairs.\n\n#### multimap_union()\n**``multimap_union(x(K,V))``** &#8594 multimap<K,V>\n\nReturns the union of all the input multimaps. If a key is found in multiple input multimaps, that key's values in the resulting multimap are the union of all the values from the input multimaps.\n\n\n\n## Approximate aggregate functions\n\n#### approx_distinct()\n**``approx_distinct(x)``** &#8594 bigint\n\nReturns the approximate number of distinct input values. This function provides an approximation of `count(DISTINCT x)`. Zero is returned if all input values are null.\n\nThis function should produce a standard error of 2.3%, which is the standard deviation of the (approximately normal) error distribution over all possible sets. It does not guarantee an upper bound on the error for any specific input set.\n\n**``approx_distinct(x, e)``** &#8594 bigint\n\nReturns the approximate number of distinct input values. This function provides an approximation of `count(DISTINCT x)`. Zero is returned if all input values are null.\n\nThis function should produce a standard error of no more than `e`, which is the standard deviation of the (approximately normal) error distribution over all possible sets. It does not guarantee an upper bound on", "doc_id": "fa1627f6-6980-4c7c-b3b9-b3a97d4b21f4", "embedding": null, "doc_hash": "a6c6983c9811b096e3f0385510a1ef966aa1a203c1628dc9444aa3ee4d9c078c", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/aggregate.md", "file_name": "aggregate.md"}, "node_info": {"start": 5582, "end": 8636, "_node_type": "1"}, "relationships": {"1": "1c0086e721dbdfb14ccb34937b80956eb381a0e7", "2": "75906804-8f96-4425-ad10-f2d7002b5730", "3": "2e74faaf-829a-4ab6-8aa1-242cad4b2030"}}, "__type__": "1"}, "2e74faaf-829a-4ab6-8aa1-242cad4b2030": {"__data__": {"text": "error distribution over all possible sets. It does not guarantee an upper bound on the error for any specific input set. The current implementation of this function requires that `e` be in the range of 0.0040625 to 0.26000.\n\n#### approx_most_frequent()\n**``approx_most_frequent(x, k)``** &#8594 map<[same as x], bigint>\n\nComputes the top frequent values up to `buckets` elements approximately.\nApproximate estimation of the function enables us to pick up the\nfrequent values with less memory. Larger `capacity` improves the\naccuracy of underlying algorithm with sacrificing the memory capacity.\nThe returned value is a map containing the top elements with\ncorresponding estimated frequency.\n\nThe error of the function depends on the permutation of the values and\nits cardinality. We can set the capacity same as the cardinality of the\nunderlying data to achieve the least error.\n\n`buckets` and `capacity` must be `bigint`. `value` can be numeric or\nstring type.\n\nThe function uses the stream summary data structure proposed in the\npaper [Efficient Computation of Frequent and Top-k Elements in Data\nStreams](https://www.cse.ust.hk/~raywong/comp5331/References/EfficientComputationOfFrequentAndTop-kElementsInDataStreams.pdf)\nby A. Metwalley, D. Agrawl and A. Abbadi.\n\n#### approx_percentile()\n**``approx_percentile(x, percentage)``** &#8594 [same as x]\n\nReturns the approximate percentile for all input values of `x` at the given `percentage`. The value of `percentage` must be between zero and one and must be constant for all input rows.\n\n**``approx_percentile(x, percentages)``** &#8594 array<[same as x]>\n\nReturns the approximate percentile for all input values of `x` at each of the specified percentages. Each element of the `percentages` array must be between zero and one, and the array must be constant for all input rows.\n\n**``approx_percentile(x, w, percentage)``** &#8594 [same as x]\n\nReturns the approximate weighed percentile for all input values of `x` using the per-item weight `w` at the percentage `percentage`. Weights must be greater or equal to 1. Integer-value weights can be thought of as a replication count for the value `x` in the percentile set. The value of `percentage` must be between zero and one and must be constant for all input rows.\n\n**``approx_percentile(x, w, percentages)``** &#8594 array<[same as x]>\n\nReturns the approximate weighed percentile for all input values of `x` using the per-item weight `w` at each of the given percentages specified in the array. Weights must be greater or equal to 1. Integer-value weights can be thought of as a replication count for the value `x` in the percentile set. Each element of the `percentages` array must be between zero and one, and the array must be constant for all input rows.\n\n#### approx_set()\n**``approx_set(x)``** &#8594 HyperLogLog\n\nSee `hyperloglog`.\n\n#### merge()\n**``merge(x)``** &#8594 HyperLogLog\n\nSee `hyperloglog`.\n\n**``merge(qdigest(T))``** &#8594 qdigest(T)\n\nSee `qdigest`.\n\n**``merge(tdigest)``** &#8594 tdigest\n\nSee `tdigest`.\n\n#### numeric_histogram()\n**``numeric_histogram(buckets, value)``** &#8594 map<double, double>\n\nComputes an approximate histogram with up to `buckets` number of buckets for all `value`s. This function is equivalent to the variant of", "doc_id": "2e74faaf-829a-4ab6-8aa1-242cad4b2030", "embedding": null, "doc_hash": "28fd36fd4dcdb24e579c40d5f72564d65e26659c4072e3453a7bde09488ad979", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/aggregate.md", "file_name": "aggregate.md"}, "node_info": {"start": 8628, "end": 11890, "_node_type": "1"}, "relationships": {"1": "1c0086e721dbdfb14ccb34937b80956eb381a0e7", "2": "fa1627f6-6980-4c7c-b3b9-b3a97d4b21f4", "3": "e85b27c2-453e-475a-b4ad-4a6cb8ba9179"}}, "__type__": "1"}, "e85b27c2-453e-475a-b4ad-4a6cb8ba9179": {"__data__": {"text": "of buckets for all `value`s. This function is equivalent to the variant of `numeric_histogram` that takes a `weight`, with a per-item weight of `1`.\n\n**``numeric_histogram(buckets, value, weight)``** &#8594 map<double, double>\n\nComputes an approximate histogram with up to `buckets` number of buckets for all `value`s with a per-item weight of `weight`. The algorithm is based loosely on:\n\n``` text\nYael Ben-Haim and Elad Tom-Tov, \"A streaming parallel decision tree algorithm\", J. Machine Learning Research 11 (2010), pp. 849--872.\n```\n\n`buckets` must be a `bigint`. `value` and `weight` must be numeric.\n\n#### qdigest_agg()\n**``qdigest_agg(x)``** &#8594 qdigest\n\nSee [Quantile digest functions](qdigest.md).\n\n#### qdigest_agg()\n**``qdigest_agg(x, w)``** &#8594 qdigest\n\nSee [Quantile digest functions](qdigest.md).\n\n#### tdigest_agg()\n**``tdigest_agg(x)``** &#8594 tdigest\n\nSee [T-Digest functions](tdigest.md).\n\n#### tdigest_agg()\n**``tdigest_agg(x, w)``** &#8594 tdigest\n\nSee [T-Digest functions](tdigest.md).\n\n\n## Statistical aggregate functions\n\n#### corr()\n**``corr(x, y)``** &#8594 double\n\nReturns correlation coefficient of input values.\n\n#### covar_pop()\n**``covar_pop(y, x)``** &#8594 double\n\nReturns the population covariance of input values.\n\n#### covar_samp()\n**``covar_samp(y, x)``** &#8594 double\n\nReturns the sample covariance of input values.\n\n#### kurtosis()\n**``kurtosis(x)``** &#8594 double\n\nReturns the excess kurtosis of all input values. Unbiased estimate using the following expression:\n``` text\nkurtosis(x) = n(n+1)/((n-1)(n-2)(n-3))sum[(x_i-mean)^4]/stddev(x)^4-3(n-1)^2/((n-2)(n-3))\n```\n\n#### regr_intercept()\n**``regr_intercept(y, x)``** &#8594 double\n\nReturns linear regression intercept of input values. `y` is the dependent value and `x` is the independent value.\n\n#### regr_slope()\n**``regr_slope(y, x)``** &#8594 double\n\nReturns linear regression slope of input values. `y` is the dependent value and `x` is the independent value.\n\n#### skewness()\n**``skewness(x)``** &#8594 double\n\nReturns the skewness of all input values. Unbiased estimate using the following expression:\n\n``` text\nskewness(x) = n/((n-1)(n-2))sum[(x_i-mean)^3]/stddev(x)^3\n```\n\n#### stddev()\n**``stddev(x)``** &#8594 double\n\nReturns the standard deviation of all input values.\n\n#### stddev_pop()\n**``stddev_pop(x)``** &#8594 double\n\nReturns the population standard deviation of all input values.\n\n#### stddev_samp()\n**``stddev_samp(x)``** &#8594 double\n\nReturns the sample standard deviation of all input values.\n\n#### variance()\n**``variance(x)``** &#8594 double\n\nReturns the", "doc_id": "e85b27c2-453e-475a-b4ad-4a6cb8ba9179", "embedding": null, "doc_hash": "ce41367bf6e16ad233056f95b876c60294e833700dd97a8cca921b343579700c", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/aggregate.md", "file_name": "aggregate.md"}, "node_info": {"start": 11898, "end": 14478, "_node_type": "1"}, "relationships": {"1": "1c0086e721dbdfb14ccb34937b80956eb381a0e7", "2": "2e74faaf-829a-4ab6-8aa1-242cad4b2030", "3": "3564b2a1-d50c-4b38-8602-0b88d4815c01"}}, "__type__": "1"}, "3564b2a1-d50c-4b38-8602-0b88d4815c01": {"__data__": {"text": "&#8594 double\n\nReturns the variance of all input values.\n\n#### var_pop()\n**``var_pop(x)``** &#8594 double\n\nReturns the population variance of all input values.\n\n#### var_samp()\n**``var_samp(x)``** &#8594 double\n\nReturns the sample variance of all input values.\n\n\n## Lambda aggregate functions\n\n#### reduce_agg()\n**``reduce_agg(inputValue T, initialState S, inputFunction(S, T, S), combineFunction(S, S, S))``** &#8594 S\n\nReduces all input values into a single value. `inputFunction` will be\ninvoked for each non-null input value. In addition to taking the input\nvalue, `inputFunction` takes the current state, initially\n`initialState`, and returns the new state. `combineFunction` will be\ninvoked to combine two states into a new state. The final state is\nreturned:\n```sql\n    SELECT id, reduce_agg(value, 0, (a, b) -> a + b, (a, b) -> a + b)\n    FROM (\n        VALUES\n            (1, 3),\n            (1, 4),\n            (1, 5),\n            (2, 6),\n            (2, 7)\n    ) AS t(id, value)\n    GROUP BY id;\n    -- (1, 12)\n    -- (2, 13)\n```\n```sql\n    SELECT id, reduce_agg(value, 1, (a, b) -> a * b, (a, b) -> a * b)\n    FROM (\n        VALUES\n            (1, 3),\n            (1, 4),\n            (1, 5),\n            (2, 6),\n            (2, 7)\n    ) AS t(id, value)\n    GROUP BY id;\n    -- (1, 60)\n    -- (2, 42)\n```\n\nThe state type must be a boolean, integer, floating-point, or\ndate/time/interval.\n\n", "doc_id": "3564b2a1-d50c-4b38-8602-0b88d4815c01", "embedding": null, "doc_hash": "16c90124145a58d754c276a35cc4dcbeea592a1808375bf5414c5541c878eeaa", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/aggregate.md", "file_name": "aggregate.md"}, "node_info": {"start": 14514, "end": 15914, "_node_type": "1"}, "relationships": {"1": "1c0086e721dbdfb14ccb34937b80956eb381a0e7", "2": "e85b27c2-453e-475a-b4ad-4a6cb8ba9179"}}, "__type__": "1"}, "3e40e01a-4376-4920-a2bb-1d73943b0d87": {"__data__": {"text": "---\ntitle: Array functions and operators\n---\n\n Subscript operator: \\[\\] {subscript_operator}\n\nThe `[]` operator is used to access an element of an array and is\nindexed starting from one:\n```sql\n    SELECT my_array[1] AS f_element\n```\n Concatenation operator: \\|\\| {concatenation_operator}\n\nThe `||` operator is used to concatenate an array with an array or an\nelement of the same type:\n```sql\n    SELECT ARRAY[1] || ARRAY[2];\n    -- [1, 2]\n\n    SELECT ARRAY[1] || 2;\n    -- [1, 2]\n\n    SELECT 2 || ARRAY[1];\n    -- [2, 1]\n```\n### Array functions\n\n#### allmatch()\n**``allmatch(array(T), function(T,boolean))``** \u2192 boolean\n\nReturns whether all elements of an array match the given predicate.\nReturns `true` if all the elements match the predicate (a special case\nis when the array is empty); `false` if one or more elements don\\'t\nmatch; `NULL` if the predicate function returns `NULL` for one or more\nelements and `true` for all other elements.\n\n#### anymatch() \n**``any_match(array(T), function(T,boolean))``** \u2192 boolean\n\nReturns whether any elements of an array match the given predicate.\nReturns `true` if one or more elements match the predicate; `false` if\nnone of the elements matches (a special case is when the array is\nempty); `NULL` if the predicate function returns `NULL` for one or more\nelements and `false` for all other elements.\n\n#### array_distinct()\n**``array_distinct(x)``** \u2192 array\n\nRemove duplicate values from the array `x`.\n\n#### array_except()\n**``array_except(x, y)``** \u2192 array\n\nReturns an array of elements in `x` but not in `y`, without duplicates.\n#### array_intersect()\n**``array_intersect(x, y)``** \u2192 array\n\nReturns an array of the elements in the intersection of `x` and `y`, without duplicates.\n#### array_join()\n**``array_join(x, delimiter, null_replacement)``** \u2192 varchar\n\nConcatenates the elements of the given array using the delimiter and an optional string to replace nulls.\n#### array_max()\n**``array_max(x)``** \u2192 x\n\nReturns the maximum value of input array.\n\n#### array_min()\n**``array_min(x)``** \u2192 x\n\nReturns the minimum value of input array.\n\n#### array_position()\n**``array_position(x, element)``** \u2192 bigint\n\nReturns the position of the f occurrence of the element in the array. Returns `NULL` if the element is not found. The position is counted from 1.\n\n#### array_remove()\n**``array_remove(x, element)``** \u2192 array\n\nReturns an array of elements in `x` without the element `element`.\n\n#### array_sort()\n**``array_sort(x)``** \u2192 array\n\nSorts and returns the array `x`. The elements of `x` must be orderable. Null elements will be placed at the end of the returned array. The sort is stable, meaning that the relative order of elements that are equal is preserved.\n\n\n\n**``array_sort(array(T), function(T,T,int))``** \u2192 array(T)\n\nSorts and returns the `array` based on the given comparator `function`. The comparator will take two nullable arguments representing two nullable elements of the `array`. It returns -1, 0, or 1 as the f nullable element is less than, equal to, or greater than the second nullable element. If the comparator function returns other values (including `NULL`), the query will fail and raise an", "doc_id": "3e40e01a-4376-4920-a2bb-1d73943b0d87", "embedding": null, "doc_hash": "2dfaac10e06b38d21d01eb8c290dac4f0f56f91738874308caafa926f7bb5071", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/array.md", "file_name": "array.md"}, "node_info": {"start": 0, "end": 3157, "_node_type": "1"}, "relationships": {"1": "74bb533a5510cec6582906aeaa72cf76c6e215cb", "3": "5114300e-fbcb-4f90-b9a2-1bdd3f568c87"}}, "__type__": "1"}, "5114300e-fbcb-4f90-b9a2-1bdd3f568c87": {"__data__": {"text": "function returns other values (including `NULL`), the query will fail and raise an error.\n```sql\n    SELECT array_sort(ARRAY[3, 2, 5, 1, 2],\n                  (x, y) -> IF(x < y, 1, IF(x = y, 0, -1)));\n-- [5, 3, 2, 2, 1]\n\nSELECT array_sort(ARRAY['bc', 'ab', 'dc'],\n                  (x, y) -> IF(x < y, 1, IF(x = y, 0, -1)));\n-- ['dc', 'bc', 'ab']\n\n\nSELECT array_sort(ARRAY[3, 2, null, 5, null, 1, 2],\n                  -- sort null first with descending order\n                  (x, y) -> CASE WHEN x IS NULL THEN -1\n                                 WHEN y IS NULL THEN 1\n                                 WHEN x < y THEN 1\n                                 WHEN x = y THEN 0\n                                 ELSE -1 END);\n-- [null, null, 5, 3, 2, 2, 1]\n\nSELECT array_sort(ARRAY[3, 2, null, 5, null, 1, 2],\n                  -- sort null last with descending order\n                  (x, y) -> CASE WHEN x IS NULL THEN 1\n                                 WHEN y IS NULL THEN -1\n                                 WHEN x < y THEN 1\n                                 WHEN x = y THEN 0\n                                 ELSE -1 END);\n-- [5, 3, 2, 2, 1, null, null]\n\nSELECT array_sort(ARRAY['a', 'abcd', 'abc'],\n                  -- sort by string length\n                  (x, y) -> IF(length(x) < length(y), -1,\n                               IF(length(x) = length(y), 0, 1)));\n-- ['a', 'abc', 'abcd']\n\nSELECT array_sort(ARRAY[ARRAY[2, 3, 1], ARRAY[4, 2, 1, 4], ARRAY[1, 2]],\n                  -- sort by array length\n                  (x, y) -> IF(cardinality(x) < cardinality(y), -1,\n                               IF(cardinality(x) =", "doc_id": "5114300e-fbcb-4f90-b9a2-1bdd3f568c87", "embedding": null, "doc_hash": "7425d73b52b055936492f19f66a7ac07d0814d33ed0d9842650f776f4fdfd9cf", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/array.md", "file_name": "array.md"}, "node_info": {"start": 3088, "end": 4713, "_node_type": "1"}, "relationships": {"1": "74bb533a5510cec6582906aeaa72cf76c6e215cb", "2": "3e40e01a-4376-4920-a2bb-1d73943b0d87", "3": "2c37b66a-16d4-4143-9b73-6afd0ecd807d"}}, "__type__": "1"}, "2c37b66a-16d4-4143-9b73-6afd0ecd807d": {"__data__": {"text": "           IF(cardinality(x) = cardinality(y), 0, 1)));\n-- [[1, 2], [2, 3, 1], [4, 2, 1, 4]]\n```\n\n#### array_union()\n**``array_union(x, y)``** \u2192 array\n\nReturns an array of the elements in the union of `x` and `y`, without duplicates.\n\n#### array_overlap()\n**``array_overlap(x, y)``** \u2192 boolean\n\nTests if arrays x and y have any non-null elements in common. Returns null if there are no non-null elements in common but either array contains null.\n\n#### cardinality()\n**``cardinality(x)``** \u2192 bigint\n\nReturns the cardinality (size) of the array x.\n\n#### concat()\n**``concat(array1, array2, ..., arrayN)``** \u2192 array\n\nConcatenates the arrays array1, array2, ..., arrayN. This function provides the same functionality as the SQL-standard concatenation operator (||).\n\n#### combinations()\n**``combinations(array(T), n)``** -> array(array(T))  \n\nReturns n-element sub-groups of input array. If the input array has no duplicates, combinations returns n-element subsets.\n```sql\nSELECT combinations(ARRAY['foo', 'bar', 'baz'], 2);\n-- [['foo', 'bar'], ['foo', 'baz'], ['bar', 'baz']]\n\nSELECT combinations(ARRAY[1, 2, 3], 2);\n-- [[1, 2], [1, 3], [2, 3]]\n\nSELECT combinations(ARRAY[1, 2, 2], 2);\n-- [[1, 2], [1, 2], [2, 2]]\n```\nOrder of sub-groups is deterministic but unspecified. Order of elements within a sub-group deterministic but unspecified. n must be not be greater than 5, and the total size of sub-groups generated must be smaller than 100,000.\n\n#### contains()\n**``contains(x, element)``** \u2192 boolean\n\nReturns true if the array x contains the element.\n\n#### contains_sequence()\n**``contains_sequence(x, seq)``** \u2192 boolean\n\nReturn true if array x contains all of array seq as a subsequence (all values in the same consecutive order).\n\n#### element_at()\n**``element_at(array(E), index)``** \u2192 E\n\nReturns element of array at given index. If index > 0, this function provides the same functionality as the SQL-standard subscript operator ([]), except that the function returns NULL when accessing an index larger than array length, whereas the subscript operator would fail in such a case. If index < 0, element_at accesses elements from the last to the first.\n\n#### filter()\n**``filter(array(T), function(T, boolean))``** -> array(T)\n\nConstructs an array from those elements of array for which function returns true:\n```sql\nSELECT filter(ARRAY[], x -> true);\n-- []\n\nSELECT filter(ARRAY[5, -6, NULL, 7], x -> x > 0);\n-- [5, 7]\n\nSELECT filter(ARRAY[5, NULL, 7, NULL], x -> x IS NOT NULL);\n-- [5, 7]\n```\n\n#### flatten()\n**``flatten(x)``** \u2192 array\n\nFlattens an array(array(T)) to an array(T) by concatenating the contained arrays.\n\n#### ngrams()\n**``ngrams(array(T), n)``** -> array(array(T))\n\nReturns n-grams (sub-sequences of adjacent n elements) for the array. The order of the n-grams in the result is unspecified.\n\n```sql\nSELECT ngrams(ARRAY['foo', 'bar', 'baz', 'foo'], 2);\n-- [['foo', 'bar'], ['bar',", "doc_id": "2c37b66a-16d4-4143-9b73-6afd0ecd807d", "embedding": null, "doc_hash": "c3ddf8e11414f976a6ec972f50b4616574e0a09f102873c38435a61d7a531174", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/array.md", "file_name": "array.md"}, "node_info": {"start": 4766, "end": 7663, "_node_type": "1"}, "relationships": {"1": "74bb533a5510cec6582906aeaa72cf76c6e215cb", "2": "5114300e-fbcb-4f90-b9a2-1bdd3f568c87", "3": "267e9a02-9646-40ee-9338-87d1b8b32956"}}, "__type__": "1"}, "267e9a02-9646-40ee-9338-87d1b8b32956": {"__data__": {"text": "'foo'], 2);\n-- [['foo', 'bar'], ['bar', 'baz'], ['baz', 'foo']]\n\nSELECT ngrams(ARRAY['foo', 'bar', 'baz', 'foo'], 3);\n-- [['foo', 'bar', 'baz'], ['bar', 'baz', 'foo']]\n\nSELECT ngrams(ARRAY['foo', 'bar', 'baz', 'foo'], 4);\n-- [['foo', 'bar', 'baz', 'foo']]\n\nSELECT ngrams(ARRAY['foo', 'bar', 'baz', 'foo'], 5);\n-- [['foo', 'bar', 'baz', 'foo']]\n\nSELECT ngrams(ARRAY[1, 2, 3, 4], 2);\n-- [[1, 2], [2, 3], [3, 4]]\n```\n\n#### none_match()\n**``none_match(array(T), function(T, boolean))``** \u2192 boolean\n\nReturns whether no elements of an array match the given predicate. Returns true if none of the elements matches the predicate (a special case is when the array is empty); false if one or more elements match; NULL if the predicate function returns NULL for one or more elements and false for all other elements.\n\n#### reduce()\n**``reduce(array(T), initialState S, inputFunction(S, T, S), outputFunction(S, R))``** \u2192 R\n\nReturns a single value reduced from array. inputFunction will be invoked for each element in array in order. In addition to taking the element, inputFunction takes the current state, initially initialState, and returns the new state. outputFunction will be invoked to turn the final state into the result value. It may be the identity function (i -> i).\n\n```sql\nSELECT reduce(ARRAY[], 0,\n              (s, x) -> s + x,\n              s -> s);\n-- 0\n\nSELECT reduce(ARRAY[5, 20, 50], 0,\n              (s, x) -> s + x,\n              s -> s);\n-- 75\n\nSELECT reduce(ARRAY[5, 20, NULL, 50], 0,\n              (s, x) -> s + x,\n              s -> s);\n-- NULL\n\nSELECT reduce(ARRAY[5, 20, NULL, 50], 0,\n              (s, x) -> s + coalesce(x, 0),\n              s -> s);\n-- 75\n\nSELECT reduce(ARRAY[5, 20, NULL, 50], 0,\n              (s, x) -> IF(x IS NULL, s, s + x),\n              s -> s);\n-- 75\n\nSELECT reduce(ARRAY[2147483647, 1], BIGINT '0',\n              (s, x) -> s + x,\n              s -> s);\n-- 2147483648\n\n-- calculates arithmetic average\nSELECT reduce(ARRAY[5, 6, 10, 20],\n              CAST(ROW(0.0, 0) AS ROW(sum DOUBLE, count INTEGER)),\n              (s, x) -> CAST(ROW(x + s.sum, s.count + 1) AS\n                             ROW(sum DOUBLE, count INTEGER)),\n              s ->", "doc_id": "267e9a02-9646-40ee-9338-87d1b8b32956", "embedding": null, "doc_hash": "e7f4281cedede8ba69573f186abf9546119751bf47dce75dc4cc161bcc4c8ec4", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/array.md", "file_name": "array.md"}, "node_info": {"start": 7647, "end": 9835, "_node_type": "1"}, "relationships": {"1": "74bb533a5510cec6582906aeaa72cf76c6e215cb", "2": "2c37b66a-16d4-4143-9b73-6afd0ecd807d", "3": "8c1b88cd-a6b1-40b1-b4c0-13f466ba7657"}}, "__type__": "1"}, "8c1b88cd-a6b1-40b1-b4c0-13f466ba7657": {"__data__": {"text": "INTEGER)),\n              s -> IF(s.count = 0, NULL, s.sum / s.count));\n-- 10.25\n```\n#### repeat()\n**``repeat(element, count)``** \u2192 array\n\nRepeat element for count times.\n\n#### reverse()\n**``reverse(x)``** \u2192 array\n\nReturns an array which has the reversed order of array x.\n\n#### sequence()\n**``sequence(start, stop)``**\n\nGenerate a sequence of integers from start to stop, incrementing by 1 if start is less than or equal to stop, otherwise -1.\n\n**``sequence(start, stop, step)``**\n\nGenerate a sequence of integers from start to stop, incrementing by step.\n\n**``sequence(start, stop)``**\n\nGenerate a sequence of dates from start date to stop date, incrementing by 1 day if start date is less than or equal to stop date, otherwise -1 day.\n\n**``sequence(start, stop, step)``**\n\nGenerate a sequence of dates from start to stop, incrementing by step. The type of step can be either INTERVAL DAY TO SECOND or INTERVAL YEAR TO MONTH.\n\n**``sequence(start, stop, step)``**\n\nGenerate a sequence of timestamps from start to stop, incrementing by step. The type of step can be either INTERVAL DAY TO SECOND or INTERVAL YEAR TO MONTH.\n\n#### shuffle()\n**``shuffle(x)``** \u2192 array\n\nGenerate a random permutation of the given array x.\n\n#### slice()\n**``slice(x, start, length)``** \u2192 array\n\nSubsets array x starting from index start (or starting from the end if start is negative) with a length of length.\n\n#### trim_array()\n**``trim_array(x, n)``** \u2192 array\n\nRemove n elements from the end of array:\n\n```sql\nSELECT trim_array(ARRAY[1, 2, 3, 4], 1);\n-- [1, 2, 3]\n\nSELECT trim_array(ARRAY[1, 2, 3, 4], 2);\n-- [1, 2]\n```\n\n#### transform()\n**``transform(array(T), function(T, R))``** \u2192 array(R)\n\nReturns an array of the results of applying the given function to each element of the given array. The function must be deterministic and must return the same type for each invocation with the same argument. If the function returns NULL, the result of the transform is NULL.\n\n```sql\n\nSELECT transform(ARRAY[], x -> x + 1);\n-- []\n\nSELECT transform(ARRAY[5, 6], x -> x + 1);\n-- [6, 7]\n\nSELECT transform(ARRAY[5, NULL, 6], x -> coalesce(x, 0) + 1);\n-- [6, 1, 7]\n\nSELECT transform(ARRAY['x', 'abc', 'z'], x -> x || '0');\n-- ['x0', 'abc0', 'z0']\n\nSELECT transform(ARRAY[ARRAY[1, NULL, 2], ARRAY[3, NULL]],\n                 a -> filter(a, x -> x IS NOT NULL));\n-- [[1, 2], [3]]\n```\n#### zip()\n**``zip(array1, array2[, ...])``** \u2192 array(row)\n\nMerges the given arrays, element-wise, into a single array of rows. The M-th element of the N-th argument will be the N-th field of the M-th output element. If the arguments have an uneven length, missing values are filled with NULL.\n\n```sql\nSELECT zip(ARRAY[1, 2], ARRAY['1b', null, '3b']);\n-- [ROW(1, '1b'), ROW(2, null), ROW(null, '3b')]\n```\n\n#### zip_with()\n**``zip_with(array1, array2, function)``** \u2192 array(R)\n\nMerges the", "doc_id": "8c1b88cd-a6b1-40b1-b4c0-13f466ba7657", "embedding": null, "doc_hash": "43bf80aaf879e39a58d31674c0803dfb92b5a8e47ed9b6a3962ef7c419f0ca29", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/array.md", "file_name": "array.md"}, "node_info": {"start": 9857, "end": 12694, "_node_type": "1"}, "relationships": {"1": "74bb533a5510cec6582906aeaa72cf76c6e215cb", "2": "267e9a02-9646-40ee-9338-87d1b8b32956", "3": "f432c8b4-798e-436f-9703-5aab4d6f057d"}}, "__type__": "1"}, "f432c8b4-798e-436f-9703-5aab4d6f057d": {"__data__": {"text": "array2, function)``** \u2192 array(R)\n\nMerges the given arrays, element-wise, into a single array using function. The M-th element of the N-th argument will be the N-th argument of the M-th invocation of function. If the arguments have an uneven length, missing values are filled with NULL.\n\n```sql\nSELECT zip_with(ARRAY[1, 3, 5], ARRAY['a', 'b', 'c'],\n                (x, y) -> (y, x));\n-- [ROW('a', 1), ROW('b', 3), ROW('c', 5)]\n\nSELECT zip_with(ARRAY[1, 2], ARRAY[3, 4],\n                (x, y) -> x + y);\n-- [4, 6]\n\nSELECT zip_with(ARRAY['a', 'b', 'c'], ARRAY['d', 'e', 'f'],\n                (x, y) -> concat(x, y));\n-- ['ad', 'be', 'cf']\n\nSELECT zip_with(ARRAY['a'], ARRAY['d', null, 'f'],\n                (x, y) -> coalesce(x, y));\n-- ['a', null, 'f']\n```\n\n", "doc_id": "f432c8b4-798e-436f-9703-5aab4d6f057d", "embedding": null, "doc_hash": "0dcaee5fba8a45e204f6fbe296b0233f95e7d462678aa7296439fe05e5523acb", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/array.md", "file_name": "array.md"}, "node_info": {"start": 12664, "end": 13421, "_node_type": "1"}, "relationships": {"1": "74bb533a5510cec6582906aeaa72cf76c6e215cb", "2": "8c1b88cd-a6b1-40b1-b4c0-13f466ba7657"}}, "__type__": "1"}, "1149e5ff-31ff-47fb-957b-5aa9f2281193": {"__data__": {"text": "---\ntitle: Binary\n---\n\n### Binary operators\n\nThe `||` operator performs concatenation.\n\n### Binary functions\n\n#### concat()\n**``concat(binary1, ..., binaryN)``** \u2192 varbinary\n\nReturns the concatenation of binary1, binary2, ..., binaryN. This function provides the same functionality as the SQL-standard concatenation operator (||).\n\n#### length()\n**``length(binary)``** \u2192 bigint\n\nReturns the length of binary in bytes.\n\n#### lpad()\n**``lpad(binary, size, padbinary)``** \u2192 varbinary\n\nLeft pads binary to size bytes with padbinary. If size is less than the length of binary, the result is truncated to size characters. size must not be negative and padbinary must be non-empty.\n\n#### rpad()\n**``rpad(binary, size, padbinary)``** \u2192 varbinary\n\nRight pads binary to size bytes with padbinary. If size is less than the length of binary, the result is truncated to size characters. size must not be negative and padbinary must be non-empty.\n\n#### substr()\n**``substr(binary, start)``** \u2192 varbinary\n\nReturns the rest of binary from the starting position start, measured in bytes. Positions start with 1. A negative starting position is interpreted as being relative to the end of the string.\n\n**``substr(binary, start, length)``** \u2192 varbinary\n\nReturns a substring from binary of length length from the starting position start, measured in bytes. Positions start with 1. A negative starting position is interpreted as being relative to the end of the string.\n\n#### reverse()\n**``reverse(binary)``** \u2192 varbinary\n\nReturns binary with the bytes in reverse order.\n\n### Base64 encoding functions\n\n#### from_base64()\n**``from_base64(string)``** \u2192 varbinary\n\nDecodes binary data from the base64 encoded string.\n\n#### to_base64()\n**``to_base64(binary)``** \u2192 varchar\n\nEncodes binary into a base64 string representation.\n\n#### from_base64url()\n**``from_base64url(string)``** \u2192 varbinary\n\nDecodes binary data from the base64 encoded string using the URL safe alphabet.\n\n#### to_base64url()\n**``to_base64url(binary)``** \u2192 varchar\n\nEncodes binary into a base64 string representation using the URL safe alphabet.\n\n#### from_base32()\n**``from_base32(string)``** \u2192 varbinary\n\nDecodes binary data from the base32 encoded string.\n\n#### to_base32()\n**``to_base32(binary)``** \u2192 varchar\n\nEncodes binary into a base32 string representation.\n\n### Hex encoding functions\n\n#### from_hex()\n**``from_hex(string)``** \u2192 varbinary\n\nDecodes binary data from the hex encoded string.\n\n#### to_hex()\n**``to_hex(binary)``** \u2192 varchar\n\nEncodes binary into a hex string representation.\n\n### Integer encoding functions\n\n#### from_big_endian_32()\n**``from_big_endian_32(binary)``** \u2192 integer\n\nDecodes the 32-bit two\u2019s complement big-endian binary. The input must be exactly 4 bytes.\n\n#### to_big_endian_32()\n**``to_big_endian_32(integer)``** \u2192 varbinary\n\nEncodes integer into a 32-bit two\u2019s complement big-endian format.\n\n#### from_big_endian_64()\n**``from_big_endian_64(binary)``** \u2192 bigint\n\nDecodes the 64-bit two\u2019s complement big-endian binary. The input must be exactly 8 bytes.\n\n#### to_big_endian_64()\n**``to_big_endian_64(bigint)``** \u2192 varbinary\n\nEncodes bigint into a 64-bit two\u2019s complement big-endian format.\n\n###", "doc_id": "1149e5ff-31ff-47fb-957b-5aa9f2281193", "embedding": null, "doc_hash": "70bc206f01f417d8d5193c0849c205b9cc45e744b340b46e38281ce5c518f0cc", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/binary.md", "file_name": "binary.md"}, "node_info": {"start": 0, "end": 3174, "_node_type": "1"}, "relationships": {"1": "95a4df97cd4b186da3008e46be33463ce5bbdb2b", "3": "d34ea9fb-0042-4b14-8749-a71c78cf17e1"}}, "__type__": "1"}, "d34ea9fb-0042-4b14-8749-a71c78cf17e1": {"__data__": {"text": "into a 64-bit two\u2019s complement big-endian format.\n\n### Floating-point encoding functions\n\n#### from_ieee754_32()\n**``from_ieee754_32(binary)``** \u2192 real\n\nDecodes the 32-bit big-endian binary in IEEE 754 single-precision floating-point format. The input must be exactly 4 bytes.\n\n#### to_ieee754_32()\n**``to_ieee754_32(real)``** \u2192 varbinary\n\nEncodes real into a 32-bit big-endian binary according to IEEE 754 single-precision floating-point format.\n\n#### from_ieee754_64()\n**``from_ieee754_64(binary)``** \u2192 double\n\nDecodes the 64-bit big-endian binary in IEEE 754 double-precision floating-point format. The input must be exactly 8 bytes.\n\n#### to_ieee754_64()\n**``to_ieee754_64(double)``** \u2192 varbinary\n\nEncodes double into a 64-bit big-endian binary according to IEEE 754 double-precision floating-point format.\n\n### Hashing functions\n\n#### crc32()\n**``crc32(binary)``** \u2192 bigint\n\nComputes the CRC-32 of binary. For general purpose hashing, use xxhash64(), as it is much faster and produces a better quality hash.\n\n#### md5()\n**``md5(binary)``** \u2192 varbinary\n\nComputes the MD5 hash of binary.\n\n#### sha1()\n**``sha1(binary)``** \u2192 varbinary\n\nComputes the SHA1 hash of binary.\n\n#### sha256()\n**``sha256(binary)``** \u2192 varbinary\n\nComputes the SHA256 hash of binary.\n\n#### sha512()\n**``sha512(binary)``** \u2192 varbinary\n\nComputes the SHA512 hash of binary.\n\n#### spooky_hash_v2_32()\n**``spooky_hash_v2_32(binary)``** \u2192 varbinary\n\nComputes the 32-bit SpookyHashV2 hash of binary.\n\n#### spooky_hash_v2_64()\n**``spooky_hash_v2_64(binary)``** \u2192 varbinary\n\nComputes the 64-bit SpookyHashV2 hash of binary.\n\n#### xxhash64()\n**``xxhash64(binary)``** \u2192 varbinary\n\nComputes the 64-bit xxHash hash of binary.\n\n### HMAC functions\n\n#### hmac_md5()\n**``hmac_md5(binary, key)``** \u2192 varbinary\n\nComputes HMAC with MD5 of binary with the given key.\n\n#### hmac_sha1()\n**``hmac_sha1(binary, key)``** \u2192 varbinary\n\nComputes HMAC with SHA1 of binary with the given key.\n\n#### hmac_sha256()\n**``hmac_sha256(binary, key)``** \u2192 varbinary\n\nComputes HMAC with SHA256 of binary with the given key.\n\n#### hmac_sha512()\n**``hmac_sha512(binary, key)``** \u2192 varbinary\n\nComputes HMAC with SHA512 of binary with the given key.\n\n\n\n", "doc_id": "d34ea9fb-0042-4b14-8749-a71c78cf17e1", "embedding": null, "doc_hash": "9419e8f99c87b3e0a6506de2faaaba3fd70d2a889918c1a4b4b4b9f1e628d40c", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/binary.md", "file_name": "binary.md"}, "node_info": {"start": 3120, "end": 5304, "_node_type": "1"}, "relationships": {"1": "95a4df97cd4b186da3008e46be33463ce5bbdb2b", "2": "1149e5ff-31ff-47fb-957b-5aa9f2281193"}}, "__type__": "1"}, "3b65d3aa-bef9-42cb-8ab7-95996283b08f": {"__data__": {"text": "---\ntitle: Bitwise\n---\n\n#### bit_count()\n**``bit_count(x, bits)``** \u2192 bigint\nCount the number of bits set in x (treated as bits-bit signed integer) in 2\u2019s complement representation:\n```sql\nSELECT bit_count(9, 64); -- 2\nSELECT bit_count(9, 8); -- 2\nSELECT bit_count(-7, 64); -- 62\nSELECT bit_count(-7, 8); -- 6\n```\n#### bitwise_and()\n**``bitwise_and(x, y)``** \u2192 bigint\nReturns the bitwise AND of x and y in 2\u2019s complement representation.\n\nBitwise AND of 19 (binary: 10011) and 25 (binary: 11001) results in 17 (binary: 10001):\n```sql\nSELECT bitwise_and(19,25); -- 17\n```\n**``bitwise_not(x)``** \u2192 bigint\n\nReturns the bitwise NOT of x in 2\u2019s complement representation (NOT x = -x - 1):\n\n```sql\nSELECT bitwise_not(-12); --  11\nSELECT bitwise_not(19);  -- -20\nSELECT bitwise_not(25);  -- -26\n```\n#### bitwise_or()\n**``bitwise_or(x, y)``** \u2192 bigint\n\nReturns the bitwise OR of x and y in 2\u2019s complement representation.\n\nBitwise OR of 19 (binary: 10011) and 25 (binary: 11001) results in 27 (binary: 11011):\n```sql\nSELECT bitwise_or(19,25); -- 27\n```\n\n#### bitwise_xor()\n**``bitwise_xor(x, y)``** \u2192 bigint\n\nReturns the bitwise XOR of x and y in 2\u2019s complement representation.\n\nBitwise XOR of 19 (binary: 10011) and 25 (binary: 11001) results in 10 (binary: 01010):\n```sql\nSELECT bitwise_xor(19,25); -- 10\n```\n\n#### bitwise_left_shift()\n**``bitwise_left_shift(value, shift)``** \u2192 [same as value]\nReturns the left shifted value of value.\n\nShifting 1 (binary: 001) by two bits results in 4 (binary: 00100):\n```sql\nSELECT bitwise_left_shift(1, 2); -- 4\n```\nShifting 5 (binary: 0101) by two bits results in 20 (binary: 010100):\n```sql\nSELECT bitwise_left_shift(5, 2); -- 20\n```\nShifting a value by 0 always results in the original value:\n```sql\nSELECT bitwise_left_shift(20, 0); -- 20\nSELECT bitwise_left_shift(42, 0); -- 42\n```\nShifting 0 by a shift always results in 0:\n```sql\nSELECT bitwise_left_shift(0, 1); -- 0\nSELECT bitwise_left_shift(0, 2); -- 0\n```\n\n#### bitwise_right_shift()\n**``bitwise_right_shift(value, shift)``** \u2192 [same as value]\n\nReturns the logical right shifted value of value.\n\nShifting 8 (binary: 1000) by three bits results in 1 (binary: 001):\n\n```sql\nSELECT bitwise_right_shift(8, 3); -- 1\n```\nShifting 9 (binary: 1001) by one bit results in 4 (binary: 100):\n\n```sql\nSELECT bitwise_right_shift(9, 1); -- 4\n```\nShifting a value by 0 always results in the original value:\n\n```sql\nSELECT bitwise_right_shift(20, 0); -- 20\nSELECT bitwise_right_shift(42, 0); -- 42\n```\nShifting a value by 64 or more bits results in 0:\n\n```sql\nSELECT bitwise_right_shift( 12, 64); -- 0\nSELECT bitwise_right_shift(-45, 64); -- 0\n```\nShifting 0 by a shift always results in 0:\n\n```sql\nSELECT bitwise_right_shift(0,", "doc_id": "3b65d3aa-bef9-42cb-8ab7-95996283b08f", "embedding": null, "doc_hash": "f5040246a9bf7c9ebd34407cbd5ebf8d307ac9245b78eafb4693dfe8ce43ecde", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/bitwise.md", "file_name": "bitwise.md"}, "node_info": {"start": 0, "end": 2701, "_node_type": "1"}, "relationships": {"1": "11c2231859919e5c426286139b4f8a646f01f196", "3": "1d223c54-9d43-470d-8f40-c55c063cf828"}}, "__type__": "1"}, "1d223c54-9d43-470d-8f40-c55c063cf828": {"__data__": {"text": "results in 0:\n\n```sql\nSELECT bitwise_right_shift(0, 1); -- 0\nSELECT bitwise_right_shift(0, 2); -- 0\n```\n\n#### bitwise_right_shift_arithmetic()\n**``bitwise_right_shift_arithmetic(value, shift)``** \u2192 [same as value]\n\nReturns the arithmetic right shifted value of value.\n\nReturns the same values as bitwise_right_shift() when shifting by less than 64 bits. Shifting by 64 or more bits results in 0 for a positive and -1 for a negative value:\n\n```sql\nSELECT bitwise_right_shift_arithmetic( 12, 64); -- 0\nSELECT bitwise_right_shift_arithmetic(-45, 64); -- -1\n```", "doc_id": "1d223c54-9d43-470d-8f40-c55c063cf828", "embedding": null, "doc_hash": "c9ad8c32bc3f9cf9349e74ea72dd5695f2195218cbe2812f67358af6acc395fc", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/bitwise.md", "file_name": "bitwise.md"}, "node_info": {"start": 2650, "end": 3207, "_node_type": "1"}, "relationships": {"1": "11c2231859919e5c426286139b4f8a646f01f196", "2": "3b65d3aa-bef9-42cb-8ab7-95996283b08f"}}, "__type__": "1"}, "251d9477-3963-4237-bc9d-d87fae787294": {"__data__": {"text": "---\ntitle: Comparisons\n---\n\n### Comparison operators {#comparison_operators}\n\n| Operator | Description                               |\n| -------- | ----------------------------------------- |\n| `<`      | Less than                                 |\n| `>`      | Greater than                              |\n| `<=`     | Less than or equal to                     |\n| `>=`     | Greater than or equal to                  |\n| `=`      | Equal                                     |\n| `<>`     | Not equal                                 |\n| `!=`     | Not equal (non-standard but popular syntax) |\n\n\n### Range operator: BETWEEN \n\nThe `BETWEEN` operator tests if a value is within a specified range. It\nuses the syntax `value BETWEEN min AND max`:\n```sql\n    SELECT 3 BETWEEN 2 AND 6;\n```\nThe statement shown above is equivalent to the following statement:\n```sql\n    SELECT 3 >= 2 AND 3 <= 6;\n```\nTo test if a value does not fall within the specified range use\n`NOT BETWEEN`:\n```sql\n    SELECT 3 NOT BETWEEN 2 AND 6;\n```\nThe statement shown above is equivalent to the following statement:\n```sql\n    SELECT 3 < 2 OR 3 > 6;\n```\nA `NULL` in a `BETWEEN` or `NOT BETWEEN` statement is evaluated using\nthe standard `NULL` evaluation rules applied to the equivalent\nexpression above:\n```sql\n    SELECT NULL BETWEEN 2 AND 4; -- null\n\n    SELECT 2 BETWEEN NULL AND 6; -- null\n\n    SELECT 2 BETWEEN 1 AND NULL; -- false\n\n    SELECT 8 BETWEEN NULL AND 6; -- false\n```\nThe `BETWEEN` and `NOT BETWEEN` operators can also be used to evaluate\nany orderable type. For example, a `VARCHAR`:\n```sql\n    SELECT 'Paul' BETWEEN 'John' AND 'Ringo'; -- true\n```\nNote that the value, min, and max parameters to `BETWEEN` and\n`NOT BETWEEN` must be the same type. For example, Trino will produce an\nerror if you ask it if John is between 2.3 and 35.2.\n\n### IS NULL and IS NOT NULL\n\nThe `IS NULL` and `IS NOT NULL` operators test whether a value is null\n(undefined). Both operators work for all data types.\n\nUsing `NULL` with `IS NULL` evaluates to true:\n```sql\n    select NULL IS NULL; -- true\n```\nBut any other constant does not:\n```sql\n    SELECT 3.0 IS NULL; -- false\n```\n### IS DISTINCT FROM and IS NOT DISTINCT FROM {#is_distinct_operator}\n\nIn SQL a `NULL` value signifies an unknown value, so any comparison\ninvolving a `NULL` will produce `NULL`. The `IS DISTINCT FROM` and\n`IS NOT DISTINCT FROM` operators treat `NULL` as a known value and both\noperators", "doc_id": "251d9477-3963-4237-bc9d-d87fae787294", "embedding": null, "doc_hash": "5619e52f7a44f561cb340ffa1b75453f379bff30a704397c7ee1bd0508071ea0", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/comparison.md", "file_name": "comparison.md"}, "node_info": {"start": 0, "end": 2432, "_node_type": "1"}, "relationships": {"1": "1c8201fa333751c86b68ffeb9bde3b9ed43e6d74", "3": "3df3f45b-a21b-4e3c-82af-097cc4e90d4e"}}, "__type__": "1"}, "3df3f45b-a21b-4e3c-82af-097cc4e90d4e": {"__data__": {"text": "FROM` operators treat `NULL` as a known value and both\noperators guarantee either a true or false outcome even in the presence\nof `NULL` input:\n```sql\n    SELECT NULL IS DISTINCT FROM NULL; -- false\n\n    SELECT NULL IS NOT DISTINCT FROM NULL; -- true\n```\nIn the example shown above, a `NULL` value is not considered distinct\nfrom `NULL`. When you are comparing values which may include `NULL` use\nthese operators to guarantee either a `TRUE` or `FALSE` result.\n\nThe following truth table demonstrate the handling of `NULL` in\n`IS DISTINCT FROM` and `IS NOT DISTINCT FROM`:\n\n| a      | b      | a = b   | a \\<\\> b | a DISTINCT b | a NOT DISTINCT b |\n|--------|--------|---------|----------|--------------|------------------|\n| `1`    | `1`    | `TRUE`  | `FALSE`  | `FALSE`      | > `TRUE`         |\n| `1`    | `2`    | `FALSE` | `TRUE`   | `TRUE`       | > `FALSE`        |\n| `1`    | `NULL` | `NULL`  | `NULL`   | `TRUE`       | > `FALSE`        |\n| `NULL` | `NULL` | `NULL`  | `NULL`   | `FALSE`      | > `TRUE`         |\n\n\n### GREATEST and LEAST\n\nThese functions are not in the SQL standard, but are a common extension.\nLike most other functions in Trino, they return null if any argument is\nnull. Note that in some other databases, such as PostgreSQL, they only\nreturn null if all arguments are null.\n\nThe following types are supported: `DOUBLE`, `BIGINT`, `VARCHAR`,\n`TIMESTAMP`, `TIMESTAMP WITH TIME ZONE`, `DATE`\n\n#### greatest ()\n**``greatest(value1, value2, ..., valueN)``** \u2192  [same as input]\n\nReturns the largest of the provided values.\n\n#### least ()\n**``least(value1, value2, ..., valueN)``** \u2192  [same as input]\n\nReturns the smallest of the provided values.\n\n### Quantified comparison predicates: ALL, ANY and SOME {#quantified_comparison_predicates}\n\nThe `ALL`, `ANY` and `SOME` quantifiers can be used together with\ncomparison operators in the following way:\n\n``` text\nexpression operator quantifier ( subquery )\n```\n\nFor example:\n```sql\n\n    SELECT 'hello' = ANY (VALUES 'hello', 'world'); -- true\n\n    SELECT 21 < ALL (VALUES 19, 20, 21); -- false\n\n    SELECT 42 >= SOME (SELECT 41 UNION ALL SELECT 42 UNION ALL SELECT 43); -- true\n```\nHere are the meanings of some quantifier and comparison operator\ncombinations:\n\n| Expression       | Meaning                                                                                      |\n| ---------------- | --------------------------------------------------------------------------------------------- |\n| `A = ALL (...)`  | Evaluates to `true` when `A` is equal to all values.                                    ", "doc_id": "3df3f45b-a21b-4e3c-82af-097cc4e90d4e", "embedding": null, "doc_hash": "968da8f17c6838cdf2bd55a3dfb193a0459a9cab3f250e3785776d11d0b88499", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/comparison.md", "file_name": "comparison.md"}, "node_info": {"start": 2378, "end": 4953, "_node_type": "1"}, "relationships": {"1": "1c8201fa333751c86b68ffeb9bde3b9ed43e6d74", "2": "251d9477-3963-4237-bc9d-d87fae787294", "3": "daf89df2-2d36-43ac-9caa-d54fb1b3f233"}}, "__type__": "1"}, "daf89df2-2d36-43ac-9caa-d54fb1b3f233": {"__data__": {"text": "                         |\n| `A <> ALL (...)` | Evaluates to `true` when `A` doesn't match any value.                                         |\n| `A < ALL (...)`  | Evaluates to `true` when `A` is smaller than the smallest value.                              |\n| `A = ANY (...)`  | Evaluates to `true` when `A` is equal to any of the values. This form is equivalent to `A IN (...)`. |\n| `A <> ANY (...)` | Evaluates to `true` when `A` doesn't match one or more values.                                |\n| `A < ANY (...)`  | Evaluates to `true` when `A` is smaller than the biggest value.                                |\n\n`ANY` and `SOME` have the same meaning and can be used interchangeably.\n\n### Pattern comparison: LIKE\n\nThe `LIKE` operator can be used to compare values with a pattern:\n```text\n    ... column [NOT] LIKE 'pattern' ESCAPE 'character';\n```\nMatching characters is case sensitive, and the pattern supports two\nsymbols for matching:\n\n-   `_` matches any single character\n-   `%` matches zero or more characters\n\nTypically it is often used as a condition in `WHERE` statements. An\nexample is a query to find all continents starting with `E`, which\nreturns `Europe`:\n```sql\n    SELECT * FROM (VALUES 'America', 'Asia', 'Africa', 'Europe', 'Australia', 'Antarctica') AS t (continent)\n    WHERE continent LIKE 'E%';\n```\nYou can negate the result by adding `NOT`, and get all other continents,\nall not starting with `E`:\n```sql\n    SELECT * FROM (VALUES 'America', 'Asia', 'Africa', 'Europe', 'Australia', 'Antarctica') AS t (continent)\n    WHERE continent NOT LIKE 'E%';\n```\n\nIf you only have one specific character to match, you can use the `_`\nsymbol for each character. The following query uses two underscores and\nproduces only `Asia` as result:\n```sql\n    SELECT * FROM (VALUES 'America', 'Asia', 'Africa', 'Europe', 'Australia', 'Antarctica') AS t (continent)\n    WHERE continent LIKE 'A__A';\n```\n\nThe wildcard characters `_` and `%` must be escaped to allow you to\nmatch them as literals. This can be achieved by specifying the `ESCAPE`\ncharacter to use:\n```sql\n    SELECT 'South_America' LIKE 'South\\_America' ESCAPE '\\';\n```\n\nThe above query returns `true` since the escaped underscore symbol\nmatches. If you need to match the used escape character as well, you can\nescape it.\n\nIf you want to match for the chosen escape character, you simply escape\nitself. For example, you can use `\\\\` to match for `''''`.\n", "doc_id": "daf89df2-2d36-43ac-9caa-d54fb1b3f233", "embedding": null, "doc_hash": "1cfeb55d6a23a45ecb65c4f6298edb3f0ea57491a9ccaa0e7bea042bc595e391", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/comparison.md", "file_name": "comparison.md"}, "node_info": {"start": 4989, "end": 7418, "_node_type": "1"}, "relationships": {"1": "1c8201fa333751c86b68ffeb9bde3b9ed43e6d74", "2": "3df3f45b-a21b-4e3c-82af-097cc4e90d4e"}}, "__type__": "1"}, "0081dda6-832e-478d-96a2-ce3db5e92d03": {"__data__": {"text": "---\ntitle: Conditional expressions\n---\n\n### CASE \n\nThe standard SQL `CASE` expression has two forms. The \"simple\" form\nsearches each `value` expression from left to right until it finds one\nthat equals `expression`:\n\n``` text\nCASE expression\n    WHEN value THEN result\n    [ WHEN ... ]\n    [ ELSE result ]\nEND\n```\n\nThe `result` for the matching `value` is returned. If no match is found,\nthe `result` from the `ELSE` clause is returned if it exists, otherwise\nnull is returned. Example:\n```sql\n    SELECT a,\n           CASE a\n               WHEN 1 THEN 'one'\n               WHEN 2 THEN 'two'\n               ELSE 'many'\n           END\n```\nThe \"searched\" form evaluates each boolean `condition` from left to\nright until one is true and returns the matching `result`:\n\n``` text\nCASE\n    WHEN condition THEN result\n    [ WHEN ... ]\n    [ ELSE result ]\nEND\n```\n\nIf no conditions are true, the `result` from the `ELSE` clause is\nreturned if it exists, otherwise null is returned. Example:\n```sql\n    SELECT a, b,\n           CASE\n               WHEN a = 1 THEN 'aaa'\n               WHEN b = 2 THEN 'bbb'\n               ELSE 'ccc'\n           END\n```\n### IF \n\nThe `IF` expression has two forms, one supplying only a `true_value` and\nthe other supplying both a `true_value` and a `false_value`:\n\n**``if(condition, true_value)``**\n\nEvaluates and returns `true_value` if `condition` is true, otherwise\nnull is returned and `true_value` is not evaluated.\n\n\n**``if(condition, true_value, false_value)``**\n\nEvaluates and returns `true_value` if `condition` is true, otherwise\nevaluates and returns `false_value`.\n\nThe following `IF` and `CASE` expressions are equivalent:\n\n``` sql\nSELECT\n  orderkey,\n  totalprice,\n  IF(totalprice >= 150000, 'High Value', 'Low Value')\nFROM tpch.sf1.orders;\n```\n\n``` sql\nSELECT\n  orderkey,\n  totalprice,\n  CASE\n    WHEN totalprice >= 150000 THEN 'High Value'\n    ELSE 'Low Value'\n  END\nFROM tpch.sf1.orders;\n```\n\n\n### COALESCE {#coalesce_function}\n\n**``coalesce(value1, value2\\[, \\...\\])``**\n\nReturns the f non-null `value` in the argument list. Like a `CASE`\nexpression, arguments are only evaluated if necessary.\n\n### NULLIF\n\n**``nullif(value1, value2)``**\n\nReturns null if `value1` equals `value2`, otherwise returns `value1`.\n\n### TRY\n\n**``try(expression)``**\n\nEvaluate an expression and handle certain types of errors by returning\n`NULL`.\n\nIn cases where it is preferable that queries produce `NULL` or default\nvalues instead of failing when corrupt or invalid data is encountered,\nthe `TRY` function may be useful. To specify default values, the `TRY`\nfunction can be used in", "doc_id": "0081dda6-832e-478d-96a2-ce3db5e92d03", "embedding": null, "doc_hash": "58b9b930a7460db4100b3dac9487c6b1babc6cfffc6f872263fd2ae5616c89f8", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/conditional.md", "file_name": "conditional.md"}, "node_info": {"start": 0, "end": 2598, "_node_type": "1"}, "relationships": {"1": "f7dc87a714740bc664e069b2703bde045e1b864a", "3": "c82cab1b-0979-469a-8f4e-3be408d0e4e6"}}, "__type__": "1"}, "c82cab1b-0979-469a-8f4e-3be408d0e4e6": {"__data__": {"text": "be useful. To specify default values, the `TRY`\nfunction can be used in conjunction with the `COALESCE` function.\n\nThe following errors are handled by `TRY`:\n\n-   Division by zero\n-   Invalid cast or function argument\n-   Numeric value out of range\n\n**``Examples``**\n\nSource table with some invalid data:\n\n``` sql\nSELECT * FROM shipping;\n```\n\n``` text\norigin_state | origin_zip | packages | total_cost\n--------------+------------+----------+------------\nCalifornia   |      94131 |       25 |        100\nCalifornia   |      P332a |        5 |         72\nCalifornia   |      94025 |        0 |        155\nNew Jersey   |      08544 |      225 |        490\n(4 rows)\n```\n\nQuery failure without `TRY`:\n\n``` sql\nSELECT CAST(origin_zip AS BIGINT) FROM shipping;\n```\n\n``` text\nQuery failed: Cannot cast 'P332a' to BIGINT\n```\n\n`NULL` values with `TRY`:\n\n``` sql\nSELECT TRY(CAST(origin_zip AS BIGINT)) FROM shipping;\n```\n\n``` text\norigin_zip\n------------\n     94131\n     NULL\n     94025\n     08544\n(4 rows)\n```\n\nQuery failure without `TRY`:\n\n``` sql\nSELECT total_cost / packages AS per_package FROM shipping;\n```\n\n``` text\nQuery failed: Division by zero\n```\n\nDefault values with `TRY` and `COALESCE`:\n\n``` sql\nSELECT COALESCE(TRY(total_cost / packages), 0) AS per_package FROM shipping;\n```\n\n``` text\nper_package\n-------------\n         4\n        14\n         0\n        19\n(4 rows)\n```\n", "doc_id": "c82cab1b-0979-469a-8f4e-3be408d0e4e6", "embedding": null, "doc_hash": "6f94f91ff804b7be3a5b670628e99165f175dd0b480bd76bb7677333100a2253", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/conditional.md", "file_name": "conditional.md"}, "node_info": {"start": 2527, "end": 3901, "_node_type": "1"}, "relationships": {"1": "f7dc87a714740bc664e069b2703bde045e1b864a", "2": "0081dda6-832e-478d-96a2-ce3db5e92d03"}}, "__type__": "1"}, "156219dc-882e-4497-9c64-9f5bb59a7845": {"__data__": {"text": "---\ntitle: Conversions\n---\n\n## Implicit Conversions\n\nDuneSQL will implicitly convert numeric and character values to the correct type if such a conversion is possible.  \nDuneSQL will not convert implicitly between character and numeric types.  \nFor example, a query that expects a varchar will not automatically convert a bigint value to an equivalent varchar.\n\nWhen necessary, values can be explicitly cast to a particular type.\n\n### Implicit Casting with numeric types\n\nDuneSQL has added support for implicit casts when performing arithmetic with `INT256` and `UINT256` and smaller types like `INTEGER`, `BIGINTEGER`, and `DECIMAL(38,0)`. This allows you to write expressions like `2 * UINT256 '1'` instead of `CAST(2 AS UINT256) * UINT256 '1'`, and similarly for other arithmetic operations.\n\nFor example:\n\n```sql\nSELECT 2 * UINT256 '1';\n```\n\nWill be equivalent to:\n\n```sql\nSELECT CAST(2 AS UINT256) * UINT256 '1';\n```\n\nPlease note that implicit casting has not been added for arithmetic with DOUBLE to make precision issues more apparent.\n\n\n\n\n### Conversion functions\n\n\n#### cast() \n**``cast(value AS type)``** \u2192 type\n\nExplicitly cast a value as a type. This can be used to cast a varchar to\na numeric value type and vice versa.\n\n\n#### try_cast()\n**``try_cast(value AS type)``** \u2192 type\n\nLike `cast`{.interpreted-text role=\"func\"}, but returns null if the cast\nfails.\n\n### Formatting\n\n#### format()\n**``format(format, args\\...)``** \u2192 varchar\n\nReturns a formatted string using the specified [format\nstring](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Formatter.html#syntax)\nand arguments:\n```sql\n    SELECT format('%s%%', 123);\n    -- '123%'\n\n    SELECT format('%.5f', pi());\n    -- '3.14159'\n\n    SELECT format('%03d', 8);\n    -- '008'\n\n    SELECT format('%,.2f', 1234567.89);\n    -- '1,234,567.89'\n\n    SELECT format('%-7s,%7s', 'hello', 'world');\n    -- 'hello  ,  world'\n\n    SELECT format('%2$s %3$s %1$s', 'a', 'b', 'c');\n    -- 'b c a'\n\n    SELECT format('%1$tA, %1$tB %1$te, %1$tY', date '2006-07-04');\n    -- 'Tuesday, July 4, 2006'\n```\n\n#### format_number()\n**``format_number(number, decimal_places)``** \u2192 varchar\nReturns a formatted string using a unit symbol:\n\n    SELECT format_number(123456); -- '123K'\n    SELECT format_number(1000000); -- '1M'\n\n\n\n### Miscellaneous\n\n#### typeof()\n**``typeof(expr)``** \u2192 varchar\n\nReturns the name of the type of the provided expression:\n```sql\n    SELECT typeof(123); -- integer\n    SELECT typeof('cat'); -- varchar(3)\n    SELECT typeof(cos(2) + 1.5); -- double\n```\n\n", "doc_id": "156219dc-882e-4497-9c64-9f5bb59a7845", "embedding": null, "doc_hash": "988d2ca2e83c3eaf60ee2768b3b79c6b491a42fda1a82f0163db1a682be83936", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/conversion.md", "file_name": "conversion.md"}, "node_info": {"start": 0, "end": 2544, "_node_type": "1"}, "relationships": {"1": "57218f210fc19c7aaa4905608df8dedf4a5a9eb1"}}, "__type__": "1"}, "a5c63800-a8a3-43ab-8c49-df5330025ea5": {"__data__": {"text": "---\ntitle: Date and time functions and operators\n---\n\nThese functions and operators operate on\n[`date and time data types`](DuneSQL-reference/SQL-language/datatypes.md/#date-and-time).\n\n### Date and time operators\n\n| Operator | Example | Result |\n| -------- | ------- | ------ |\n| `+` | `date '2012-08-08' + interval '2' day` | `2012-08-10` |\n| `+` | `time '01:00' + interval '3' hour` | `04:00:00.000` |\n| `+` | `timestamp '2012-08-08 01:00' + interval '29' hour` | `2012-08-09 06:00:00.000` |\n| `+` | `timestamp '2012-10-31 01:00' + interval '1' month` | `2012-11-30 01:00:00.000` |\n| `+` | `interval '2' day + interval '3' hour` | `2 03:00:00.000` |\n| `+` | `interval '3' year + interval '5' month` | `3-5` |\n| `-` | `date '2012-08-08' - interval '2' day` | `2012-08-06` |\n| `-` | `time '01:00' - interval '3' hour` | `22:00:00.000` |\n| `-` | `timestamp '2012-08-08 01:00' - interval '29' hour` | `2012-08-06 20:00:00.000` |\n| `-` | `timestamp '2012-10-31 01:00' - interval '1' month` | `2012-09-30 01:00:00.000` |\n| `-` | `interval '2' day - interval '3' hour` | `1 21:00:00.000` |\n| `-` | `interval '3' year - interval '5' month` | `2-7` |\n\n\n### Time zone conversion\n\nThe `AT TIME ZONE` operator sets the time zone of a timestamp:\n```sql\n    SELECT timestamp '2012-10-31 01:00 UTC';\n    -- 2012-10-31 01:00:00.000 UTC\n\n    SELECT timestamp '2012-10-31 01:00 UTC' AT TIME ZONE 'America/Los_Angeles';\n    -- 2012-10-30 18:00:00.000 America/Los_Angeles\n```\n### Date and time functions\n\n#### current_date\n**``current_date``**\n\nReturns the current date as of the start of the query.\n#### current_time\n**``current_time``**\n\nReturns the current time with time zone as of the start of the query.\n\n\n#### current_timestamp\n**``current_timestamp``**\n\nReturns the current timestamp with time zone as of the start of the\nquery, with `3` digits of subsecond precision,\n\n\n#### current_timestamp()\n**``current_timestamp(p)``**\n\nReturns the current `timestamp with time zone\nas `timestamp-with-time-zone-data-type` of the start of the query, with `p` digits of subsecond precision:\n```sql\n    SELECT current_timestamp(6);\n    -- 2020-06-24 08:25:31.759993 America/Los_Angeles\n```\n\n#### current_timezone()\n**``current_timezone()``** \u2192 varchar\n\nReturns the current time zone in the format defined by IANA (e.g.,\n`America/Los_Angeles`) or as fixed offset from UTC (e.g., `+08:35`)\n\n\n#### date()\n**``date(x)``** \u2192 date\n\nThis is an alias for `CAST(x AS date)`.\n\n\n#### last_day_of_month()\n**``last_day_of_month(x)``** \u2192 date\n\nReturns the last day of the", "doc_id": "a5c63800-a8a3-43ab-8c49-df5330025ea5", "embedding": null, "doc_hash": "09b0a177214f042c327249e5231b2d8793e052c0231f7ad5ac030d51c0e43fcb", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}, "node_info": {"start": 0, "end": 2535, "_node_type": "1"}, "relationships": {"1": "702dc3e4a27955421bc6547a65cd6d15ef07b272", "3": "02ba00a8-ed4b-4619-869f-12f6ca0a6330"}}, "__type__": "1"}, "02ba00a8-ed4b-4619-869f-12f6ca0a6330": {"__data__": {"text": "\u2192 date\n\nReturns the last day of the month.\n\n\n#### from_iso8601_timestamp()\n**``from_iso8601_timestamp(string)``** \u2192 timestamp(3) with time zone\n\nParses the ISO 8601 formatted date `string`, optionally with time and\ntime zone, into a `timestamp(3) with time zone`. The time defaults to\n`00:00:00.000`, and the time zone defaults to the session time zone:\n```sql\n    SELECT from_iso8601_timestamp('2020-05-11');\n    -- 2020-05-11 00:00:00.000 America/Vancouver\n\n    SELECT from_iso8601_timestamp('2020-05-11T11:15:05');\n    -- 2020-05-11 11:15:05.000 America/Vancouver\n\n    SELECT from_iso8601_timestamp('2020-05-11T11:15:05.055+01:00');\n    -- 2020-05-11 11:15:05.055 +01:00\n```\n\n#### from_iso8601_timestamp_nanos()\n**``from_iso8601_timestamp_nanos(string)``** \u2192 timestamp(9) with time zone\n\nParses the ISO 8601 formatted date and time `string`. The time zone\ndefaults to the session time zone:\n```sql\n    SELECT from_iso8601_timestamp_nanos('2020-05-11T11:15:05');\n    -- 2020-05-11 11:15:05.000000000 America/Vancouver\n\n    SELECT from_iso8601_timestamp_nanos('2020-05-11T11:15:05.123456789+01:00');\n    -- 2020-05-11 11:15:05.123456789 +01:00\n```\n\n#### from_iso8601_date()\n**``from_iso8601_date(string)``** \u2192 date\n\nParses the ISO 8601 formatted date `string` into a `date`. The date can\nbe a calendar date, a week date using ISO week numbering, or year and\nday of year combined:\n```sql\n    SELECT from_iso8601_date('2020-05-11');\n    -- 2020-05-11\n\n    SELECT from_iso8601_date('2020-W10');\n    -- 2020-03-02\n\n    SELECT from_iso8601_date('2020-123');\n    -- 2020-05-02\n```\n\n#### at_timezone()\n**``at_timezone(timestamp, zone)``** \u2192 timestamp(p) with time zone\n\nChange the time zone component of `timestamp` with precision `p` to\n`zone` while preserving the instant in time.\n\n\n#### with_timezone()\n**``with_timezone(timestamp, zone)``** \u2192 timestamp(p) with time zone\n\nReturns a timestamp with time zone from `timestamp` with precision `p`\nand `zone`.\n\n#### from_unixtime()\n**``from_unixtime(unixtime)``** \u2192 timestamp(3) with time zone\n\nReturns the UNIX timestamp `unixtime` as a timestamp with time zone.\n`unixtime` is the number of seconds since `1970-01-01 00:00:00 UTC`.\n\n\n#### from_unixtime()\n**``from_unixtime(unixtime, zone)``** \u2192 timestamp(3) with time zone\n\nReturns the UNIX timestamp `unixtime` as a timestamp with time zone\nusing `zone` for the time zone. `unixtime` is the number of seconds\nsince `1970-01-01 00:00:00 UTC`.\n\n#### from_unixtime()\n**``from_unixtime(unixtime, hours, minutes)``** \u2192 timestamp(3) with time zone\n\nReturns the UNIX timestamp `unixtime` as a timestamp with time zone\nusing `hours` and `minutes` for the time zone offset.", "doc_id": "02ba00a8-ed4b-4619-869f-12f6ca0a6330", "embedding": null, "doc_hash": "378010253fd9afc53f3065cae65103390fb4d027776431d2058605a51de49823", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}, "node_info": {"start": 2507, "end": 5166, "_node_type": "1"}, "relationships": {"1": "702dc3e4a27955421bc6547a65cd6d15ef07b272", "2": "a5c63800-a8a3-43ab-8c49-df5330025ea5", "3": "7eadf116-90df-4bba-a7b0-a6d97641274a"}}, "__type__": "1"}, "7eadf116-90df-4bba-a7b0-a6d97641274a": {"__data__": {"text": "with time zone\nusing `hours` and `minutes` for the time zone offset. `unixtime` is the\nnumber of seconds since `1970-01-01 00:00:00` in `double` data type.\n\n#### from_unixtime_nanos()\n**``from_unixtime_nanos(unixtime)``** \u2192 timestamp(9) with time zone\n\nReturns the UNIX timestamp `unixtime` as a timestamp with time zone.\n`unixtime` is the number of nanoseconds since\n`1970-01-01 00:00:00.000000000 UTC`:\n```sql\n    SELECT from_unixtime_nanos(100);\n    -- 1970-01-01 00:00:00.000000100 UTC\n\n    SELECT from_unixtime_nanos(DECIMAL '1234');\n    -- 1970-01-01 00:00:00.000001234 UTC\n\n    SELECT from_unixtime_nanos(DECIMAL '1234.499');\n    -- 1970-01-01 00:00:00.000001234 UTC\n\n    SELECT from_unixtime_nanos(DECIMAL '-1234');\n    -- 1969-12-31 23:59:59.999998766 UTC\n```\n\n\n#### now()\n**``now()``** \u2192 timestamp(3) with time zone\n\nThis is an alias for `current_timestamp`.\n\n#### to_iso8601()\n**``to_iso8601(x)``** \u2192 varchar\n\nFormats `x` as an ISO 8601 string. `x` can be date, timestamp, or\ntimestamp with time zone.\n\n\n#### to_milliseconds()\n**``to_milliseconds(interval)``** \u2192 bigint\n\nReturns the day-to-second `interval` as milliseconds.\n\n\n#### to_unixtime()\n**``to_unixtime(timestamp)``** \u2192 double\n\nReturns `timestamp` as a UNIX timestamp.\n\n\n### Truncation function\n\nThe `date_trunc` function supports the following units:\n\n| Unit      | Example                          | Truncated Value             |\n| --------- | -------------------------------- | --------------------------- |\n| `second`  | `2001-08-22 03:04:05.000`        | `2001-08-22 03:04:05.000`   |\n| `minute`  | `2001-08-22 03:04:00.000`        | `2001-08-22 03:04:00.000`   |\n| `hour`    | `2001-08-22 03:00:00.000`        | `2001-08-22 03:00:00.000`   |\n| `day`     | `2001-08-22 00:00:00.000`        | `2001-08-22 00:00:00.000`   |\n| `week`    | `2001-08-20 00:00:00.000`        | `2001-08-20 00:00:00.000`   |\n| `month`   | `2001-08-01 00:00:00.000`        | `2001-08-01 00:00:00.000`   |\n| `quarter` | `2001-07-01 00:00:00.000`        | `2001-07-01 00:00:00.000`   |\n| `year`    | `2001-01-01 00:00:00.000`        | `2001-01-01 00:00:00.000`   |\n\nThe above examples use the timestamp `2001-08-22 03:04:05.321` as the\ninput.\n\n####", "doc_id": "7eadf116-90df-4bba-a7b0-a6d97641274a", "embedding": null, "doc_hash": "5e577a16f010ce984583d7cdd85cbf3853dee851defc4bc412d1a5a70d3b1fc8", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}, "node_info": {"start": 5138, "end": 7334, "_node_type": "1"}, "relationships": {"1": "702dc3e4a27955421bc6547a65cd6d15ef07b272", "2": "02ba00a8-ed4b-4619-869f-12f6ca0a6330", "3": "e7e6193e-f910-4454-8ea4-e6116a382a0a"}}, "__type__": "1"}, "e7e6193e-f910-4454-8ea4-e6116a382a0a": {"__data__": {"text": "03:04:05.321` as the\ninput.\n\n#### date_trunc()\n**``date_trunc(unit, x)``** \u2192 \\[same as input\\]\n\nReturns `x` truncated to `unit`:\n```sql\n    SELECT date_trunc('day' , TIMESTAMP '2022-10-20 05:10:00');\n    -- 2022-10-20 00:00:00.000\n\n    SELECT date_trunc('month' , TIMESTAMP '2022-10-20 05:10:00');\n    -- 2022-10-01 00:00:00.000\n\n    SELECT date_trunc('year', TIMESTAMP '2022-10-20 05:10:00');\n    -- 2022-01-01 00:00:00.000\n```\n\n### Interval functions\n\nThe functions in this section support the following interval units:\n\n| Unit          | Description             |\n| ------------- | ----------------------- |\n| `millisecond` | Milliseconds            |\n| `second`      | Seconds                 |\n| `minute`      | Minutes                 |\n| `hour`        | Hours                   |\n| `day`         | Days                    |\n| `week`        | Weeks                   |\n| `month`       | Months                  |\n| `quarter`     | Quarters of a year      |\n| `year`        | Years                   |\n\n#### date_add()\n**``date_add(unit, value, timestamp)``** \u2192 same as input\n\nAdds an interval `value` of type `unit` to `timestamp`. Subtraction can\nbe performed by using a negative value:\n```sql\n    SELECT date_add('second', 86, TIMESTAMP '2020-03-01 00:00:00');\n    -- 2020-03-01 00:01:26.000\n\n    SELECT date_add('hour', 9, TIMESTAMP '2020-03-01 00:00:00');\n    -- 2020-03-01 09:00:00.000\n\n    SELECT date_add('day', -1, TIMESTAMP '2020-03-01 00:00:00 UTC');\n    -- 2020-02-29 00:00:00.000 UTC\n```\n\n#### date_diff()\n**``date_diff(unit, timestamp1, timestamp2)``** \u2192 bigint\n\nReturns `timestamp2 - timestamp1` expressed in terms of `unit`:\n```sql\n    SELECT date_diff('second', TIMESTAMP '2020-03-01 00:00:00', TIMESTAMP '2020-03-02 00:00:00');\n    -- 86400\n\n    SELECT date_diff('hour', TIMESTAMP '2020-03-01 00:00:00 UTC', TIMESTAMP '2020-03-02 00:00:00 UTC');\n    -- 24\n\n    SELECT date_diff('day', DATE '2020-03-01', DATE '2020-03-02');\n    -- 1\n\n    SELECT date_diff('second', TIMESTAMP '2020-06-01 12:30:45.000000000', TIMESTAMP '2020-06-02 12:30:45.123456789');\n ", "doc_id": "e7e6193e-f910-4454-8ea4-e6116a382a0a", "embedding": null, "doc_hash": "a467f11df880f3f1f96d54ab6c9f7c118e826ba4a8b2d73e2d475519b2b6da0e", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}, "node_info": {"start": 7362, "end": 9438, "_node_type": "1"}, "relationships": {"1": "702dc3e4a27955421bc6547a65cd6d15ef07b272", "2": "7eadf116-90df-4bba-a7b0-a6d97641274a", "3": "650945f8-b90c-423f-90be-d4060c5f240f"}}, "__type__": "1"}, "650945f8-b90c-423f-90be-d4060c5f240f": {"__data__": {"text": "'2020-06-02 12:30:45.123456789');\n    -- 86400\n\n    SELECT date_diff('millisecond', TIMESTAMP '2020-06-01 12:30:45.000000000', TIMESTAMP '2020-06-02 12:30:45.123456789');\n    -- 86400123\n```\n\n### Duration function\n\nThe `parse_duration` function supports the following units:\n\n| Unit | Description   |\n| ---- | ------------- |\n| `ns` | Nanoseconds   |\n| `us` | Microseconds  |\n| `ms` | Milliseconds  |\n| `s`  | Seconds       |\n| `m`  | Minutes       |\n| `h`  | Hours         |\n| `d`  | Days          |\n\n\n#### parse_duration()\n**``parse_duration(string)``** \u2192 interval\n\nParses `string` of format `value unit` into an interval, where `value`\nis fractional number of `unit` values:\n```sql\n    SELECT parse_duration('42.8ms');\n    -- 0 00:00:00.043\n\n    SELECT parse_duration('3.81 d');\n    -- 3 19:26:24.000\n\n    SELECT parse_duration('5m');\n    -- 0 00:05:00.000\n```\n\n\n#### human_readable_seconds()\n**``human_readable_seconds(double)``** \u2192 varchar\n\nFormats the double value of `seconds` into a human readable string\ncontaining `weeks`, `days`, `hours`, `minutes`, and `seconds`:\n```sql\n    SELECT human_readable_seconds(96);\n    -- 1 minute, 36 seconds\n\n    SELECT human_readable_seconds(3762);\n    -- 1 hour, 2 minutes, 42 seconds\n\n    SELECT human_readable_seconds(56363463);\n    -- 93 weeks, 1 day, 8 hours, 31 minutes, 3 seconds\n```\n\n### MySQL date functions\n\nThe functions in this section use a format string that is compatible\nwith the MySQL `date_parse` and `str_to_date` functions. The following\ntable, based on the MySQL manual, describes the format specifiers:\n\n | Specifier | Description                                                                                                     |\n|-----------|-----------------------------------------------------------------------------------------------------------------|\n| `%a`      | Abbreviated weekday name (`Sun` .. `Sat`)                                                                        |\n| `%b`      | Abbreviated month name (`Jan` .. `Dec`)                                                                          |\n| `%c`      | Month, numeric (`1` .. `12`)[^1]                                                     ", "doc_id": "650945f8-b90c-423f-90be-d4060c5f240f", "embedding": null, "doc_hash": "2d41e545552a04a444f68a141464a972f746dd3c1a63db15894d4bf757328131", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}, "node_info": {"start": 9437, "end": 11620, "_node_type": "1"}, "relationships": {"1": "702dc3e4a27955421bc6547a65cd6d15ef07b272", "2": "e7e6193e-f910-4454-8ea4-e6116a382a0a", "3": "390680d0-5366-4669-a91c-bc9b35b38940"}}, "__type__": "1"}, "390680d0-5366-4669-a91c-bc9b35b38940": {"__data__": {"text": "                                               |\n| `%D`      | Day of the month with English suffix (`0th`, `1st`, `2nd`, `3rd`, ...)                                           |\n| `%d`      | Day of the month, numeric (`01` .. `31`)[^2]                                                                     |\n| `%e`      | Day of the month, numeric (`1` .. `31`)[^3]                                                                      |\n| `%f`      | Fraction of second (6 digits for printing: `000000` .. `999000`; 1 - 9 digits for parsing: `0` .. `999999999`)[^4] |\n| `%H`      | Hour (`00` .. `23`)                                                                                             |\n| `%h`      | Hour (`01` .. `12`)                                                                                             |\n| `%I`      | Hour (`01` .. `12`)                                                                                             |\n| `%i`      | Minutes, numeric (`00` .. `59`)                                                                                 |\n| `%j`      | Day of year (`001` .. `366`)                                                                                     |\n| `%k`      | Hour (`0` .. `23`)                 ", "doc_id": "390680d0-5366-4669-a91c-bc9b35b38940", "embedding": null, "doc_hash": "d6de8ccd195ee9b97f6b8875c81e96524dc424a3c3521e40e8981b845feed583", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}, "node_info": {"start": 11654, "end": 12911, "_node_type": "1"}, "relationships": {"1": "702dc3e4a27955421bc6547a65cd6d15ef07b272", "2": "650945f8-b90c-423f-90be-d4060c5f240f", "3": "ad891fee-0d1f-418b-8f1f-06130585c458"}}, "__type__": "1"}, "ad891fee-0d1f-418b-8f1f-06130585c458": {"__data__": {"text": "                                                                                             |\n| `%l`      | Hour (`1` .. `12`)                                                                                              |\n| `%M`      | Month name (`January` .. `December`)                                                                             |\n| `%m`      | Month, numeric (`01` .. `12`)[^5]                                                                                |\n| `%p`      | `AM` or `PM`                                                                                                    |\n| `%r`      | Time of day, 12-hour (equivalent to `%h:%i:%s %p`)                                                               |\n| `%S`      | Seconds (`00` .. `59`)                                                                                          |\n| `%s`      | Seconds (`00` .. `59`)                                                                                          |\n| `%T`      | Time of day, 24-hour (equivalent to `%H:%i:%s`)                                                                   |\n| `%U`      | Week (`00` .. `53`), where Sunday", "doc_id": "ad891fee-0d1f-418b-8f1f-06130585c458", "embedding": null, "doc_hash": "5a30d3847e322469af5578db34f6d7546dba4777d483372b659e7d0a7ec08826", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}, "node_info": {"start": 12912, "end": 14083, "_node_type": "1"}, "relationships": {"1": "702dc3e4a27955421bc6547a65cd6d15ef07b272", "2": "390680d0-5366-4669-a91c-bc9b35b38940", "3": "b71e0166-ac13-48c9-9d31-4ef1985eb777"}}, "__type__": "1"}, "b71e0166-ac13-48c9-9d31-4ef1985eb777": {"__data__": {"text": "     | Week (`00` .. `53`), where Sunday is the first day of the week                                                    |\n| `%u`      | Week (`00` .. `53`), where Monday is the first day of the week                                                    |\n| `%V`      | Week (`01` .. `53`), where Sunday is the first day of the week; used with `%X`                                    |\n| `%v`      | Week (`01` .. `53`), where Monday is the first day of the week; used with `%x`                                    |\n| `%W`      | Weekday name (`Sunday` .. `Saturday`)                                                                           |\n| `%w`      | Day of the week (`0` .. `6`), where Sunday is the first day of the week[^6]                                        |\n| `%X`      | Year for the week where Sunday is the first day of the week, numeric, four digits; used with `%V`                |\n| `%x`      | Year for the week, where Monday is the first day of the week, numeric, four digits; used with `%v`                |\n| `%Y`      | Year, numeric, four digits                                                                                       |\n| `%y`      | Year, numeric (two digits)[^7]                                                                                   |\n| `%%`      | A literal `%` character                                                                                          |\n| `%x`      | `x`, for any `x` not\n\n\n\n\nThe following specifiers are not currently supported:\n`%D %U %u %V %w %X`\n\n\n\n**``date_format(timestamp, format)``** \u2192", "doc_id": "b71e0166-ac13-48c9-9d31-4ef1985eb777", "embedding": null, "doc_hash": "cd08d0b4cb6bdcc501b8d2bcc24b4c1567eace802ee4801b9e649f4c163c300b", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}, "node_info": {"start": 14055, "end": 15629, "_node_type": "1"}, "relationships": {"1": "702dc3e4a27955421bc6547a65cd6d15ef07b272", "2": "ad891fee-0d1f-418b-8f1f-06130585c458", "3": "6df20991-9e56-4946-ace0-45cb7b15e139"}}, "__type__": "1"}, "6df20991-9e56-4946-ace0-45cb7b15e139": {"__data__": {"text": "%X`\n\n\n\n**``date_format(timestamp, format)``** \u2192 varchar\n\nFormats `timestamp` as a string using `format`:\n```sql\n    SELECT date_format(TIMESTAMP '2022-10-20 05:10:00', '%m-%d-%Y %H');\n    -- 10-20-2022 05\n```\n\n**``date_parse(string, format)``** \u2192 timestamp\n\nParses `string` into a timestamp using `format`:\n```sql\n    SELECT date_parse('2022/10/20/05', '%Y/%m/%d/%H');\n    -- 2022-10-20 05:00:00.000\n```\n### Java date functions\n\nThe functions in this section use a format string that is compatible\nwith JodaTime\\'s\n[DateTimeFormat](http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html)\npattern format.\n\n#### format_datetime()\n**``format_datetime(timestamp, format)``** \u2192 varchar\n\nFormats `timestamp` as a string using `format`.\n\n#### parse_datetime()\n**``parse_datetime(string, format)``** \u2192 timestamp\n\nParses `string` into a timestamp with time zone using `format`.\n\n### Extraction function\n\nThe `extract` function supports the following fields:\n\n| Field             | Description         |\n| ----------------- | ------------------- |\n| `YEAR`            | `year`              |\n| `QUARTER`         | `quarter`           |\n| `MONTH`           | `month`             |\n| `WEEK`            | `week`              |\n| `DAY`             | `day`               |\n| `DAY_OF_MONTH`    | `day`               |\n| `DAY_OF_WEEK`     | `day_of_week`       |\n| `DOW`             | `day_of_week`       |\n| `DAY_OF_YEAR`     | `day_of_year`       |\n| `DOY`             | `day_of_year`       |\n| `YEAR_OF_WEEK`    | `year_of_week`      |\n| `YOW`             | `year_of_week`      |\n| `HOUR`            | `hour`              |\n| `MINUTE`          | `minute`            |\n| `SECOND`          | `second`            |\n| `TIMEZONE_HOUR`   | `timezone_hour`     |\n| `TIMEZONE_MINUTE` | `timezone_minute`   |\n\n\nThe types supported by the `extract` function vary depending on the\nfield to be extracted. Most fields support all date and time types.\n\n**``extract(field FROM x)``** \u2192 bigint\n\nReturns `field` from", "doc_id": "6df20991-9e56-4946-ace0-45cb7b15e139", "embedding": null, "doc_hash": "19998eefbd0a8811aff413c21d56b91ccefb065c69f82da62ef11df1089a2bdd", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}, "node_info": {"start": 15614, "end": 17626, "_node_type": "1"}, "relationships": {"1": "702dc3e4a27955421bc6547a65cd6d15ef07b272", "2": "b71e0166-ac13-48c9-9d31-4ef1985eb777", "3": "ec7028d0-6bce-476e-ad45-d51f4e8e70a3"}}, "__type__": "1"}, "ec7028d0-6bce-476e-ad45-d51f4e8e70a3": {"__data__": {"text": "FROM x)``** \u2192 bigint\n\nReturns `field` from `x`:\n```sql\n    SELECT extract(YEAR FROM TIMESTAMP '2022-10-20 05:10:00');\n    -- 2022\n```\n!!!note\n    This SQL-standard function uses special syntax for specifying the\n    arguments.\n\n### Convenience extraction functions\n\n#### day()\n**``day(x)``** \u2192 bigint\n\n\nReturns the day of the month from `x`.\n\n#### day_of_month()\n**``day_of_month(x)``** \u2192 bigint\n\nThis is an alias for `day`.\n\n#### day_of_week()\n**``day_of_week(x)``** \u2192 bigint\n\nReturns the ISO day of the week from `x`. The value ranges from `1` (Monday) to `7` (Sunday).\n\n#### day_of_year()\n**``day_of_year(x)``** \u2192 bigint\n\nReturns the day of the year from `x`. The value ranges from `1` to `366`.\n\n#### dow()\n**``dow(x)``** \u2192 bigint\n\nThis is an alias for `day_of_week`.\n\n#### doy()\n**``doy(x)``** \u2192 bigint\n\nThis is an alias for `day_of_year`.\n\n#### hour()\n**``hour(x)``** \u2192 bigint\n\nReturns the hour of the day from `x`. The value ranges from `0` to `23`.\n\n#### millisecond()\n**``millisecond(x)``** \u2192 bigint\n\nReturns the millisecond of the second from `x`.\n\n#### minute()\n**``minute(x)``** \u2192 bigint\n\nReturns the minute of the hour from `x`.\n\n#### month()\n**``month(x)``** \u2192 bigint\n\nReturns the month of the year from `x`.\n\n#### quarter()\n**``quarter(x)``** \u2192 bigint\n\nReturns the quarter of the year from `x`. The value ranges from `1` to `4`.\n\n#### second()\n**``second(x)``** \u2192 bigint\n\nReturns the second of the minute from `x`.\n\n#### timezone_hour()\n**``timezone_hour(timestamp)``** \u2192 bigint\n\nReturns the hour of the time zone offset from `timestamp`.\n\n#### timezone_minute()\n**``timezone_minute(timestamp)``** \u2192 bigint\n\nReturns the minute of the time zone offset from `timestamp`.\n\n#### week()\n**``week(x)``** \u2192 bigint\n\nReturns the [ISO week]() of the year from `x`. The value ranges from `1` to `53`.\n\n#### week_of_year()\n**``week_of_year(x)``** \u2192 bigint\n\nThis is an alias for `week`.\n\n#### year()\n**``year(x)``** \u2192 bigint\n\nReturns the year from `x`.\n\n#### year_of_week()\n**``year_of_week(x)``** \u2192 bigint\n\nReturns the year of the [ISO week]() from `x`.\n\n#### yow()\n**``yow(x)``** \u2192 bigint\n\nThis is an alias for `year_of_week`.\n\n[^1]: This specifier does not support `0` as a month or day.\n[^2]: This specifier does not support `0` as a month or day.\n[^3]: This specifier does not support `0` as a month or day.\n[^4]: Timestamp is truncated to milliseconds.\n[^5]: This specifier does not support `0` as a month or day.\n[^6]: This specifier is not supported yet. Consider using `day_of_week` (it uses `1-7` instead of `0-6`).\n[^7]: When parsing, two-digit year format assumes range `1970` .. `2069`, so \"70\" will result in year `1970` but \"69\" will produce `2069`.\n", "doc_id": "ec7028d0-6bce-476e-ad45-d51f4e8e70a3", "embedding": null, "doc_hash": "69ee9f700c343377998e70c54950f8a5baf6fcf18ff9a09bd4d10bf84ac0f226", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}, "node_info": {"start": 17629, "end": 20296, "_node_type": "1"}, "relationships": {"1": "702dc3e4a27955421bc6547a65cd6d15ef07b272", "2": "6df20991-9e56-4946-ace0-45cb7b15e139"}}, "__type__": "1"}, "32161ec0-3cab-4004-9732-f5d583a56ca2": {"__data__": {"text": "---\ntitle: Decimal functions and operators\n---\n\n### Decimal literals {#decimal_literal}\n\nUse the `DECIMAL 'xxxxxxx.yyyyyyy'` syntax to define a decimal literal.\n\nThe precision of a decimal type for a literal will be equal to the\nnumber of digits in the literal (including trailing and leading zeros).\nThe scale will be equal to the number of digits in the fractional part\n(including trailing zeros).\n\n| Example literal                     | Data type     |\n| ----------------------------------- | -------------|\n| `DECIMAL '0'`                       | `DECIMAL(1)` |\n| `DECIMAL '12345'`                   | `DECIMAL(5)` |\n| `DECIMAL '0000012345.1234500000'`   | `DECIMAL(20, 10)` |\n\n\n### Binary arithmetic decimal operators\n\nStandard mathematical operators are supported. The table below explains\nprecision and scale calculation rules for result. Assuming `x` is of\ntype `DECIMAL(xp, xs)` and `y` is of type `DECIMAL(yp, ys)`.\n\n| Operation          | Result type precision                            | Result type scale |\n|--------------------|--------------------------------------------------|-------------------|\n| `x + y` and `x -y` | `min(38,1 +max(xs, ys) + max(xp - xs, yp - ys))` | `max(xs, ys)`     |\n| `x * y`            | `min(38, xp + yp)`                               | `xs + ys`         |\n| `x / y`            | `min(38, xp + ys + max(0, ys-xs))`               | `max(xs, ys)`     |\n| `x % y`            | `min(xp - xs, yp - ys) + max(xs, bs)`            | `max(xs, ys)`     |\n\n\nIf the mathematical result of the operation is not exactly representable\nwith the precision and scale of the result data type, then an exception\ncondition is raised: `Value is out of range`.\n\nWhen operating on decimal types with different scale and precision, the\nvalues are first coerced to a common super type. For types near the\nlargest representable precision (38), this can result in \"Value is out of\nrange\" errors when one of the operands doesn't fit in the common super\ntype. For example, the common super type of decimal(38, 0) and\ndecimal(38, 1) is decimal(38, 1), but certain values that fit in\ndecimal(38, 0) cannot be represented as a decimal(38, 1).\n\n### Comparison operators\n\nAll standard `comparison` work for the\ndecimal type.\n\n### Unary decimal operators\n\nThe `-` operator performs negation. The type of result is same as type\nof argument.\n", "doc_id": "32161ec0-3cab-4004-9732-f5d583a56ca2", "embedding": null, "doc_hash": "be9d319d792c769f3aa56886be90b8a500ddf3adfccf2ca87d602d525ae121fd", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/decimal.md", "file_name": "decimal.md"}, "node_info": {"start": 0, "end": 2351, "_node_type": "1"}, "relationships": {"1": "f6ba683c6473cd3a6df1fa8c3e908339794669e9"}}, "__type__": "1"}, "fa3a9d81-7d4d-4e45-80d9-444f08dbc65f": {"__data__": {"text": "---\ntitle: HyperLogLog functions\n---\n\nTrino implements the [`approx_distinct`](DuneSQL-reference/Functions-and-operators/aggregate/#approximate-aggregate-functions) function using the\n[HyperLogLog](https://en.wikipedia.org/wiki/HyperLogLog) data structure.\n\n### Data structures\n\nTrino implements HyperLogLog data sketches as a set of 32-bit buckets\nwhich store a *maximum hash*. They can be stored sparsely (as a map from\nbucket ID to bucket), or densely (as a contiguous memory block). The\nHyperLogLog data structure starts as the sparse representation,\nswitching to dense when it is more efficient. The P4HyperLogLog\nstructure is initialized densely and remains dense for its lifetime.\n\n`hyperloglog_type` implicitly casts to\n`p4hyperloglog_type`, while one can\nexplicitly cast `HyperLogLog` to `P4HyperLogLog`:\n```text\n    cast(hll AS P4HyperLogLog)\n```\n### Serialization\n\nData sketches can be serialized to and deserialized from `varbinary`.\nThis allows them to be stored for later use. Combined with the ability\nto merge multiple sketches, this allows one to calculate\n`approx_distinct` of the elements of a partition of a query, then for the entirety of a query with very little\ncost.\n\nFor example, calculating the `HyperLogLog` for daily unique users will\nallow weekly or monthly unique users to be calculated incrementally by\ncombining the dailies. This is similar to computing weekly revenue by\nsumming daily revenue. Uses of `approx_distinct` with `GROUPING SETS` can be converted to use `HyperLogLog`.  \nExamples:  \n  ```sql\n    CREATE TABLE visit_summaries (  \n      visit_date date,\n      hll varbinary\n    )\n    INSERT INTO visit_summaries\n    SELECT visit_date, cast(approx_set(user_id) AS varbinary)\n    FROM user_visits\n    GROUP BY visit_date;\n\n    SELECT cardinality(merge(cast(hll AS HyperLogLog))) AS weekly_unique_users\n    FROM visit_summaries\n    WHERE visit_date >= current_date - interval '7' day;\n  ```\n### Functions\n\n#### approx_set()\n**``approx_set(x)``** \u2192 HyperLogLog\n\nReturns the `HyperLogLog` sketch of the input data set of `x`. This data\nsketch underlies `approx_distinct` and can be stored and used later by calling `cardinality()`.\n\n#### cardinality()\n**``cardinality(hll)``** \u2192 bigint\n\nThis will perform `approx_distinct` on\nthe data summarized by the `hll` HyperLogLog data sketch.\n\n\n#### empty_hll()\n**``empty_hll()``** \u2192 HyperLogLog\n\nReturns an empty `HyperLogLog`.\n\n#### merge()\n**``merge(hyperloglog)``** \u2192 HyperLogLog\nReturns the `HyperLogLog` of the aggregate union of the individual `hll`\nHyperLogLog structures.\n", "doc_id": "fa3a9d81-7d4d-4e45-80d9-444f08dbc65f", "embedding": null, "doc_hash": "925b9743a02d69e237d54fbb877f90cbeb9a10685238e941149ec5a084289893", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/hyperloglog.md", "file_name": "hyperloglog.md"}, "node_info": {"start": 0, "end": 2559, "_node_type": "1"}, "relationships": {"1": "83e70db047942a49741ea84000ab3d37820dd24a"}}, "__type__": "1"}, "476dcb35-8d4e-4344-b342-b24ea700104d": {"__data__": {"text": "---\ntitle: Overview\ndescription: DuneSQL supports a wide range of built-in functions and operators.\n---\n\n\nThis chapter describes the built-in SQL functions and operators supported by Trino. They allow you to implement complex functionality and behavior of the SQL executed by Trino operating on the underlying data sources.\n\nUsing ``SHOW FUNCTIONS`` in the query editor returns a list of all available functions, including custom functions, with all supported arguments and a short description.\n\n### DuneSQL Added Functions:\n- [Binary (DuneSQL)](varbinary.md)\n\n### Trino Base Functions:\n- [Aggregate](aggregate.md)  \n- [Array](array.md)  \n- [Binary](binary.md)  \n- [Bitwise](bitwise.md)\n- [Comparison](comparison.md)  \n- [Conditional](conditional.md)  \n- [Conversion](conversion.md)  \n- [Date and time](datetime.md)  \n- [Decimal](decimal.md)   \n- [HyperLogLog](hyperloglog.md)    \n- [JSON](json.md)  \n- [Lambda](lambda.md)  \n- [Logical](logical.md)    \n- [Map](map.md)  \n- [Math](math.md)  \n- [Quantile digest](qdigest.md)  \n- [Regular expression](regexp.md)   \n- [Set Digest](setdigest.md)  \n- [String](string.md)  \n- [System](system.md)  \n- [Table](table.md)  \n- [Teradata](teradata.md)  \n- [T-Digest](tdigest.md)  \n- [URL](url.md)  \n- [UUID](uuid.md)\n- [Window](window.md)  \n\n", "doc_id": "476dcb35-8d4e-4344-b342-b24ea700104d", "embedding": null, "doc_hash": "bf491d31001609e3255c299bc9a2295f4ea892e1cc9cf9cec888e0b7e58b9310", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 1279, "_node_type": "1"}, "relationships": {"1": "54df972ad7f2dbdfd18a315f51bc502a5e1a24be"}}, "__type__": "1"}, "af0ef1bd-1d2e-4f7e-a376-c8972fce5e52": {"__data__": {"text": "---\ntitle: JSON functions and operators\n---\n\nThe SQL standard describes functions and operators to process JSON data.\nThey allow you to access JSON data according to its structure, generate\nJSON data, and store it persistently in SQL tables.\n\nImportantly, the SQL standard imposes that there is no dedicated data\ntype to represent JSON data in SQL. Instead, JSON data is represented as\ncharacter or binary strings. Although Trino supports `JSON` type, it is\nnot used or produced by the following functions.\n\nTrino supports three functions for querying JSON data:\n`json_exists<json_exists`,\n`json_query<json_query`, and\n`json_value<json_value`.  \nEach of them is based on the same mechanism of exploring and processing JSON input using JSON path.  \n\nTrino also supports two functions for generating JSON data\n`json_array<json_array`, and\n`json_object<json_object>`.\n\n# JSON path language\n\nThe JSON path language is a special language, used exclusively by\ncertain SQL operators to specify the query to perform on the JSON input.\nAlthough JSON path expressions are embedded in SQL queries, their syntax\nsignificantly differs from SQL. The semantics of predicates, operators,\netc. in JSON path expressions generally follow the semantics of SQL. The\nJSON path language is case-sensitive for keywords and identifiers.\n\n## JSON path syntax and semantics {#json_path_syntax_and_semantics}\n\nJSON path expressions are recursive structures. Although the name\n\"path\" suggests a linear sequence of operations going step by step\ndeeper into the JSON structure, a JSON path expression is in fact a\ntree. It can access the input JSON item multiple times, in multiple\nways, and combine the results. Moreover, the result of a JSON path\nexpression is not a single item, but an ordered sequence of items. Each\nof the sub-expressions takes one or more input sequences, and returns a\nsequence as the result.\n\n!!! note\n    In the lax mode, most path operations f unnest all JSON arrays in\n    the input sequence. Any divergence from this rule is mentioned in the\n    following listing. Path modes are explained in\n    [`json_path_modes`](#json_path_modes).\n\n\nThe JSON path language features are divided into: literals, variables,\narithmetic binary expressions, arithmetic unary expressions, and a group\nof operators collectively known as accessors.\n\n### literals\n\n-   numeric literals\n\n    They include exact and approximate numbers, and are interpreted as\n    if they were SQL values.\n\n``` text\n-1, 1.2e3, NaN\n```\n\n-   string literals\n\n    They are enclosed in double quotes.\n\n``` text\n\"Some text\"\n```\n\n-   boolean literals\n\n``` text\ntrue, false\n```\n\n-   null literal\n\n    It has the semantics of the JSON null, not of SQL null. See\n    `json_comparison_rules`.\n\n``` text\nnull\n```\n\n### variables\n\n-   context variable\n\n    It refers to the currently processed input of the JSON function.\n\n``` text\n$\n```\n\n-   named variable\n\n    It refers to a named parameter by its name.\n\n``` text\n$param\n```\n\n-   current item variable\n\n    It is used inside the filter expression to refer to the currently\n    processed item from the input sequence.\n\n``` text\n@\n```\n\n-   last subscript variable\n\n    It refers to the last index of the innermost enclosing array. Array\n    indexes in JSON path expressions are zero-based.\n\n``` text\nlast\n```\n\n### arithmetic binary expressions\n\nThe JSON path language supports five arithmetic binary operators:\n\n```", "doc_id": "af0ef1bd-1d2e-4f7e-a376-c8972fce5e52", "embedding": null, "doc_hash": "658991a76e31b35ecee1d6fae33e89d7d83efdc69e50519a64c99f735a4ef17a", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 0, "end": 3410, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "3": "ff3b0afa-e047-42b3-a473-80f522823b5d"}}, "__type__": "1"}, "ff3b0afa-e047-42b3-a473-80f522823b5d": {"__data__": {"text": "JSON path language supports five arithmetic binary operators:\n\n``` text\n<path1> + <path2>\n<path1> - <path2>\n<path1> * <path2>\n<path1> / <path2>\n<path1> % <path2>\n```\n\nBoth operands, `<path1>` and `<path2>`, are evaluated to sequences of\nitems. For arithmetic binary operators, each input sequence must contain\na single numeric item. The arithmetic operation is performed according\nto SQL semantics, and it returns a sequence containing a single element\nwith the result.\n\nThe operators follow the same precedence rules as in SQL arithmetic\noperations, and parentheses can be used for grouping.\n\n### arithmetic unary expressions\n\n``` text\n+ <path>\n- <path>\n```\n\nThe operand `<path>` is evaluated to a sequence of items. Every item\nmust be a numeric value. The unary plus or minus is applied to every\nitem in the sequence, following SQL semantics, and the results form the\nreturned sequence.\n\n### member accessor\n\nThe member accessor returns the value of the member with the specified\nkey for each JSON object in the input sequence.\n\n``` text\n<path>.key\n<path>.\"key\"\n```\n\nThe condition when a JSON object does not have such a member is called a\nstructural error. In the lax mode, it is suppressed, and the faulty\nobject is excluded from the result.\n\nLet `<path>` return a sequence of three JSON objects:\n\n``` text\n{\"customer\" : 100, \"region\" : \"AFRICA\"},\n{\"region\" : \"ASIA\"},\n{\"customer\" : 300, \"region\" : \"AFRICA\", \"comment\" : null}\n```\n\nthe expression `<path>.customer` succeeds in the f and the third\nobject, but the second object lacks the required member. In strict mode,\npath evaluation fails. In lax mode, the second object is silently\nskipped, and the resulting sequence is `100, 300`.\n\nAll items in the input sequence must be JSON objects.\n\n!!! note\n    Trino does not support JSON objects with duplicate keys.\n\n\n### wildcard member accessor\n\nReturns values from all key-value pairs for each JSON object in the\ninput sequence. All the partial results are concatenated into the\nreturned sequence.\n\n``` text\n<path>.*\n```\n\nLet `<path>` return a sequence of three JSON objects:\n\n``` text\n{\"customer\" : 100, \"region\" : \"AFRICA\"},\n{\"region\" : \"ASIA\"},\n{\"customer\" : 300, \"region\" : \"AFRICA\", \"comment\" : null}\n```\n\nThe results is:\n\n``` text\n100, \"AFRICA\", \"ASIA\", 300, \"AFRICA\", null\n```\n\nAll items in the input sequence must be JSON objects.\n\nThe order of values returned from a single JSON object is arbitrary. The\nsub-sequences from all JSON objects are concatenated in the same order\nin which the JSON objects appear in the input sequence.\n\n### array accessor\n\nReturns the elements at the specified indexes for each JSON array in the\ninput sequence. Indexes are zero-based.\n\n``` text\n<path>[ <subscripts> ]\n```\n\nThe `<subscripts>` list contains one or more subscripts. Each subscript\nspecifies a single index or a range (ends inclusive):\n\n``` text\n<path>[<path1>, <path2> to <path3>, <path4>,...]\n```\n\nIn lax mode, any non-array items resulting from the evaluation of the\ninput sequence are wrapped into single-element arrays. Note that this is\nan exception to the rule of automatic array wrapping.\n\nEach array in the input sequence is processed in the following way:\n\n-   The variable `last` is set to the last index of the array.\n-   All subscript indexes are", "doc_id": "ff3b0afa-e047-42b3-a473-80f522823b5d", "embedding": null, "doc_hash": "f3787bf3fabb835f84dd13af686ba5d0f04a87fe712b208172673f56be5c5539", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 3352, "end": 6617, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "af0ef1bd-1d2e-4f7e-a376-c8972fce5e52", "3": "1ddf2704-0cf9-4719-8ebb-3957684e955c"}}, "__type__": "1"}, "1ddf2704-0cf9-4719-8ebb-3957684e955c": {"__data__": {"text": "is set to the last index of the array.\n-   All subscript indexes are computed in order of declaration. For a\n    singleton subscript `<path1>`, the result must be a singleton\n    numeric item. For a range subscript `<path2> to <path3>`, two\n    numeric items are expected.\n-   The specified array elements are added in order to the output\n    sequence.\n\nLet `<path>` return a sequence of three JSON arrays:\n\n``` text\n[0, 1, 2], [\"a\", \"b\", \"c\", \"d\"], [null, null]\n```\n\nThe following expression returns a sequence containing the last element\nfrom every array:\n\n``` text\n<path>[last] --> 2, \"d\", null\n```\n\nThe following expression returns the third and fourth element from every\narray:\n\n``` text\n<path>[2 to 3] --> 2, \"c\", \"d\"\n```\n\nNote that the f array does not have the fourth element, and the last\narray does not have the third or fourth element. Accessing non-existent\nelements is a structural error. In strict mode, it causes the path\nexpression to fail. In lax mode, such errors are suppressed, and only\nthe existing elements are returned.\n\nAnother example of a structural error is an improper range specification\nsuch as `5 to 3`.\n\nNote that the subscripts may overlap, and they do not need to follow the\nelement order. The order in the returned sequence follows the\nsubscripts:\n\n``` text\n<path>[1, 0, 0] --> 1, 0, 0, \"b\", \"a\", \"a\", null, null, null\n```\n\n### wildcard array accessor\n\nReturns all elements of each JSON array in the input sequence.\n\n``` text\n<path>[*]\n```\n\nIn lax mode, any non-array items resulting from the evaluation of the\ninput sequence are wrapped into single-element arrays. Note that this is\nan exception to the rule of automatic array wrapping.\n\nThe output order follows the order of the original JSON arrays. Also,\nthe order of elements within the arrays is preserved.\n\nLet `<path>` return a sequence of three JSON arrays:\n\n``` text\n[0, 1, 2], [\"a\", \"b\", \"c\", \"d\"], [null, null]\n<path>[*] --> 0, 1, 2, \"a\", \"b\", \"c\", \"d\", null, null\n```\n\n### filter\n\nRetrieves the items from the input sequence which satisfy the predicate.\n\n``` text\n<path>?( <predicate> )\n```\n\nJSON path predicates are syntactically similar to boolean expressions in\nSQL. However, the semantics are different in many aspects:\n\n-   They operate on sequences of items.\n-   They have their own error handling (they never fail).\n-   They behave different depending on the lax or strict mode.\n\nThe predicate evaluates to `true`, `false`, or `unknown`. Note that some\npredicate expressions involve nested JSON path expression. When\nevaluating the nested path, the variable `@` refers to the currently\nexamined item from the input sequence.\n\nThe following predicate expressions are supported:\n\n-   Conjunction\n\n``` text\n<predicate1> && <predicate2>\n```\n\n-   Disjunction\n\n``` text\n<predicate1> || <predicate2>\n```\n\n-   Negation\n\n``` text\n! <predicate>\n```\n\n-   `exists` predicate\n\n``` text\nexists( <path> )\n```\n\nReturns `true` if the nested path evaluates to a non-empty sequence, and\n`false` when the nested path evaluates to an empty sequence. If the path\nevaluation throws an error, returns `unknown`.\n\n-   `starts with` predicate\n\n```", "doc_id": "1ddf2704-0cf9-4719-8ebb-3957684e955c", "embedding": null, "doc_hash": "220ab388588614a54fccdf2a11b219af5322b006aa8a03729cb95f3682f203e7", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 6623, "end": 9749, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "ff3b0afa-e047-42b3-a473-80f522823b5d", "3": "1e5b77ec-d0c1-4ff6-ac44-6ee4f3ba1f1d"}}, "__type__": "1"}, "1e5b77ec-d0c1-4ff6-ac44-6ee4f3ba1f1d": {"__data__": {"text": "`unknown`.\n\n-   `starts with` predicate\n\n``` text\n<path> starts with \"Some text\"\n<path> starts with $variable\n```\n\nThe nested `<path>` must evaluate to a sequence of textual items, and\nthe other operand must evaluate to a single textual item. If evaluating\nof either operand throws an error, the result is `unknown`. All items\nfrom the sequence are checked for starting with the right operand. The\nresult is `true` if a match is found, otherwise `false`. However, if any\nof the comparisons throws an error, the result in the strict mode is\n`unknown`. The result in the lax mode depends on whether the match or\nthe error was found f.\n\n-   `is unknown` predicate\n\n``` text\n( <predicate> ) is unknown\n```\n\nReturns `true` if the nested predicate evaluates to `unknown`, and\n`false` otherwise.\n\n-   Comparisons\n\n``` text\n<path1> == <path2>\n<path1> <> <path2>\n<path1> != <path2>\n<path1> < <path2>\n<path1> > <path2>\n<path1> <= <path2>\n<path1> >= <path2>\n```\n\nBoth operands of a comparison evaluate to sequences of items. If either\nevaluation throws an error, the result is `unknown`. Items from the left\nand right sequence are then compared pairwise. Similarly to the\n`starts with` predicate, the result is `true` if any of the comparisons\nreturns `true`, otherwise `false`. However, if any of the comparisons\nthrows an error, for example because the compared types are not\ncompatible, the result in the strict mode is `unknown`. The result in\nthe lax mode depends on whether the `true` comparison or the error was\nfound f.\n\n#### Comparison rules {#json_comparison_rules}\n\nNull values in the context of comparison behave different than SQL null:\n\n-   null == null \\--\\> `true`\n-   null != null, null \\< null, \\... \\--\\> `false`\n-   null compared to a scalar value \\--\\> `false`\n-   null compared to a JSON array or a JSON object \\--\\> `false`\n\nWhen comparing two scalar values, `true` or `false` is returned if the\ncomparison is successfully performed. The semantics of the comparison is\nthe same as in SQL. In case of an error, e.g. comparing text and number,\n`unknown` is returned.\n\nComparing a scalar value with a JSON array or a JSON object, and\ncomparing JSON arrays/objects is an error, so `unknown` is returned.\n\n#### Examples of filter\n\nLet `<path>` return a sequence of three JSON objects:\n\n``` text\n{\"customer\" : 100, \"region\" : \"AFRICA\"},\n{\"region\" : \"ASIA\"},\n{\"customer\" : 300, \"region\" : \"AFRICA\", \"comment\" : null}\n```\n\n``` text\n<path>?(@.region != \"ASIA\") --> {\"customer\" : 100, \"region\" : \"AFRICA\"},\n                                {\"customer\" : 300, \"region\" : \"AFRICA\", \"comment\" : null}\n<path>?(!exists(@.customer)) --> {\"region\" : \"ASIA\"}\n```\n\nThe following accessors are collectively referred to as **item\nmethods**.\n\n### double()\n\nConverts numeric or text values into double values.\n\n``` text\n<path>.double()\n```\n\nLet `<path>` return a sequence `-1, 23e4, \"5.6\"`:\n\n``` text\n<path>.double() --> -1e0,", "doc_id": "1e5b77ec-d0c1-4ff6-ac44-6ee4f3ba1f1d", "embedding": null, "doc_hash": "97c485763b93ed9971d423829fea2b6dd5e13714f774c73f63748ae80e5c4aef", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 9765, "end": 12679, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "1ddf2704-0cf9-4719-8ebb-3957684e955c", "3": "0124ba20-1aa1-4873-847f-487f9bd5f391"}}, "__type__": "1"}, "0124ba20-1aa1-4873-847f-487f9bd5f391": {"__data__": {"text": "text\n<path>.double() --> -1e0, 23e4, 5.6e0\n```\n\n### ceiling(), floor(), and abs()\n\nGets the ceiling, the floor or the absolute value for every numeric item\nin the sequence. The semantics of the operations is the same as in SQL.\n\nLet `<path>` return a sequence `-1.5, -1, 1.3`:\n\n``` text\n<path>.ceiling() --> -1.0, -1, 2.0\n<path>.floor() --> -2.0, -1, 1.0\n<path>.abs() --> 1.5, 1, 1.3\n```\n\n### keyvalue()\n\nReturns a collection of JSON objects including one object per every\nmember of the original object for every JSON object in the sequence.\n\n``` text\n<path>.keyvalue()\n```\n\nThe returned objects have three members:\n\n-   \\\"name\\\", which is the original key,\n-   \\\"value\\\", which is the original bound value,\n-   \\\"id\\\", which is the unique number, specific to an input object.\n\nLet `<path>` be a sequence of three JSON objects:\n\n``` text\n{\"customer\" : 100, \"region\" : \"AFRICA\"},\n{\"region\" : \"ASIA\"},\n{\"customer\" : 300, \"region\" : \"AFRICA\", \"comment\" : null}\n```\n\n``` text\n<path>.keyvalue() --> {\"name\" : \"customer\", \"value\" : 100, \"id\" : 0},\n                      {\"name\" : \"region\", \"value\" : \"AFRICA\", \"id\" : 0},\n                      {\"name\" : \"region\", \"value\" : \"ASIA\", \"id\" : 1},\n                      {\"name\" : \"customer\", \"value\" : 300, \"id\" : 2},\n                      {\"name\" : \"region\", \"value\" : \"AFRICA\", \"id\" : 2},\n                      {\"name\" : \"comment\", \"value\" : null, \"id\" : 2}\n```\n\nIt is required that all items in the input sequence are JSON objects.\n\nThe order of the returned values follows the order of the original JSON\nobjects. However, within objects, the order of returned entries is\narbitrary.\n\n### type()\n\nReturns a textual value containing the type name for every item in the\nsequence.\n\n``` text\n<path>.type()\n```\n\nThis method does not perform array unwrapping in the lax mode.\n\nThe returned values are:\n\n-   `\"null\"` for JSON null,\n-   `\"number\"` for a numeric item,\n-   `\"string\"` for a textual item,\n-   `\"boolean\"` for a boolean item,\n-   `\"date\"` for an item of type date,\n-   `\"time without time zone\"` for an item of type time,\n-   `\"time with time zone\"` for an item of type time with time zone,\n-   `\"timestamp without time zone\"` for an item of type timestamp,\n-   `\"timestamp with time zone\"` for an item of type timestamp with time\n    zone,\n-   `\"array\"` for JSON array,\n-   `\"object\"` for JSON object,\n\n### size()\n\nReturns a numeric value containing the size for every JSON array in the\nsequence.\n\n``` text\n<path>.size()\n```\n\nThis method does not perform array unwrapping in the lax mode. Instead,\nall non-array items are wrapped in singleton JSON arrays, so their size\nis `1`.\n\nIt is required that all items in", "doc_id": "0124ba20-1aa1-4873-847f-487f9bd5f391", "embedding": null, "doc_hash": "ef33445304b29419d8e005734e000a971981db846223b79a16d532f1d363cb33", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 12691, "end": 15348, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "1e5b77ec-d0c1-4ff6-ac44-6ee4f3ba1f1d", "3": "4a8e1008-069e-47ef-b4cc-2673f7663c00"}}, "__type__": "1"}, "4a8e1008-069e-47ef-b4cc-2673f7663c00": {"__data__": {"text": "arrays, so their size\nis `1`.\n\nIt is required that all items in the input sequence are JSON arrays.\n\nLet `<path>` return a sequence of three JSON arrays:\n\n``` text\n[0, 1, 2], [\"a\", \"b\", \"c\", \"d\"], [null, null]\n<path>.size() --> 3, 4, 2\n```\n\n## Limitations\n\nThe SQL standard describes the `datetime()` JSON path item method and\nthe `like_regex()` JSON path predicate. Trino does not support them.\n\n## JSON path modes {#json_path_modes}\n\nThe JSON path expression can be evaluated in two modes: strict and lax.\nIn the strict mode, it is required that the input JSON data strictly\nfits the schema required by the path expression. In the lax mode, the\ninput JSON data can diverge from the expected schema.\n\nThe following table shows the differences between the two modes.\n\n| Condition                                 | strict mode                                                | lax mode                                                   |\n| ----------------------------------------- | ---------------------------------------------------------- | ---------------------------------------------------------- |\n| Performing an operation which requires a non-array on an array, e.g.: | ERROR | The array is automatically unnested, and the operation is performed on each array element. `$.key` requires a JSON object  `$.floor()` requires a numeric value |\n| Performing an operation which requires an array on a non-array, e.g.: | ERROR | The non-array item is automatically wrapped in a singleton array, and the operation is performed on the array. `$[0]`, `$[*]`, `$.size()` |\n| A structural error: accessing a non-existent element of an array or a non-existent member of a JSON object, e.g.: | ERROR | The error is suppressed, and the operation results in an empty sequence. `$[-1]` (array index out of bounds) `$.key`, where the input JSON object does not have a member `key\n\n\n### Examples of the lax mode behavior\n\nLet `<path>` return a sequence of three items, a JSON array, a JSON\nobject, and a scalar numeric value:\n\n``` text\n[1, \"a\", null], {\"key1\" : 1.0, \"key2\" : true}, -2e3\n```\n\nThe following example shows the wildcard array accessor in the lax mode.\nThe JSON array returns all its elements, while the JSON object and the\nnumber are wrapped in singleton arrays and then unnested, so effectively\nthey appear unchanged in the output sequence:\n\n``` text\n<path>[*] --> 1, \"a\", null, {\"key1\" : 1.0, \"key2\" : true}, -2e3\n```\n\nWhen calling the `size()` method, the JSON object and the number are\nalso wrapped in singleton arrays:\n\n``` text\n<path>.size() --> 3, 1, 1\n```\n\nIn some cases, the lax mode cannot prevent failure. In the following\nexample, even though the JSON array is unwrapped prior to calling the\n`floor()` method, the item `\"a\"` causes type mismatch.\n\n``` text\n<path>.floor() --> ERROR\n```\n\n## json_exists\n\nThe `json_exists` function determines whether a JSON value satisfies a\nJSON path specification.\n\n``` text\nJSON_EXISTS(\n    json_input [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ],\n   ", "doc_id": "4a8e1008-069e-47ef-b4cc-2673f7663c00", "embedding": null, "doc_hash": "24c628a37eb5f9a6bc0570f21c594a90d43d517b003b6ccc2641765e7c2e5635", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 15324, "end": 18334, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "0124ba20-1aa1-4873-847f-487f9bd5f391", "3": "862043aa-d260-4902-a0c3-0a63be34df97"}}, "__type__": "1"}, "862043aa-d260-4902-a0c3-0a63be34df97": {"__data__": {"text": "[ ENCODING { UTF8 | UTF16 | UTF32 } ] ],\n    json_path\n    [ PASSING json_argument [, ...] ]\n    [ { TRUE | FALSE | UNKNOWN | ERROR } ON ERROR ]\n    )\n```\n\nThe `json_path` is evaluated using the `json_input` as the context\nvariable (`$`), and the passed arguments as the named variables\n(`$variable_name`). The returned value is `true` if the path returns a\nnon-empty sequence, and `false` if the path returns an empty sequence.\nIf an error occurs, the returned value depends on the `ON ERROR` clause.\nThe default value returned `ON ERROR` is `FALSE`. The `ON ERROR` clause\nis applied for the following kinds of errors:\n\n-   Input conversion errors, such as malformed JSON\n-   JSON path evaluation errors, e.g. division by zero\n\n`json_input` is a character string or a binary string. It should contain\na single JSON item. For a binary string, you can specify encoding.\n\n`json_path` is a string literal, containing the path mode specification,\nand the path expression, following the syntax rules described in\n`json_path_syntax_and_semantics`{.interpreted-text role=\"ref\"}.\n\n``` text\n'strict ($.price + $.tax)?(@ > 99.9)'\n'lax $[0 to 1].floor()?(@ > 10)'\n```\n\nIn the `PASSING` clause you can pass arbitrary expressions to be used by\nthe path expression.\n\n``` text\nPASSING orders.totalprice AS O_PRICE,\n        orders.tax % 10 AS O_TAX\n```\n\nThe passed parameters can be referenced in the path expression by named\nvariables, prefixed with `$`.\n\n``` text\n'lax $?(@.price > $O_PRICE || @.tax > $O_TAX)'\n```\n\nAdditionally to SQL values, you can pass JSON values, specifying the\nformat and optional encoding:\n\n``` text\nPASSING orders.json_desc FORMAT JSON AS o_desc,\n        orders.binary_record FORMAT JSON ENCODING UTF16 AS o_rec\n```\n\nNote that the JSON path language is case-sensitive, while the unquoted\nSQL identifiers are upper-cased. Therefore, it is recommended to use\nquoted identifiers in the `PASSING` clause:\n\n``` text\n'lax $.$KeyName' PASSING nation.name AS KeyName --> ERROR; no passed value found\n'lax $.$KeyName' PASSING nation.name AS \"KeyName\" --> correct\n```\n\n### Examples\n\nLet `customers` be a table containing two columns: `id:bigint`,\n`description:varchar`.\n\n| id  | description                                                      |\n| --- | ---------------------------------------------------------------- |\n| 101 | '{\"comment\" : \"nice\", \"children\" : [10, 13, 16]}'                 |\n| 102 | '{\"comment\" : \"problematic\", \"children\" : [8, 11]}'               |\n| 103 | '{\"comment\" : \"knows best\", \"children\" : [2]}'                    |\n\n\n\nThe following query checks which customers have children above the age\nof 10:\n\n```sql\nSELECT\n      id,\n      json_exists(\n                  description,\n                  'lax", "doc_id": "862043aa-d260-4902-a0c3-0a63be34df97", "embedding": null, "doc_hash": "86ed9565461432649a8e6b28528ba26912b390708b972219bcdc9773a5073979", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 18357, "end": 21086, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "4a8e1008-069e-47ef-b4cc-2673f7663c00", "3": "4b6d0f99-5078-4c3d-aeee-0a7187cf6d96"}}, "__type__": "1"}, "4b6d0f99-5078-4c3d-aeee-0a7187cf6d96": {"__data__": {"text": "                 'lax $.children[*]?(@ > 10)'\n                 ) AS children_above_ten\nFROM customers\n```\n```text\n  id    children_above_ten\n  ----- --------------------\n  101   true\n  102   true\n  103   false\n```\nIn the following query, the path mode is strict. We check the third\nchild for each customer. This should cause a structural error for the\ncustomers who do not have three or more children. This error is handled\naccording to the `ON ERROR` clause.\n\n``` text\nSELECT\n      id,\n      json_exists(\n                  description,\n                  'strict $.children[2]?(@ > 10)'\n                  UNKNOWN ON ERROR\n                 ) AS child_3_above_ten\nFROM customers\n```\n```text\n  id    child_3_above_ten\n  ----- -------------------\n  101   true\n  102   NULL\n  103   NULL\n```\n## json_query\n\nThe `json_query` function extracts a JSON value from a JSON value.\n\n``` text\nJSON_QUERY(\n    json_input [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ],\n    json_path\n    [ PASSING json_argument [, ...] ]\n    [ RETURNING type [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ] ]\n    [ WITHOUT [ ARRAY ] WRAPPER |\n      WITH [ { CONDITIONAL | UNCONDITIONAL } ] [ ARRAY ] WRAPPER ]\n    [ { KEEP | OMIT } QUOTES [ ON SCALAR STRING ] ]\n    [ { ERROR | NULL | EMPTY ARRAY | EMPTY OBJECT } ON EMPTY ]\n    [ { ERROR | NULL | EMPTY ARRAY | EMPTY OBJECT } ON ERROR ]\n    )\n```\n\nThe `json_path` is evaluated using the `json_input` as the context\nvariable (`$`), and the passed arguments as the named variables\n(`$variable_name`).\n\nThe returned value is a JSON item returned by the path. By default, it\nis represented as a character string (`varchar`). In the `RETURNING`\nclause, you can specify other character string type or `varbinary`. With\n`varbinary`, you can also specify the desired encoding.\n\n`json_input` is a character string or a binary string. It should contain\na single JSON item. For a binary string, you can specify encoding.\n\n`json_path` is a string literal, containing the path mode specification,\nand the path expression, following the syntax rules described in\n`json_path_syntax_and_semantics`{.interpreted-text role=\"ref\"}.\n\n``` text\n'strict $.keyvalue()?(@.name == $cust_id)'\n'lax $[5 to last]'\n```\n\nIn the `PASSING` clause you can pass arbitrary expressions to be used by\nthe path expression.\n\n``` text\nPASSING orders.custkey AS CUST_ID\n```\n\nThe passed parameters can be referenced in the path expression by named\nvariables, prefixed with `$`.\n\n``` text\n'strict $.keyvalue()?(@.value == $CUST_ID)'\n```\n\nAdditionally to SQL values, you can pass JSON values, specifying the\nformat and optional encoding:\n\n``` text\nPASSING orders.json_desc FORMAT JSON AS o_desc,\n  ", "doc_id": "4b6d0f99-5078-4c3d-aeee-0a7187cf6d96", "embedding": null, "doc_hash": "4fb5a1993975c516da1e2aab0f37f7b740222c1ca20de0a0361048d9e7952d42", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 21114, "end": 23798, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "862043aa-d260-4902-a0c3-0a63be34df97", "3": "6fd0a250-a461-4f06-8771-c8002258d3e8"}}, "__type__": "1"}, "6fd0a250-a461-4f06-8771-c8002258d3e8": {"__data__": {"text": "text\nPASSING orders.json_desc FORMAT JSON AS o_desc,\n        orders.binary_record FORMAT JSON ENCODING UTF16 AS o_rec\n```\n\nNote that the JSON path language is case-sensitive, while the unquoted\nSQL identifiers are upper-cased. Therefore, it is recommended to use\nquoted identifiers in the `PASSING` clause:\n\n``` text\n'lax $.$KeyName' PASSING nation.name AS KeyName --> ERROR; no passed value found\n'lax $.$KeyName' PASSING nation.name AS \"KeyName\" --> correct\n```\n\nThe `ARRAY WRAPPER` clause lets you modify the output by wrapping the\nresults in a JSON array. `WITHOUT ARRAY WRAPPER` is the default option.\n`WITH CONDITIONAL ARRAY WRAPPER` wraps every result which is not a\nsingleton JSON array or JSON object. `WITH UNCONDITIONAL ARRAY WRAPPER`\nwraps every result.\n\nThe `QUOTES` clause lets you modify the result for a scalar string by\nremoving the double quotes being part of the JSON string representation.\n\n#### Examples\n\nLet `customers` be a table containing two columns: `id:bigint`,\n`description:varchar`.\n\n  id    description\n  ----- ---------------------------------------------------------------\n  101   \\'{\\\"comment\\\" : \\\"nice\\\", \\\"children\\\" : \\[10, 13, 16\\]}\\'\n  102   \\'{\\\"comment\\\" : \\\"problematic\\\", \\\"children\\\" : \\[8, 11\\]}\\'\n  103   \\'{\\\"comment\\\" : \\\"knows best\\\", \\\"children\\\" : \\[2\\]}\\'\n\nThe following query gets the `children` array for each customer:\n\n``` text\nSELECT\n      id,\n      json_query(\n                 description,\n                 'lax $.children'\n                ) AS children\nFROM customers\n```\n```text\n  id    children\n  ----- ------------------\n  101   \\'\\[10,13,16\\]\\'\n  102   \\'\\[8,11\\]\\'\n  103   \\'\\[2\\]\\'\n```\nThe following query gets the collection of children for each customer.\nNote that the `json_query` function can only output a single JSON item.\nIf you don\\'t use array wrapper, you get an error for every customer\nwith multiple children. The error is handled according to the `ON ERROR`\nclause.\n\n``` text\nSELECT\n      id,\n      json_query(\n                 description,\n                 'lax $.children[*]'\n                 WITHOUT ARRAY WRAPPER\n                 NULL ON ERROR\n                ) AS children\nFROM customers\n```\n```text\n  id    children\n  ----- ----------\n  101   NULL\n  102   NULL\n  103   \\'2\\'\n```\n\nThe following query gets the last child for each customer, wrapped in a\nJSON array:\n\n``` text\nSELECT\n      id,\n      json_query(\n                 description,\n                 'lax $.children[last]'\n                 WITH ARRAY WRAPPER\n                ) AS last_child\nFROM customers\n```\n```text\n  id   ", "doc_id": "6fd0a250-a461-4f06-8771-c8002258d3e8", "embedding": null, "doc_hash": "80b456bf3dcb70f4cfd6e7bd61a32cb73da5c4bf7b1100a16a7f4feba63f9d30", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 23755, "end": 26322, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "4b6d0f99-5078-4c3d-aeee-0a7187cf6d96", "3": "27cc0b9f-3e38-4725-a175-f7fec59bd7a7"}}, "__type__": "1"}, "27cc0b9f-3e38-4725-a175-f7fec59bd7a7": {"__data__": {"text": "customers\n```\n```text\n  id    last_child\n  ----- ------------\n  101   \\'\\[16\\]\\'\n  102   \\'\\[11\\]\\'\n  103   \\'\\[2\\]\\'\n```\nThe following query gets all children above the age of 12 for each\ncustomer, wrapped in a JSON array. The second and the third customer\ndon\\'t have children of this age. Such case is handled according to the\n`ON EMPTY` clause. The default value returned `ON EMPTY` is `NULL`. In\nthe following example, `EMPTY ARRAY ON EMPTY` is specified.\n\n``` text\nSELECT\n      id,\n      json_query(\n                 description,\n                 'strict $.children[*]?(@ > 12)'\n                 WITH ARRAY WRAPPER\n                 EMPTY ARRAY ON EMPTY\n                ) AS children\nFROM customers\n```\n```text\n  id    children\n  ----- ---------------\n  101   \\'\\[13,16\\]\\'\n  102   \\'\\[\\]\\'\n  103   \\'\\[\\]\\'\n```\nThe following query shows the result of the `QUOTES` clause. Note that\n`KEEP QUOTES` is the default.\n\n``` text\nSELECT\n      id,\n      json_query(description, 'strict $.comment' KEEP QUOTES) AS quoted_comment,\n      json_query(description, 'strict $.comment' OMIT QUOTES) AS unquoted_comment\nFROM customers\n```\n```text\n  id    quoted_comment        unquoted_comment\n  ----- --------------------- ------------------\n  101   \\'\\\"nice\\\"\\'          \\'nice\\'\n  102   \\'\\\"problematic\\\"\\'   \\'problematic\\'\n  103   \\'\\\"knows best\\\"\\'    \\'knows best\\'\n```\nIf an error occurs, the returned value depends on the `ON ERROR` clause.\nThe default value returned `ON ERROR` is `NULL`. One example of error is\nmultiple items returned by the path. Other errors caught and handled\naccording to the `ON ERROR` clause are:\n\n-   Input conversion errors, such as malformed JSON\n-   JSON path evaluation errors, e.g. division by zero\n-   Output conversion errors\n\n## json_value\n\nThe `json_value` function extracts a scalar SQL value from a JSON value.\n\n``` text\nJSON_VALUE(\n    json_input [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ],\n    json_path\n    [ PASSING json_argument [, ...] ]\n    [ RETURNING type ]\n    [ { ERROR | NULL | DEFAULT expression } ON EMPTY ]\n    [ { ERROR | NULL | DEFAULT expression } ON ERROR ]\n    )\n```\n\nThe `json_path` is evaluated using the `json_input` as the context\nvariable (`$`), and the passed arguments as the named variables\n(`$variable_name`).\n\nThe returned value is the SQL scalar returned by the path. By default,\nit is converted to string (`varchar`). In the `RETURNING` clause, you\ncan specify other desired type: a character string type, numeric,\nboolean or datetime type.\n\n`json_input` is a character string or a binary string. It should contain\na single JSON item. For a binary string, you can specify encoding.\n\n`json_path` is a string literal, containing the path mode", "doc_id": "27cc0b9f-3e38-4725-a175-f7fec59bd7a7", "embedding": null, "doc_hash": "a92c38abee15b34c2cc4511c537992b4f328fa268453359237ee5e4939256215", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 26347, "end": 29065, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "6fd0a250-a461-4f06-8771-c8002258d3e8", "3": "cf05d3d8-3e40-405a-b5fe-b55575048fbf"}}, "__type__": "1"}, "cf05d3d8-3e40-405a-b5fe-b55575048fbf": {"__data__": {"text": "encoding.\n\n`json_path` is a string literal, containing the path mode specification,\nand the path expression, following the syntax rules described in\n`json_path_syntax_and_semantics`{.interpreted-text role=\"ref\"}.\n\n``` text\n'strict $.price + $tax'\n'lax $[last].abs().floor()'\n```\n\nIn the `PASSING` clause you can pass arbitrary expressions to be used by\nthe path expression.\n\n``` text\nPASSING orders.tax AS O_TAX\n```\n\nThe passed parameters can be referenced in the path expression by named\nvariables, prefixed with `$`.\n\n``` text\n'strict $[last].price + $O_TAX'\n```\n\nAdditionally to SQL values, you can pass JSON values, specifying the\nformat and optional encoding:\n\n``` text\nPASSING orders.json_desc FORMAT JSON AS o_desc,\n        orders.binary_record FORMAT JSON ENCODING UTF16 AS o_rec\n```\n\nNote that the JSON path language is case-sensitive, while the unquoted\nSQL identifiers are upper-cased. Therefore, it is recommended to use\nquoted identifiers in the `PASSING` clause:\n\n``` text\n'lax $.$KeyName' PASSING nation.name AS KeyName --> ERROR; no passed value found\n'lax $.$KeyName' PASSING nation.name AS \"KeyName\" --> correct\n```\n\nIf the path returns an empty sequence, the `ON EMPTY` clause is applied.\nThe default value returned `ON EMPTY` is `NULL`. You can also specify\nthe default value:\n\n``` text\nDEFAULT -1 ON EMPTY\n```\n\nIf an error occurs, the returned value depends on the `ON ERROR` clause.\nThe default value returned `ON ERROR` is `NULL`. One example of error is\nmultiple items returned by the path. Other errors caught and handled\naccording to the `ON ERROR` clause are:\n\n-   Input conversion errors, such as malformed JSON\n-   JSON path evaluation errors, e.g. division by zero\n-   Returned scalar not convertible to the desired type\n\n### Examples\n\nLet `customers` be a table containing two columns: `id:bigint`,\n`description:varchar`.\n\n  id    description\n  ----- ---------------------------------------------------------------\n  101   \\'{\\\"comment\\\" : \\\"nice\\\", \\\"children\\\" : \\[10, 13, 16\\]}\\'\n  102   \\'{\\\"comment\\\" : \\\"problematic\\\", \\\"children\\\" : \\[8, 11\\]}\\'\n  103   \\'{\\\"comment\\\" : \\\"knows best\\\", \\\"children\\\" : \\[2\\]}\\'\n\nThe following query gets the `comment` for each customer as `char(12)`:\n\n``` text\nSELECT id, json_value(\n                      description,\n                      'lax $.comment'\n                      RETURNING char(12)\n                     ) AS comment\nFROM customers\n```\n```text\n  id    comment\n  ----- ------------------\n  101   \\'nice \\'\n  102   \\'problematic \\'\n  103   \\'knows best \\'\n```\nThe following query gets the f child\\'s age for each customer as\n`tinyint`:\n\n``` text\nSELECT id, json_value(\n                      description,\n                      'lax $.children[0]'\n                      RETURNING", "doc_id": "cf05d3d8-3e40-405a-b5fe-b55575048fbf", "embedding": null, "doc_hash": "faf57389845eba5a1efd03e1dbf821666e7ad0d6495caa00ed9bc648c5ce677b", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 29030, "end": 31791, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "27cc0b9f-3e38-4725-a175-f7fec59bd7a7", "3": "c06fd51f-2158-4dae-95ad-31ae45dd7880"}}, "__type__": "1"}, "c06fd51f-2158-4dae-95ad-31ae45dd7880": {"__data__": {"text": "                 RETURNING tinyint\n                     ) AS child\nFROM customers\n```\n```text\n  id    child\n  ----- -------\n  101   10\n  102   8\n  103   2\n```\nThe following query gets the third child\\'s age for each customer. In\nthe strict mode, this should cause a structural error for the customers\nwho do not have the third child. This error is handled according to the\n`ON ERROR` clause.\n\n``` text\nSELECT id, json_value(\n                      description,\n                      'strict $.children[2]'\n                      DEFAULT 'err' ON ERROR\n                     ) AS child\nFROM customers\n```\n```text\n  id    child\n  ----- ---------\n  101   \\'16\\'\n  102   \\'err\\'\n  103   \\'err\\'\n```\nAfter changing the mode to lax, the structural error is suppressed, and\nthe customers without a third child produce empty sequence. This case is\nhandled according to the `ON EMPTY` clause.\n\n``` text\nSELECT id, json_value(\n                      description,\n                      'lax $.children[2]'\n                      DEFAULT 'missing' ON EMPTY\n                     ) AS child\nFROM customers\n```\n```text\n  id    child\n  ----- -------------\n  101   \\'16\\'\n  102   \\'missing\\'\n  103   \\'missing\\'\n```\n## json_array\n\nThe `json_array` function creates a JSON array containing given\nelements.\n\n``` text\nJSON_ARRAY(\n    [ array_element [, ...]\n      [ { NULL ON NULL | ABSENT ON NULL } ] ],\n    [ RETURNING type [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ] ]\n    )\n```\n\n#### Argument types\n\nThe array elements can be arbitrary expressions. Each passed value is\nconverted into a JSON item according to its type, and optional `FORMAT`\nand `ENCODING` specification.\n\nYou can pass SQL values of types boolean, numeric, and character string.\nThey are converted to corresponding JSON literals:\n```sql\n    SELECT json_array(true, 12e-1, 'text')\n    --> '[true,1.2,\"text\"]'\n```\nAdditionally to SQL values, you can pass JSON values. They are character\nor binary strings with a specified format and optional encoding:\n```\n    SELECT json_array(\n                      '[  \"text\"  ] ' FORMAT JSON,\n                      X'5B0035005D00' FORMAT JSON ENCODING UTF16\n                     )\n    --> '[[\"text\"],[5]]'\n```\n\nYou can also nest other JSON-returning functions. In that case, the\n`FORMAT` option is implicit:\n```sql\n    SELECT json_array(\n                     ", "doc_id": "c06fd51f-2158-4dae-95ad-31ae45dd7880", "embedding": null, "doc_hash": "7de54784594486e35eefb05ab72c1fa273f6a39b461236e4872cf398c46b4627", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 31843, "end": 34193, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "cf05d3d8-3e40-405a-b5fe-b55575048fbf", "3": "7e594392-2881-4bf3-8145-63edcf45c152"}}, "__type__": "1"}, "7e594392-2881-4bf3-8145-63edcf45c152": {"__data__": {"text": "                    json_query('{\"key\" : [  \"value\"  ]}', 'lax $.key')\n                     )\n    --> '[[\"value\"]]'\n```\nOther passed values are cast to varchar, and they become JSON text\nliterals:\n```sql\n    SELECT json_array(\n                      DATE '2001-01-31',\n                      UUID '12151fd2-7586-11e9-8f9e-2a86e4085a59'\n                     )\n    --> '[\"2001-01-31\",\"12151fd2-7586-11e9-8f9e-2a86e4085a59\"]'\n```\nYou can omit the arguments altogether to get an empty array:\n```sql\n    SELECT json_array() --> '[]'\n```\n### Null handling\n\nIf a value passed for an array element is `null`, it is treated\naccording to the specified null treatment option. If `ABSENT ON NULL` is\nspecified, the null element is omitted in the result. If `NULL ON NULL`\nis specified, JSON `null` is added to the result. `ABSENT ON NULL` is\nthe default configuration:\n```sql\n    SELECT json_array(true, null, 1)\n    --> '[true,1]'\n\n    SELECT json_array(true, null, 1 ABSENT ON NULL)\n    --> '[true,1]'\n\n    SELECT json_array(true, null, 1 NULL ON NULL)\n    --> '[true,null,1]'\n```\n### Returned type\n\nThe SQL standard imposes that there is no dedicated data type to\nrepresent JSON data in SQL. Instead, JSON data is represented as\ncharacter or binary strings. By default, the `json_array` function\nreturns varchar containing the textual representation of the JSON array.\nWith the `RETURNING` clause, you can specify other character string\ntype:\n```sql\n    SELECT json_array(true, 1 RETURNING VARCHAR(100))\n    --> '[true,1]'\n```\n\nYou can also specify to use varbinary and the required encoding as\nreturn type. The default encoding is UTF8:\n```sql\n    SELECT json_array(true, 1 RETURNING VARBINARY)\n    --> X'5b 74 72 75 65 2c 31 5d'\n\n    SELECT json_array(true, 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF8)\n    --> X'5b 74 72 75 65 2c 31 5d'\n\n    SELECT json_array(true, 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF16)\n    --> X'5b 00 74 00 72 00 75 00 65 00 2c 00 31 00 5d 00'\n\n    SELECT json_array(true, 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF32)\n    --> X'5b 00 00 00 74 00 00 00 72 00 00 00 75 00 00 00 65 00 00 00 2c 00 00 00 31 00 00 00 5d 00 00 00'\n```\n## json_object\n\nThe `json_object` function creates a JSON object containing given\nkey-value pairs.\n\n```text\nJSON_OBJECT(\n    [ key_value [, ...]\n      [ { NULL ON NULL | ABSENT ON NULL } ] ],\n      [ { WITH UNIQUE [ KEYS ] | WITHOUT UNIQUE [ KEYS ] } ]\n    [ RETURNING type [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ] ]\n   ", "doc_id": "7e594392-2881-4bf3-8145-63edcf45c152", "embedding": null, "doc_hash": "46f31d0c5c56b44229743f9a839f82f8d8290c9ddb17cea476c8fa4a1db10745", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 34203, "end": 36697, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "c06fd51f-2158-4dae-95ad-31ae45dd7880", "3": "ca741a93-427f-42d7-b452-a06ae456198b"}}, "__type__": "1"}, "ca741a93-427f-42d7-b452-a06ae456198b": {"__data__": {"text": "ENCODING { UTF8 | UTF16 | UTF32 } ] ] ]\n    )\n```\n\n#### Argument passing conventions\n\nThere are two conventions for passing keys and values:\n```sql\n    SELECT json_object('key1' : 1, 'key2' : true)\n    --> '{\"key1\":1,\"key2\":true}'\n\n    SELECT json_object(KEY 'key1' VALUE 1, KEY 'key2' VALUE true)\n    --> '{\"key1\":1,\"key2\":true}'\n```\nIn the second convention, you can omit the `KEY` keyword:\n```sql\n    SELECT json_object('key1' VALUE 1, 'key2' VALUE true)\n    --> '{\"key1\":1,\"key2\":true}'\n```\n#### Argument types\n\nThe keys can be arbitrary expressions. They must be of character string\ntype. Each key is converted into a JSON text item, and it becomes a key\nin the created JSON object. Keys must not be null.\n\nThe values can be arbitrary expressions. Each passed value is converted\ninto a JSON item according to its type, and optional `FORMAT` and\n`ENCODING` specification.\n\nYou can pass SQL values of types boolean, numeric, and character string.\nThey are converted to corresponding JSON literals:\n```sql\n    SELECT json_object('x' : true, 'y' : 12e-1, 'z' : 'text')\n    --> '{\"x\":true,\"y\":1.2,\"z\":\"text\"}'\n```\nAdditionally to SQL values, you can pass JSON values. They are character\nor binary strings with a specified format and optional encoding:\n```sql\n    SELECT json_object(\n                       'x' : '[  \"text\"  ] ' FORMAT JSON,\n                       'y' : X'5B0035005D00' FORMAT JSON ENCODING UTF16\n                      )\n    --> '{\"x\":[\"text\"],\"y\":[5]}'\n```\nYou can also nest other JSON-returning functions. In that case, the\n`FORMAT` option is implicit:\n```sql\n    SELECT json_object(\n                       'x' : json_query('{\"key\" : [  \"value\"  ]}', 'lax $.key')\n                      )\n    --> '{\"x\":[\"value\"]}'\n```\nOther passed values are cast to varchar, and they become JSON text\nliterals:\n```sql\n    SELECT json_object(\n                       'x' : DATE '2001-01-31',\n                       'y' : UUID '12151fd2-7586-11e9-8f9e-2a86e4085a59'\n                      )\n    --> '{\"x\":\"2001-01-31\",\"y\":\"12151fd2-7586-11e9-8f9e-2a86e4085a59\"}'\n```\n\nYou can omit the arguments altogether to get an empty object:\n```sql\n    SELECT json_object() --> '{}'\n```\n#### Null handling\n\nThe values passed for JSON object keys must not be null. It is allowed\nto pass `null` for JSON object values. A null value is treated according\nto the specified null treatment option. If `NULL ON NULL` is specified,\na JSON object entry", "doc_id": "ca741a93-427f-42d7-b452-a06ae456198b", "embedding": null, "doc_hash": "8a5d1454972bb7092c78cabd40720ab5f1d479427e7b805e623e4dd2ea622637", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 36668, "end": 39096, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "7e594392-2881-4bf3-8145-63edcf45c152", "3": "ae995665-7d65-4af0-b5b6-7be34fb7434d"}}, "__type__": "1"}, "ae995665-7d65-4af0-b5b6-7be34fb7434d": {"__data__": {"text": "the specified null treatment option. If `NULL ON NULL` is specified,\na JSON object entry with `null` value is added to the result. If\n`ABSENT ON NULL` is specified, the entry is omitted in the result.\n`NULL ON NULL` is the default configuration.:\n```sql\n    SELECT json_object('x' : null, 'y' : 1)\n    --> '{\"x\":null,\"y\":1}'\n\n    SELECT json_object('x' : null, 'y' : 1 NULL ON NULL)\n    --> '{\"x\":null,\"y\":1}'\n\n    SELECT json_object('x' : null, 'y' : 1 ABSENT ON NULL)\n    --> '{\"y\":1}'\n```\n#### Key uniqueness\n\nIf a duplicate key is encountered, it is handled according to the\nspecified key uniqueness constraint.\n\nIf `WITH UNIQUE KEYS` is specified, a duplicate key results in a query\nfailure:\n```sql\n    SELECT json_object('x' : null, 'x' : 1 WITH UNIQUE KEYS)\n    --> failure: \"duplicate key passed to JSON_OBJECT function\"\n```\n\nNote that this option is not supported if any of the arguments has a\n`FORMAT` specification.\n\nIf `WITHOUT UNIQUE KEYS` is specified, duplicate keys are not supported\ndue to implementation limitation. `WITHOUT UNIQUE KEYS` is the default\nconfiguration.\n\n#### Returned type\n\nThe SQL standard imposes that there is no dedicated data type to\nrepresent JSON data in SQL. Instead, JSON data is represented as\ncharacter or binary strings. By default, the `json_object` function\nreturns varchar containing the textual representation of the JSON\nobject. With the `RETURNING` clause, you can specify other character\nstring type:\n```sql\n    SELECT json_object('x' : 1 RETURNING VARCHAR(100))\n    --> '{\"x\":1}'\n```\nYou can also specify to use varbinary and the required encoding as\nreturn type. The default encoding is UTF8:\n```sql\n    SELECT json_object('x' : 1 RETURNING VARBINARY)\n    --> X'7b 22 78 22 3a 31 7d'\n\n    SELECT json_object('x' : 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF8)\n    --> X'7b 22 78 22 3a 31 7d'\n\n    SELECT json_object('x' : 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF16)\n    --> X'7b 00 22 00 78 00 22 00 3a 00 31 00 7d 00'\n\n    SELECT json_object('x' : 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF32)\n    --> X'7b 00 00 00 22 00 00 00 78 00 00 00 22 00 00 00 3a 00 00 00 31 00 00 00 7d 00 00 00'\n```\n!!!warning\n    The following functions and operators are not compliant with the SQL\n    standard, and should be considered deprecated. According to the SQL\n    standard, there shall be no `JSON` data type. Instead, JSON values\n    should be represented as string values. The remaining functionality of\n    the following functions is covered by the functions described\n    previously.\n\n\n### Cast to JSON\n\nThe following types can be cast to JSON:\n\n-   `BOOLEAN`\n-   `TINYINT`\n-   `SMALLINT`\n-   `INTEGER`\n-   `BIGINT`\n-   `REAL`\n-   `DOUBLE`\n-   `VARCHAR`\n\nAdditionally, `ARRAY`, `MAP`, and `ROW` types can be cast to JSON when\nthe following requirements are met:\n\n-   `ARRAY` types can be cast when the element type of", "doc_id": "ae995665-7d65-4af0-b5b6-7be34fb7434d", "embedding": null, "doc_hash": "891b4f6eab0a195b0fb1bf186912ebe5b9a2c1682bb2b5c700a604570971f802", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 39052, "end": 41930, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "ca741a93-427f-42d7-b452-a06ae456198b", "3": "7090f775-2cc2-4d5a-b83a-42fe9ae7a357"}}, "__type__": "1"}, "7090f775-2cc2-4d5a-b83a-42fe9ae7a357": {"__data__": {"text": "met:\n\n-   `ARRAY` types can be cast when the element type of the array is one\n    of the supported types.\n-   `MAP` types can be cast when the key type of the map is `VARCHAR`\n    and the value type of the map is a supported type,\n-   `ROW` types can be cast when every field type of the row is a\n    supported type.\n\n!!!note\n\n    Cast operations with supported `character string types\n    <string-data-types>`{.interpreted-text role=\"ref\"} treat the input as a\n    string, not validated as JSON. This means that a cast operation with a\n    string-type input of invalid JSON results in a succesful cast to invalid\n    JSON.\n\n    Instead, consider using the `json_parse`{.interpreted-text role=\"func\"}\n    function to create validated JSON from a string.\n\n\nThe following examples show the behavior of casting to JSON with these\ntypes:\n```sql\n    SELECT CAST(NULL AS JSON);\n    -- NULL\n\n    SELECT CAST(1 AS JSON);\n    -- JSON '1'\n\n    SELECT CAST(9223372036854775807 AS JSON);\n    -- JSON '9223372036854775807'\n\n    SELECT CAST('abc' AS JSON);\n    -- JSON '\"abc\"'\n\n    SELECT CAST(true AS JSON);\n    -- JSON 'true'\n\n    SELECT CAST(1.234 AS JSON);\n    -- JSON '1.234'\n\n    SELECT CAST(ARRAY[1, 23, 456] AS JSON);\n    -- JSON '[1,23,456]'\n\n    SELECT CAST(ARRAY[1, NULL, 456] AS JSON);\n    -- JSON '[1,null,456]'\n\n    SELECT CAST(ARRAY[ARRAY[1, 23], ARRAY[456]] AS JSON);\n    -- JSON '[[1,23],[456]]'\n\n    SELECT CAST(MAP(ARRAY['k1', 'k2', 'k3'], ARRAY[1, 23, 456]) AS JSON);\n    -- JSON '{\"k1\":1,\"k2\":23,\"k3\":456}'\n\n    SELECT CAST(CAST(ROW(123, 'abc', true) AS\n                ROW(v1 BIGINT, v2 VARCHAR, v3 BOOLEAN)) AS JSON);\n    -- JSON '{\"v1\":123,\"v2\":\"abc\",\"v3\":true}'\n```\nCasting from NULL to `JSON` is not straightforward. Casting from a\nstandalone `NULL` will produce SQL `NULL` instead of `JSON 'null'`.\nHowever, when casting from arrays or map containing `NULL`s, the\nproduced `JSON` will have `null`s in it.\n\n### Cast from JSON\n\nCasting to `BOOLEAN`, `TINYINT`, `SMALLINT`, `INTEGER`, `BIGINT`,\n`REAL`, `DOUBLE` or `VARCHAR` is supported. Casting to `ARRAY` and `MAP`\nis supported when the element type of the array is one of the supported\ntypes, or when the key type of the map is `VARCHAR` and value type of\nthe map is one of the supported types. Behaviors of the casts are shown\nwith the examples below:\n```sql\n    SELECT CAST(JSON 'null' AS VARCHAR);\n    -- NULL\n\n    SELECT CAST(JSON '1' AS INTEGER);\n    -- 1\n\n    SELECT CAST(JSON '9223372036854775807' AS BIGINT);\n    -- 9223372036854775807\n\n    SELECT CAST(JSON '\"abc\"' AS VARCHAR);\n    -- abc\n\n    SELECT CAST(JSON 'true' AS BOOLEAN);\n    -- true\n\n    SELECT CAST(JSON", "doc_id": "7090f775-2cc2-4d5a-b83a-42fe9ae7a357", "embedding": null, "doc_hash": "8d20980c48d46e7f074980a15a7e8dabd928a61c0ba734d12db5b0feffe77771", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 41958, "end": 44595, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "ae995665-7d65-4af0-b5b6-7be34fb7434d", "3": "128ae49c-a2c7-4c0b-a1b8-5002f0e27d81"}}, "__type__": "1"}, "128ae49c-a2c7-4c0b-a1b8-5002f0e27d81": {"__data__": {"text": "AS BOOLEAN);\n    -- true\n\n    SELECT CAST(JSON '1.234' AS DOUBLE);\n    -- 1.234\n\n    SELECT CAST(JSON '[1,23,456]' AS ARRAY(INTEGER));\n    -- [1, 23, 456]\n\n    SELECT CAST(JSON '[1,null,456]' AS ARRAY(INTEGER));\n    -- [1, NULL, 456]\n\n    SELECT CAST(JSON '[[1,23],[456]]' AS ARRAY(ARRAY(INTEGER)));\n    -- [[1, 23], [456]]\n\n    SELECT CAST(JSON '{\"k1\":1,\"k2\":23,\"k3\":456}' AS MAP(VARCHAR, INTEGER));\n    -- {k1=1, k2=23, k3=456}\n\n    SELECT CAST(JSON '{\"v1\":123,\"v2\":\"abc\",\"v3\":true}' AS\n                ROW(v1 BIGINT, v2 VARCHAR, v3 BOOLEAN));\n    -- {v1=123, v2=abc, v3=true}\n\n    SELECT CAST(JSON '[123,\"abc\",true]' AS\n                ROW(v1 BIGINT, v2 VARCHAR, v3 BOOLEAN));\n    -- {v1=123, v2=abc, v3=true}\n```\n\nJSON arrays can have mixed element types and JSON maps can have mixed\nvalue types. This makes it impossible to cast them to SQL arrays and\nmaps in some cases. To address this, Trino supports partial casting of\narrays and maps:\n```sql\n    SELECT CAST(JSON '[[1, 23], 456]' AS ARRAY(JSON));\n    -- [JSON '[1,23]', JSON '456']\n\n    SELECT CAST(JSON '{\"k1\": [1, 23], \"k2\": 456}' AS MAP(VARCHAR, JSON));\n    -- {k1 = JSON '[1,23]', k2 = JSON '456'}\n\n    SELECT CAST(JSON '[null]' AS ARRAY(JSON));\n    -- [JSON 'null']\n```\nWhen casting from `JSON` to `ROW`, both JSON array and JSON object are\nsupported.\n\n## Other JSON functions\n\nIn addition to the functions explained in more details in the preceding\nsections, the following functions are available:\n\n#### is_json_scalar()\n**``is_json_scalar``** \u2192 boolean\n\nDetermine if `json` is a scalar (i.e. a JSON number, a JSON string,\n`true`, `false` or `null`):\n```sql\n    SELECT is_json_scalar('1');         -- true\n    SELECT is_json_scalar('[1, 2, 3]'); -- false\n```\n\n#### json_array_contains() \n**``json_array_contains(json, value)``** \u2192 boolean\n\nDetermine if `value` exists in `json` (a string containing a JSON\narray):\n```sql\n    SELECT json_array_contains('[1, 2, 3]', 2); -- true\n```\n\n#### json_array_get()\n**``json_array_get(json_array, index)``** \u2192 json\n\n!!!warning \n\n    The semantics of this function are broken. If the extracted element is a\n    string, it will be converted into an invalid `JSON` value that is not\n    properly quoted (the value will not be surrounded by quotes and any\n    interior quotes will not be escaped).\n\n    We recommend against using this function. It cannot be fixed without\n    impacting existing usages and may be removed in a future release.\n\nReturns the element at the specified index into the", "doc_id": "128ae49c-a2c7-4c0b-a1b8-5002f0e27d81", "embedding": null, "doc_hash": "c14caa2694321d33a11511a26831bb873efceb0e2fcfeee534e64ba150ed7c59", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 44609, "end": 47103, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "7090f775-2cc2-4d5a-b83a-42fe9ae7a357", "3": "05f5e274-02a6-437b-8658-577a517c7754"}}, "__type__": "1"}, "05f5e274-02a6-437b-8658-577a517c7754": {"__data__": {"text": "may be removed in a future release.\n\nReturns the element at the specified index into the `json_array`. The\nindex is zero-based:\n```sql\n    SELECT json_array_get('[\"a\", [3, 9], \"c\"]', 0); -- JSON 'a' (invalid JSON)\n    SELECT json_array_get('[\"a\", [3, 9], \"c\"]', 1); -- JSON '[3,9]'\n```\nThis function also supports negative indexes for fetching element\nindexed from the end of an array:\n```sql\n    SELECT json_array_get('[\"c\", [3, 9], \"a\"]', -1); -- JSON 'a' (invalid JSON)\n    SELECT json_array_get('[\"c\", [3, 9], \"a\"]', -2); -- JSON '[3,9]'\n```\nIf the element at the specified index doesn\\'t exist, the function\nreturns null:\n```sql\n    SELECT json_array_get('[]', 0);                -- NULL\n    SELECT json_array_get('[\"a\", \"b\", \"c\"]', 10);  -- NULL\n    SELECT json_array_get('[\"c\", \"b\", \"a\"]', -10); -- NULL\n```\n\n\n#### json_array_length()\n**``json_array_length``** \u2192 bigint\n\nReturns the array length of `json` (a string containing a JSON array):\n```sql\n    SELECT json_array_length('[1, 2, 3]'); -- 3\n```\n\n\n**``json_extract(json, json_path)``** \u2192 json\n\nEvaluates the [JSONPath]()-like expression `json_path` on `json` (a\nstring containing JSON) and returns the result as a JSON string:\n```sql\n    SELECT json_extract(json, '$.store.book');\n    SELECT json_extract(json, '$.store[book]');\n    SELECT json_extract(json, '$.store[\"book name\"]');\n```\n\n#### json_extract_scalar()\n**``json_extract_scalar(json, json_path)``** \u2192 varchar\n\nLike `json_extract`, but returns the\nresult value as a string (as opposed to being encoded as JSON). The\nvalue referenced by `json_path` must be a scalar (boolean, number or\nstring):\n```sql\n    SELECT json_extract_scalar('[1, 2, 3]', '$[2]');\n    SELECT json_extract_scalar(json, '$.store.book[0].author');\n```\n\n```sql\nWITH json_table AS (\n    SELECT\n        json_parse(json_content) AS parsed_json\n    FROM\n        (VALUES\n            ('{\"name\": \"John\", \"value\": 42}'),\n            ('{\"name\": \"Jane\", \"value\": 36}')\n        ) AS json_data (json_content)\n)\nSELECT\n    json_extract_scalar(parsed_json, '$.name') AS name,\n    json_extract_scalar(parsed_json, '$.value') AS value\nFROM\n    json_table;\n```\n\n#### json_format()\n**``json_format(json)``** \u2192 varchar\n\nReturns the JSON text serialized from the input JSON value. This is\ninverse function to `json_parse`{.interpreted-text role=\"func\"}. :\n```sql\n    SELECT json_format(JSON '[1, 2, 3]'); -- '[1,2,3]'\n    SELECT json_format(JSON '\"a\"');       -- '\"a\"'\n```\n\n`json_format` and", "doc_id": "05f5e274-02a6-437b-8658-577a517c7754", "embedding": null, "doc_hash": "d92557e7330be8c4bb5f155200bdbfaff091e9b7e5138a2a8513cae45f8c93b2", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 47065, "end": 49528, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "128ae49c-a2c7-4c0b-a1b8-5002f0e27d81", "3": "fc9a7b07-aac7-4a96-8d2f-f6c109d82ffb"}}, "__type__": "1"}, "fc9a7b07-aac7-4a96-8d2f-f6c109d82ffb": {"__data__": {"text": "     -- '\"a\"'\n```\n\n`json_format` and `CAST(json AS VARCHAR)`\nhave completely different semantics.\n\n`json_format` serializes the input JSON\nvalue to JSON text conforming to `7159`.\nThe JSON value can be a JSON object, a JSON array, a JSON string, a JSON\nnumber, `true`, `false` or `null`:\n```sql\n    SELECT json_format(JSON '{\"a\": 1, \"b\": 2}'); -- '{\"a\":1,\"b\":2}'\n    SELECT json_format(JSON '[1, 2, 3]');        -- '[1,2,3]'\n    SELECT json_format(JSON '\"abc\"');            -- '\"abc\"'\n    SELECT json_format(JSON '42');               -- '42'\n    SELECT json_format(JSON 'true');             -- 'true'\n    SELECT json_format(JSON 'null');             -- 'null'\n```\n`CAST(json AS VARCHAR)` casts the JSON value to the corresponding SQL\nVARCHAR value. For JSON string, JSON number, `true`, `false` or `null`,\nthe cast behavior is same as the corresponding SQL type. JSON object and\nJSON array cannot be cast to VARCHAR. :\n```sql\n    SELECT CAST(JSON '{\"a\": 1, \"b\": 2}' AS VARCHAR); -- ERROR!\n    SELECT CAST(JSON '[1, 2, 3]' AS VARCHAR);        -- ERROR!\n    SELECT CAST(JSON '\"abc\"' AS VARCHAR);            -- 'abc' (the double quote is gone)\n    SELECT CAST(JSON '42' AS VARCHAR);               -- '42'\n    SELECT CAST(JSON 'true' AS VARCHAR);             -- 'true'\n    SELECT CAST(JSON 'null' AS VARCHAR);             -- NULL\n```\n\n#### json_parse()\n**``json_parse(string)``** \u2192 json\n\nReturns the JSON value deserialized from the input JSON text. This is\ninverse function to `json_format`:\n```sql\n    SELECT json_parse('[1, 2, 3]');   -- JSON '[1,2,3]'\n    SELECT json_parse('\"abc\"');       -- JSON '\"abc\"'\n```\n!!!note\n    `json_parse` and `CAST(string AS JSON)`\n    have completely different semantics.\n\n`json_parse` expects a JSON text\nconforming to `7159`, and returns the JSON\nvalue deserialized from the JSON text. The JSON value can be a JSON\nobject, a JSON array, a JSON string, a JSON number, `true`, `false` or\n`null`. :\n```sql\n    SELECT json_parse('not_json');         -- ERROR!\n    SELECT json_parse('[\"a\": 1, \"b\": 2]'); -- JSON '[\"a\": 1, \"b\": 2]'\n    SELECT json_parse('[1, 2, 3]');        -- JSON '[1,2,3]'\n    SELECT json_parse('\"abc\"');            -- JSON '\"abc\"'\n    SELECT json_parse('42');               -- JSON '42'\n    SELECT json_parse('true');             -- JSON 'true'\n    SELECT json_parse('null');             -- JSON", "doc_id": "fc9a7b07-aac7-4a96-8d2f-f6c109d82ffb", "embedding": null, "doc_hash": "aa0df74ff1e318af002a0d12828a9fe81d366bdca1ef6d6592c9e4f5872e4aab", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 49574, "end": 51917, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "05f5e274-02a6-437b-8658-577a517c7754", "3": "ccbade4c-6b85-4876-9354-cbf51ad71298"}}, "__type__": "1"}, "ccbade4c-6b85-4876-9354-cbf51ad71298": {"__data__": {"text": "json_parse('null');             -- JSON 'null'\n```\n\n`CAST(string AS JSON)` takes any VARCHAR value as input, and returns a\nJSON string with its value set to input string. :\n```sql\n    SELECT CAST('not_json' AS JSON);         -- JSON '\"not_json\"'\n    SELECT CAST('[\"a\": 1, \"b\": 2]' AS JSON); -- JSON '\"[\\\"a\\\": 1, \\\"b\\\": 2]\"'\n    SELECT CAST('[1, 2, 3]' AS JSON);        -- JSON '\"[1, 2, 3]\"'\n    SELECT CAST('\"abc\"' AS JSON);            -- JSON '\"\\\"abc\\\"\"'\n    SELECT CAST('42' AS JSON);               -- JSON '\"42\"'\n    SELECT CAST('true' AS JSON);             -- JSON '\"true\"'\n    SELECT CAST('null' AS JSON);             -- JSON '\"null\"'\n```\n\n\n#### json_size()\n**``json_size(json, json_path)``** \u2192 bigint\n\nLike `json_extract`, but returns the size\nof the value. For objects or arrays, the size is the number of members,\nand the size of a scalar value is zero:\n```sql\n    SELECT json_size('{\"x\": {\"a\": 1, \"b\": 2}}', '$.x');   -- 2\n    SELECT json_size('{\"x\": [1, 2, 3]}', '$.x');          -- 3\n    SELECT json_size('{\"x\": {\"a\": 1, \"b\": 2}}', '$.x.a'); -- 0\n```\n", "doc_id": "ccbade4c-6b85-4876-9354-cbf51ad71298", "embedding": null, "doc_hash": "62ddab0783be79d6f41a5b79aeffb6c25e84e56e3cabedf46796abb665d377e0", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}, "node_info": {"start": 51907, "end": 52969, "_node_type": "1"}, "relationships": {"1": "c7c50dfaeab91cad40cbb455d832b860e3e220f1", "2": "fc9a7b07-aac7-4a96-8d2f-f6c109d82ffb"}}, "__type__": "1"}, "a5c40de4-ebb3-473a-a373-60327f589248": {"__data__": {"text": "---\ntitle: Lambda expressions\n---\n\nLambda expressions are anonymous functions which are passed as arguments\nto higher-order SQL functions.\n\nLambda expressions are written with `->`:\n```text\n    x -> x + 1\n    (x, y) -> x + y\n    x -> regexp_like(x, 'a+')\n    x -> x[1] / x[2]\n    x -> IF(x > 0, x, -x)\n    x -> COALESCE(x, 0)\n    x -> CAST(x AS JSON)\n    x -> x + TRY(1 / 0)\n```\n## Limitations\n\nMost SQL expressions can be used in a lambda body, with a few\nexceptions:\n\n-   Subqueries are not supported: `x -> 2 + (SELECT 3)`\n-   Aggregations are not supported: `x -> max(y)`\n\n## Examples\n\nObtain the squared elements of an array column with\n`transform`:\n```sql\n    SELECT numbers,\n           transform(numbers, n -> n * n) as squared_numbers\n    FROM (\n        VALUES\n            (ARRAY[1, 2]),\n            (ARRAY[3, 4]),\n            (ARRAY[5, 6, 7])\n    ) AS t(numbers);\n```\n**Results**:  \n\n| numbers   | squared_numbers |\n|-----------|-----------------|\n| [1, 2]    | [1, 4]          |\n| [3, 4]    | [9, 16]         |\n| [5, 6, 7] | [25, 36, 49]    |\n\n\nThe function `transform` can be also\nemployed to safely cast the elements of an array to strings:\n```sql\n    SELECT transform(prices, n -> TRY_CAST(n AS VARCHAR) || '$') as price_tags\n    FROM (\n        VALUES\n            (ARRAY[100, 200]),\n            (ARRAY[30, 4])\n    ) AS t(prices);\n```\n**Results**: \n\n| price_tags  |\n|-------------|\n| [100$, 200$] |\n| [30$, 4$]    |\n\nBesides the array column being manipulated, other columns can be\ncaptured as well within the lambda expression. The following statement\nprovides a showcase of this feature for calculating the value of the\nlinear function `f(x) = ax + b` with `transform`:\n```sql\n    SELECT xvalues,\n           a,\n           b,\n           transform(xvalues, x -> a * x + b) as linear_function_values\n    FROM (\n        VALUES\n            (ARRAY[1, 2], 10, 5),\n            (ARRAY[3, 4], 4, 2)\n    ) AS t(xvalues, a, b);\n```\n**Results**: \n\n| xvalues | a  | b | linear_function_values |\n|---------|----|---|------------------------|\n| [1, 2]  | 10 | 5 | [15, 25]               |\n| [3, 4]  |  4 | 2 | [14, 18]               |\n\n\nFind the array elements containing at least one value", "doc_id": "a5c40de4-ebb3-473a-a373-60327f589248", "embedding": null, "doc_hash": "4ad6445df362c7d8b87613663e020e463f68b1c830b62d1f4bdae197b1caefd1", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/lambda.md", "file_name": "lambda.md"}, "node_info": {"start": 0, "end": 2188, "_node_type": "1"}, "relationships": {"1": "f40cd9380740eff0176ae51621e285600bdff08f", "3": "72a1a59d-0f7f-4cd1-888a-bd8cb19d0fd9"}}, "__type__": "1"}, "72a1a59d-0f7f-4cd1-888a-bd8cb19d0fd9": {"__data__": {"text": "      |\n\n\nFind the array elements containing at least one value greater than `100`\nwith `any_match`{.interpreted-text role=\"func\"}:\n```sql\n    SELECT numbers\n    FROM (\n        VALUES\n            (ARRAY[1,NULL,3]),\n            (ARRAY[10,20,30]),\n            (ARRAY[100,200,300])\n    ) AS t(numbers)\n    WHERE any_match(numbers, n ->  COALESCE(n, 0) > 100);\n    -- [100, 200, 300]\n```\nCapitalize the f word in a string via `regexp_replace`:\n```sql\n    SELECT regexp_replace('once upon a time ...', '^(\\w)(\\w*)(\\s+.*)$',x -> upper(x[1]) || x[2] || x[3]);\n    -- Once upon a time ...\n```\n\nLambda expressions can be also applied in aggregation functions.\nFollowing statement is a sample the overly complex calculation of the\nsum of all elements of a column by making use of `reduce_agg`:\n```sql\n    SELECT reduce_agg(value, 0, (a, b) -> a + b, (a, b) -> a + b) sum_values\n    FROM (\n        VALUES (1), (2), (3), (4), (5)\n    ) AS t(value);\n    -- 15\n```", "doc_id": "72a1a59d-0f7f-4cd1-888a-bd8cb19d0fd9", "embedding": null, "doc_hash": "b303e287ee4f606b18fc31e122e31cca7c03f5f8c675e3f4db1a62f76adf7758", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/lambda.md", "file_name": "lambda.md"}, "node_info": {"start": 2125, "end": 3075, "_node_type": "1"}, "relationships": {"1": "f40cd9380740eff0176ae51621e285600bdff08f", "2": "a5c40de4-ebb3-473a-a373-60327f589248"}}, "__type__": "1"}, "3f718723-b803-46ee-b34b-515fc2bf63c1": {"__data__": {"text": "---\ntitle: List of functions by topic\n---\n\n## Aggregate\n\nFor more details, see `aggregate`{.interpreted-text role=\"doc\"}\n\n-   `approx_distinct`{.interpreted-text role=\"func\"}\n-   `approx_most_frequent`{.interpreted-text role=\"func\"}\n-   `approx_percentile`{.interpreted-text role=\"func\"}\n-   `approx_set()`\n-   `arbitrary`{.interpreted-text role=\"func\"}\n-   `array_agg`{.interpreted-text role=\"func\"}\n-   `avg`{.interpreted-text role=\"func\"}\n-   `bitwise_and_agg`{.interpreted-text role=\"func\"}\n-   `bitwise_or_agg`{.interpreted-text role=\"func\"}\n-   `bool_and`{.interpreted-text role=\"func\"}\n-   `bool_or`{.interpreted-text role=\"func\"}\n-   `checksum`{.interpreted-text role=\"func\"}\n-   `corr`{.interpreted-text role=\"func\"}\n-   `count`{.interpreted-text role=\"func\"}\n-   `count_if`{.interpreted-text role=\"func\"}\n-   `covar_pop`{.interpreted-text role=\"func\"}\n-   `covar_samp`{.interpreted-text role=\"func\"}\n-   `every`{.interpreted-text role=\"func\"}\n-   `geometric_mean`{.interpreted-text role=\"func\"}\n-   `histogram`{.interpreted-text role=\"func\"}\n-   `kurtosis`{.interpreted-text role=\"func\"}\n-   `map_agg`{.interpreted-text role=\"func\"}\n-   `map_union`{.interpreted-text role=\"func\"}\n-   `max`{.interpreted-text role=\"func\"}\n-   `max_by`{.interpreted-text role=\"func\"}\n-   `merge()`\n-   `min`{.interpreted-text role=\"func\"}\n-   `min_by`{.interpreted-text role=\"func\"}\n-   `multimap_agg`{.interpreted-text role=\"func\"}\n-   `numeric_histogram`{.interpreted-text role=\"func\"}\n-   `qdigest_agg()`\n-   `regr_intercept`{.interpreted-text role=\"func\"}\n-   `regr_slope`{.interpreted-text role=\"func\"}\n-   `skewness`{.interpreted-text role=\"func\"}\n-   `sum`{.interpreted-text role=\"func\"}\n-   `stddev`{.interpreted-text role=\"func\"}\n-   `stddev_pop`{.interpreted-text role=\"func\"}\n-   `stddev_samp`{.interpreted-text role=\"func\"}\n-   `tdigest_agg()`\n-   `variance`{.interpreted-text role=\"func\"}\n-   `var_pop`{.interpreted-text role=\"func\"}\n-   `var_samp`{.interpreted-text role=\"func\"}\n\n## Array\n\nFor more details, see `array`{.interpreted-text role=\"doc\"}\n\n-   `all_match`{.interpreted-text role=\"func\"}\n-   `any_match`{.interpreted-text role=\"func\"}\n-   `array_distinct`{.interpreted-text role=\"func\"}\n-   `array_except`{.interpreted-text role=\"func\"}\n-   `array_intersect`{.interpreted-text role=\"func\"}\n-   `array_join`{.interpreted-text role=\"func\"}\n-   `array_max`{.interpreted-text", "doc_id": "3f718723-b803-46ee-b34b-515fc2bf63c1", "embedding": null, "doc_hash": "0ea18592a18ff6cf632919f1f230494306b37805aacaa225433a7923013d5b11", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}, "node_info": {"start": 0, "end": 2386, "_node_type": "1"}, "relationships": {"1": "a6862ae86aeebd0d2a552f49918a5c585d690125", "3": "786d4d9d-b0d8-4d83-b860-49c9e2872db4"}}, "__type__": "1"}, "786d4d9d-b0d8-4d83-b860-49c9e2872db4": {"__data__": {"text": "role=\"func\"}\n-   `array_max`{.interpreted-text role=\"func\"}\n-   `array_min`{.interpreted-text role=\"func\"}\n-   `array_position`{.interpreted-text role=\"func\"}\n-   `array_remove`{.interpreted-text role=\"func\"}\n-   `array_sort`{.interpreted-text role=\"func\"}\n-   `array_union`{.interpreted-text role=\"func\"}\n-   `arrays_overlap`{.interpreted-text role=\"func\"}\n-   `cardinality`{.interpreted-text role=\"func\"}\n-   `combinations`{.interpreted-text role=\"func\"}\n-   `concat()`\n-   `contains`{.interpreted-text role=\"func\"}\n-   `element_at`{.interpreted-text role=\"func\"}\n-   `filter`{.interpreted-text role=\"func\"}\n-   `flatten`{.interpreted-text role=\"func\"}\n-   `ngrams`{.interpreted-text role=\"func\"}\n-   `none_match`{.interpreted-text role=\"func\"}\n-   `reduce`{.interpreted-text role=\"func\"}\n-   `repeat`{.interpreted-text role=\"func\"}\n-   `reverse()`\n-   `sequence`{.interpreted-text role=\"func\"}\n-   `shuffle`{.interpreted-text role=\"func\"}\n-   `slice`{.interpreted-text role=\"func\"}\n-   `transform`{.interpreted-text role=\"func\"}\n-   `trim_array`{.interpreted-text role=\"func\"}\n-   `zip`{.interpreted-text role=\"func\"}\n-   `zip_with`{.interpreted-text role=\"func\"}\n\n## Binary\n\nFor more details, see `binary`{.interpreted-text role=\"doc\"}\n\n-   `concat()`\n-   `crc32`{.interpreted-text role=\"func\"}\n-   `from_base32`{.interpreted-text role=\"func\"}\n-   `from_base64`{.interpreted-text role=\"func\"}\n-   `from_base64url`{.interpreted-text role=\"func\"}\n-   `from_big_endian_32`{.interpreted-text role=\"func\"}\n-   `from_big_endian_64`{.interpreted-text role=\"func\"}\n-   `from_hex`{.interpreted-text role=\"func\"}\n-   `from_ieee754_32`{.interpreted-text role=\"func\"}\n-   `from_ieee754_64`{.interpreted-text role=\"func\"}\n-   `hmac_md5`{.interpreted-text role=\"func\"}\n-   `hmac_sha1`{.interpreted-text role=\"func\"}\n-   `hmac_sha256`{.interpreted-text role=\"func\"}\n-   `hmac_sha512`{.interpreted-text role=\"func\"}\n-   `length()`\n-   `lpad()`\n-   `md5`{.interpreted-text role=\"func\"}\n-   `murmur3`{.interpreted-text role=\"func\"}\n-   `reverse()`\n-   `rpad()`\n-   `sha1`{.interpreted-text role=\"func\"}\n-   `sha256`{.interpreted-text role=\"func\"}\n-   `sha512`{.interpreted-text role=\"func\"}\n-   `spooky_hash_v2_32`{.interpreted-text role=\"func\"}\n-   `spooky_hash_v2_64`{.interpreted-text role=\"func\"}\n-   `substr()`\n-   `to_base32`{.interpreted-text role=\"func\"}\n- ", "doc_id": "786d4d9d-b0d8-4d83-b860-49c9e2872db4", "embedding": null, "doc_hash": "a4c7a4551ae8454458efdc905358324983513a9b9ed65483292648f7710fce29", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}, "node_info": {"start": 2344, "end": 4695, "_node_type": "1"}, "relationships": {"1": "a6862ae86aeebd0d2a552f49918a5c585d690125", "2": "3f718723-b803-46ee-b34b-515fc2bf63c1", "3": "aa76c0b9-a63c-4023-8251-a9e0ae4af85e"}}, "__type__": "1"}, "aa76c0b9-a63c-4023-8251-a9e0ae4af85e": {"__data__": {"text": " `to_base32`{.interpreted-text role=\"func\"}\n-   `to_base64`{.interpreted-text role=\"func\"}\n-   `to_base64url`{.interpreted-text role=\"func\"}\n-   `to_big_endian_32`{.interpreted-text role=\"func\"}\n-   `to_big_endian_64`{.interpreted-text role=\"func\"}\n-   `to_hex`{.interpreted-text role=\"func\"}\n-   `to_ieee754_32`{.interpreted-text role=\"func\"}\n-   `to_ieee754_64`{.interpreted-text role=\"func\"}\n-   `xxhash64`{.interpreted-text role=\"func\"}\n\n## Bitwise\n\nFor more details, see `bitwise`{.interpreted-text role=\"doc\"}\n\n-   `bit_count`{.interpreted-text role=\"func\"}\n-   `bitwise_and`{.interpreted-text role=\"func\"}\n-   `bitwise_left_shift`{.interpreted-text role=\"func\"}\n-   `bitwise_not`{.interpreted-text role=\"func\"}\n-   `bitwise_or`{.interpreted-text role=\"func\"}\n-   `bitwise_right_shift`{.interpreted-text role=\"func\"}\n-   `bitwise_right_shift_arithmetic`{.interpreted-text role=\"func\"}\n-   `bitwise_xor`{.interpreted-text role=\"func\"}\n\n## Color\n\nFor more details, see `color`{.interpreted-text role=\"doc\"}\n\n-   `bar`{.interpreted-text role=\"func\"}\n-   `color`{.interpreted-text role=\"func\"}\n-   `render`{.interpreted-text role=\"func\"}\n-   `rgb`{.interpreted-text role=\"func\"}\n\n# Comparison\n\nFor more details, see `comparison`{.interpreted-text role=\"doc\"}\n\n-   `greatest`{.interpreted-text role=\"func\"}\n-   `least`{.interpreted-text role=\"func\"}\n\n# Conditional\n\nFor more details, see `conditional`{.interpreted-text role=\"doc\"}\n\n-   `coalesce <coalesce_function>`{.interpreted-text role=\"ref\"}\n-   `if <if_function>`{.interpreted-text role=\"ref\"}\n-   `nullif <nullif_function>`{.interpreted-text role=\"ref\"}\n-   `try <try_function>`{.interpreted-text role=\"ref\"}\n\n# Conversion\n\nFor more details, see `conversion`{.interpreted-text role=\"doc\"}\n\n-   `cast`{.interpreted-text role=\"func\"}\n-   `format`{.interpreted-text role=\"func\"}\n-   `try_cast`{.interpreted-text role=\"func\"}\n-   `typeof`{.interpreted-text role=\"func\"}\n\n# Date and time\n\nFor more details, see `datetime`{.interpreted-text role=\"doc\"}\n\n-   `AT TIME ZONE <at_time_zone_operator>`{.interpreted-text role=\"ref\"}\n-   `current_date`{.interpreted-text role=\"data\"}\n-   `current_time`{.interpreted-text role=\"data\"}\n-   `current_timestamp`{.interpreted-text role=\"data\"}\n-   `localtime`{.interpreted-text role=\"data\"}\n-   `localtimestamp`{.interpreted-text role=\"data\"}\n-   `current_timezone`{.interpreted-text role=\"func\"}\n-   `date`{.interpreted-text role=\"func\"}\n-   `date_add`{.interpreted-text role=\"func\"}\n-  ", "doc_id": "aa76c0b9-a63c-4023-8251-a9e0ae4af85e", "embedding": null, "doc_hash": "b802b2678d880e18424455420b711fdb2a074766b615b92190bfc59ea1a492e5", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}, "node_info": {"start": 4696, "end": 7175, "_node_type": "1"}, "relationships": {"1": "a6862ae86aeebd0d2a552f49918a5c585d690125", "2": "786d4d9d-b0d8-4d83-b860-49c9e2872db4", "3": "421b0b9d-87cb-4d4d-a04a-4e9e4ffbbd85"}}, "__type__": "1"}, "421b0b9d-87cb-4d4d-a04a-4e9e4ffbbd85": {"__data__": {"text": " `date_add`{.interpreted-text role=\"func\"}\n-   `date_diff`{.interpreted-text role=\"func\"}\n-   `date_format`{.interpreted-text role=\"func\"}\n-   `date_parse`{.interpreted-text role=\"func\"}\n-   `date_trunc`{.interpreted-text role=\"func\"}\n-   `format_datetime`{.interpreted-text role=\"func\"}\n-   `from_iso8601_date`{.interpreted-text role=\"func\"}\n-   `from_iso8601_timestamp`{.interpreted-text role=\"func\"}\n-   `from_unixtime`{.interpreted-text role=\"func\"}\n-   `from_unixtime_nanos`{.interpreted-text role=\"func\"}\n-   `human_readable_seconds`{.interpreted-text role=\"func\"}\n-   `last_day_of_month`{.interpreted-text role=\"func\"}\n-   `now`{.interpreted-text role=\"func\"}\n-   `parse_duration`{.interpreted-text role=\"func\"}\n-   `to_iso8601`{.interpreted-text role=\"func\"}\n-   `to_milliseconds`{.interpreted-text role=\"func\"}\n-   `to_unixtime`{.interpreted-text role=\"func\"}\n-   `with_timezone`{.interpreted-text role=\"func\"}\n\n# Geospatial\n\nFor more details, see `geospatial`{.interpreted-text role=\"doc\"}\n\n-   `bing_tile`{.interpreted-text role=\"func\"}\n-   `bing_tile_at`{.interpreted-text role=\"func\"}\n-   `bing_tile_coordinates`{.interpreted-text role=\"func\"}\n-   `bing_tile_polygon`{.interpreted-text role=\"func\"}\n-   `bing_tile_quadkey`{.interpreted-text role=\"func\"}\n-   `bing_tile_zoom_level`{.interpreted-text role=\"func\"}\n-   `bing_tiles_around`{.interpreted-text role=\"func\"}\n-   `convex_hull_agg`{.interpreted-text role=\"func\"}\n-   `from_encoded_polyline`{.interpreted-text role=\"func\"}\n-   `from_geojson_geometry`{.interpreted-text role=\"func\"}\n-   `geometry_from_hadoop_shape`{.interpreted-text role=\"func\"}\n-   `geometry_invalid_reason`{.interpreted-text role=\"func\"}\n-   `geometry_nearest_points`{.interpreted-text role=\"func\"}\n-   `geometry_to_bing_tiles`{.interpreted-text role=\"func\"}\n-   `geometry_union`{.interpreted-text role=\"func\"}\n-   `geometry_union_agg`{.interpreted-text role=\"func\"}\n-   `great_circle_distance`{.interpreted-text role=\"func\"}\n-   `line_interpolate_point`{.interpreted-text role=\"func\"}\n-   `line_locate_point`{.interpreted-text role=\"func\"}\n-   `simplify_geometry`{.interpreted-text role=\"func\"}\n-   `ST_Area`{.interpreted-text role=\"func\"}\n-   `ST_AsBinary`{.interpreted-text role=\"func\"}\n-   `ST_AsText`{.interpreted-text role=\"func\"}\n-   `ST_Boundary`{.interpreted-text role=\"func\"}\n-   `ST_Buffer`{.interpreted-text role=\"func\"}\n-   `ST_Centroid`{.interpreted-text role=\"func\"}\n-  ", "doc_id": "421b0b9d-87cb-4d4d-a04a-4e9e4ffbbd85", "embedding": null, "doc_hash": "71789de71f80d79f9dcce21372a4c13db4ee90f6e1c651aacf54d19c773c0e20", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}, "node_info": {"start": 7177, "end": 9600, "_node_type": "1"}, "relationships": {"1": "a6862ae86aeebd0d2a552f49918a5c585d690125", "2": "aa76c0b9-a63c-4023-8251-a9e0ae4af85e", "3": "080b4e9a-c148-4fcd-96f8-cf8f3d14576e"}}, "__type__": "1"}, "080b4e9a-c148-4fcd-96f8-cf8f3d14576e": {"__data__": {"text": "`ST_Centroid`{.interpreted-text role=\"func\"}\n-   `ST_Contains`{.interpreted-text role=\"func\"}\n-   `ST_ConvexHull`{.interpreted-text role=\"func\"}\n-   `ST_CoordDim`{.interpreted-text role=\"func\"}\n-   `ST_Crosses`{.interpreted-text role=\"func\"}\n-   `ST_Difference`{.interpreted-text role=\"func\"}\n-   `ST_Dimension`{.interpreted-text role=\"func\"}\n-   `ST_Disjoint`{.interpreted-text role=\"func\"}\n-   `ST_Distance`{.interpreted-text role=\"func\"}\n-   `ST_EndPoint`{.interpreted-text role=\"func\"}\n-   `ST_Envelope`{.interpreted-text role=\"func\"}\n-   `ST_Equals`{.interpreted-text role=\"func\"}\n-   `ST_ExteriorRing`{.interpreted-text role=\"func\"}\n-   `ST_Geometries`{.interpreted-text role=\"func\"}\n-   `ST_GeometryFromText`{.interpreted-text role=\"func\"}\n-   `ST_GeometryN`{.interpreted-text role=\"func\"}\n-   `ST_GeometryType`{.interpreted-text role=\"func\"}\n-   `ST_GeomFromBinary`{.interpreted-text role=\"func\"}\n-   `ST_InteriorRings`{.interpreted-text role=\"func\"}\n-   `ST_InteriorRingN`{.interpreted-text role=\"func\"}\n-   `ST_Intersects`{.interpreted-text role=\"func\"}\n-   `ST_Intersection`{.interpreted-text role=\"func\"}\n-   `ST_IsClosed`{.interpreted-text role=\"func\"}\n-   `ST_IsEmpty`{.interpreted-text role=\"func\"}\n-   `ST_IsSimple`{.interpreted-text role=\"func\"}\n-   `ST_IsRing`{.interpreted-text role=\"func\"}\n-   `ST_IsValid`{.interpreted-text role=\"func\"}\n-   `ST_Length`{.interpreted-text role=\"func\"}\n-   `ST_LineFromText`{.interpreted-text role=\"func\"}\n-   `ST_LineString`{.interpreted-text role=\"func\"}\n-   `ST_MultiPoint`{.interpreted-text role=\"func\"}\n-   `ST_NumGeometries`{.interpreted-text role=\"func\"}\n-   `ST_NumInteriorRing`{.interpreted-text role=\"func\"}\n-   `ST_NumPoints`{.interpreted-text role=\"func\"}\n-   `ST_Overlaps`{.interpreted-text role=\"func\"}\n-   `ST_Point`{.interpreted-text role=\"func\"}\n-   `ST_PointN`{.interpreted-text role=\"func\"}\n-   `ST_Points`{.interpreted-text role=\"func\"}\n-   `ST_Polygon`{.interpreted-text role=\"func\"}\n-   `ST_Relate`{.interpreted-text role=\"func\"}\n-   `ST_StartPoint`{.interpreted-text role=\"func\"}\n-   `ST_SymDifference`{.interpreted-text role=\"func\"}\n-   `ST_Touches`{.interpreted-text role=\"func\"}\n-   `ST_Union`{.interpreted-text role=\"func\"}\n-   `ST_Within`{.interpreted-text role=\"func\"}\n-   `ST_X`{.interpreted-text role=\"func\"}\n-   `ST_XMax`{.interpreted-text role=\"func\"}\n-   `ST_XMin`{.interpreted-text role=\"func\"}\n- ", "doc_id": "080b4e9a-c148-4fcd-96f8-cf8f3d14576e", "embedding": null, "doc_hash": "5d26b0d8bae7cc37ac049d5573204034d1a8f73e9c4123b466ed54a798851311", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}, "node_info": {"start": 9598, "end": 11982, "_node_type": "1"}, "relationships": {"1": "a6862ae86aeebd0d2a552f49918a5c585d690125", "2": "421b0b9d-87cb-4d4d-a04a-4e9e4ffbbd85", "3": "06b249ba-50af-4a2b-98f0-47cb73af850b"}}, "__type__": "1"}, "06b249ba-50af-4a2b-98f0-47cb73af850b": {"__data__": {"text": " `ST_XMin`{.interpreted-text role=\"func\"}\n-   `ST_Y`{.interpreted-text role=\"func\"}\n-   `ST_YMax`{.interpreted-text role=\"func\"}\n-   `ST_YMin`{.interpreted-text role=\"func\"}\n-   `to_encoded_polyline`{.interpreted-text role=\"func\"}\n-   `to_geojson_geometry`{.interpreted-text role=\"func\"}\n-   `to_geometry`{.interpreted-text role=\"func\"}\n-   `to_spherical_geography`{.interpreted-text role=\"func\"}\n\n# HyperLogLog\n\nFor more details, see `hyperloglog`{.interpreted-text role=\"doc\"}\n\n-   `approx_set`{.interpreted-text role=\"func\"}\n-   `cardinality()`\n-   `empty_approx_set`{.interpreted-text role=\"func\"}\n-   `merge`{.interpreted-text role=\"func\"}\n\n# JSON\n\nFor more details, see `json`{.interpreted-text role=\"doc\"}\n\n-   `is_json_scalar`{.interpreted-text role=\"func\"}\n-   `json_array() <json_array>`{.interpreted-text role=\"ref\"}\n-   `json_array_contains`{.interpreted-text role=\"func\"}\n-   `json_array_get`{.interpreted-text role=\"func\"}\n-   `json_array_length`{.interpreted-text role=\"func\"}\n-   `json_exists() <json_exists>`{.interpreted-text role=\"ref\"}\n-   `json_extract`{.interpreted-text role=\"func\"}\n-   `json_extract_scalar`{.interpreted-text role=\"func\"}\n-   `json_format`{.interpreted-text role=\"func\"}\n-   `json_parse`{.interpreted-text role=\"func\"}\n-   `json_object() <json_object>`{.interpreted-text role=\"ref\"}\n-   `json_query() <json_query>`{.interpreted-text role=\"ref\"}\n-   `json_size`{.interpreted-text role=\"func\"}\n-   `json_value() <json_value>`{.interpreted-text role=\"ref\"}\n\n# Lambda\n\nFor more details, see `lambda`{.interpreted-text role=\"doc\"}\n\n-   `any_match`{.interpreted-text role=\"func\"}\n-   `reduce_agg`{.interpreted-text role=\"func\"}\n-   `regexp_replace`{.interpreted-text role=\"func\"}\n-   `transform`{.interpreted-text role=\"func\"}\n\n# Machine learning\n\nFor more details, see `ml`{.interpreted-text role=\"doc\"}\n\n-   `classify`{.interpreted-text role=\"func\"}\n-   `features`{.interpreted-text role=\"func\"}\n-   `learn_classifier`{.interpreted-text role=\"func\"}\n-   `learn_libsvm_classifier`{.interpreted-text role=\"func\"}\n-   `learn_libsvm_regressor`{.interpreted-text role=\"func\"}\n-   `learn_regressor`{.interpreted-text role=\"func\"}\n-   `regress`{.interpreted-text role=\"func\"}\n\n# Map\n\nFor more details, see `map`{.interpreted-text role=\"doc\"}\n\n-   `cardinality`{.interpreted-text role=\"func\"}\n-   `element_at`{.interpreted-text role=\"func\"}\n-   `map`{.interpreted-text role=\"func\"}\n-   `map_concat`{.interpreted-text role=\"func\"}\n-  ", "doc_id": "06b249ba-50af-4a2b-98f0-47cb73af850b", "embedding": null, "doc_hash": "5a7a5f96db6ff43b785efed08e0c21105f01ff62c4e148732627ca7efdc3c72f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}, "node_info": {"start": 11987, "end": 14449, "_node_type": "1"}, "relationships": {"1": "a6862ae86aeebd0d2a552f49918a5c585d690125", "2": "080b4e9a-c148-4fcd-96f8-cf8f3d14576e", "3": "b8ef17ac-6b0c-4f52-90ab-42d21d068f11"}}, "__type__": "1"}, "b8ef17ac-6b0c-4f52-90ab-42d21d068f11": {"__data__": {"text": "`map_concat`{.interpreted-text role=\"func\"}\n-   `map_entries`{.interpreted-text role=\"func\"}\n-   `map_filter`{.interpreted-text role=\"func\"}\n-   `map_from_entries`{.interpreted-text role=\"func\"}\n-   `map_keys`{.interpreted-text role=\"func\"}\n-   `map_values`{.interpreted-text role=\"func\"}\n-   `map_zip_with`{.interpreted-text role=\"func\"}\n-   `multimap_from_entries`{.interpreted-text role=\"func\"}\n-   `transform_keys`{.interpreted-text role=\"func\"}\n-   `transform_values`{.interpreted-text role=\"func\"}\n\n# Math\n\nFor more details, see `math`{.interpreted-text role=\"doc\"}\n\n-   `abs`{.interpreted-text role=\"func\"}\n-   `acos`{.interpreted-text role=\"func\"}\n-   `asin`{.interpreted-text role=\"func\"}\n-   `atan`{.interpreted-text role=\"func\"}\n-   `beta_cdf`{.interpreted-text role=\"func\"}\n-   `cbrt`{.interpreted-text role=\"func\"}\n-   `ceil`{.interpreted-text role=\"func\"}\n-   `cos`{.interpreted-text role=\"func\"}\n-   `cosh`{.interpreted-text role=\"func\"}\n-   `cosine_similarity`{.interpreted-text role=\"func\"}\n-   `degrees`{.interpreted-text role=\"func\"}\n-   `e`{.interpreted-text role=\"func\"}\n-   `exp`{.interpreted-text role=\"func\"}\n-   `floor`{.interpreted-text role=\"func\"}\n-   `from_base`{.interpreted-text role=\"func\"}\n-   `infinity`{.interpreted-text role=\"func\"}\n-   `inverse_beta_cdf`{.interpreted-text role=\"func\"}\n-   `inverse_normal_cdf`{.interpreted-text role=\"func\"}\n-   `is_finite`{.interpreted-text role=\"func\"}\n-   `is_nan`{.interpreted-text role=\"func\"}\n-   `ln`{.interpreted-text role=\"func\"}\n-   `log`{.interpreted-text role=\"func\"}\n-   `log2`{.interpreted-text role=\"func\"}\n-   `log10`{.interpreted-text role=\"func\"}\n-   `mod`{.interpreted-text role=\"func\"}\n-   `nan`{.interpreted-text role=\"func\"}\n-   `normal_cdf`{.interpreted-text role=\"func\"}\n-   `pi`{.interpreted-text role=\"func\"}\n-   `pow`{.interpreted-text role=\"func\"}\n-   `power`{.interpreted-text role=\"func\"}\n-   `radians`{.interpreted-text role=\"func\"}\n-   `rand`{.interpreted-text role=\"func\"}\n-   `random`{.interpreted-text role=\"func\"}\n-   `round`{.interpreted-text role=\"func\"}\n-   `sign`{.interpreted-text role=\"func\"}\n-   `sin`{.interpreted-text role=\"func\"}\n-   `sqrt`{.interpreted-text role=\"func\"}\n-   `tan`{.interpreted-text role=\"func\"}\n-   `tanh`{.interpreted-text role=\"func\"}\n-   `to_base`{.interpreted-text role=\"func\"}\n-   `truncate`{.interpreted-text role=\"func\"}\n-  ", "doc_id": "b8ef17ac-6b0c-4f52-90ab-42d21d068f11", "embedding": null, "doc_hash": "982b92d082f8121e64406634f6c017607c72203b6d57ce7121e2504049a82590", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}, "node_info": {"start": 14447, "end": 16813, "_node_type": "1"}, "relationships": {"1": "a6862ae86aeebd0d2a552f49918a5c585d690125", "2": "06b249ba-50af-4a2b-98f0-47cb73af850b", "3": "83ade6fc-f559-4b19-b909-e32a53e0ba7e"}}, "__type__": "1"}, "83ade6fc-f559-4b19-b909-e32a53e0ba7e": {"__data__": {"text": " `truncate`{.interpreted-text role=\"func\"}\n-   `width_bucket`{.interpreted-text role=\"func\"}\n-   `wilson_interval_lower`{.interpreted-text role=\"func\"}\n-   `wilson_interval_upper`{.interpreted-text role=\"func\"}\n\n# Quantile digest\n\nFor more details, see `qdigest`{.interpreted-text role=\"doc\"}\n\n-   `merge()`\n-   `qdigest_agg`{.interpreted-text role=\"func\"}\n-   `value_at_quantile`{.interpreted-text role=\"func\"}\n-   `values_at_quantiles`{.interpreted-text role=\"func\"}\n\n# Regular expression\n\nFor more details, see `regexp`{.interpreted-text role=\"doc\"}\n\n-   `regexp_count`{.interpreted-text role=\"func\"}\n-   `regexp_extract`{.interpreted-text role=\"func\"}\n-   `regexp_extract_all`{.interpreted-text role=\"func\"}\n-   `regexp_like`{.interpreted-text role=\"func\"}\n-   `regexp_position`{.interpreted-text role=\"func\"}\n-   `regexp_replace`{.interpreted-text role=\"func\"}\n-   `regexp_split`{.interpreted-text role=\"func\"}\n\n# Session\n\nFor more details, see `session`{.interpreted-text role=\"doc\"}\n\n-   `current_catalog`{.interpreted-text role=\"data\"}\n-   `current_groups`{.interpreted-text role=\"func\"}\n-   `current_schema`{.interpreted-text role=\"data\"}\n-   `current_user`{.interpreted-text role=\"data\"}\n\n# Set Digest\n\nFor more details, see `setdigest`{.interpreted-text role=\"doc\"}\n\n-   `make_set_digest`{.interpreted-text role=\"func\"}\n-   `merge_set_digest`{.interpreted-text role=\"func\"}\n-   `cardinality() <setdigest-cardinality>`{.interpreted-text\n    role=\"ref\"}\n-   `intersection_cardinality`{.interpreted-text role=\"func\"}\n-   `jaccard_index`{.interpreted-text role=\"func\"}\n-   `hash_counts`{.interpreted-text role=\"func\"}\n\n# String\n\nFor more details, see `string`{.interpreted-text role=\"doc\"}\n\n-   `chr`{.interpreted-text role=\"func\"}\n-   `codepoint`{.interpreted-text role=\"func\"}\n-   `concat`{.interpreted-text role=\"func\"}\n-   `concat_ws`{.interpreted-text role=\"func\"}\n-   `format`{.interpreted-text role=\"func\"}\n-   `from_utf8`{.interpreted-text role=\"func\"}\n-   `hamming_distance`{.interpreted-text role=\"func\"}\n-   `length`{.interpreted-text role=\"func\"}\n-   `levenshtein_distance`{.interpreted-text role=\"func\"}\n-   `lower`{.interpreted-text role=\"func\"}\n-   `lpad`{.interpreted-text role=\"func\"}\n-   `ltrim`{.interpreted-text role=\"func\"}\n-   `luhn_check`{.interpreted-text role=\"func\"}\n-   `normalize`{.interpreted-text role=\"func\"}\n-   `position`{.interpreted-text role=\"func\"}\n-   `replace`{.interpreted-text role=\"func\"}\n-   `reverse`{.interpreted-text role=\"func\"}\n-", "doc_id": "83ade6fc-f559-4b19-b909-e32a53e0ba7e", "embedding": null, "doc_hash": "1f138bcc0a2820a150cdbdcd48479d5a228d9e812491a44a19bb8af1d063867d", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}, "node_info": {"start": 16816, "end": 19300, "_node_type": "1"}, "relationships": {"1": "a6862ae86aeebd0d2a552f49918a5c585d690125", "2": "b8ef17ac-6b0c-4f52-90ab-42d21d068f11", "3": "0d25c5d7-a26d-4ea1-b4a5-696f569d50b5"}}, "__type__": "1"}, "0d25c5d7-a26d-4ea1-b4a5-696f569d50b5": {"__data__": {"text": "  `reverse`{.interpreted-text role=\"func\"}\n-   `rpad`{.interpreted-text role=\"func\"}\n-   `rtrim`{.interpreted-text role=\"func\"}\n-   `soundex`{.interpreted-text role=\"func\"}\n-   `split`{.interpreted-text role=\"func\"}\n-   `split_part`{.interpreted-text role=\"func\"}\n-   `split_to_map`{.interpreted-text role=\"func\"}\n-   `split_to_multimap`{.interpreted-text role=\"func\"}\n-   `starts_with`{.interpreted-text role=\"func\"}\n-   `strpos`{.interpreted-text role=\"func\"}\n-   `substr`{.interpreted-text role=\"func\"}\n-   `substring`{.interpreted-text role=\"func\"}\n-   `to_utf8`{.interpreted-text role=\"func\"}\n-   `translate`{.interpreted-text role=\"func\"}\n-   `trim`{.interpreted-text role=\"func\"}\n-   `upper`{.interpreted-text role=\"func\"}\n-   `word_stem`{.interpreted-text role=\"func\"}\n\n# System\n\nFor more details, see `system`{.interpreted-text role=\"doc\"}\n\n-   `version`{.interpreted-text role=\"func\"}\n\n# T-Digest\n\nFor more details, see `tdigest`{.interpreted-text role=\"doc\"}\n\n-   `merge()`\n-   `tdigest_agg`{.interpreted-text role=\"func\"}\n-   `value_at_quantile()`\n\n# Teradata\n\nFor more details, see `teradata`{.interpreted-text role=\"doc\"}\n\n-   `char2hexint`{.interpreted-text role=\"func\"}\n-   `index`{.interpreted-text role=\"func\"}\n-   `to_char`{.interpreted-text role=\"func\"}\n-   `to_timestamp`{.interpreted-text role=\"func\"}\n-   `to_date`{.interpreted-text role=\"func\"}\n\n# URL\n\nFor more details, see `url`{.interpreted-text role=\"doc\"}\n\n-   `url_decode`{.interpreted-text role=\"func\"}\n-   `url_encode`{.interpreted-text role=\"func\"}\n-   `url_extract_fragment`{.interpreted-text role=\"func\"}\n-   `url_extract_host`{.interpreted-text role=\"func\"}\n-   `url_extract_parameter`{.interpreted-text role=\"func\"}\n-   `url_extract_path`{.interpreted-text role=\"func\"}\n-   `url_extract_port`{.interpreted-text role=\"func\"}\n-   `url_extract_protocol`{.interpreted-text role=\"func\"}\n-   `url_extract_query`{.interpreted-text role=\"func\"}\n\n# UUID\n\nFor more details, see `uuid`{.interpreted-text role=\"doc\"}\n\n-   `uuid`{.interpreted-text role=\"func\"}\n\n# Window\n\nFor more details, see `window`{.interpreted-text role=\"doc\"}\n\n-   `cume_dist`{.interpreted-text role=\"func\"}\n-   `dense_rank`{.interpreted-text role=\"func\"}\n-   `f_value`{.interpreted-text role=\"func\"}\n-   `lag`{.interpreted-text role=\"func\"}\n-   `last_value`{.interpreted-text role=\"func\"}\n-   `lead`{.interpreted-text role=\"func\"}\n-   `nth_value`{.interpreted-text role=\"func\"}\n- ", "doc_id": "0d25c5d7-a26d-4ea1-b4a5-696f569d50b5", "embedding": null, "doc_hash": "391aa115826f5b80e57f8785be1dd0adbdf964e4a383eee9292bee74fd96e576", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}, "node_info": {"start": 19302, "end": 21730, "_node_type": "1"}, "relationships": {"1": "a6862ae86aeebd0d2a552f49918a5c585d690125", "2": "83ade6fc-f559-4b19-b909-e32a53e0ba7e", "3": "9247f59f-6218-4ebe-8efe-3990f4ccfc44"}}, "__type__": "1"}, "9247f59f-6218-4ebe-8efe-3990f4ccfc44": {"__data__": {"text": " `nth_value`{.interpreted-text role=\"func\"}\n-   `ntile`{.interpreted-text role=\"func\"}\n-   `percent_rank`{.interpreted-text role=\"func\"}\n-   `rank`{.interpreted-text role=\"func\"}\n-   `row_number`{.interpreted-text role=\"func\"}\n", "doc_id": "9247f59f-6218-4ebe-8efe-3990f4ccfc44", "embedding": null, "doc_hash": "6998a601590bcc07e7f88b48db7ba2e96fac35368f6dc97e91f5e6a502a5c15d", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}, "node_info": {"start": 21725, "end": 21952, "_node_type": "1"}, "relationships": {"1": "a6862ae86aeebd0d2a552f49918a5c585d690125", "2": "0d25c5d7-a26d-4ea1-b4a5-696f569d50b5"}}, "__type__": "1"}, "991fc9d6-8cd4-45cb-986a-273a4be18677": {"__data__": {"text": "---\ntitle: List of functions and operators\n---\n\n# \\#\n\n-   `[] substring operator <subscript_operator>`{.interpreted-text\n    role=\"ref\"}\n-   `|| concatenation operator <concatenation_operator>`{.interpreted-text\n    role=\"ref\"}\n-   `\\< comparison operator <comparison_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `\\> comparison operator <comparison_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `<= comparison operator <comparison_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `>= comparison operator <comparison_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `= comparison operator <comparison_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `<> comparison operator <comparison_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `\\!= comparison operator <comparison_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `-> lambda expression <lambda_expressions>`{.interpreted-text\n    role=\"ref\"}\n-   `+ mathematical operator <mathematical_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `- mathematical operator <mathematical_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `* mathematical operator <mathematical_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `/ mathematical operator <mathematical_operators>`{.interpreted-text\n    role=\"ref\"}\n-   `% mathematical operator <mathematical_operators>`{.interpreted-text\n    role=\"ref\"}\n\n# A\n\n-   `abs`{.interpreted-text role=\"func\"}\n-   `acos`{.interpreted-text role=\"func\"}\n-   `ALL <quantified_comparison_predicates>`{.interpreted-text\n    role=\"ref\"}\n-   `all_match`{.interpreted-text role=\"func\"}\n-   `AND <logical_operators>`{.interpreted-text role=\"ref\"}\n-   `ANY <quantified_comparison_predicates>`{.interpreted-text\n    role=\"ref\"}\n-   `any_match`{.interpreted-text role=\"func\"}\n-   `approx_distinct`{.interpreted-text role=\"func\"}\n-   `approx_most_frequent`{.interpreted-text role=\"func\"}\n-   `approx_percentile`{.interpreted-text role=\"func\"}\n-   `approx_set`{.interpreted-text role=\"func\"}\n-   `arbitrary`{.interpreted-text role=\"func\"}\n-   `array_agg`{.interpreted-text role=\"func\"}\n-   `array_distinct`{.interpreted-text role=\"func\"}\n-   `array_except`{.interpreted-text role=\"func\"}\n-   `array_intersect`{.interpreted-text role=\"func\"}\n-   `array_join`{.interpreted-text role=\"func\"}\n-   `array_max`{.interpreted-text role=\"func\"}\n-   `array_min`{.interpreted-text role=\"func\"}\n-   `array_position`{.interpreted-text role=\"func\"}\n-   `array_remove`{.interpreted-text role=\"func\"}\n-   `array_sort`{.interpreted-text role=\"func\"}\n-  ", "doc_id": "991fc9d6-8cd4-45cb-986a-273a4be18677", "embedding": null, "doc_hash": "d16e2b9ca3fc505ddfaf8a9da8dec9fe1b33cf52fa68807ecbee0b5226189a34", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}, "node_info": {"start": 0, "end": 2516, "_node_type": "1"}, "relationships": {"1": "3835cf4523eb2e570be91df2075436476b9df2a0", "3": "c79cb631-9334-4f74-929a-302aba46aa37"}}, "__type__": "1"}, "c79cb631-9334-4f74-929a-302aba46aa37": {"__data__": {"text": " `array_sort`{.interpreted-text role=\"func\"}\n-   `array_union`{.interpreted-text role=\"func\"}\n-   `arrays_overlap`{.interpreted-text role=\"func\"}\n-   `asin`{.interpreted-text role=\"func\"}\n-   `AT TIME ZONE <at_time_zone_operator>`{.interpreted-text role=\"ref\"}\n-   `at_timezone`{.interpreted-text role=\"func\"}\n-   `atan`{.interpreted-text role=\"func\"}\n-   `atan2`{.interpreted-text role=\"func\"}\n-   `avg`{.interpreted-text role=\"func\"}\n\n# B\n\n-   `bar`{.interpreted-text role=\"func\"}\n-   `beta_cdf`{.interpreted-text role=\"func\"}\n-   `BETWEEN <range_operator>`{.interpreted-text role=\"ref\"}\n-   `bing_tile`{.interpreted-text role=\"func\"}\n-   `bing_tile_at`{.interpreted-text role=\"func\"}\n-   `bing_tile_coordinates`{.interpreted-text role=\"func\"}\n-   `bing_tile_polygon`{.interpreted-text role=\"func\"}\n-   `bing_tile_quadkey`{.interpreted-text role=\"func\"}\n-   `bing_tile_zoom_level`{.interpreted-text role=\"func\"}\n-   `bing_tiles_around`{.interpreted-text role=\"func\"}\n-   `bit_count`{.interpreted-text role=\"func\"}\n-   `bitwise_and`{.interpreted-text role=\"func\"}\n-   `bitwise_and_agg`{.interpreted-text role=\"func\"}\n-   `bitwise_left_shift`{.interpreted-text role=\"func\"}\n-   `bitwise_not`{.interpreted-text role=\"func\"}\n-   `bitwise_or`{.interpreted-text role=\"func\"}\n-   `bitwise_or_agg`{.interpreted-text role=\"func\"}\n-   `bitwise_right_shift`{.interpreted-text role=\"func\"}\n-   `bitwise_right_shift_arithmetic`{.interpreted-text role=\"func\"}\n-   `bitwise_xor`{.interpreted-text role=\"func\"}\n-   `bool_and`{.interpreted-text role=\"func\"}\n-   `bool_or`{.interpreted-text role=\"func\"}\n\n# C\n\n-   `cardinality`{.interpreted-text role=\"func\"}\n-   `CASE <case_expression>`{.interpreted-text role=\"ref\"}\n-   `cast`{.interpreted-text role=\"func\"}\n-   `cbrt`{.interpreted-text role=\"func\"}\n-   `ceil`{.interpreted-text role=\"func\"}\n-   `ceiling`{.interpreted-text role=\"func\"}\n-   `char2hexint`{.interpreted-text role=\"func\"}\n-   `checksum`{.interpreted-text role=\"func\"}\n-   `chr`{.interpreted-text role=\"func\"}\n-   `classify`{.interpreted-text role=\"func\"}\n-   `coalesce <coalesce_function>`{.interpreted-text role=\"ref\"}\n-   `codepoint`{.interpreted-text role=\"func\"}\n-   `color`{.interpreted-text role=\"func\"}\n-   `combinations`{.interpreted-text role=\"func\"}\n-   `concat`{.interpreted-text role=\"func\"}\n-   `concat_ws`{.interpreted-text role=\"func\"}\n-   `contains`{.interpreted-text role=\"func\"}\n-  ", "doc_id": "c79cb631-9334-4f74-929a-302aba46aa37", "embedding": null, "doc_hash": "5ce65a082766efd4699e2dadb06689cfa78057e7fd7e2819903bce9e73267619", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}, "node_info": {"start": 2473, "end": 4873, "_node_type": "1"}, "relationships": {"1": "3835cf4523eb2e570be91df2075436476b9df2a0", "2": "991fc9d6-8cd4-45cb-986a-273a4be18677", "3": "7aa6553a-d662-4300-b24a-bebb1b3c9966"}}, "__type__": "1"}, "7aa6553a-d662-4300-b24a-bebb1b3c9966": {"__data__": {"text": "  `contains`{.interpreted-text role=\"func\"}\n-   `contains_sequence`{.interpreted-text role=\"func\"}\n-   `convex_hull_agg`{.interpreted-text role=\"func\"}\n-   `corr`{.interpreted-text role=\"func\"}\n-   `cos`{.interpreted-text role=\"func\"}\n-   `cosh`{.interpreted-text role=\"func\"}\n-   `cosine_similarity`{.interpreted-text role=\"func\"}\n-   `count`{.interpreted-text role=\"func\"}\n-   `count_if`{.interpreted-text role=\"func\"}\n-   `covar_pop`{.interpreted-text role=\"func\"}\n-   `covar_samp`{.interpreted-text role=\"func\"}\n-   `crc32`{.interpreted-text role=\"func\"}\n-   `cume_dist`{.interpreted-text role=\"func\"}\n-   `current_date`{.interpreted-text role=\"data\"}\n-   `current_groups`{.interpreted-text role=\"func\"}\n-   `current_time`{.interpreted-text role=\"data\"}\n-   `current_timestamp`{.interpreted-text role=\"data\"}\n-   `current_timezone`{.interpreted-text role=\"func\"}\n-   `current_user`{.interpreted-text role=\"data\"}\n\n# D\n\n-   `date`{.interpreted-text role=\"func\"}\n-   `date_add`{.interpreted-text role=\"func\"}\n-   `date_diff`{.interpreted-text role=\"func\"}\n-   `date_format`{.interpreted-text role=\"func\"}\n-   `date_parse`{.interpreted-text role=\"func\"}\n-   `date_trunc`{.interpreted-text role=\"func\"}\n-   `day`{.interpreted-text role=\"func\"}\n-   `day_of_month`{.interpreted-text role=\"func\"}\n-   `day_of_week`{.interpreted-text role=\"func\"}\n-   `day_of_year`{.interpreted-text role=\"func\"}\n-   `DECIMAL <decimal_literal>`{.interpreted-text role=\"ref\"}\n-   `degrees`{.interpreted-text role=\"func\"}\n-   `dense_rank`{.interpreted-text role=\"func\"}\n-   `dow`{.interpreted-text role=\"func\"}\n-   `doy`{.interpreted-text role=\"func\"}\n\n# E\n\n-   `e`{.interpreted-text role=\"func\"}\n-   `element_at`{.interpreted-text role=\"func\"}\n-   `empty_approx_set`{.interpreted-text role=\"func\"}\n-   `evaluate_classifier_predictions`\n-   `every`{.interpreted-text role=\"func\"}\n-   `extract`{.interpreted-text role=\"func\"}\n-   `exp`{.interpreted-text role=\"func\"}\n\n# F\n\n-   `features`{.interpreted-text role=\"func\"}\n-   `filter`{.interpreted-text role=\"func\"}\n-   `f_value`{.interpreted-text role=\"func\"}\n-   `flatten`{.interpreted-text role=\"func\"}\n-   `floor`{.interpreted-text role=\"func\"}\n-   `format`{.interpreted-text role=\"func\"}\n-   `format_datetime`{.interpreted-text role=\"func\"}\n-   `format_number`{.interpreted-text role=\"func\"}\n-   `from_base`{.interpreted-text role=\"func\"}\n-   `from_base32`{.interpreted-text role=\"func\"}\n-  ", "doc_id": "7aa6553a-d662-4300-b24a-bebb1b3c9966", "embedding": null, "doc_hash": "a0488238bdb4e4c3b07a863c57a5b56b23b8077a6b868a571e0d920ab5cc2fe9", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}, "node_info": {"start": 4876, "end": 7295, "_node_type": "1"}, "relationships": {"1": "3835cf4523eb2e570be91df2075436476b9df2a0", "2": "c79cb631-9334-4f74-929a-302aba46aa37", "3": "1086a26c-c8a2-4b93-a381-555673ddcc8c"}}, "__type__": "1"}, "1086a26c-c8a2-4b93-a381-555673ddcc8c": {"__data__": {"text": "`from_base32`{.interpreted-text role=\"func\"}\n-   `from_base64`{.interpreted-text role=\"func\"}\n-   `from_base64url`{.interpreted-text role=\"func\"}\n-   `from_big_endian_32`{.interpreted-text role=\"func\"}\n-   `from_big_endian_64`{.interpreted-text role=\"func\"}\n-   `from_encoded_polyline`{.interpreted-text role=\"func\"}\n-   `from_geojson_geometry`\n-   `from_hex`{.interpreted-text role=\"func\"}\n-   `from_ieee754_32`{.interpreted-text role=\"func\"}\n-   `from_ieee754_64`{.interpreted-text role=\"func\"}\n-   `from_iso8601_date`{.interpreted-text role=\"func\"}\n-   `from_iso8601_timestamp`{.interpreted-text role=\"func\"}\n-   `from_iso8601_timestamp_nanos`{.interpreted-text role=\"func\"}\n-   `from_unixtime`{.interpreted-text role=\"func\"}\n-   `from_unixtime_nanos`{.interpreted-text role=\"func\"}\n-   `from_utf8`{.interpreted-text role=\"func\"}\n\n# G\n\n-   `geometric_mean`{.interpreted-text role=\"func\"}\n-   `geometry_from_hadoop_shape`{.interpreted-text role=\"func\"}\n-   `geometry_invalid_reason`{.interpreted-text role=\"func\"}\n-   `geometry_nearest_points`{.interpreted-text role=\"func\"}\n-   `geometry_to_bing_tiles`{.interpreted-text role=\"func\"}\n-   `geometry_union`{.interpreted-text role=\"func\"}\n-   `geometry_union_agg`{.interpreted-text role=\"func\"}\n-   `great_circle_distance`{.interpreted-text role=\"func\"}\n-   `greatest`{.interpreted-text role=\"func\"}\n\n# H\n\n-   `hamming_distance`{.interpreted-text role=\"func\"}\n-   `hash_counts`{.interpreted-text role=\"func\"}\n-   `histogram`{.interpreted-text role=\"func\"}\n-   `hmac_md5`{.interpreted-text role=\"func\"}\n-   `hmac_sha1`{.interpreted-text role=\"func\"}\n-   `hmac_sha256`{.interpreted-text role=\"func\"}\n-   `hmac_sha512`{.interpreted-text role=\"func\"}\n-   `hour`{.interpreted-text role=\"func\"}\n-   `human_readable_seconds`{.interpreted-text role=\"func\"}\n\n# I\n\n-   `if <if_function>`{.interpreted-text role=\"ref\"}\n-   `index`{.interpreted-text role=\"func\"}\n-   `infinity`{.interpreted-text role=\"func\"}\n-   `intersection_cardinality`{.interpreted-text role=\"func\"}\n-   `inverse_beta_cdf`{.interpreted-text role=\"func\"}\n-   `inverse_normal_cdf`{.interpreted-text role=\"func\"}\n-   `is_finite`{.interpreted-text role=\"func\"}\n-   `is_infinite`{.interpreted-text role=\"func\"}\n-   `is_json_scalar`{.interpreted-text role=\"func\"}\n-   `is_nan`{.interpreted-text role=\"func\"}\n-   `IS NOT DISTINCT <is_distinct_operator>`{.interpreted-text\n    role=\"ref\"}\n-   `IS NOT NULL", "doc_id": "1086a26c-c8a2-4b93-a381-555673ddcc8c", "embedding": null, "doc_hash": "525f623bf5470fb2df0884609e9620fbff4bc3c26502c7891d12c6bb8fac9558", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}, "node_info": {"start": 7293, "end": 9699, "_node_type": "1"}, "relationships": {"1": "3835cf4523eb2e570be91df2075436476b9df2a0", "2": "7aa6553a-d662-4300-b24a-bebb1b3c9966", "3": "6b822332-752c-4865-9c14-aeca89ec6091"}}, "__type__": "1"}, "6b822332-752c-4865-9c14-aeca89ec6091": {"__data__": {"text": "   role=\"ref\"}\n-   `IS NOT NULL <is_null_operator>`{.interpreted-text role=\"ref\"}\n-   `IS DISTINCT <is_distinct_operator>`{.interpreted-text role=\"ref\"}\n-   `IS NULL <is_null_operator>`{.interpreted-text role=\"ref\"}\n\n# J\n\n-   `jaccard_index`{.interpreted-text role=\"func\"}\n-   `json_array() <json_array>`{.interpreted-text role=\"ref\"}\n-   `json_array_contains`{.interpreted-text role=\"func\"}\n-   `json_array_get`{.interpreted-text role=\"func\"}\n-   `json_array_length`{.interpreted-text role=\"func\"}\n-   `json_exists() <json_exists>`{.interpreted-text role=\"ref\"}\n-   `json_extract`{.interpreted-text role=\"func\"}\n-   `json_extract_scalar`{.interpreted-text role=\"func\"}\n-   `json_format`{.interpreted-text role=\"func\"}\n-   `json_object() <json_object>`{.interpreted-text role=\"ref\"}\n-   `json_parse`{.interpreted-text role=\"func\"}\n-   `json_query() <json_query>`{.interpreted-text role=\"ref\"}\n-   `json_size`{.interpreted-text role=\"func\"}\n-   `json_value() <json_value>`{.interpreted-text role=\"ref\"}\n\n# K\n\n-   `kurtosis`{.interpreted-text role=\"func\"}\n\n# L\n\n-   `lag`{.interpreted-text role=\"func\"}\n-   `last_day_of_month`{.interpreted-text role=\"func\"}\n-   `last_value`{.interpreted-text role=\"func\"}\n-   `lead`{.interpreted-text role=\"func\"}\n-   `learn_classifier`{.interpreted-text role=\"func\"}\n-   `learn_libsvm_classifier`{.interpreted-text role=\"func\"}\n-   `learn_libsvm_regressor`{.interpreted-text role=\"func\"}\n-   `learn_regressor`{.interpreted-text role=\"func\"}\n-   `least`{.interpreted-text role=\"func\"}\n-   `length`{.interpreted-text role=\"func\"}\n-   `levenshtein_distance`{.interpreted-text role=\"func\"}\n-   `line_interpolate_point`{.interpreted-text role=\"func\"}\n-   `line_interpolate_points`{.interpreted-text role=\"func\"}\n-   `line_locate_point`{.interpreted-text role=\"func\"}\n-   `listagg`{.interpreted-text role=\"func\"}\n-   `ln`{.interpreted-text role=\"func\"}\n-   `localtime`{.interpreted-text role=\"data\"}\n-   `localtimestamp`{.interpreted-text role=\"data\"}\n-   `log`{.interpreted-text role=\"func\"}\n-   `log10`{.interpreted-text role=\"func\"}\n-   `log2`{.interpreted-text role=\"func\"}\n-   `lower`{.interpreted-text role=\"func\"}\n-   `lpad`{.interpreted-text role=\"func\"}\n-   `ltrim`{.interpreted-text role=\"func\"}\n-   `luhn_check`{.interpreted-text role=\"func\"}\n\n# M\n\n-   `make_set_digest`{.interpreted-text role=\"func\"}\n-   `map`{.interpreted-text role=\"func\"}\n-   `map_agg`{.interpreted-text role=\"func\"}\n- ", "doc_id": "6b822332-752c-4865-9c14-aeca89ec6091", "embedding": null, "doc_hash": "6817c899cb999fe062a3f2d551bd25fc8520bfd53afe1925e8ded09f6f853f51", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}, "node_info": {"start": 9722, "end": 12150, "_node_type": "1"}, "relationships": {"1": "3835cf4523eb2e570be91df2075436476b9df2a0", "2": "1086a26c-c8a2-4b93-a381-555673ddcc8c", "3": "bcf61072-3ca2-4852-a9bd-f1ea0486a6dd"}}, "__type__": "1"}, "bcf61072-3ca2-4852-a9bd-f1ea0486a6dd": {"__data__": {"text": "  `map_agg`{.interpreted-text role=\"func\"}\n-   `map_concat`{.interpreted-text role=\"func\"}\n-   `map_entries`{.interpreted-text role=\"func\"}\n-   `map_filter`{.interpreted-text role=\"func\"}\n-   `map_from_entries`{.interpreted-text role=\"func\"}\n-   `map_keys`{.interpreted-text role=\"func\"}\n-   `map_union`{.interpreted-text role=\"func\"}\n-   `map_values`{.interpreted-text role=\"func\"}\n-   `map_zip_with`{.interpreted-text role=\"func\"}\n-   `max`{.interpreted-text role=\"func\"}\n-   `max_by`{.interpreted-text role=\"func\"}\n-   `md5`{.interpreted-text role=\"func\"}\n-   `merge`{.interpreted-text role=\"func\"}\n-   `merge_set_digest`{.interpreted-text role=\"func\"}\n-   `millisecond`{.interpreted-text role=\"func\"}\n-   `min`{.interpreted-text role=\"func\"}\n-   `min_by`{.interpreted-text role=\"func\"}\n-   `minute`{.interpreted-text role=\"func\"}\n-   `mod`{.interpreted-text role=\"func\"}\n-   `month`{.interpreted-text role=\"func\"}\n-   `multimap_agg`{.interpreted-text role=\"func\"}\n-   `multimap_from_entries`{.interpreted-text role=\"func\"}\n-   `murmur3`{.interpreted-text role=\"func\"}\n\n# N\n\n-   `nan`{.interpreted-text role=\"func\"}\n-   `ngrams`{.interpreted-text role=\"func\"}\n-   `none_match`{.interpreted-text role=\"func\"}\n-   `normal_cdf`{.interpreted-text role=\"func\"}\n-   `normalize`{.interpreted-text role=\"func\"}\n-   `NOT <logical_operators>`{.interpreted-text role=\"ref\"}\n-   `NOT BETWEEN <range_operator>`{.interpreted-text role=\"ref\"}\n-   `now`{.interpreted-text role=\"func\"}\n-   `nth_value`{.interpreted-text role=\"func\"}\n-   `ntile`{.interpreted-text role=\"func\"}\n-   `nullif <nullif_function>`{.interpreted-text role=\"ref\"}\n-   `numeric_histogram`{.interpreted-text role=\"func\"}\n\n# O\n\n-   `objectid`\n-   `objectid_timestamp`{.interpreted-text role=\"func\"}\n-   `OR <logical_operators>`{.interpreted-text role=\"ref\"}\n\n# P\n\n-   `parse_datetime`{.interpreted-text role=\"func\"}\n-   `parse_duration`{.interpreted-text role=\"func\"}\n-   `parse_data_size`{.interpreted-text role=\"func\"}\n-   `percent_rank`{.interpreted-text role=\"func\"}\n-   `pi`{.interpreted-text role=\"func\"}\n-   `position`{.interpreted-text role=\"func\"}\n-   `pow`{.interpreted-text role=\"func\"}\n-   `power`{.interpreted-text role=\"func\"}\n\n# Q\n\n-   `qdigest_agg`{.interpreted-text role=\"func\"}\n-   `quarter`{.interpreted-text role=\"func\"}\n\n# R\n\n-   `radians`{.interpreted-text role=\"func\"}\n-   `rand`{.interpreted-text role=\"func\"}\n-  ", "doc_id": "bcf61072-3ca2-4852-a9bd-f1ea0486a6dd", "embedding": null, "doc_hash": "a0749d26086286094d4657867a4f66ee7983193fbc52ceab67c0be774dcacc58", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}, "node_info": {"start": 12133, "end": 14526, "_node_type": "1"}, "relationships": {"1": "3835cf4523eb2e570be91df2075436476b9df2a0", "2": "6b822332-752c-4865-9c14-aeca89ec6091", "3": "a93c4ede-134c-4389-8b9b-5bfeba630a6a"}}, "__type__": "1"}, "a93c4ede-134c-4389-8b9b-5bfeba630a6a": {"__data__": {"text": "  `rand`{.interpreted-text role=\"func\"}\n-   `random`{.interpreted-text role=\"func\"}\n-   `rank`{.interpreted-text role=\"func\"}\n-   `reduce`{.interpreted-text role=\"func\"}\n-   `reduce_agg`{.interpreted-text role=\"func\"}\n-   `regexp_count`{.interpreted-text role=\"func\"}\n-   `regexp_extract`{.interpreted-text role=\"func\"}\n-   `regexp_extract_all`{.interpreted-text role=\"func\"}\n-   `regexp_like`{.interpreted-text role=\"func\"}\n-   `regexp_position`{.interpreted-text role=\"func\"}\n-   `regexp_replace`{.interpreted-text role=\"func\"}\n-   `regexp_split`{.interpreted-text role=\"func\"}\n-   `regress`{.interpreted-text role=\"func\"}\n-   `regr_intercept`{.interpreted-text role=\"func\"}\n-   `regr_slope`{.interpreted-text role=\"func\"}\n-   `render`{.interpreted-text role=\"func\"}\n-   `repeat`{.interpreted-text role=\"func\"}\n-   `replace`{.interpreted-text role=\"func\"}\n-   `reverse`{.interpreted-text role=\"func\"}\n-   `rgb`{.interpreted-text role=\"func\"}\n-   `round`{.interpreted-text role=\"func\"}\n-   `row_number`{.interpreted-text role=\"func\"}\n-   `rpad`{.interpreted-text role=\"func\"}\n-   `rtrim`{.interpreted-text role=\"func\"}\n\n# S\n\n-   `second`{.interpreted-text role=\"func\"}\n-   `sequence`{.interpreted-text role=\"func\"}\n-   `sha1`{.interpreted-text role=\"func\"}\n-   `sha256`{.interpreted-text role=\"func\"}\n-   `sha512`{.interpreted-text role=\"func\"}\n-   `shuffle`{.interpreted-text role=\"func\"}\n-   `sign`{.interpreted-text role=\"func\"}\n-   `simplify_geometry`{.interpreted-text role=\"func\"}\n-   `sin`{.interpreted-text role=\"func\"}\n-   `skewness`{.interpreted-text role=\"func\"}\n-   `slice`{.interpreted-text role=\"func\"}\n-   `SOME <quantified_comparison_predicates>`{.interpreted-text\n    role=\"ref\"}\n-   `soundex`{.interpreted-text role=\"func\"}\n-   `spatial_partitioning`\n-   `spatial_partitions`\n-   `split`{.interpreted-text role=\"func\"}\n-   `split_part`{.interpreted-text role=\"func\"}\n-   `split_to_map`{.interpreted-text role=\"func\"}\n-   `split_to_multimap`{.interpreted-text role=\"func\"}\n-   `spooky_hash_v2_32`{.interpreted-text role=\"func\"}\n-   `spooky_hash_v2_64`{.interpreted-text role=\"func\"}\n-   `sqrt`{.interpreted-text role=\"func\"}\n-   `ST_Area`{.interpreted-text role=\"func\"}\n-   `ST_AsBinary`{.interpreted-text role=\"func\"}\n-   `ST_AsText`{.interpreted-text role=\"func\"}\n-   `ST_Boundary`{.interpreted-text role=\"func\"}\n-   `ST_Buffer`{.interpreted-text role=\"func\"}\n-  ", "doc_id": "a93c4ede-134c-4389-8b9b-5bfeba630a6a", "embedding": null, "doc_hash": "2e2ecf492d2966f0f3d43bc297dcd2d708e4393e5c256e4c1a607c42fe929404", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}, "node_info": {"start": 14530, "end": 16913, "_node_type": "1"}, "relationships": {"1": "3835cf4523eb2e570be91df2075436476b9df2a0", "2": "bcf61072-3ca2-4852-a9bd-f1ea0486a6dd", "3": "3b8f9544-0db4-49df-9eec-2f16be0fa94a"}}, "__type__": "1"}, "3b8f9544-0db4-49df-9eec-2f16be0fa94a": {"__data__": {"text": " `ST_Buffer`{.interpreted-text role=\"func\"}\n-   `ST_Centroid`{.interpreted-text role=\"func\"}\n-   `ST_Contains`{.interpreted-text role=\"func\"}\n-   `ST_ConvexHull`{.interpreted-text role=\"func\"}\n-   `ST_CoordDim`{.interpreted-text role=\"func\"}\n-   `ST_Crosses`{.interpreted-text role=\"func\"}\n-   `ST_Difference`{.interpreted-text role=\"func\"}\n-   `ST_Dimension`{.interpreted-text role=\"func\"}\n-   `ST_Disjoint`{.interpreted-text role=\"func\"}\n-   `ST_Distance`{.interpreted-text role=\"func\"}\n-   `ST_EndPoint`{.interpreted-text role=\"func\"}\n-   `ST_Envelope`{.interpreted-text role=\"func\"}\n-   `ST_EnvelopeAsPts`{.interpreted-text role=\"func\"}\n-   `ST_Equals`{.interpreted-text role=\"func\"}\n-   `ST_ExteriorRing`{.interpreted-text role=\"func\"}\n-   `ST_Geometries`{.interpreted-text role=\"func\"}\n-   `ST_GeometryFromText`{.interpreted-text role=\"func\"}\n-   `ST_GeometryN`{.interpreted-text role=\"func\"}\n-   `ST_GeometryType`{.interpreted-text role=\"func\"}\n-   `ST_GeomFromBinary`{.interpreted-text role=\"func\"}\n-   `ST_InteriorRingN`{.interpreted-text role=\"func\"}\n-   `ST_InteriorRings`{.interpreted-text role=\"func\"}\n-   `ST_Intersection`{.interpreted-text role=\"func\"}\n-   `ST_Intersects`{.interpreted-text role=\"func\"}\n-   `ST_IsClosed`{.interpreted-text role=\"func\"}\n-   `ST_IsEmpty`{.interpreted-text role=\"func\"}\n-   `ST_IsRing`{.interpreted-text role=\"func\"}\n-   `ST_IsSimple`{.interpreted-text role=\"func\"}\n-   `ST_IsValid`{.interpreted-text role=\"func\"}\n-   `ST_Length`{.interpreted-text role=\"func\"}\n-   `ST_LineFromText`{.interpreted-text role=\"func\"}\n-   `ST_LineString`{.interpreted-text role=\"func\"}\n-   `ST_MultiPoint`{.interpreted-text role=\"func\"}\n-   `ST_NumGeometries`{.interpreted-text role=\"func\"}\n-   `ST_NumInteriorRing`\n-   `ST_NumPoints`{.interpreted-text role=\"func\"}\n-   `ST_Overlaps`{.interpreted-text role=\"func\"}\n-   `ST_Point`{.interpreted-text role=\"func\"}\n-   `ST_PointN`{.interpreted-text role=\"func\"}\n-   `ST_Points`{.interpreted-text role=\"func\"}\n-   `ST_Polygon`{.interpreted-text role=\"func\"}\n-   `ST_Relate`{.interpreted-text role=\"func\"}\n-   `ST_StartPoint`{.interpreted-text role=\"func\"}\n-   `ST_SymDifference`{.interpreted-text role=\"func\"}\n-   `ST_Touches`{.interpreted-text role=\"func\"}\n-   `ST_Union`{.interpreted-text role=\"func\"}\n-   `ST_Within`{.interpreted-text role=\"func\"}\n-   `ST_X`{.interpreted-text role=\"func\"}\n-   `ST_XMax`{.interpreted-text", "doc_id": "3b8f9544-0db4-49df-9eec-2f16be0fa94a", "embedding": null, "doc_hash": "cfa23624a8c6da88804d978faae1d33b5c4e90da92b5d094e865de334be7b6fb", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}, "node_info": {"start": 16909, "end": 19303, "_node_type": "1"}, "relationships": {"1": "3835cf4523eb2e570be91df2075436476b9df2a0", "2": "a93c4ede-134c-4389-8b9b-5bfeba630a6a", "3": "563221d2-b46c-4ddb-a62a-3c13a6c618dc"}}, "__type__": "1"}, "563221d2-b46c-4ddb-a62a-3c13a6c618dc": {"__data__": {"text": "role=\"func\"}\n-   `ST_XMax`{.interpreted-text role=\"func\"}\n-   `ST_XMin`{.interpreted-text role=\"func\"}\n-   `ST_Y`{.interpreted-text role=\"func\"}\n-   `ST_YMax`{.interpreted-text role=\"func\"}\n-   `ST_YMin`{.interpreted-text role=\"func\"}\n-   `starts_with`{.interpreted-text role=\"func\"}\n-   `stddev`{.interpreted-text role=\"func\"}\n-   `stddev_pop`{.interpreted-text role=\"func\"}\n-   `stddev_samp`{.interpreted-text role=\"func\"}\n-   `strpos`{.interpreted-text role=\"func\"}\n-   `substr`{.interpreted-text role=\"func\"}\n-   `substring`{.interpreted-text role=\"func\"}\n-   `sum`{.interpreted-text role=\"func\"}\n\n# T\n\n-   `tan`{.interpreted-text role=\"func\"}\n-   `tanh`{.interpreted-text role=\"func\"}\n-   `tdigest_agg`{.interpreted-text role=\"func\"}\n-   `timestamp_objectid`{.interpreted-text role=\"func\"}\n-   `timezone_hour`{.interpreted-text role=\"func\"}\n-   `timezone_minute`{.interpreted-text role=\"func\"}\n-   `to_base`{.interpreted-text role=\"func\"}\n-   `to_base32`{.interpreted-text role=\"func\"}\n-   `to_base64`{.interpreted-text role=\"func\"}\n-   `to_base64url`{.interpreted-text role=\"func\"}\n-   `to_big_endian_32`{.interpreted-text role=\"func\"}\n-   `to_big_endian_64`{.interpreted-text role=\"func\"}\n-   `to_char`{.interpreted-text role=\"func\"}\n-   `to_date`{.interpreted-text role=\"func\"}\n-   `to_encoded_polyline`{.interpreted-text role=\"func\"}\n-   `to_geojson_geometry`\n-   `to_geometry`{.interpreted-text role=\"func\"}\n-   `to_hex`{.interpreted-text role=\"func\"}\n-   `to_ieee754_32`{.interpreted-text role=\"func\"}\n-   `to_ieee754_64`{.interpreted-text role=\"func\"}\n-   `to_iso8601`{.interpreted-text role=\"func\"}\n-   `to_milliseconds`{.interpreted-text role=\"func\"}\n-   `to_spherical_geography`{.interpreted-text role=\"func\"}\n-   `to_timestamp`{.interpreted-text role=\"func\"}\n-   `to_unixtime`{.interpreted-text role=\"func\"}\n-   `to_utf8`{.interpreted-text role=\"func\"}\n-   `transform`{.interpreted-text role=\"func\"}\n-   `transform_keys`{.interpreted-text role=\"func\"}\n-   `transform_values`{.interpreted-text role=\"func\"}\n-   `translate`{.interpreted-text role=\"func\"}\n-   `trim`{.interpreted-text role=\"func\"}\n-   `trim_array`{.interpreted-text role=\"func\"}\n-   `truncate`{.interpreted-text role=\"func\"}\n-   `try <try_function>`{.interpreted-text role=\"ref\"}\n-   `try_cast`{.interpreted-text role=\"func\"}\n-   `typeof`{.interpreted-text role=\"func\"}\n\n# U\n\n- ", "doc_id": "563221d2-b46c-4ddb-a62a-3c13a6c618dc", "embedding": null, "doc_hash": "e5d742fea536641776a46272dafbaa895e0209eb03b9271f9ff5cfac29d0a3de", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}, "node_info": {"start": 19306, "end": 21664, "_node_type": "1"}, "relationships": {"1": "3835cf4523eb2e570be91df2075436476b9df2a0", "2": "3b8f9544-0db4-49df-9eec-2f16be0fa94a", "3": "fe89d6a5-3c1c-4d65-bce4-be1b9470ca35"}}, "__type__": "1"}, "fe89d6a5-3c1c-4d65-bce4-be1b9470ca35": {"__data__": {"text": "role=\"func\"}\n\n# U\n\n-   `upper`{.interpreted-text role=\"func\"}\n-   `url_decode`{.interpreted-text role=\"func\"}\n-   `url_encode`{.interpreted-text role=\"func\"}\n-   `url_extract_fragment`{.interpreted-text role=\"func\"}\n-   `url_extract_host`{.interpreted-text role=\"func\"}\n-   `url_extract_parameter`{.interpreted-text role=\"func\"}\n-   `url_extract_path`{.interpreted-text role=\"func\"}\n-   `url_extract_protocol`{.interpreted-text role=\"func\"}\n-   `url_extract_port`{.interpreted-text role=\"func\"}\n-   `url_extract_query`{.interpreted-text role=\"func\"}\n-   `uuid`{.interpreted-text role=\"func\"}\n\n# V\n\n-   `value_at_quantile`{.interpreted-text role=\"func\"}\n-   `values_at_quantiles`{.interpreted-text role=\"func\"}\n-   `var_pop`{.interpreted-text role=\"func\"}\n-   `var_samp`{.interpreted-text role=\"func\"}\n-   `variance`{.interpreted-text role=\"func\"}\n-   `version`{.interpreted-text role=\"func\"}\n\n# W\n\n-   `week`{.interpreted-text role=\"func\"}\n-   `week_of_year`{.interpreted-text role=\"func\"}\n-   `width_bucket`{.interpreted-text role=\"func\"}\n-   `wilson_interval_lower`{.interpreted-text role=\"func\"}\n-   `wilson_interval_upper`{.interpreted-text role=\"func\"}\n-   `with_timezone`{.interpreted-text role=\"func\"}\n-   `word_stem`{.interpreted-text role=\"func\"}\n\n# X\n\n-   `xxhash64`{.interpreted-text role=\"func\"}\n\n# Y\n\n-   `year`{.interpreted-text role=\"func\"}\n-   `year_of_week`{.interpreted-text role=\"func\"}\n-   `yow`{.interpreted-text role=\"func\"}\n\n# Z\n\n-   `zip`{.interpreted-text role=\"func\"}\n-   `zip_with`{.interpreted-text role=\"func\"}\n", "doc_id": "fe89d6a5-3c1c-4d65-bce4-be1b9470ca35", "embedding": null, "doc_hash": "8edcd84a02e33fd559aa9f8a77dcd5b34eff41f4e1bf3f9645fbd5889b314118", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}, "node_info": {"start": 21684, "end": 23224, "_node_type": "1"}, "relationships": {"1": "3835cf4523eb2e570be91df2075436476b9df2a0", "2": "563221d2-b46c-4ddb-a62a-3c13a6c618dc"}}, "__type__": "1"}, "6e715757-924a-4eaa-a77f-595f0628af0e": {"__data__": {"text": "---\ntitle: Logical operators\n---\n\n## Logical operators\n\n| Operator | Description                  | Example  |\n|----------|------------------------------|----------|\n| `AND`    | True if both values are true | a AND b  |\n| `OR`     | True if either value is true | a OR b   |\n| `NOT`    | True if the value is false   | NOT a    |\n\n## Effect of NULL on logical operators\n\nThe result of an `AND` comparison may be `NULL` if one or both sides of\nthe expression are `NULL`. If at least one side of an `AND` operator is\n`FALSE` the expression evaluates to `FALSE`:\n```sql\n    SELECT CAST(null AS boolean) AND true; -- null\n\n    SELECT CAST(null AS boolean) AND false; -- false\n\n    SELECT CAST(null AS boolean) AND CAST(null AS boolean); -- null\n```\nThe result of an `OR` comparison may be `NULL` if one or both sides of\nthe expression are `NULL`. If at least one side of an `OR` operator is\n`TRUE` the expression evaluates to `TRUE`:\n```sql\n    SELECT CAST(null AS boolean) OR CAST(null AS boolean); -- null\n\n    SELECT CAST(null AS boolean) OR false; -- null\n\n    SELECT CAST(null AS boolean) OR true; -- true\n```\n\nThe following truth table demonstrates the handling of `NULL` in `AND`\nand `OR`:\n\n| a       | b       | a AND b | a OR b |\n|---------|---------|---------|--------|\n| `TRUE`  | `TRUE`  | `TRUE`  | `TRUE` |\n| `TRUE`  | `FALSE` | `FALSE` | `TRUE` |\n| `TRUE`  | `NULL`  | `NULL`  | `TRUE` |\n| `FALSE` | `TRUE`  | `FALSE` | `TRUE` |\n| `FALSE` | `FALSE` | `FALSE` | `FALSE`|\n| `FALSE` | `NULL`  | `FALSE` | `NULL` |\n| `NULL`  | `TRUE`  | `NULL`  | `TRUE` |\n| `NULL`  | `FALSE` | `FALSE` | `NULL` |\n| `NULL`  | `NULL`  | `NULL`  | `NULL` |\n\nThe logical complement of `NULL` is `NULL` as shown in the following\nexample:\n```sql\n    SELECT NOT CAST(null AS boolean); -- null\n```\nThe following truth table demonstrates the handling of `NULL` in `NOT`:\n\n| a       | NOT a  |\n|---------|--------|\n| `TRUE`  | `FALSE`|\n| `FALSE` | `TRUE` |\n| `NULL`  | `NULL` |\n", "doc_id": "6e715757-924a-4eaa-a77f-595f0628af0e", "embedding": null, "doc_hash": "4e8e71bd5f8e94a73a80564b62c6833889b83145a26c7916f02f734ba2050ff8", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/logical.md", "file_name": "logical.md"}, "node_info": {"start": 0, "end": 1960, "_node_type": "1"}, "relationships": {"1": "605b5e82f33cc49ee0315b1c79c10859aa611738"}}, "__type__": "1"}, "642490c5-dd0c-4d98-82ee-1307a410939f": {"__data__": {"text": "---\ntitle: Map functions and operators\n---\n\n## Subscript operator: \\[\\]\n\nThe `[]` operator is used to retrieve the value corresponding to a given\nkey from a map:\n```sql\n    SELECT name_to_age_map['Bob'] AS bob_age;\n```\n## Map functions\n\n#### cardinality()\n**``cardinality(x)``** \u2192 bigint\n\nReturns the cardinality (size) of the map `x`.\n\n#### element_at()\n**``element_at(map(K,V), key)``** \u2192 V\n\nReturns value for given `key`, or `NULL` if the key is not contained in\nthe map.\n\n#### map()\n**``map()``** \u2192 map(unknown, unknown)\n\nReturns an empty map:\n```sql\n    SELECT map();\n    -- {}\n```\n\n**``map(array(K), array(V))``** \u2192 map(K,V)\n\n\nReturns a map created using the given key/value arrays:\n```sql\n    SELECT map(ARRAY[1,3], ARRAY[2,4]);\n    -- {1 -> 2, 3 -> 4}\n```\nSee also `map_agg` and `multimap_agg` for creating a map as an aggregation.\n\n\n#### map_from_entries()\n**``map_from_entries(array(row(K,V)))``** \u2192 map(K,V)\n\nReturns a map created from the given array of entries:\n```sql\n    SELECT map_from_entries(ARRAY[(1, 'x'), (2, 'y')]);\n    -- {1 -> 'x', 2 -> 'y'}\n```\n\n#### multimap_from_entries()\n**``multimap_from_entries(array(row(K,V)))``** \u2192 map(K,array(V))\n\nReturns a multimap created from the given array of entries. Each key can\nbe associated with multiple values:\n```sql\n    SELECT multimap_from_entries(ARRAY[(1, 'x'), (2, 'y'), (1, 'z')]);\n    -- {1 -> ['x', 'z'], 2 -> ['y']}\n```\n\n#### map_entries()\n**``map_entries(map(K,V))``** \u2192 array(row(K,V))\n\nReturns an array of all entries in the given map:\n```sql\n    SELECT map_entries(MAP(ARRAY[1, 2], ARRAY['x', 'y']));\n    -- [ROW(1, 'x'), ROW(2, 'y')]\n```\n\n#### map_concat()\n**``map_concat(map1(K,V), map2(K,V), ..., mapN(K,V))``** \u2192 map(K,V)\n\nReturns the union of all the given maps. If a key is found in multiple\ngiven maps, that key\\'s value in the resulting map comes from the last\none of those maps.\n\n\n#### map_filter()\n**``map_filter(map(K,V), function(K,V,boolean))``** \u2192 map(K,V)\n\nConstructs a map from those entries of `map` for which `function`\nreturns true:\n```sql\n    SELECT map_filter(MAP(ARRAY[], ARRAY[]), (k, v) -> true);\n    -- {}\n\n    SELECT map_filter(MAP(ARRAY[10, 20, 30], ARRAY['a', NULL, 'c']),\n                      (k, v) -> v IS NOT NULL);\n    -- {10 -> a, 30 -> c}\n\n    SELECT map_filter(MAP(ARRAY['k1', 'k2', 'k3'], ARRAY[20, 3, 15]),\n                     ", "doc_id": "642490c5-dd0c-4d98-82ee-1307a410939f", "embedding": null, "doc_hash": "f1574fc6723d670b6733a57ebb22b59f6ad85abbcc6be3f4758b3339b20c32ce", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/map.md", "file_name": "map.md"}, "node_info": {"start": 0, "end": 2345, "_node_type": "1"}, "relationships": {"1": "93ac7374f6bfe9dfe845be7ad99c32b028be673c", "3": "af0d9b97-d3b5-4cb8-9c97-cad1cea92b24"}}, "__type__": "1"}, "af0d9b97-d3b5-4cb8-9c97-cad1cea92b24": {"__data__": {"text": "                    (k, v) -> v > 10);\n    -- {k1 -> 20, k3 -> 15}\n```\n\n#### map_keys()\n**``map_keys(x(K,V))``** \u2192 array(K)\n\nReturns all the keys in the map `x`.\n\n#### map_values()\n**``map_values(x(K,V))``** \u2192 array(V)\n\nReturns all the values in the map `x`.\n\n#### map_zip_with()\n**``map_zip_with(map(K,V1), map(K,V2), function(K,V1,V2,V3))``** \u2192 map(K,V3)\n\nMerges the two given maps into a single map by applying `function` to\nthe pair of values with the same key. For keys only presented in one\nmap, NULL will be passed as the value for the missing key:\n```sql\n    SELECT map_zip_with(MAP(ARRAY[1, 2, 3], ARRAY['a', 'b', 'c']),\n                        MAP(ARRAY[1, 2, 3], ARRAY['d', 'e', 'f']),\n                        (k, v1, v2) -> concat(v1, v2));\n    -- {1 -> ad, 2 -> be, 3 -> cf}\n\n    SELECT map_zip_with(MAP(ARRAY['k1', 'k2'], ARRAY[1, 2]),\n                        MAP(ARRAY['k2', 'k3'], ARRAY[4, 9]),\n                        (k, v1, v2) -> (v1, v2));\n    -- {k1 -> ROW(1, null), k2 -> ROW(2, 4), k3 -> ROW(null, 9)}\n\n    SELECT map_zip_with(MAP(ARRAY['a', 'b', 'c'], ARRAY[1, 8, 27]),\n                        MAP(ARRAY['a', 'b', 'c'], ARRAY[1, 2, 3]),\n                        (k, v1, v2) -> k || CAST(v1 / v2 AS VARCHAR));\n    -- {a -> a1, b -> b4, c -> c9}\n```\n\n#### transform_keys()\n**``transform_keys(map(K1,V), function(K1,V,K2))``** \u2192 map(K2,V)\n\n\nReturns a map that applies `function` to each entry of `map` and\ntransforms the keys:\n```sql\n    SELECT transform_keys(MAP(ARRAY[], ARRAY[]), (k, v) -> k + 1);\n    -- {}\n\n    SELECT transform_keys(MAP(ARRAY [1, 2, 3], ARRAY ['a', 'b', 'c']),\n                          (k, v) -> k + 1);\n    -- {2 -> a, 3 -> b, 4 -> c}\n\n    SELECT transform_keys(MAP(ARRAY ['a', 'b', 'c'], ARRAY [1, 2, 3]),\n                          (k, v) -> v * v);\n    -- {1 -> 1, 4 -> 2, 9 -> 3}\n\n    SELECT transform_keys(MAP(ARRAY ['a', 'b'], ARRAY [1,", "doc_id": "af0d9b97-d3b5-4cb8-9c97-cad1cea92b24", "embedding": null, "doc_hash": "0046ef2e80ed3fa7c8baab44d3adcd8dabc75e29c25951488b03f945709607d3", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/map.md", "file_name": "map.md"}, "node_info": {"start": 2346, "end": 4232, "_node_type": "1"}, "relationships": {"1": "93ac7374f6bfe9dfe845be7ad99c32b028be673c", "2": "642490c5-dd0c-4d98-82ee-1307a410939f", "3": "0706f04f-e140-4531-9afb-ca892cdf1b5b"}}, "__type__": "1"}, "0706f04f-e140-4531-9afb-ca892cdf1b5b": {"__data__": {"text": "transform_keys(MAP(ARRAY ['a', 'b'], ARRAY [1, 2]),\n                          (k, v) -> k || CAST(v as VARCHAR));\n    -- {a1 -> 1, b2 -> 2}\n\n    SELECT transform_keys(MAP(ARRAY [1, 2], ARRAY [1.0, 1.4]),\n                          (k, v) -> MAP(ARRAY[1, 2], ARRAY['one', 'two'])[k]);\n    -- {one -> 1.0, two -> 1.4}\n```\n\n#### transform_values()\n**``transform_values(map(K,V1), function(K,V1,V2))``** \u2192 map(K,V2)\n\nReturns a map that applies `function` to each entry of `map` and\ntransforms the values:\n```sql\n    SELECT transform_values(MAP(ARRAY[], ARRAY[]), (k, v) -> v + 1);\n    -- {}\n\n    SELECT transform_values(MAP(ARRAY [1, 2, 3], ARRAY [10, 20, 30]),\n                            (k, v) -> v + k);\n    -- {1 -> 11, 2 -> 22, 3 -> 33}\n\n    SELECT transform_values(MAP(ARRAY [1, 2, 3], ARRAY ['a', 'b', 'c']),\n                            (k, v) -> k * k);\n    -- {1 -> 1, 2 -> 4, 3 -> 9}\n\n    SELECT transform_values(MAP(ARRAY ['a', 'b'], ARRAY [1, 2]),\n                            (k, v) -> k || CAST(v as VARCHAR));\n    -- {a -> a1, b -> b2}\n\n    SELECT transform_values(MAP(ARRAY [1, 2], ARRAY [1.0, 1.4]),\n                            (k, v) -> MAP(ARRAY[1, 2], ARRAY['one', 'two'])[k]\n                              || '_' || CAST(v AS VARCHAR));\n    -- {1 -> one_1.0, 2 -> two_1.4}\n```\n", "doc_id": "0706f04f-e140-4531-9afb-ca892cdf1b5b", "embedding": null, "doc_hash": "066e1c2ddca93870ff893bc9ca0964f7fa75ddf2cbe913d390bf646e0990865f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/map.md", "file_name": "map.md"}, "node_info": {"start": 4186, "end": 5478, "_node_type": "1"}, "relationships": {"1": "93ac7374f6bfe9dfe845be7ad99c32b028be673c", "2": "af0d9b97-d3b5-4cb8-9c97-cad1cea92b24"}}, "__type__": "1"}, "afa87745-b32b-4940-a142-b37ce9ab7856": {"__data__": {"text": "---\ntitle: Mathematical functions and operators\n---\n\n# Mathematical operators\n\n| Operator | Description                                      |\n|----------|--------------------------------------------------|\n| `+`      | Addition                                         |\n| `-`      | Subtraction                                      |\n| `*`      | Multiplication                                   |\n| `/`      | Division (integer division performs truncation)  |\n| `%`      | Modulus (remainder)                              |\n\n## Mathematical functions\n\n#### abs()\n**``abs(x)``** \u2192 same as input  \nReturns the absolute value of `x`.\n\n#### cbrt()\n**``cbrt(x)``** \u2192 double  \nReturns the cube root of `x`.\n\n#### ceil()\n**``ceil(x)``** \u2192 same as input  \nThis is an alias for `ceiling`.\n\n#### ceiling()\n**``ceiling(x)``** \u2192 same as input  \nReturns `x` rounded up to the nearest integer.\n\n#### degrees()\n**``degrees(x)``** \u2192 double  \nConverts angle `x` in radians to degrees.\n\n#### e()\n**``e()``** \u2192 double  \nReturns the constant Euler's number.\n\n#### exp()\n**``exp(x)``** \u2192 double  \nReturns Euler's number raised to the power of `x`.\n\n#### floor()\n**``floor(x)``** \u2192 same as input  \nReturns `x` rounded down to the nearest integer.\n\n#### ln()\n**``ln(x)``** \u2192 double  \nReturns the natural logarithm of `x`.\n\n#### log()\n**``log(b, x)``** \u2192 double  \nReturns the base `b` logarithm of `x`.\n\n#### log2()\n**``log2(x)``** \u2192 double  \nReturns the base 2 logarithm of `x`.\n\n#### log10()\n**``log10(x)``** \u2192 double  \nReturns the base 10 logarithm of `x`.\n\n#### mod()\n**``mod(n, m)``** \u2192 same as input  \nReturns the modulus (remainder) of `n` divided by `m`.\n\n#### pi()\n**``pi()``** \u2192 double  \nReturns the constant Pi.\n\n#### pow()\n**``pow(x, p)``** \u2192 double  \nThis is an alias for `power`.\n\n#### power()\n**``power(x, p)``** \u2192 double  \nReturns `x` raised to the power of `p`.\n\n#### radians()\n**``radians(x)``** \u2192 double  \nConverts angle `x` in degrees to radians.\n\n#### round()\n**``round(x)``** \u2192 same as input  \nReturns `x` rounded to the nearest integer.\n\n#### round()\n**``round(x, d)``** \u2192 same as input  \nReturns `x` rounded to `d` decimal places.\n\n#### sign()\n**``sign(x)``** \u2192 same as input  \nReturns the signum function of `x`, that is:\n-   0 if the argument is 0,\n-   1 if the argument is greater than 0,\n-   -1 if the argument is less than 0.\nFor double arguments, the function additionally", "doc_id": "afa87745-b32b-4940-a142-b37ce9ab7856", "embedding": null, "doc_hash": "61eabd51659c6a60ffd3ee25ed83f8642ae99f71bebb458094053e1b5d878a39", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/math.md", "file_name": "math.md"}, "node_info": {"start": 0, "end": 2381, "_node_type": "1"}, "relationships": {"1": "99d7b566516d0df3047c5f6ad9f1de74e264bba8", "3": "880d9436-52fb-4385-8363-4aa27ccaa1d7"}}, "__type__": "1"}, "880d9436-52fb-4385-8363-4aa27ccaa1d7": {"__data__": {"text": "-1 if the argument is less than 0.\nFor double arguments, the function additionally returns:\n-   NaN if the argument is NaN,\n-   1 if the argument is +Infinity,\n-   -1 if the argument is -Infinity.\n\n#### sqrt()\n**``sqrt(x)``** \u2192 double  \nReturns the square root of `x`.\n\n#### truncate()\n**``truncate(x)``** \u2192 double  \nReturns `x` rounded to integer by dropping digits after decimal point.\n\n#### width_bucket()\n**``width_bucket(x, bound1, bound2, n)``** \u2192 bigint  \nReturns the bin number of `x` in an equi-width histogram with the specified `bound1` and `bound2` bounds and `n` number of buckets.\n\n#### width_bucket()\n**``width_bucket(x, bins)``** \u2192 bigint  \nReturns the bin number of `x` according to the bins specified by the array `bins`. The `bins` parameter must be an array of doubles and is assumed to be in sorted ascending order.\n\n## Random functions\n\n#### rand()\n**``rand()``** \u2192 double  \nThis is an alias for `random()`.\n\n#### random()\n**``random()``** \u2192 double  \nReturns a pseudo-random value in the range 0.0 <= x < 1.0.\n\n#### random()\n**``random(n)``** \u2192 same as input  \nReturns a pseudo-random number between 0 and n (exclusive).\n\n#### random()\n**``random(m, n)``** \u2192 same as input  \nReturns a pseudo-random number between m and n (exclusive).\n\n## Trigonometric functions\nAll trigonometric function arguments are expressed in radians. See unit conversion functions `degrees` and `radians`.\n\n#### acos()\n**``acos(x)``** \u2192 double  \nReturns the arc cosine of `x`.\n\n#### asin()\n**``asin(x)``** \u2192 double  \nReturns the arc sine of `x`.\n\n#### atan()\n**``atan(x)``** \u2192 double  \nReturns the arc tangent of `x`.\n\n#### atan2()\n**``atan2(y, x)``** \u2192 double  \nReturns the arc tangent of `y / x`.\n\n#### cos()\n**``cos(x)``** \u2192 double  \nReturns the cosine of `x`.\n\n#### cosh()\n**``cosh(x)``** \u2192 double  \nReturns the hyperbolic cosine of `x`.\n\n#### sin()\n**``sin(x)``** \u2192 double  \nReturns the sine of `x`.\n\n#### tan()\n**``tan(x)``** \u2192 double  \nReturns the tangent of `x`.\n\n#### tanh()\n**``tanh(x)``** \u2192 double  \nReturns the hyperbolic tangent of `x`.\n\n## Floating point functions\n\n#### infinity()\n**``infinity()``** \u2192 double  \nReturns the constant representing positive infinity.\n\n#### is_finite()\n**``is_finite(x)``** \u2192 boolean  \nDetermine if `x` is finite.\n\n#### is_infinite()\n**``is_infinite(x)``** \u2192 boolean  \nDetermine if `x` is infinite.\n\n#### is_nan()\n**``is_nan(x)``** \u2192 boolean  \nDetermine if `x` is not-a-number.\n\n#### nan()\n**``nan()``** \u2192 double  \nReturns the constant representing not-a-number.\n\n## Base conversion functions\n\n#### from_base()\n**``from_base(string, radix)``** \u2192 bigint  \nReturns the value of `string` interpreted as a base-`radix` number.\n\n#### to_base()\n**``to_base(x, radix)``** \u2192 varchar  \nReturns the base-`radix` representation of `x`.\n\n## Statistical", "doc_id": "880d9436-52fb-4385-8363-4aa27ccaa1d7", "embedding": null, "doc_hash": "a4ebf3dcf285736a8f78ae20070fd39c1139d211a9399a92a02a61a0a105a698", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/math.md", "file_name": "math.md"}, "node_info": {"start": 2312, "end": 5093, "_node_type": "1"}, "relationships": {"1": "99d7b566516d0df3047c5f6ad9f1de74e264bba8", "2": "afa87745-b32b-4940-a142-b37ce9ab7856", "3": "bde8c9d0-e68f-4d69-933a-11c18cb39a57"}}, "__type__": "1"}, "bde8c9d0-e68f-4d69-933a-11c18cb39a57": {"__data__": {"text": "\nReturns the base-`radix` representation of `x`.\n\n## Statistical functions\n\n#### cosine_similarity()\n**``cosine_similarity(x, y)``** \u2192 double  \nReturns the cosine similarity between the sparse vectors `x` and `y`:\n    SELECT cosine_similarity(MAP(ARRAY['a'], ARRAY[1.0]), MAP(ARRAY['a'], ARRAY[2.0])); -- 1.0\n\n#### wilson_interval_lower()\n**``wilson_interval_lower(successes, trials, z)``** \u2192 double  \nReturns the lower bound of the Wilson score interval of a Bernoulli\ntrial process at a confidence specified by the z-score `z`.\n\n#### wilson_interval_upper()\n**``wilson_interval_upper(successes, trials, z)``** \u2192 double  \nReturns the upper bound of the Wilson score interval of a Bernoulli\ntrial process at a confidence specified by the z-score `z`.\n\n## Cumulative distribution functions\n\n#### beta_cdf()\n**``beta_cdf(a, b, v)``** \u2192 double  \nCompute the Beta cdf with given a, b parameters: P(N < v; a, b). The a,\nb parameters must be positive real numbers and value v must be a real\nvalue. The value v must lie on the interval [0, 1].\n\n#### inverse_beta_cdf()\n**``inverse_beta_cdf(a, b, p)``** \u2192 double  \nCompute the inverse of the Beta cdf with given a, b parameters for the\ncumulative probability (p): P(N < n). The a, b parameters must be\npositive real values. The probability p must lie on the interval [0,\n1].\n\n#### inverse_normal_cdf()\n**``inverse_normal_cdf(mean, sd, p)``** \u2192 double  \nCompute the inverse of the Normal cdf with given mean and standard\n\n#### normal_cdf()\n**``normal_cdf(mean, sd, v)``** \u2192 double  \nCompute the Normal cdf with given mean and standard deviation (sd): P(N\n< v; mean, sd). The mean and value v must be real values and the\nstandard deviation must be a real and positive value.\n\n", "doc_id": "bde8c9d0-e68f-4d69-933a-11c18cb39a57", "embedding": null, "doc_hash": "5a04b2e018245d44c02a4c71b389b8c6c149b29ce15765b45d92dcf1aef3070f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/math.md", "file_name": "math.md"}, "node_info": {"start": 5099, "end": 6815, "_node_type": "1"}, "relationships": {"1": "99d7b566516d0df3047c5f6ad9f1de74e264bba8", "2": "880d9436-52fb-4385-8363-4aa27ccaa1d7"}}, "__type__": "1"}, "c50c54b7-a9b8-4e82-806d-11513062d2f9": {"__data__": {"text": "---\ntitle: Machine learning functions\n---\n\nThe machine learning plugin provides machine learning functionality as\nan aggregation function. It enables you to train Support Vector Machine\n(SVM) based classifiers and regressors for the supervised learning\nproblems.\n\n> Note: The machine learning functions are not optimized for distributed\nprocessing. The capability to train large data sets is limited by this\nexecution of the final training on a single instance.\n\n# Feature vector\n\nTo solve a problem with the machine learning technique, especially as a\nsupervised learning problem, it is necessary to represent the data set\nwith the sequence of pairs of labels and feature vector. A label is a\ntarget value you want to predict from the unseen feature and a feature\nis a A N-dimensional vector whose elements are numerical values. In\nTrino, a feature vector is represented as a map-type value, whose key is\nan index of each feature, so that it can express a sparse vector. Since\nclassifiers and regressors can recognize the map-type feature vector,\nthere is a function to construct the feature from the existing numerical\nvalues, `features`:\n\n```sql\nSELECT features(1.0, 2.0, 3.0) AS features;\n```\nResult:  \n\n| Features         |\n|------------------|\n| {0=1.0, 1=2.0, 2=3.0} |\n\n\nThe output from `features` can be directly passed to ML functions.\n\n# Classification\n\nClassification is a type of supervised learning problem to predict the\ndistinct label from the given feature vector. The interface looks\nsimilar to the construction of the SVM model from the sequence of pairs\nof labels and features implemented in Teradata Aster or [BigQuery\nML](https://cloud.google.com/bigquery-ml/docs/bigqueryml-intro). The\nfunction to train a classification model looks like as follows:\n```sql\n    SELECT\n      learn_classifier(\n        species,\n        features(sepal_length, sepal_width, petal_length, petal_width)\n      ) AS model\n    FROM\n      iris\n```\nIt returns the trained model in a serialized format.\n\n``` text\nmodel\n-------------------------------------------------\n3c 43 6c 61 73 73 69 66 69 65 72 28 76 61 72 63\n68 61 72 29 3e\n```\n\n`classify` returns the predicted label by using the trained model. The trained model can not be saved natively,\nand needs to be passed in the format of a nested query:\n```sql\n    SELECT\n      classify(features(5.9, 3, 5.1, 1.8), model) AS predicted_label\n    FROM (\n      SELECT\n        learn_classifier(species, features(sepal_length, sepal_width, petal_length, petal_width)) AS model\n      FROM\n        iris\n    ) t\n```\n\n``` text\npredicted_label\n-----------------\nIris-virginica\n```\n\nAs a result you need to run the training process at the same time when\npredicting values. Internally, the model is trained by\n[libsvm](https://www.csie.ntu.edu.tw/~cjlin/libsvm/). You can use\n`learn_libsvm_classifier` to control the\ninternal parameters of the model.\n\n# Regression\n\nRegression is another type of supervised learning problem, predicting\ncontinuous value, unlike the classification problem. The target must be\nnumerical values that can be described as `double`.\n\nThe following code shows the creation of the model predicting\n`sepal_length` from the other 3 features:\n```sql\n    SELECT\n      learn_regressor(sepal_length, features(sepal_width,", "doc_id": "c50c54b7-a9b8-4e82-806d-11513062d2f9", "embedding": null, "doc_hash": "8d269d2c47e5bf6d600ecd566f915ecb21320eaf6e62133729d4b7658e6eeee9", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/ml.md", "file_name": "ml.md"}, "node_info": {"start": 0, "end": 3272, "_node_type": "1"}, "relationships": {"1": "1a20d4e9546875ebc47b2265f675fece5d271bfd", "3": "49e9c908-27b7-4869-924c-5308798bb17c"}}, "__type__": "1"}, "49e9c908-27b7-4869-924c-5308798bb17c": {"__data__": {"text": "   learn_regressor(sepal_length, features(sepal_width, petal_length, petal_width)) AS model\n    FROM\n      iris\n```\nThe way to use the model is similar to the classification case:\n```sql\n    SELECT\n      regress(features(3, 5.1, 1.8), model) AS predicted_target\n    FROM (\n      SELECT\n        learn_regressor(sepal_length, features(sepal_width, petal_length, petal_width)) AS model\n      FROM iris\n    ) t;\n```\n``` text\npredicted_target\n-------------------\n6.407376822560477\n```\n\nInternally, the model is trained by\n[libsvm](https://www.csie.ntu.edu.tw/~cjlin/libsvm/).\n`learn_libsvm_regressor` provides you a\nway to control the training process.\n\n# Machine learning functions {#machine-learning-functions-1}\n\n#### features()\n**``features(double, ...)``** \u2192 map(bigint, double)  \nReturns the map representing the feature vector.\n\n#### learn_classifier()\n**``learn_classifier(label, features)``** \u2192 Classifier\n\nReturns an SVM-based classifier model, trained with the given label and\nfeature data sets.\n\n#### learn_libsvm_classifier()\n**``learn_libsvm_classifier(label, features, params)``** \u2192 Classifier\n\nReturns an SVM-based classifier model, trained with the given label and\nfeature data sets. You can control the training process by libsvm\nparameters.\n\n#### classify()\n**``classify(features, model)``** \u2192 label\n\nReturns a label predicted by the given classifier SVM model.\n\n#### learn_regressor()\n**``learn_regressor(target, features)``** \u2192 Regressor\n\nReturns an SVM-based regressor model, trained with the given target and\nfeature data sets.\n\n#### learn_libsvm_regressor()\n**``learn_libsvm_regressor(target, features, params)``** \u2192 Regressor\n\nReturns an SVM-based regressor model, trained with the given target and\nfeature data sets. You can control the training process by libsvm\nparameters.\n\n#### regress()\n**``regress(features, model)``** \u2192 target\n\nReturns a predicted target value by the given regressor SVM model.\n\n", "doc_id": "49e9c908-27b7-4869-924c-5308798bb17c", "embedding": null, "doc_hash": "2f277d082771fa7ebc340eb1da255c8f7d8d521ad9428d96a0b115847c1b48a4", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/ml.md", "file_name": "ml.md"}, "node_info": {"start": 3218, "end": 5142, "_node_type": "1"}, "relationships": {"1": "1a20d4e9546875ebc47b2265f675fece5d271bfd", "2": "c50c54b7-a9b8-4e82-806d-11513062d2f9"}}, "__type__": "1"}, "e6edbcb1-58e9-4e0e-8f45-0377d79209ba": {"__data__": {"text": "---\ntitle: Quantile digest functions\n---\n\n# Data structures\n\nA quantile digest is a data sketch which stores approximate percentile\ninformation. The Trino type for this data structure is called `qdigest`,\nand it takes a parameter which must be one of `bigint`, `double` or\n`real` which represent the set of numbers that may be ingested by the\n`qdigest`. They may be merged without losing precision, and for storage\nand retrieval they may be cast to/from `VARBINARY`.\n\n## Functions\n\n#### merge()\n**``merge(qdigest)``** \u2192 qdigest\n\nMerges all input `qdigest`s into a single `qdigest`.\n\n#### values_at_quantile()\n**``value_at_quantile(qdigest(T), quantile)``** \u2192 T\n\nReturns the approximate percentile value from the quantile digest given\nthe number `quantile` between 0 and 1.\n\n#### values_at_quantiles()\n**``values_at_quantiles(qdigest(T), quantiles)``** \u2192 array(T)\n\nReturns the approximate percentile values as an array given the input\nquantile digest and array of values between 0 and 1 which represent the\nquantiles to return.\n\n#### qdigest_agg()\n**``qdigest_agg(x)``** \u2192 qdigest(same as x)\n\nReturns the `qdigest` which is composed of all input values of `x`.\n\n#### qdigest_agg()\n**``qdigest_agg(x, w)``** \u2192 qdigest(same as x)\n\nReturns the `qdigest` which is composed of all input values of `x` using\nthe per-item weight `w`.\n\n#### qdigest_agg()\n**``qdigest_agg(x, w, accuracy)``** \u2192 qdigest(same as x)\n\nReturns the `qdigest` which is composed of all input values of `x` using\nthe per-item weight `w` and maximum error of `accuracy`. `accuracy` must\nbe a value greater than zero and less than one, and it must be constant\nfor all input rows.\n", "doc_id": "e6edbcb1-58e9-4e0e-8f45-0377d79209ba", "embedding": null, "doc_hash": "bc645bb46299739d49df8a5562d0102786019ccfe8f3eb6fcbcc7815821199ed", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/qdigest.md", "file_name": "qdigest.md"}, "node_info": {"start": 0, "end": 1642, "_node_type": "1"}, "relationships": {"1": "4b95232cca47456f08d70378bc8527b6dc416f37"}}, "__type__": "1"}, "72e2f566-3403-46f4-8cf9-8f1ae8a8cbe7": {"__data__": {"text": "---\ntitle: Regular expression functions\n---\n\nAll of the regular expression functions use the [Java pattern]() syntax,\nwith a few notable exceptions:\n\n-   When using multi-line mode (enabled via the `(?m)` flag), only `\\n`\n    is recognized as a line terminator. Additionally, the `(?d)` flag is\n    not supported and must not be used.\n-   Case-insensitive matching (enabled via the `(?i)` flag) is always\n    performed in a Unicode-aware manner. However, context-sensitive and\n    local-sensitive matching is not supported. Additionally, the `(?u)`\n    flag is not supported and must not be used.\n-   Surrogate pairs are not supported. For example, `\\uD800\\uDC00` is\n    not treated as `U+10000` and must be specified as `\\x{10000}`.\n-   Boundaries (`\\b`) are incorrectly handled for a non-spacing mark\n    without a base character.\n-   `\\Q` and `\\E` are not supported in character classes (such as\n    `[A-Z123]`) and are instead treated as literals.\n-   Unicode character classes (`\\p{prop}`) are supported with the\n    following differences:\n    -   All underscores in names must be removed. For example, use\n        `OldItalic` instead of `Old_Italic`.\n    -   Scripts must be specified directly, without the `Is`, `script=`\n        or `sc=` prefixes. Example: `\\p{Hiragana}`\n    -   Blocks must be specified with the `In` prefix. The `block=` and\n        `blk=` prefixes are not supported. Example: `\\p{Mongolian}`\n    -   Categories must be specified directly, without the `Is`,\n        `general_category=` or `gc=` prefixes. Example: `\\p{L}`\n    -   Binary properties must be specified directly, without the `Is`.\n        Example: `\\p{NoncharacterCodePoint}`\n\n#### regexp_count()\n**``regexp_count(string, pattern)``** \u2192 bigint\n\nReturns the number of occurrence of `pattern` in `string`:\n```sql\n    SELECT regexp_count('1a 2b 14m', '\\s*[a-z]+\\s*'); -- 3\n```\n#### regexp_extract_all()\n**``regexp_extract_all(string, pattern)``** \u2192 array(varchar)\n\nReturns the substring(s) matched by the regular expression `pattern` in\n`string`:\n```sql\n    SELECT regexp_extract_all('1a 2b 14m', '\\d+'); -- [1, 2, 14]\n```\n\n**``regexp_extract_all(string, pattern, group)``** \u2192 array(varchar)\n\nFinds all occurrences of the regular expression `pattern` in `string`\nand returns the [capturing group number]() `group`:\n```sql\n    SELECT regexp_extract_all('1a 2b 14m', '(\\d+)([a-z]+)', 2); -- ['a', 'b', 'm']\n```\n\n#### regexp_extract()\n**``regexp_extract(string, pattern)``** \u2192 varchar\n\nReturns the f substring matched by the regular expression `pattern`\nin `string`:\n```sql\n    SELECT regexp_extract('1a 2b 14m', '\\d+'); -- 1\n```\n\n**``regexp_extract(string, pattern,", "doc_id": "72e2f566-3403-46f4-8cf9-8f1ae8a8cbe7", "embedding": null, "doc_hash": "cbe859cf9b48721b5913afbc7959c7c0ef1b9a699ced8ec68c73632f184fc15f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/regexp.md", "file_name": "regexp.md"}, "node_info": {"start": 0, "end": 2650, "_node_type": "1"}, "relationships": {"1": "6cd0bce7108b1e2da0267c6f0229a8c4b9dd86db", "3": "28fbd09a-5a46-4e5e-b26b-11183bff01c1"}}, "__type__": "1"}, "28fbd09a-5a46-4e5e-b26b-11183bff01c1": {"__data__": {"text": "-- 1\n```\n\n**``regexp_extract(string, pattern, group)``** \u2192 varchar\n\nFinds the f occurrence of the regular expression `pattern` in\n`string` and returns the [capturing group number]() `group`:\n```sql\n    SELECT regexp_extract('1a 2b 14m', '(\\d+)([a-z]+)', 2); -- 'a'\n```\n\n#### regexp_like()\n**``regexp_like(string, pattern)``** \u2192 boolean\n\nEvaluates the regular expression `pattern` and determines if it is\ncontained within `string`.\n\nThe `pattern` only needs to be contained within `string`, rather than\nneeding to match all of `string`. In other words, this performs a\n*contains* operation rather than a *match* operation. You can match the\nentire string by anchoring the pattern using `^` and `$`:\n```sql\n    SELECT regexp_like('1a 2b 14m', '\\d+b'); -- true\n```  \n\n#### regexp_position()\n**``regexp_position(string, pattern)``** \u2192 integer\n\nReturns the index of the f occurrence (counting from 1) of `pattern`\nin `string`. Returns -1 if not found:\n```sql\n    SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\\b\\d+\\b'); -- 8\n```\n\n**``regexp_position(string, pattern, start)``** \u2192 integer\n\nReturns the index of the f occurrence of `pattern` in `string`,\nstarting from `start` (include `start`). Returns -1 if not found:\n```sql\n    SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\\b\\d+\\b', 5); -- 8\n    SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\\b\\d+\\b', 12); -- 19\n```\n\n\n**``regexp_position(string, pattern, start, occurrence)``** \u2192 integer\n\nReturns the index of the nth `occurrence` of `pattern` in `string`,\nstarting from `start` (include `start`). Returns -1 if not found:\n```sql\n    SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\\b\\d+\\b', 12, 1); -- 19\n    SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\\b\\d+\\b', 12, 2); -- 31\n    SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\\b\\d+\\b', 12, 3);\n```\n\n#### regexp_replace()\n**``regexp_replace(string, pattern)``** \u2192 varchar\n\nRemoves every instance of the substring matched by the regular\nexpression `pattern` from `string`:\n\n    SELECT regexp_replace('1a 2b 14m', '\\d+[ab] '); -- '14m'\n\n\n**``regexp_replace(string, pattern, replacement)``** \u2192 varchar\n\nReplaces every instance of the substring matched by the regular\nexpression `pattern` in `string` with `replacement`. [Capturing\ngroups]() can be referenced in `replacement` using `$g` for a numbered\ngroup or `${name}` for a named group. A dollar sign (`$`) may be\nincluded in the replacement by escaping it with a backslash (`\\$`):\n```sql\n    SELECT regexp_replace('1a 2b 14m', '(\\d+)([ab]) ', '3c$2 '); -- '3ca 3cb 14m'\n```\n\n\n**``regexp_replace(string, pattern, function)``** \u2192 varchar\n\nReplaces every instance of the substring matched by the regular\nexpression `pattern`", "doc_id": "28fbd09a-5a46-4e5e-b26b-11183bff01c1", "embedding": null, "doc_hash": "a8aae6d47929108eae6a672c6791d5f5f913c193e32532126bc8305c1c967480", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/regexp.md", "file_name": "regexp.md"}, "node_info": {"start": 2608, "end": 5412, "_node_type": "1"}, "relationships": {"1": "6cd0bce7108b1e2da0267c6f0229a8c4b9dd86db", "2": "72e2f566-3403-46f4-8cf9-8f1ae8a8cbe7", "3": "3a502aef-b32f-4bcc-b315-30cb40b8e95b"}}, "__type__": "1"}, "3a502aef-b32f-4bcc-b315-30cb40b8e95b": {"__data__": {"text": "every instance of the substring matched by the regular\nexpression `pattern` in `string` using `function`. The\n`lambda expression <lambda>`{.interpreted-text role=\"doc\"} `function` is\ninvoked for each match with the [capturing groups]() passed as an array.\nCapturing group numbers start at one; there is no group for the entire\nmatch (if you need this, surround the entire expression with\nparenthesis). :\n\n    SELECT regexp_replace('new york', '(\\w)(\\w*)', x -> upper(x[1]) || lower(x[2])); --'New York'\n\n#### regexp_split()\n**``regexp_split(string, pattern)``** \u2192 array(varchar)\n\nSplits `string` using the regular expression `pattern` and returns an\narray. Trailing empty strings are preserved:\n```sql\n    SELECT regexp_split('1a 2b 14m', '\\s*[a-z]+\\s*'); -- [1, 2, 14, ]\n```\n", "doc_id": "3a502aef-b32f-4bcc-b315-30cb40b8e95b", "embedding": null, "doc_hash": "7672ad29dfa715b9a23039393d4c3a84c94b24d232609664cd0675113880aed2", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/regexp.md", "file_name": "regexp.md"}, "node_info": {"start": 5380, "end": 6156, "_node_type": "1"}, "relationships": {"1": "6cd0bce7108b1e2da0267c6f0229a8c4b9dd86db", "2": "28fbd09a-5a46-4e5e-b26b-11183bff01c1"}}, "__type__": "1"}, "45ebac77-fb68-46b5-834c-c2a62ac314aa": {"__data__": {"text": "---\ntitle: Set Digest functions\n---\n\n## Set Digest functions\n\nTrino offers several functions that deal with the\n[MinHash](https://en.wikipedia.org/wiki/MinHash) technique.\n\nMinHash is used to quickly estimate the [Jaccard similarity\ncoefficient](https://en.wikipedia.org/wiki/Jaccard_index) between two\nsets.\n\nIt is commonly used in data mining to detect near-duplicate web pages at\nscale. By using this information, the search engines efficiently avoid\nshowing within the search results two pages that are nearly identical.\n\nThe following example showcases how the Set Digest functions can be used\nto naively estimate the similarity between texts. The input texts are\nsplit by using the function `ngrams` to\n[4-shingles](https://en.wikipedia.org/wiki/W-shingling) which are used\nas input for creating a set digest of each initial text. The set digests\nare compared to each other to get an approximation of the similarity of\ntheir corresponding initial texts:\n\n```sql\nWITH text_input(id, text) AS (\n         VALUES\n             (1, 'The quick brown fox jumps over the lazy dog'),\n             (2, 'The quick and the lazy'),\n             (3, 'The quick brown fox jumps over the dog')\n     ),\n     text_ngrams(id, ngrams) AS (\n         SELECT id,\n                transform(\n                  ngrams(\n                    split(text, ' '),\n                    4\n                  ),\n                  token -> array_join(token, ' ')\n                )\n         FROM text_input\n     ),\n     minhash_digest(id, digest) AS (\n         SELECT id,\n                (SELECT make_set_digest(v) FROM unnest(ngrams) u(v))\n         FROM text_ngrams\n     ),\n     setdigest_side_by_side(id1, digest1, id2, digest2) AS (\n         SELECT m1.id as id1,\n                m1.digest as digest1,\n                m2.id as id2,\n                m2.digest as digest2\n         FROM (SELECT id, digest FROM minhash_digest) m1\n         JOIN (SELECT id, digest FROM minhash_digest) m2\n           ON m1.id != m2.id AND m1.id < m2.id\n     )\nSELECT id1,\n       id2,\n       intersection_cardinality(digest1, digest2) AS intersection_cardinality,\n       jaccard_index(digest1, digest2)            AS jaccard_index\nFROM", "doc_id": "45ebac77-fb68-46b5-834c-c2a62ac314aa", "embedding": null, "doc_hash": "75b1dc388a623ef146d441f4f9c6eb8f0aa28a19f7a7453f220f478364e96216", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/setdigest.md", "file_name": "setdigest.md"}, "node_info": {"start": 0, "end": 2178, "_node_type": "1"}, "relationships": {"1": "c0c03f3d7fc8050052ab5378ab24ec56aa189b89", "3": "707a707c-784b-4b2e-b56c-6291a4ea08a9"}}, "__type__": "1"}, "707a707c-784b-4b2e-b56c-6291a4ea08a9": {"__data__": {"text": "           AS jaccard_index\nFROM setdigest_side_by_side\nORDER BY id1, id2;\n```\nResults:  \n\n| id1 | id2 | intersection_cardinality | jaccard_index |\n|-----|-----|--------------------------|---------------|\n|  1  |  2  |            0             |      0.0      |\n|  1  |  3  |            4             |      0.6      |\n|  2  |  3  |            0             |      0.0      |\n\nThe above result listing points out, as expected, that the texts with\nthe id 1 and 3 are quite similar.\n\nOne may argue that the text with the id 2 is somewhat similar to the\ntexts with the id 1 and 3. Due to the fact in the example above\n4-shingles are taken into account for measuring the similarity of the\ntexts, there are no intersections found for the text pairs 1 and 2,\nrespectively 3 and 2 and therefore there the similarity index for\nthese text pairs is 0.\n\n## Data structures\n\nTrino implements Set Digest data sketches by encapsulating the following\ncomponents:\n\n-   [HyperLogLog](https://en.wikipedia.org/wiki/HyperLogLog)\n-   [MinHash with a single hash\n    function](http://en.wikipedia.org/wiki/MinHash#Variant_with_a_single_hash_function)\n\nThe HyperLogLog structure is used for the approximation of the distinct\nelements in the original set.\n\nThe MinHash structure is used to store a low memory footprint signature\nof the original set. The similarity of any two sets is estimated by\ncomparing their signatures.\n\nThe Trino type for this data structure is called `setdigest`. Trino\noffers the ability to merge multiple Set Digest data sketches.\n\n## Serialization\n\nData sketches can be serialized to and deserialized from `varbinary`.\nThis allows them to be stored for later use.\n\n## Functions\n\n#### make_set_digest()\n**``make_set_digest(x)``** \u2192 setdigest\n\nComposes all input values of `x` into a `setdigest`.\n\nCreate a `setdigest` corresponding to a `bigint` array:\n```sql\n    SELECT make_set_digest(value)\n    FROM (VALUES 1, 2, 3) T(value);\n```\nCreate a `setdigest` corresponding to a `varchar` array:\n\n    SELECT make_set_digest(value)\n    FROM (VALUES 'Trino', 'SQL', 'on', 'everything') T(value);\n\n\n#### merge_set_digest()\n**``merge_set_digest(setdigest, setdigest)``** \u2192 setdigest\n\n\nReturns the `setdigest` of the aggregate union of the individual\n`setdigest` Set Digest structures.\n\nReturns the cardinality of the set digest from its internal\n`HyperLogLog` component.\n\nExamples:\n```sql\n    SELECT cardinality(make_set_digest(value))\n    FROM (VALUES 1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5) T(value);\n    -- 5\n```\n\n#### intersection_cardinality()\n**``intersection_cardinality(x,y)``** \u2192 long\n\nReturns the estimation for the cardinality of the intersection of the\ntwo set digests.\n\n`x` and `y` must be", "doc_id": "707a707c-784b-4b2e-b56c-6291a4ea08a9", "embedding": null, "doc_hash": "a13baf55cce1ac58328ad756e4814d9c028164eb481eabb0235d23296e91c8a9", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/setdigest.md", "file_name": "setdigest.md"}, "node_info": {"start": 2159, "end": 4848, "_node_type": "1"}, "relationships": {"1": "c0c03f3d7fc8050052ab5378ab24ec56aa189b89", "2": "45ebac77-fb68-46b5-834c-c2a62ac314aa", "3": "abaa565c-8620-4cd9-9f1f-25313a0b6f5b"}}, "__type__": "1"}, "abaa565c-8620-4cd9-9f1f-25313a0b6f5b": {"__data__": {"text": "of the\ntwo set digests.\n\n`x` and `y` must be of type `setdigest`\n\nExamples:\n```sql\n    SELECT intersection_cardinality(make_set_digest(v1), make_set_digest(v2))\n    FROM (VALUES (1, 1), (NULL, 2), (2, 3), (3, 4)) T(v1, v2);\n    -- 3\n```\n\n#### jaccard_index()\n**``jaccard_index(x, y)``** \u2192 double\n\nReturns the estimation of [Jaccard\nindex](https://en.wikipedia.org/wiki/Jaccard_index) for the two set\ndigests.\n\n`x` and `y` must be of type `setdigest`.\n\nExamples:\n```sql\n    SELECT jaccard_index(make_set_digest(v1), make_set_digest(v2))\n    FROM (VALUES (1, 1), (NULL,2), (2, 3), (NULL, 4)) T(v1, v2);\n    -- 0.5\n```\n\n#### hash_counts()\n**``hash_counts(x)``** \u2192 map(bigint, bigint)\n\nReturns a map containing the\n[Murmur3Hash128](https://en.wikipedia.org/wiki/MurmurHash#MurmurHash3)\nhashed values and the count of their occurences within the internal\n`MinHash` structure belonging to `x`.\n\n`x` must be of type `setdigest`.\n\nExamples:\n```sql\n    SELECT hash_counts(make_set_digest(value))\n    FROM (VALUES 1, 1, 1, 2, 2) T(value);\n    -- {19144387141682250=3, -2447670524089286488=2}\n```\n", "doc_id": "abaa565c-8620-4cd9-9f1f-25313a0b6f5b", "embedding": null, "doc_hash": "7b42f750a7a99e031508fe64620adb543a061e37f1ef6e023577ee790ffef0fa", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/setdigest.md", "file_name": "setdigest.md"}, "node_info": {"start": 4824, "end": 5910, "_node_type": "1"}, "relationships": {"1": "c0c03f3d7fc8050052ab5378ab24ec56aa189b89", "2": "707a707c-784b-4b2e-b56c-6291a4ea08a9"}}, "__type__": "1"}, "22b5ea76-02af-405f-bee0-d5a3c0c5c49f": {"__data__": {"text": "---\ntitle: String functions and operators\n---\n\n## String operators\n\nThe `||` operator performs concatenation.\n\nThe `LIKE` statement can be used for pattern matching and is documented\nin `like_operator`{.interpreted-text role=\"ref\"}.\n\n## String functions\n\n\n!!!Note\n    These functions assume that the input strings contain valid UTF-8 encoded Unicode code points. There are no explicit checks for valid UTF-8, and the functions may return incorrect results on invalid UTF-8. Invalid UTF-8 data can be corrected with from_utf8.\n\n    Additionally, the functions operate on Unicode code points and not user-visible characters (or grapheme clusters). Some     languages combine multiple code points into a single user-perceived character, the basic unit of a writing system for a     language, but the functions will treat each code point as a separate unit.\n\n    The lower and upper functions do not perform locale-sensitive, context-sensitive, or one-to-many mappings required for some     languages. Specifically, this will return incorrect results for Lithuanian, Turkish, and Azeri.\n\n\n#### chr()\n**``chr(n)``** \u2192 varchar  \nReturns the Unicode code point `n` as a single character string.\n\n#### codepoint()\n**``codepoint(string)``** \u2192 integer  \nReturns the Unicode code point of the only character of `string`.\n\n#### concat()\n**``concat(string1, ..., stringN)``** \u2192 varchar  \nReturns the concatenation of `string1`, `string2`, `...`, `stringN`. This function provides the same functionality as the SQL-standard concatenation operator (`||`).\n\n#### concat_ws()\n**``concat_ws(string0, string1, ..., stringN)``** \u2192 varchar  \nReturns the concatenation of `string1`, `string2`, `...`, `stringN` using `string0` as a separator. If `string0` is null, then the return value is null. Any null values provided in the arguments after the separator are skipped.\n\n#### concat_ws()\n**``concat_ws(string0, array(varchar))``** \u2192 varchar  \nReturns the concatenation of elements in the array using `string0` as a separator. If `string0` is null, then the return value is null. Any null values in the array are skipped.\n\n#### format()\n**``format(format, args...)``** \u2192 varchar  \nSee `format`.\n\n#### hamming_distance()\n**``hamming_distance(string1, string2)``** \u2192 bigint  \nReturns the Hamming distance of `string1` and `string2`, i.e. the number of positions at which the corresponding characters are different. Note that the two strings must have the same length.\n\n#### length()\n**``length(string)``** \u2192 bigint  \nReturns the length of `string` in characters.\n\n#### levenshtein_distance()\n**``levenshtein_distance(string1, string2)``** \u2192 bigint  \nReturns the Levenshtein edit distance of `string1` and `string2`, i.e. the minimum number of single-character edits (insertions, deletions or substitutions) needed to change `string1` into `string2`.\n\n#### lower()\n**``lower(string)``** \u2192 varchar  \nConverts `string` to lowercase.\n\n#### lpad()\n**``lpad(string, size, padstring)``** \u2192 varchar  \nLeft pads `string` to `size` characters with `padstring`. If `size` is less than the length of `string`, the result is truncated to `size` characters. `size` must not be negative and `padstring` must be non-empty.\n\n#### ltrim()\n**``ltrim(string)``** \u2192 varchar  \nRemoves leading whitespace from", "doc_id": "22b5ea76-02af-405f-bee0-d5a3c0c5c49f", "embedding": null, "doc_hash": "7f2a08157a760365ad42224c918d5383d3279e5b31b303c17ad4df51049f9fe2", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/string.md", "file_name": "string.md"}, "node_info": {"start": 0, "end": 3262, "_node_type": "1"}, "relationships": {"1": "5e40d91595902954d6cfd8b4060f62d358fc47a3", "3": "d3b98b06-604b-4c2a-8a16-bf41b5c32505"}}, "__type__": "1"}, "d3b98b06-604b-4c2a-8a16-bf41b5c32505": {"__data__": {"text": "\u2192 varchar  \nRemoves leading whitespace from `string`.\n\n#### luhn_check()\n**``luhn_check(string)``** \u2192 boolean  \nTests whether a `string` of digits is valid according to the [Luhn algorithm](https://en.wikipedia.org/wiki/Luhn_algorithm).\nThis checksum function, also known as `modulo 10` or `mod 10`, is widely applied on credit card numbers and government identification numbers to distinguish valid numbers from mistyped, incorrect numbers.\n\n\nValid identification number:\n\n    select luhn_check('79927398713');\n    -- true\n\nInvalid identification number:\n\n    select luhn_check('79927398714');\n    -- false\n\n#### position()\n**``position(substring IN string)``** \u2192 bigint\n\nReturns the starting position of the first instance of `substring` in `string`. Positions start with `1`. If not found, `0` is returned.\n\nNote: This SQL-standard function has special syntax and uses the `IN` keyword for the arguments. See also `strpos`.\n\n#### replace()\n**``replace(string, search)``** \u2192 varchar\n\nRemoves all instances of `search` from `string`.\n\n**``replace(string, search, replace)``** \u2192 varchar\n\nReplaces all instances of `search` with `replace` in `string`.\n\n#### reverse()\n**``reverse(string)``** \u2192 varchar\n\nReturns `string` with the characters\n\n#### rpad()\n**``rpad(string, size, padstring)``** \u2192 varchar\n\nRight pads `string` to `size` characters with `padstring`. If `size` is less than the length of `string`, the result is truncated to `size` characters. `size` must not be negative and `padstring` must be non-empty.\n\n#### rtrim()\n**``rtrim(string)``** \u2192 varchar\n\nRemoves trailing whitespace from `string`.\n\n#### soundex()\n**``soundex(char)``** \u2192 string\n\n`soundex` returns a character string containing the phonetic representation of `char`.\n\nIt is typically used to evaluate the similarity of two expressions phonetically, that is how the string sounds when spoken:\n```sql\n    SELECT name\n    FROM nation\n    WHERE SOUNDEX(name)  = SOUNDEX('CHYNA');\n```\n```text\n     name  |\n    -------+----\n     CHINA |\n    (1 row)\n```\n\n#### split()\n**``split(string, delimiter)``** \u2192 array(varchar)\n\nSplits `string` on `delimiter` and returns an array.\n\n#### split()\n**``split(string, delimiter, limit)``** \u2192 array(varchar)\n\nSplits `string` on `delimiter` and returns an array of size at most `limit`. The last element in the array always contain everything left in the `string`. `limit` must be a positive number.\n\n#### split_part()\n**``split_part(string, delimiter, index)``** \u2192 varchar\n\nSplits `string` on `delimiter` and returns the field `index`. Field indexes start with `1`. If the index is larger than the number of fields, then null is returned.\n\n#### split_to_map()\n**``split_to_map(string, entryDelimiter, keyValueDelimiter)``** \u2192 map<varchar, varchar>\n\nSplits `string` by `entryDelimiter` and `keyValueDelimiter` and returns a map. `entryDelimiter` splits `string` into key-value pairs. `keyValueDelimiter` splits each pair into key and value.\n\n#### split_to_multimap()\n**``split_to_multimap(string, entryDelimiter, keyValueDelimiter)``**", "doc_id": "d3b98b06-604b-4c2a-8a16-bf41b5c32505", "embedding": null, "doc_hash": "363dda860ee89a22afc46e00b20778bae5d8ebde58b864fad22a3068c5e7a5a6", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/string.md", "file_name": "string.md"}, "node_info": {"start": 3226, "end": 6262, "_node_type": "1"}, "relationships": {"1": "5e40d91595902954d6cfd8b4060f62d358fc47a3", "2": "22b5ea76-02af-405f-bee0-d5a3c0c5c49f", "3": "fdfe23ee-66c0-413b-b702-1a6f416e205e"}}, "__type__": "1"}, "fdfe23ee-66c0-413b-b702-1a6f416e205e": {"__data__": {"text": "entryDelimiter, keyValueDelimiter)``** \u2192 map(varchar, array(varchar))\n\nSplits `string` by `entryDelimiter` and `keyValueDelimiter` and returns a map containing an array of values for each unique key. `entryDelimiter` splits `string` into key-value pairs. `keyValueDelimiter` splits each pair into key and value. The values for each key will be in the same order as they appeared in `string`.\n\n#### strpos()\n**``strpos(string, substring)``** \u2192 bigint\n\nReturns the starting position of the first instance of `substring` in `string`. Positions start with `1`. If not found, `0` is returned.\n\n**``strpos(string, substring, instance)``** \u2192 bigint\n\nReturns the position of the N-th `instance` of `substring` in `string`. When `instance` is a negative number the search will start from the end of `string`. Positions start with `1`. If not found, `0` is returned.\n\n#### starts_with()\n**``starts_with(string, substring)``** \u2192 boolean\n\nTests whether `substring` is a prefix of `string`.\n\n#### substring()\n**``substr(string, start)``** \u2192 varchar\n\nThis is an alias for `substring`.\n\n**``substring(string, start)``** \u2192 varchar\n\nReturns the rest of `string` from the starting position `start`. Positions start with `1`. A negative starting position is interpreted as being relative to the end of the string.\n\n**``substr(string, start, length)``** \u2192 varchar\n\nThis is an alias for `substring`.\n\n**``substring(string, start, length)``** \u2192 varchar\n\nReturns a substring from `string` of length `length` from the starting position `start`. Positions start with `1`. A negative starting position is interpreted as being relative to the end of the string.\n\n#### translate()\n**``translate(source, from, to)``** \u2192 varchar\n\nReturns the `source` string translated by replacing characters found in the\n\n\n**``translate(source, from, to)``** \u2192 varchar\n\nReturns the `source` string translated by replacing characters found in the `from` string with the corresponding characters in the `to` string. If the `from` string contains duplicates, only the first is used. If the `source` character does not exist in the `from` string, the `source` character will be copied without translation. If the index of the matching character in the `from` string is beyond the length of the `to` string, the `source` character will be omitted from the resulting string.\n\nHere are some examples illustrating the translate function:\n```sql\n    SELECT translate('abcd', '', ''); -- 'abcd'\n    SELECT translate('abcd', 'a', 'z'); -- 'zbcd'\n    SELECT translate('abcda', 'a', 'z'); -- 'zbcdz'\n    SELECT translate('Palho\u00e7a', '\u00e7','c'); -- 'Palhoca'\n    SELECT translate('abcd', 'b', U&'\\+01F600'); -- a\ud83d\ude00cd\n    SELECT translate('abcd', 'a', ''); -- 'bcd'\n    SELECT translate('abcd', 'a', 'zy'); -- 'zbcd'\n    SELECT translate('abcd', 'ac', 'z'); -- 'zbd'\n    SELECT translate('abcd', 'aac', 'zq'); -- 'zbd'\n````\n\n#### trim()\n**``trim(string)``** \u2192 varchar\n\nRemoves leading and trailing whitespace from `string`.\n\n**``trim( \\[ \\[ specification \\] \\[ string \\] FROM \\] source )``** \u2192 varchar\n\nRemoves any leading and/or trailing characters as specified up to and including `string` from `source`:\n```sql\n", "doc_id": "fdfe23ee-66c0-413b-b702-1a6f416e205e", "embedding": null, "doc_hash": "1075867572fa59fe82d2137a9cc82465b29f5259f6484520ecb0dbf9bfb407d6", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/string.md", "file_name": "string.md"}, "node_info": {"start": 6263, "end": 9413, "_node_type": "1"}, "relationships": {"1": "5e40d91595902954d6cfd8b4060f62d358fc47a3", "2": "d3b98b06-604b-4c2a-8a16-bf41b5c32505", "3": "e068dc45-9190-4f6b-8ee7-d9709798a220"}}, "__type__": "1"}, "e068dc45-9190-4f6b-8ee7-d9709798a220": {"__data__": {"text": "as specified up to and including `string` from `source`:\n```sql\n    SELECT trim('!' FROM '!foo!'); -- 'foo'\n    SELECT trim(LEADING FROM '  abcd');  -- 'abcd'\n    SELECT trim(BOTH '$' FROM '$var$'); -- 'var'\n    SELECT trim(TRAILING 'ER' FROM upper('worker')); -- 'WORK'\n```\n\n#### upper()\n**``upper(string)``** \u2192 varchar\n\nConverts `string` to uppercase.\n\n#### word_stem()\n**``word_stem(word)``** \u2192 varchar\n\nReturns the stem of `word` in the English language.\n\n**``word_stem(word, lang)``** \u2192 varchar\n\nReturns the stem of `word` in the `lang` language.\n\n## Unicode functions\n\n#### normalize()\n**``normalize(string)``** \u2192 varchar\n\nTransforms `string` with NFC normalization form.\n\n**``normalize(string, form)``** \u2192 varchar\n\nTransforms `string` with the specified normalization form. `form` must be one of the following keywords:\n\n| Form  | Description                                                   |\n|-------|---------------------------------------------------------------|\n| `NFD` | Canonical Decomposition                                       |\n| `NFC` | Canonical Decomposition, followed by Canonical Composition    |\n| `NFKD`| Compatibility Decomposition                                   |\n| `NFKC`| Compatibility Decomposition, followed by Canonical Composition|\n\n!!! note\n\n    This SQL-standard function has special syntax and requires specifying\n    `form` as a keyword, not as a string.\n\n#### to_utf8()\n**``to_utf8(string)``** \u2192 varbinary\n\nEncodes `string` into a UTF-8 varbinary representation.\n\n#### from_utf8()\n**``from_utf8(binary)``** \u2192 varchar\n\nDecodes a UTF-8 encoded string from `binary`. Invalid UTF-8 sequences are replaced with the Unicode replacement character `U+FFFD`.\n\n**``from_utf8(binary, replace)``** \u2192 varchar\n\nDecodes a UTF-8 encoded string from `binary`. Invalid UTF-8 sequences are replaced with `replace`. The replacement string `replace` must either be a single character or empty (in which case invalid characters are removed).\n", "doc_id": "e068dc45-9190-4f6b-8ee7-d9709798a220", "embedding": null, "doc_hash": "c563352245932a372a6a39b0569893b8e8c670d5e591e9481787e34370416d2e", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/string.md", "file_name": "string.md"}, "node_info": {"start": 9386, "end": 11351, "_node_type": "1"}, "relationships": {"1": "5e40d91595902954d6cfd8b4060f62d358fc47a3", "2": "fdfe23ee-66c0-413b-b702-1a6f416e205e"}}, "__type__": "1"}, "ad243e5d-adbb-4603-9156-fa2c15434de4": {"__data__": {"text": "---\ntitle: System information\n---\n## System information\n\nFunctions providing information about the Trino cluster system environment. More information is available by querying the various schemas and tables exposed by the `/connector/system`.\n\n## Function\n\n**``version()``** -> varchar\n\nReturns the Trino version used on the cluster. Equivalent to the value of the `node_version` column in the `system.runtime.nodes` table.\n", "doc_id": "ad243e5d-adbb-4603-9156-fa2c15434de4", "embedding": null, "doc_hash": "0f74078fd0929ebf07ce539eb197ff7977d6bf230df66ac3fdf92f5cf387c2a2", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/system.md", "file_name": "system.md"}, "node_info": {"start": 0, "end": 423, "_node_type": "1"}, "relationships": {"1": "b941e25beab4714a2991c561a8045df5a671467e"}}, "__type__": "1"}, "37da259f-40d4-459e-93b8-3984a452ce0a": {"__data__": {"text": "---\ntitle: Table functions\n---\n\n!!!warning\n    This is currently not in operation in DuneSQL. It is a placeholder for future work.\n\n\nA table function is a function returning a table. It can be invoked\ninside the `FROM` clause of a query:\n```sql\n    SELECT * FROM TABLE(my_function(1, 100))\n```\nThe row type of the returned table can depend on the arguments passed\nwith invocation of the function. If different row types can be returned,\nthe function is a **polymorphic table function**.\n\nPolymorphic table functions allow you to dynamically invoke custom logic\nfrom within the SQL query. They can be used for working with external\nsystems as well as for enhancing Trino with capabilities going beyond\nthe SQL standard.\n\nTrino supports adding custom table functions. They are declared by\nconnectors through implementing dedicated interfaces. For guidance on\nadding new table functions, see the\n`developer guide.\n\nConnectors offer support for different functions on a per-connector\nbasis. For more information about supported table functions, refer to\nthe `connector\ndocumentation <../../connector>`.\n\n## Table function invocation\n\nYou invoke a table function in the `FROM` clause of a query. Table\nfunction invocation syntax is similar to a scalar function call.\n\n### Function resolution\n\nEvery table function is provided by a catalog, and it belongs to a\nschema in the catalog. You can qualify the function name with a schema\nname, or with catalog and schema names:  \n```sql\n    SELECT * FROM TABLE(schema_name.my_function(1, 100))\n    SELECT * FROM TABLE(catalog_name.schema_name.my_function(1, 100))\n```\nOtherwise, the standard Trino name resolution is applied. The connection\nbetween the function and the catalog must be identified, because the\nfunction is executed by the corresponding connector. If the function is\nnot registered by the specified catalog, the query fails.\n\nThe table function name is resolved case-insensitive, analogically to\nscalar function and table resolution in Trino.\n\n### Argument passing conventions\n\nThere are two conventions of passing arguments to a table function:\n\n-   **Arguments passed by name**:\n```sql\n        SELECT * FROM TABLE(my_function(row_count => 100, column_count => 1))\n```\nIn this convention, you can pass the arguments in arbitrary order.\nArguments declared with default values can be skipped. Argument names\nare resolved case-sensitive, and with automatic uppercasing of unquoted\nnames.\n\n-   **Arguments passed positionally**:\n```sql\n        SELECT * FROM TABLE(my_function(1, 100))\n```\nIn this convention, you must follow the order in which the arguments are\ndeclared. You can skip a suffix of the argument list, provided that all\nthe skipped arguments are declared with default values.\n\nYou cannot mix the argument conventions in one invocation.\n\nAll arguments must be constant expressions, and they can be of any SQL\ntype, which is compatible with the declared argument type. You can also\nuse parameters in arguments:\n\n```sql\n    PREPARE stmt FROM\n    SELECT * FROM TABLE(my_function(row_count => ? + 1, column_count => ?));\n\n    EXECUTE stmt USING 100, 1;\n```", "doc_id": "37da259f-40d4-459e-93b8-3984a452ce0a", "embedding": null, "doc_hash": "997f2f41440016d7804626da50c4a14e12b4f2a427fe315bf5e49c41484a890c", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/table.md", "file_name": "table.md"}, "node_info": {"start": 0, "end": 3115, "_node_type": "1"}, "relationships": {"1": "865cf46b429b4adeee71193b63c30921809f4bb8"}}, "__type__": "1"}, "fe0e73d8-ab73-40f1-875b-14cfed8e1f78": {"__data__": {"text": "---\ntitle: T-Digest functions\n---\n\n## Data structures\n\nA T-digest is a data sketch which stores approximate percentile\ninformation. The Trino type for this data structure is called `tdigest`.\nT-digests can be merged, and for storage and retrieval they can be cast\nto and from `VARBINARY`.\n\n## Functions\n\n#### merge()\n**``merge(tdigest)``** \u2192 tdigest\n\nAggregates all inputs into a single `tdigest`.\n\n#### values_at_quantile()\n**``value_at_quantile(tdigest, quantile)``** \u2192 double\n\nReturns the approximate percentile value from the T-digest, given the number `quantile` between 0 and 1.\n\n#### values_at_quantiles()\n**``values_at_quantiles(tdigest, quantiles)``** \u2192 array(double)\n\nReturns the approximate percentile values as an array, given the input T-digest and an array of values between 0 and 1, which represent the quantiles to return.\n\n#### tdigest_agg()\n**``tdigest_agg(x)``** \u2192 tdigest\n\nComposes all input values of `x` into a `tdigest`. `x` can be of any numeric type.\n\n\n**``tdigest_agg(x, w)``** \u2192 tdigest\n\nComposes all input values of `x` into a `tdigest` using the per-item weight `w`. `w` must be greater or equal than 1. `x` and `w` can be of any numeric type.\n", "doc_id": "fe0e73d8-ab73-40f1-875b-14cfed8e1f78", "embedding": null, "doc_hash": "10cd7c1808e8febba0aad773a020429b72d578eb801f182b81eaa687e3171ec7", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/tdigest.md", "file_name": "tdigest.md"}, "node_info": {"start": 0, "end": 1173, "_node_type": "1"}, "relationships": {"1": "95bd3a3ff0209fd9511fac413a38c1a56818775d"}}, "__type__": "1"}, "04171a41-dc7d-4865-9c22-41ae9ce2d1d6": {"__data__": {"text": "---\ntitle: Teradata functions\n---\n\nThese functions provide compatibility with Teradata SQL.\n\n## String functions\n\n#### char2()\n**``char2hexint(string)``** \u2192 varchar\n\nReturns the hexadecimal representation of the UTF-16BE encoding of the string.\n\n#### index()\n**``index(string, substring)``** \u2192 bigint\n\nAlias for `strpos` function.\n\n## Date functions\n\nThe functions in this section use a format string that is compatible\nwith the Teradata datetime functions. The following table, based on the\nTeradata reference manual, describes the supported format specifiers:\n\n  | Specifier | Description                   |\n|-----------|-------------------------------|\n| - / , . ; : | Punctuation characters are ignored |\n| dd        | Day of month (1-31)           |\n| hh        | Hour of day (1-12)            |\n| hh24      | Hour of the day (0-23)        |\n| mi        | Minute (0-59)                 |\n| mm        | Month (01-12)                 |\n| ss        | Second (0-59)                 |\n| yyyy      | 4-digit year                  |\n| yy        | 2-digit year                  |\n\n!!!warning\n    Case insensitivity is not currently supported. All specifiers must be\n    lowercase.\n\n\n#### to_char()\n**``to_char(timestamp, format)``** \u2192 varchar\n\nFormats `timestamp` as a string using `format`.\n\n#### to_timestamp()\n**``to_timestamp(string, format)``** \u2192 timestamp\n\nParses `string` into a `TIMESTAMP` using `format`.\n\n#### to_date()\n**``to_date(string, format)``** \u2192 date\n\nParses `string` into a `DATE` using `format`.\n\n", "doc_id": "04171a41-dc7d-4865-9c22-41ae9ce2d1d6", "embedding": null, "doc_hash": "fb924404bc72789f16c2b137b63cd91ac995b9072530a65479891d93ed96e403", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/teradata.md", "file_name": "teradata.md"}, "node_info": {"start": 0, "end": 1515, "_node_type": "1"}, "relationships": {"1": "cb0006c38d2b16470cfc3402d02a2eb66a6cb9d4"}}, "__type__": "1"}, "ff5ea6c8-6d98-4ec0-8b4a-c06bb2dfb38e": {"__data__": {"text": "---\ntitle: URL functions\n---\n\n## Extraction functions\n\nThe URL extraction functions extract components from HTTP URLs (or any\nvalid URIs conforming to `2396`{.interpreted-text role=\"rfc\"}). The\nfollowing syntax is supported:\n\n``` text\n[protocol:][//host[:port]][path][?query][#fragment]\n```\n\nThe extracted components do not contain URI syntax separators such as\n`:` or `?`.\n\n#### url_extract_fragment()\n**``url_extract_fragment(url)``** \u2192 varchar\n\nReturns the fragment identifier from `url`.\n\n#### url_extract_host()\n**``url_extract_host(url)``** \u2192 varchar\n\nReturns the host from `url`.\n\n#### url_extract_parameter()\n**``url_extract_parameter(url, name)``** \u2192 varchar\n\nReturns the value of the f query string parameter named `name` from `url`. Parameter extraction is handled in the typical manner as specified by RFC 1866#section-8.2.1.\n\n#### url_extract_path()\n**``url_extract_path(url)``** \u2192 varchar\n\nReturns the path from `url`.\n\n#### url_extract_port()\n**``url_extract_port(url)``** \u2192 bigint\n\nReturns the port number from `url`.\n\n#### url_extract_protocol()\n**``url_extract_protocol(url)``** \u2192 varchar\n\nReturns the protocol from `url`.\n\n#### url_extract_query()\n**``url_extract_query(url)``** \u2192 varchar\n\nReturns the query string from `url`.\n\n## Encoding functions\n\n#### url_encode()\n**``url_encode(value)``** \u2192 varchar\n\nEscapes `value` by encoding it so that it can be safely included in URL query parameter names and values.\n\n#### url_decode()\n**``url_decode(value)``** \u2192 varchar\n\nUnescapes the URL encoded `value`. This function is the inverse of `url_encode`.\n", "doc_id": "ff5ea6c8-6d98-4ec0-8b4a-c06bb2dfb38e", "embedding": null, "doc_hash": "fa4f309017237ea709027a66834e31623960c2068120c17849f8042050800ff1", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/url.md", "file_name": "url.md"}, "node_info": {"start": 0, "end": 1568, "_node_type": "1"}, "relationships": {"1": "9d7c7cbf680009058d6fa27fda32323e8be11c81"}}, "__type__": "1"}, "3f871c8a-e01b-431a-8079-d74421b1ca53": {"__data__": {"text": "---\ntitle: UUID functions\n---\n\n\n**``uuid()``** \u2192 uuid\n\nReturns a pseudo randomly generated `uuid_type`(type 4).\n", "doc_id": "3f871c8a-e01b-431a-8079-d74421b1ca53", "embedding": null, "doc_hash": "bb65d8bf35706e82df36c4d9f02aa79a39f25440c25831632cd3efaa5ee65b8e", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/uuid.md", "file_name": "uuid.md"}, "node_info": {"start": 0, "end": 112, "_node_type": "1"}, "relationships": {"1": "aa0adab1a07c50fc3f1a38830c026e002e5cb7e0"}}, "__type__": "1"}, "febc905c-c65d-46d7-a64a-d68d275f4cc7": {"__data__": {"text": "---\ntitle: Varbinary functions (DuneSQL)\n---\n\n## Varbinary Functions\n\nDune SQL represents byte arrays using the varbinary type.\n\nTo make it simpler to work with byte arrays we have the following helper functions, which work with these two kinds of representation. They simplify interactions with byte arrays, as they automatically account for the `0x`-prefix and use byte index instead of character index. For instance, the bytearray_substring methods take indexes by byte, not by character (twice the byte array length).\n\n\n## Byte Array Manipulation Functions\n\n#### bytearray_concat()\n\n**``bytearray_concat(varbinary, varbinary)``** \u2192 varbinary  \n\nConcatenates two byte arrays or strings.\n\n**`bytearry_concat(varchar, varchar)`** \u2192 varchar\n\nConcatenates two byte arrays or strings.\n\n#### bytearray_length()\n\n**``bytearray_length(varbinary)``** \u2192 bigint\n\nReturns the length of a byte array.\n\n**``bytearray_length(varchar)``** \u2192 varchar\n\nReturns the length of a string.\n\n#### bytearray_ltrim()\n\n**``bytearray_ltrim(varbinary)``** \u2192 varbinary\n\nRemoves zero bytes or spaces from the beginning of a byte array\n\n**``bytearray_ltrim(varchar)``** \u2192 varchar\n\nRemoves spaces from the beginning of a string.\n\n#### bytearray_position()\n\n**``bytearray_position(varbinary, varbinary)``** \u2192 bigint\n\nReturns the index of the first occurrence of a given bytearray or string (or 0 if not found) within a byte array or string.\n\n**``bytearray_position(varchar, varchar)``** \u2192 bigint\n\nReturns the index of the first occurrence of a given bytearray or string (or 0 if not found) within a byte array or string.\n\n#### bytearray_replace()\n\n**``bytearray_replace(varbinary, varbinary, varbinary)``** \u2192 varbinary\n\nGreedily replaces occurrences of a pattern within a byte array.\n\n**``bytearray_replace(varchar, varchar, varchar)``** \u2192 varchar\n\nGreedily replaces occurrences of a pattern within a string.\n\n#### bytearray_reverse()\n\n**``bytearray_reverse(varbinary)``** \u2192 varbinary\n\nReverses a given byte array.\n\n**``bytearray_reverse(varchar)``** \u2192 varchar\n\nReverses a given string.\n\n#### bytearray_rtrim()\n\n**``bytearray_rtrim(varbinary) or bytearray_rtrim(varchar)``** \u2192 varbinary or varchar\n\nRemoves zero bytes or spaces from the end of a byte array or string.\n\n#### bytearray_starts_with()\n\n**``bytearray_starts_with(varbinary, varbinary)``** \u2192 boolean\n\nDetermines whether a byte array starts with a prefix.\n\n**``bytearray_starts_with(varchar, varchar)``** \u2192 boolean\n\nDetermines whether a string starts with a prefix.\n\n#### bytearray_substring()\n\n**``bytearray_substring(varbinary, integer)``** \u2192 varbinary\n\nReturns a suffix byte array or string starting at a given index.\n\n**``bytearray_substring(varchar, integer)``** \u2192 varchar\n\nReturns a suffix string starting at a given index.\n\n**``bytearray_substring(varbinary, integer, integer)``** \u2192 varbinary\n\nReturns a sub byte array or string of a given length starting at an index.\n\n**``bytearray_substring(varchar,", "doc_id": "febc905c-c65d-46d7-a64a-d68d275f4cc7", "embedding": null, "doc_hash": "c017dfa7effde044d5b98666616a50dff481d9b0a191cc80e684f1c80f08c396", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/varbinary.md", "file_name": "varbinary.md"}, "node_info": {"start": 0, "end": 2937, "_node_type": "1"}, "relationships": {"1": "fa15efb471b788d149d1993c822fa18ea619a49c", "3": "e4035023-6fdb-40af-9e53-ff486ea8d5f4"}}, "__type__": "1"}, "e4035023-6fdb-40af-9e53-ff486ea8d5f4": {"__data__": {"text": "at an index.\n\n**``bytearray_substring(varchar, integer, integer)``** \u2192 varchar\n\nReturns a sub string of a given length starting at an index.\n\n## Byte Array to Numeric Functions\n\nThe byte array conversion functions throw an overflow exception if the byte array is larger than the number of bytes supported of the type, even if the most significant bytes are all zero. It is possible to use `bytearray_ltrim` in order to trim the zero bytes from the left.\n\n[Here is a dashboard](https://dune.com/dune/dune-sql-byte-array-functions-uint256-int256-support) with examples covering all of the above functions.\n\n#### bytearray_to_integer()\n\n**``bytearray_to_integer(varbinary)``** \u2192 integer\n\nReturns the `INTEGER` value of a big-endian byte array of length <= 4 representing the integer in two's complement. If the byte array has length < 4 it is padded with zero bytes.\n\n#### bytearray_to_bigint()\n\n**``bytearray_to_bigint(varbinary)``** \u2192 bigint\n\nReturns the `BIGINT` value of a big-endian byte array of length <= 8 representing the bigint in two's complement. If the byte array has length < 8 it is padded with zero bytes.\n\n#### bytearray_to_decimal()\n\n**``bytearray_to_decimal(varbinary)``** \u2192 decimal(38,0)\n\nReturns the `DECIMAL(38,0)` value of a big-endian byte array of length <= 16 representing the decimal(38,0) in two's complement. If the byte array has length < 16 it is padded with zero bytes.\n\n#### bytearray_to_uint256()\n\n**``bytearray_to_uint256(varbinary)``** \u2192 uint256\n\nReturns the `UINT256` of a big-endian byte array of length <= 32 representing the unsigned integer. If the byte array has length < 32 it is padded with zero bytes.\n\n#### bytearray_to_int256()\n\n**``bytearray_to_int256(varbinary)``** \u2192 int256\n\nReturns the `INT256` of a big-endian byte array of length <= 32 representing the signed integer. If the byte array has length < 32 it is padded with zero bytes.\n\n#### bytea2numeric()\n\n**``bytea2numeric(varbinary)``** \u2192 bigint\n\nThis function has been deprecated. It is an alias for `bytearray_to_bigint`.\n", "doc_id": "e4035023-6fdb-40af-9e53-ff486ea8d5f4", "embedding": null, "doc_hash": "04b7942f26f59e1d92c211f85e1dcb1f0c4e3061f3b47cd9a84d66b55188011a", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/varbinary.md", "file_name": "varbinary.md"}, "node_info": {"start": 2891, "end": 4917, "_node_type": "1"}, "relationships": {"1": "fa15efb471b788d149d1993c822fa18ea619a49c", "2": "febc905c-c65d-46d7-a64a-d68d275f4cc7"}}, "__type__": "1"}, "855530bb-74f6-47ed-83f9-2ede21784336": {"__data__": {"text": "---\ntitle: Window functions\n---\n\n## Window functions\n\nWindow functions perform calculations across rows of the query result.\nThey run after the `HAVING` clause but before the `ORDER BY` clause.\nInvoking a window function requires special syntax using the `OVER`\nclause to specify the window. For example, the following query ranks\norders for each clerk by price:\n```sql\n    SELECT orderkey, clerk, totalprice,\n           rank() OVER (PARTITION BY clerk\n                        ORDER BY totalprice DESC) AS rnk\n    FROM orders\n    ORDER BY clerk, rnk\n```\nThe window can be specified in two ways (see\n`window_clause`):\n\n-   By a reference to a named window specification defined in the\n    `WINDOW` clause,\n-   By an in-line window specification which allows to define window\n    components as well as refer to the window components pre-defined in\n    the `WINDOW` clause.\n\n## Aggregate functions\n\nAll `aggregate` can be used as window functions by adding the `OVER` clause. The aggregate function is\ncomputed for each row over the rows within the current row's window\nframe.\n\nFor example, the following query produces a rolling sum of order prices\nby day for each clerk:\n```sql\n    SELECT clerk, orderdate, orderkey, totalprice,\n           sum(totalprice) OVER (PARTITION BY clerk\n                                 ORDER BY orderdate) AS rolling_sum\n    FROM orders\n    ORDER BY clerk, orderdate, orderkey\n```\n## Ranking functions\n\n#### cume_dist()\n**cume_dist()** \u2192 bigint\n\nReturns the cumulative distribution of a value in a group of values. The\nresult is the number of rows preceding or peer with the row in the\nwindow ordering of the window partition divided by the total number of\nrows in the window partition. Thus, any tie values in the ordering will\nevaluate to the same distribution value.\n\n#### dense_rank()\n**dense_rank()** \u2192 bigint\n\nReturns the rank of a value in a group of values. This is similar to `rank`, except that tie values do not produce gaps in the sequence.\n\n#### ntile()\n**ntile(n)** \u2192 bigint\n\nDivides the rows for each window partition into `n` buckets ranging from `1` to at most `n`. Bucket values will differ by at most `1`. If the number of rows in the partition does not divide evenly into the number of buckets, then the remainder values are distributed one per bucket, starting with the first bucket.\n\nFor example, with `6` rows and `4` buckets, the bucket values would be as follows: `1` `1` `2` `2` `3` `4`\n\n#### percent_rank()\n**percent_rank()** \u2192 double\n\nReturns the percentage ranking of a value in group of values. The result is `(r - 1) / (n - 1)` where `r` is the `rank` of the row and `n` is the total number of rows in the window partition.\n\n#### rank()\n**rank()** \u2192 bigint\n\nReturns the rank of a value in a group of values. The rank is one plus the number of rows preceding the row that are not peer with the row. Thus, tie values in the ordering will produce gaps in the sequence. The ranking is performed for each window partition.\n\n#### row_number()\n**row_number()** \u2192 bigint\n\nReturns a unique, sequential number for each row, starting with one, according to the ordering of rows within the window partition.\n\n\n## Value functions\n\nBy default, null", "doc_id": "855530bb-74f6-47ed-83f9-2ede21784336", "embedding": null, "doc_hash": "64c4eab90ceafb17beef085a509cfecb967af196a98c6786c52025d8432899e2", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/window.md", "file_name": "window.md"}, "node_info": {"start": 0, "end": 3192, "_node_type": "1"}, "relationships": {"1": "863bfb8affce16421dfdefe28fd7e85ab66f8e61", "3": "9daa592b-8b7b-4006-9630-aa6d6a58e9b5"}}, "__type__": "1"}, "9daa592b-8b7b-4006-9630-aa6d6a58e9b5": {"__data__": {"text": "of rows within the window partition.\n\n\n## Value functions\n\nBy default, null values are respected. If `IGNORE NULLS` is specified,\nall rows where `x` is null are excluded from the calculation. If\n`IGNORE NULLS` is specified and `x` is null for all rows, the\n`default_value` is returned, or if it is not specified, `null` is\nreturned.\n\n#### f_value()\n**f_value(x)** \u2192 [same as input]\n\nReturns the f value of the window.\n\n#### last_value()\n**last_value(x)** \u2192 [same as input]\n\nReturns the last value of the window.\n\n#### nth_value()\n**nth_value(x, offset)** \u2192 [same as input]\n\nReturns the value at the specified offset from the beginning of the window. Offsets start at `1`. The offset can be any scalar expression. If the offset is null or greater than the number of values in the window, `null` is returned. It is an error for the offset to be zero or negative.\n\n#### lead()\n**lead(x[, offset [, default_value]])** \u2192 [same as input]\n\nReturns the value at `offset` rows after the current row in the window partition. Offsets start at `0`, which is the current row. The offset can be any scalar expression. The default `offset` is `1`. If the offset is null, `null` is returned. If the offset refers to a row that is not within the partition, the `default_value` is returned, or if it is not specified `null` is returned. The `lead` function requires that the window ordering be specified. Window frame must not be specified.\n\n#### lag()\n**lag(x[, offset [, default_value]])** \u2192 [same as input]\n\nReturns the value at `offset` rows before the current row in the window partition. Offsets start at `0`, which is the current row. The offset can be any scalar expression. The default `offset` is `1`. If the offset is null, `null` is returned. If the offset refers to a row that is not within the partition, the `default_value` is returned, or if it is not specified `null` is returned. The `lag` function requires that the window ordering be specified. Window frame must not be specified.\n\n", "doc_id": "9daa592b-8b7b-4006-9630-aa6d6a58e9b5", "embedding": null, "doc_hash": "952381db58fddff7693e50bf7f8f32ab45c4527ef9b3b68ec8ec5ea2e881af5f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/window.md", "file_name": "window.md"}, "node_info": {"start": 3117, "end": 5101, "_node_type": "1"}, "relationships": {"1": "863bfb8affce16421dfdefe28fd7e85ab66f8e61", "2": "855530bb-74f6-47ed-83f9-2ede21784336"}}, "__type__": "1"}, "08711a83-754a-4069-a058-04da6c960cc0": {"__data__": {"text": "# ALTER MATERIALIZED VIEW\n\n## Synopsis\n\n``` text\nALTER MATERIALIZED VIEW [ IF EXISTS ] name RENAME TO new_name\nALTER MATERIALIZED VIEW name SET PROPERTIES property_name = expression [, ...]\n```\n## Description\n\nChange the name of an existing materialized view.\n\nThe optional `IF EXISTS` clause causes the error to be suppressed if the\nmaterialized view does not exist. The error is not suppressed if the\nmaterialized view does not exist, but a table or view with the given\nname exists.\n\n### SET PROPERTIES {#alter-materialized-view-set-properties}\n\nThe `ALTER MATERIALIZED VIEW SET PROPERTIES` statement followed by some\nnumber of `property_name` and `expression` pairs applies the specified\nproperties and values to a materialized view. Ommitting an already-set\nproperty from this statement leaves that property unchanged in the\nmaterialized view.\n\nA property in a `SET PROPERTIES` statement can be set to `DEFAULT`,\nwhich reverts its value back to the default in that materialized view.\n\nSupport for `ALTER MATERIALIZED VIEW SET PROPERTIES` varies between\nconnectors. Refer to the connector documentation for more details.\n\n## Examples\n\nRename materialized view `people` to `users` in the current schema:\n\n    ALTER MATERIALIZED VIEW people RENAME TO users;\n\nRename materialized view `people` to `users`, if materialized view\n`people` exists in the current catalog and schema:\n\n    ALTER MATERIALIZED VIEW IF EXISTS people RENAME TO users;\n\nSet view properties (`x = y`) in materialized view `people`:\n\n    ALTER MATERIALIZED VIEW people SET PROPERTIES x = 'y';\n\nSet multiple view properties (`foo = 123` and `foo bar = 456`) in\nmaterialized view `people`:\n\n    ALTER MATERIALIZED VIEW people SET PROPERTIES foo = 123, \"foo bar\" = 456;\n\nSet view property `x` to its default value in materialized view\n`people`:\n\n    ALTER MATERIALIZED VIEW people SET PROPERTIES x = DEFAULT;\n\n## See also\n\n-   `create-materialized-view`{.interpreted-text role=\"doc\"}\n-   `refresh-materialized-view`{.interpreted-text role=\"doc\"}\n-   `drop-materialized-view`{.interpreted-text role=\"doc\"}\n", "doc_id": "08711a83-754a-4069-a058-04da6c960cc0", "embedding": null, "doc_hash": "b236a76b31da48872738080971e4de72fb260881b3239ed65b238eff97ad86d2", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/alter-materialized-view.md", "file_name": "alter-materialized-view.md"}, "node_info": {"start": 0, "end": 2072, "_node_type": "1"}, "relationships": {"1": "3ae8c3a974d6f57476d54c5070b003581677d03f"}}, "__type__": "1"}, "18ba54ed-8318-4f01-824b-6888d954cc39": {"__data__": {"text": "# ALTER TABLE\n\n## Synopsis\n\n``` text\nALTER TABLE [ IF EXISTS ] name RENAME TO new_name\nALTER TABLE [ IF EXISTS ] name ADD COLUMN [ IF NOT EXISTS ] column_name data_type\n  [ NOT NULL ] [ COMMENT comment ]\n  [ WITH ( property_name = expression [, ...] ) ]\nALTER TABLE [ IF EXISTS ] name DROP COLUMN [ IF EXISTS ] column_name\nALTER TABLE [ IF EXISTS ] name RENAME COLUMN [ IF EXISTS ] old_name TO new_name\nALTER TABLE [ IF EXISTS ] name ALTER COLUMN column_name SET DATA TYPE new_type\nALTER TABLE name SET AUTHORIZATION ( user | USER user | ROLE role )\nALTER TABLE name SET PROPERTIES property_name = expression [, ...]\nALTER TABLE name EXECUTE command [ ( parameter => expression [, ... ] ) ]\n    [ WHERE expression ]\n```\n\n## Description\n\nChange the definition of an existing table.\n\nThe optional `IF EXISTS` (when used before the table name) clause causes\nthe error to be suppressed if the table does not exists.\n\nThe optional `IF EXISTS` (when used before the column name) clause\ncauses the error to be suppressed if the column does not exists.\n\nThe optional `IF NOT EXISTS` clause causes the error to be suppressed if\nthe column already exists.\n\n### SET PROPERTIES {#alter-table-set-properties}\n\nThe `ALTER TABLE SET PROPERTIES` statement followed by some number of\n`property_name` and `expression` pairs applies the specified properties\nand values to a table. Ommitting an already-set property from this\nstatement leaves that property unchanged in the table.\n\nA property in a `SET PROPERTIES` statement can be set to `DEFAULT`,\nwhich reverts its value back to the default in that table.\n\nSupport for `ALTER TABLE SET PROPERTIES` varies between connectors, as\nnot all connectors support modifying table properties.\n\n### EXECUTE {#alter-table-execute}\n\nThe `ALTER TABLE EXECUTE` statement followed by a `command` and\n`parameters` modifies the table according to the specified command and\nparameters. `ALTER TABLE EXECUTE` supports different commands on a\nper-connector basis.\n\nYou can use the `=>` operator for passing named parameter values. The\nleft side is the name of the parameter, the right side is the value\nbeing passed:\n\n    ALTER TABLE hive.schema.test_table EXECUTE optimize(file_size_threshold => '10MB')\n\n## Examples\n\nRename table `users` to `people`:\n\n    ALTER TABLE users RENAME TO people;\n\nRename table `users` to `people` if table `users` exists:\n\n    ALTER TABLE IF EXISTS users RENAME TO people;\n\nAdd column `zip` to the `users` table:\n\n    ALTER TABLE users ADD COLUMN zip varchar;\n\nAdd column `zip` to the `users` table if table `users` exists and column\n`zip` not already exists:\n\n    ALTER TABLE IF EXISTS users ADD COLUMN IF NOT EXISTS zip varchar;\n\nDrop column `zip` from the `users` table:\n\n    ALTER TABLE users DROP COLUMN zip;\n\nDrop column `zip` from the `users` table if table `users` and column\n`zip` exists:\n\n    ALTER TABLE IF EXISTS users DROP COLUMN IF EXISTS zip;\n\nRename column `id` to `user_id` in the `users` table:\n\n    ALTER TABLE users RENAME COLUMN id TO user_id;\n\nRename column `id` to `user_id` in the `users` table if table `users`\nand column `id` exists:\n\n    ALTER TABLE IF EXISTS users RENAME column", "doc_id": "18ba54ed-8318-4f01-824b-6888d954cc39", "embedding": null, "doc_hash": "a06f2cb258bf186bfee6acae34935da5242bea05b7e0ec9a1591d9d90b421b3f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/alter-table.md", "file_name": "alter-table.md"}, "node_info": {"start": 0, "end": 3149, "_node_type": "1"}, "relationships": {"1": "2267eb40d6bc0cf1e7b8eee28bd8c5acf05c342a", "3": "07ae1165-0d60-40fa-af5a-ed64313b06f2"}}, "__type__": "1"}, "07ae1165-0d60-40fa-af5a-ed64313b06f2": {"__data__": {"text": "exists:\n\n    ALTER TABLE IF EXISTS users RENAME column IF EXISTS id to user_id;\n\nChange type of column `id` to `bigint` in the `users` table:\n\n    ALTER TABLE users ALTER COLUMN id SET DATA TYPE bigint;\n\nChange owner of table `people` to user `alice`:\n\n    ALTER TABLE people SET AUTHORIZATION alice\n\nAllow everyone with role public to drop and alter table `people`:\n\n    ALTER TABLE people SET AUTHORIZATION ROLE PUBLIC\n\nSet table properties (`x = y`) in table `people`:\n\n    ALTER TABLE people SET PROPERTIES x = 'y';\n\nSet multiple table properties (`foo = 123` and `foo bar = 456`) in table\n`people`:\n\n    ALTER TABLE people SET PROPERTIES foo = 123, \"foo bar\" = 456;\n\nSet table property `x` to its default value in table`people`:\n\n    ALTER TABLE people SET PROPERTIES x = DEFAULT;\n\nCollapse files in a table that are over 10 megabytes in size, as\nsupported by the Hive connector:\n\n    ALTER TABLE hive.schema.test_table EXECUTE optimize(file_size_threshold => '10MB')\n\n## See also\n\n`create-table`{.interpreted-text role=\"doc\"}\n", "doc_id": "07ae1165-0d60-40fa-af5a-ed64313b06f2", "embedding": null, "doc_hash": "aa30431e8b1f91c34e80724ba5a9d205e97cbef57a479cb23f08ec0eb02677c2", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/alter-table.md", "file_name": "alter-table.md"}, "node_info": {"start": 3095, "end": 4127, "_node_type": "1"}, "relationships": {"1": "2267eb40d6bc0cf1e7b8eee28bd8c5acf05c342a", "2": "18ba54ed-8318-4f01-824b-6888d954cc39"}}, "__type__": "1"}, "b2d95a78-9934-4761-8b0a-527589b47693": {"__data__": {"text": "# ALTER VIEW\n\n## Synopsis\n\n``` text\nALTER VIEW name RENAME TO new_name\nALTER VIEW name SET AUTHORIZATION ( user | USER user | ROLE role )\n```\n\n## Description\n\nChange the definition of an existing view.\n\n## Examples\n\nRename view `people` to `users`:\n\n    ALTER VIEW people RENAME TO users\n\nChange owner of VIEW `people` to user `alice`:\n\n    ALTER VIEW people SET AUTHORIZATION alice\n\n## See also\n\n`create-view`{.interpreted-text role=\"doc\"}\n", "doc_id": "b2d95a78-9934-4761-8b0a-527589b47693", "embedding": null, "doc_hash": "f48d8b6e01928d2ea625048558d90f5e4d41fa6d2b8f0e799c1861ebe0f12601", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/alter-view.md", "file_name": "alter-view.md"}, "node_info": {"start": 0, "end": 441, "_node_type": "1"}, "relationships": {"1": "420e8cf9959cc5896252761eb2a396c43d712daf"}}, "__type__": "1"}, "ccf7ae75-94ff-4d0f-bd65-177281bff8dd": {"__data__": {"text": "# ANALYZE\n\n## Synopsis\n\n``` text\nANALYZE table_name [ WITH ( property_name = expression [, ...] ) ]\n```\n\n## Description\n\nCollects table and column statistics for a given table.\n\nThe optional `WITH` clause can be used to provide connector-specific\nproperties. To list all available properties, run the following query:\n\n    SELECT * FROM system.metadata.analyze_properties\n\n## Examples\n\nAnalyze table `web` to collect table and column statistics:\n\n    ANALYZE web;\n\nAnalyze table `stores` in catalog `hive` and schema `default`:\n\n    ANALYZE hive.default.stores;\n\nAnalyze partitions `'1992-01-01', '1992-01-02'` from a Hive partitioned\ntable `sales`:\n\n    ANALYZE hive.default.sales WITH (partitions = ARRAY[ARRAY['1992-01-01'], ARRAY['1992-01-02']]);\n\nAnalyze partitions with complex partition key (`state` and `city`\ncolumns) from a Hive partitioned table `customers`:\n\n    ANALYZE hive.default.customers WITH (partitions = ARRAY[ARRAY['CA', 'San Francisco'], ARRAY['NY', 'NY']]);\n\nAnalyze only columns `department` and `product_id` for partitions\n`'1992-01-01', '1992-01-02'` from a Hive partitioned table `sales`:\n\n    ANALYZE hive.default.sales WITH (\n        partitions = ARRAY[ARRAY['1992-01-01'], ARRAY['1992-01-02']],\n        columns = ARRAY['department', 'product_id']);\n", "doc_id": "ccf7ae75-94ff-4d0f-bd65-177281bff8dd", "embedding": null, "doc_hash": "89928400f0208d848be8d1f27b5a5a45a58987c6dbcf6d3d1258f9d9ad5b16e6", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/analyze.md", "file_name": "analyze.md"}, "node_info": {"start": 0, "end": 1280, "_node_type": "1"}, "relationships": {"1": "972293085b68603417c72038f245e4c2652e50da"}}, "__type__": "1"}, "7333f29b-6762-4e30-961c-9bfaf2c2fb6b": {"__data__": {"text": "# CREATE MATERIALIZED VIEW\n\n## Synopsis\n\n``` text\nCREATE [ OR REPLACE ] MATERIALIZED VIEW\n[ IF NOT EXISTS ] view_name\n[ COMMENT string ]\n[ WITH properties ]\nAS query\n```\n\n## Description\n\nCreate and validate the definition of a new materialized view\n`view_name` of a `select`{.interpreted-text role=\"doc\"} `query`. You\nneed to run the `refresh-materialized-view`{.interpreted-text\nrole=\"doc\"} statement after the creation to populate the materialized\nview with data. This materialized view is a physical manifestation of\nthe query results at time of refresh. The data is stored, and can be\nreferenced by future queries.\n\nQueries accessing materialized views are typically faster than\nretrieving data from a view created with the same query. Any\ncomputation, aggregation, and other operation to create the data is\nperformed once during refresh of the materialized views, as compared to\neach time of accessing the view. Multiple reads of view data over time,\nor by multiple users, all trigger repeated processing. This is avoided\nfor materialized views.\n\nWhen the underlying data changes, the materialized view becomes out of\nsync with the source tables. Update the data in the materialized view\nwith the `refresh-materialized-view`{.interpreted-text role=\"doc\"}\nstatement.\n\nThe optional `OR REPLACE` clause causes the materialized view to be\nreplaced if it already exists rather than raising an error.\n\nThe optional `IF NOT EXISTS` clause causes the materialized view only to\nbe created or replaced if it does not exist yet.\n\nThe optional `COMMENT` clause causes a `string` comment to be stored\nwith the metadata about the materialized view. The comment is displayed\nwith the `show-create-materialized-view`{.interpreted-text role=\"doc\"}\nstatement and is available in the table\n`system.metadata.materialized_view_properties`.\n\nThe optional `WITH` clause is used to define properties for the\nmaterialized view creation. Separate multiple property/value pairs by\ncommas. The connector uses the properties as input parameters for the\nmaterialized view refresh operation. The supported properties are\ndifferent for each connector and detailed in the SQL support section of\nthe specific connector\\'s documentation.\n\nAfter successful creation, all metadata about the materialized view is\navailable in a\n`system table <system_metadata_materialized_views>`{.interpreted-text\nrole=\"ref\"}.\n\n## Examples\n\nCreate a simple materialized view `cancelled_orders` over the `orders`\ntable that only includes cancelled orders. Note that `orderstatus` is a\nnumeric value that is potentially meaningless to a consumer, yet the\nname of the view clarifies the content:\n\n    CREATE MATERIALIZED VIEW cancelled_orders\n    AS\n        SELECT orderkey, totalprice\n        FROM orders\n        WHERE orderstatus = 3;\n\nCreate or replace a materialized view `order_totals_by_date` that\nsummarizes `orders` across all orders from all customers:\n\n    CREATE OR REPLACE MATERIALIZED VIEW order_totals_by_date\n    AS\n        SELECT orderdate, sum(totalprice) AS price\n        FROM orders\n        GROUP BY orderdate;\n\nCreate a materialized view for a catalog using the Iceberg connector,\nwith a comment and partitioning on two fields in the storage:\n\n    CREATE MATERIALIZED VIEW orders_nation_mkgsegment\n    COMMENT 'Orders with nation and market segment data'\n    WITH ( partitioning = ARRAY['mktsegment', 'nationkey'] )\n    AS\n        SELECT o.*, c.nationkey,", "doc_id": "7333f29b-6762-4e30-961c-9bfaf2c2fb6b", "embedding": null, "doc_hash": "07553a37e95057ae928e3d4a099206052f0c4557c673247ecddfa73c6c196724", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/create-materialized-view.md", "file_name": "create-materialized-view.md"}, "node_info": {"start": 0, "end": 3423, "_node_type": "1"}, "relationships": {"1": "75261e68400d3d3c28eec769c722bf8206dfce99", "3": "0ad3b069-5d4c-4330-b73f-fe648a169fe9"}}, "__type__": "1"}, "0ad3b069-5d4c-4330-b73f-fe648a169fe9": {"__data__": {"text": "  AS\n        SELECT o.*, c.nationkey, c.mktsegment\n        FROM orders AS o\n        JOIN customer AS c\n        ON o.custkey = c.custkey;\n\nSet multiple properties:\n\n    WITH ( format = 'ORC', partitioning = ARRAY['_date'] )\n\nShow defined materialized view properties for all catalogs:\n\n    SELECT * FROM system.metadata.materialized_view_properties;\n\nShow metadata about the materialized views in all catalogs:\n\n    SELECT * FROM system.metadata.materialized_views;\n\n## See also\n\n-   `drop-materialized-view`{.interpreted-text role=\"doc\"}\n-   `show-create-materialized-view`{.interpreted-text role=\"doc\"}\n-   `refresh-materialized-view`{.interpreted-text role=\"doc\"}\n", "doc_id": "0ad3b069-5d4c-4330-b73f-fe648a169fe9", "embedding": null, "doc_hash": "27c8cf0ad25e3eca1cf45860874e20e0ca88cc01a6fbcd096a9ee77dd0d79321", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/create-materialized-view.md", "file_name": "create-materialized-view.md"}, "node_info": {"start": 3386, "end": 4052, "_node_type": "1"}, "relationships": {"1": "75261e68400d3d3c28eec769c722bf8206dfce99", "2": "7333f29b-6762-4e30-961c-9bfaf2c2fb6b"}}, "__type__": "1"}, "716c710a-8559-4208-9fa8-a091bacd8cce": {"__data__": {"text": "# CREATE TABLE AS\n\n## Synopsis\n\n``` text\nCREATE TABLE [ IF NOT EXISTS ] table_name [ ( column_alias, ... ) ]\n[ COMMENT table_comment ]\n[ WITH ( property_name = expression [, ...] ) ]\nAS query\n[ WITH [ NO ] DATA ]\n```\n\n## Description\n\nCreate a new table containing the result of a `select`{.interpreted-text\nrole=\"doc\"} query. Use `create-table`{.interpreted-text role=\"doc\"} to\ncreate an empty table.\n\nThe optional `IF NOT EXISTS` clause causes the error to be suppressed if\nthe table already exists.\n\nThe optional `WITH` clause can be used to set properties on the newly\ncreated table. To list all available table properties, run the following\nquery:\n\n    SELECT * FROM system.metadata.table_properties\n\n## Examples\n\nCreate a new table `orders_column_aliased` with the results of a query\nand the given column names:\n\n    CREATE TABLE orders_column_aliased (order_date, total_price)\n    AS\n    SELECT orderdate, totalprice\n    FROM orders\n\nCreate a new table `orders_by_date` that summarizes `orders`:\n\n    CREATE TABLE orders_by_date\n    COMMENT 'Summary of orders by date'\n    WITH (format = 'ORC')\n    AS\n    SELECT orderdate, sum(totalprice) AS price\n    FROM orders\n    GROUP BY orderdate\n\nCreate the table `orders_by_date` if it does not already exist:\n\n    CREATE TABLE IF NOT EXISTS orders_by_date AS\n    SELECT orderdate, sum(totalprice) AS price\n    FROM orders\n    GROUP BY orderdate\n\nCreate a new `empty_nation` table with the same schema as `nation` and\nno data:\n\n    CREATE TABLE empty_nation AS\n    SELECT *\n    FROM nation\n    WITH NO DATA\n\n## See also\n\n`create-table`{.interpreted-text role=\"doc\"}, `select`{.interpreted-text\nrole=\"doc\"}\n", "doc_id": "716c710a-8559-4208-9fa8-a091bacd8cce", "embedding": null, "doc_hash": "4d3bba3c03ab0a44b517c3a4f4e2392b9ba9222658b89062b09e5d62d0653fed", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/create-table-as.md", "file_name": "create-table-as.md"}, "node_info": {"start": 0, "end": 1655, "_node_type": "1"}, "relationships": {"1": "6df4e3127c93f09bdae012d6ea0679cb85edbc34"}}, "__type__": "1"}, "0453c618-7209-47d4-983e-85c81c4118f5": {"__data__": {"text": "# CREATE TABLE\n\n## Synopsis\n\n``` text\nCREATE TABLE [ IF NOT EXISTS ]\ntable_name (\n  { column_name data_type [ NOT NULL ]\n      [ COMMENT comment ]\n      [ WITH ( property_name = expression [, ...] ) ]\n  | LIKE existing_table_name\n      [ { INCLUDING | EXCLUDING } PROPERTIES ]\n  }\n  [, ...]\n)\n[ COMMENT table_comment ]\n[ WITH ( property_name = expression [, ...] ) ]\n```\n\n## Description\n\nCreate a new, empty table with the specified columns. Use\n`create-table-as`{.interpreted-text role=\"doc\"} to create a table with\ndata.\n\nThe optional `IF NOT EXISTS` clause causes the error to be suppressed if\nthe table already exists.\n\nThe optional `WITH` clause can be used to set properties on the newly\ncreated table or on single columns. To list all available table\nproperties, run the following query:\n\n    SELECT * FROM system.metadata.table_properties\n\nTo list all available column properties, run the following query:\n\n    SELECT * FROM system.metadata.column_properties\n\nThe `LIKE` clause can be used to include all the column definitions from\nan existing table in the new table. Multiple `LIKE` clauses may be\nspecified, which allows copying the columns from multiple tables.\n\nIf `INCLUDING PROPERTIES` is specified, all of the table properties are\ncopied to the new table. If the `WITH` clause specifies the same\nproperty name as one of the copied properties, the value from the `WITH`\nclause will be used. The default behavior is `EXCLUDING PROPERTIES`. The\n`INCLUDING PROPERTIES` option maybe specified for at most one table.\n\n## Examples\n\nCreate a new table `orders`:\n\n    CREATE TABLE orders (\n      orderkey bigint,\n      orderstatus varchar,\n      totalprice double,\n      orderdate date\n    )\n    WITH (format = 'ORC')\n\nCreate the table `orders` if it does not already exist, adding a table\ncomment and a column comment:\n\n    CREATE TABLE IF NOT EXISTS orders (\n      orderkey bigint,\n      orderstatus varchar,\n      totalprice double COMMENT 'Price in cents.',\n      orderdate date\n    )\n    COMMENT 'A table to keep track of orders.'\n\nCreate the table `bigger_orders` using the columns from `orders` plus\nadditional columns at the start and end:\n\n    CREATE TABLE bigger_orders (\n      another_orderkey bigint,\n      LIKE orders,\n      another_orderdate date\n    )\n\n## See also\n\n`alter-table`{.interpreted-text role=\"doc\"},\n`drop-table`{.interpreted-text role=\"doc\"},\n`create-table-as`{.interpreted-text role=\"doc\"},\n`show-create-table`{.interpreted-text role=\"doc\"}\n", "doc_id": "0453c618-7209-47d4-983e-85c81c4118f5", "embedding": null, "doc_hash": "c59eaa6abf09efeb191d1f36b459778cbf868b0550b81b80fbc8c7b8d5b1ca45", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/create-table.md", "file_name": "create-table.md"}, "node_info": {"start": 0, "end": 2476, "_node_type": "1"}, "relationships": {"1": "58608d569516c575d0314b0529ec02e2d565dce0"}}, "__type__": "1"}, "b81d0fd4-43ed-4458-b1b2-60df6b5b63e1": {"__data__": {"text": "# CREATE VIEW\n\n## Synopsis\n\n``` text\nCREATE [ OR REPLACE ] VIEW view_name\n[ COMMENT view_comment ]\n[ SECURITY { DEFINER | INVOKER } ]\nAS query\n```\n\n## Description\n\nCreate a new view of a `select`{.interpreted-text role=\"doc\"} query. The\nview is a logical table that can be referenced by future queries. Views\ndo not contain any data. Instead, the query stored by the view is\nexecuted every time the view is referenced by another query.\n\nThe optional `OR REPLACE` clause causes the view to be replaced if it\nalready exists rather than raising an error.\n\n## Security\n\nIn the default `DEFINER` security mode, tables referenced in the view\nare accessed using the permissions of the view owner (the *creator* or\n*definer* of the view) rather than the user executing the query. This\nallows providing restricted access to the underlying tables, for which\nthe user may not be allowed to access directly.\n\nIn the `INVOKER` security mode, tables referenced in the view are\naccessed using the permissions of the user executing the query (the\n*invoker* of the view). A view created in this mode is simply a stored\nquery.\n\nRegardless of the security mode, the `current_user` function will always\nreturn the user executing the query and thus may be used within views to\nfilter out rows or otherwise restrict access.\n\n## Examples\n\nCreate a simple view `test` over the `orders` table:\n\n    CREATE VIEW test AS\n    SELECT orderkey, orderstatus, totalprice / 2 AS half\n    FROM orders\n\nCreate a view `test_with_comment` with a view comment:\n\n    CREATE VIEW test_with_comment\n    COMMENT 'A view to keep track of orders.'\n    AS\n    SELECT orderkey, orderstatus, totalprice\n    FROM orders\n\nCreate a view `orders_by_date` that summarizes `orders`:\n\n    CREATE VIEW orders_by_date AS\n    SELECT orderdate, sum(totalprice) AS price\n    FROM orders\n    GROUP BY orderdate\n\nCreate a view that replaces an existing view:\n\n    CREATE OR REPLACE VIEW test AS\n    SELECT orderkey, orderstatus, totalprice / 4 AS quarter\n    FROM orders\n\n## See also\n\n`drop-view`{.interpreted-text role=\"doc\"},\n`show-create-view`{.interpreted-text role=\"doc\"}\n", "doc_id": "b81d0fd4-43ed-4458-b1b2-60df6b5b63e1", "embedding": null, "doc_hash": "616bb7a71146aef5191ad6cf83acfa383cb8d2b694d513be24ebb9265db455df", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/create-view.md", "file_name": "create-view.md"}, "node_info": {"start": 0, "end": 2116, "_node_type": "1"}, "relationships": {"1": "c9b150ac1b55d595a22ca441f225bf76260144f3"}}, "__type__": "1"}, "a76f6bd5-8e0f-4dc8-b997-bd890289e967": {"__data__": {"text": "# DELETE\n\n## Synopsis\n\n``` text\nDELETE FROM table_name [ WHERE condition ]\n```\n\n## Description\n\nDelete rows from a table. If the `WHERE` clause is specified, only the\nmatching rows are deleted. Otherwise, all rows from the table are\ndeleted.\n\n## Examples\n\nDelete all line items shipped by air:\n\n    DELETE FROM lineitem WHERE shipmode = 'AIR';\n\nDelete all line items for low priority orders:\n\n    DELETE FROM lineitem\n    WHERE orderkey IN (SELECT orderkey FROM orders WHERE priority = 'LOW');\n\nDelete all orders:\n\n    DELETE FROM orders;\n\n## Limitations\n\nSome connectors have limited or no support for `DELETE`. See connector\ndocumentation for more details.\n", "doc_id": "a76f6bd5-8e0f-4dc8-b997-bd890289e967", "embedding": null, "doc_hash": "6f6f3cfd15f711364fac6799690ea9a66f3f422116464f52afece33aeaa85ab7", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/delete.md", "file_name": "delete.md"}, "node_info": {"start": 0, "end": 659, "_node_type": "1"}, "relationships": {"1": "fe8ba53394a005842201e62311b5aba3ca1bce5b"}}, "__type__": "1"}, "73aade9a-e941-433f-9146-0babc895bf40": {"__data__": {"text": "# DESCRIBE INPUT\n\n## Synopsis\n\n``` text\nDESCRIBE INPUT statement_name\n```\n\n## Description\n\nLists the input parameters of a prepared statement along with the\nposition and type of each parameter. Parameter types that cannot be\ndetermined will appear as `unknown`.\n\n## Examples\n\nPrepare and describe a query with three parameters:\n\n``` sql\nPREPARE my_select1 FROM\nSELECT ? FROM nation WHERE regionkey = ? AND name < ?;\n```\n\n``` sql\nDESCRIBE INPUT my_select1;\n```\n\n``` text\nPosition | Type\n--------------------\n       0 | unknown\n       1 | bigint\n       2 | varchar\n(3 rows)\n```\n\nPrepare and describe a query with no parameters:\n\n``` sql\nPREPARE my_select2 FROM\nSELECT * FROM nation;\n```\n\n``` sql\nDESCRIBE INPUT my_select2;\n```\n\n``` text\nPosition | Type\n-----------------\n(0 rows)\n```\n\n## See also\n\n`prepare`{.interpreted-text role=\"doc\"}\n", "doc_id": "73aade9a-e941-433f-9146-0babc895bf40", "embedding": null, "doc_hash": "9b407612f8849ce9f3e026d4b48288129791a4fe896f60b50d2faccbf32691d2", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/describe-input.md", "file_name": "describe-input.md"}, "node_info": {"start": 0, "end": 836, "_node_type": "1"}, "relationships": {"1": "ca0402ec5262d2a05eadabc76f234ea726a10c2f"}}, "__type__": "1"}, "cf075db0-8e6f-44b1-8de6-5e97de799a1b": {"__data__": {"text": "# DESCRIBE OUTPUT\n\n## Synopsis\n\n``` text\nDESCRIBE OUTPUT statement_name\n```\n\n## Description\n\nList the output columns of a prepared statement, including the column\nname (or alias), catalog, schema, table, type, type size in bytes, and a\nboolean indicating if the column is aliased.\n\n## Examples\n\nPrepare and describe a query with four output columns:\n\n    PREPARE my_select1 FROM\n    SELECT * FROM nation;\n\n``` sql\nDESCRIBE OUTPUT my_select1;\n```\n\n``` text\nColumn Name | Catalog | Schema | Table  |  Type   | Type Size | Aliased\n-------------+---------+--------+--------+---------+-----------+---------\nnationkey   | tpch    | sf1    | nation | bigint  |         8 | false\nname        | tpch    | sf1    | nation | varchar |         0 | false\nregionkey   | tpch    | sf1    | nation | bigint  |         8 | false\ncomment     | tpch    | sf1    | nation | varchar |         0 | false\n(4 rows)\n```\n\nPrepare and describe a query whose output columns are expressions:\n\n    PREPARE my_select2 FROM\n    SELECT count(*) as my_count, 1+2 FROM nation;\n\n``` sql\nDESCRIBE OUTPUT my_select2;\n```\n\n``` text\nColumn Name | Catalog | Schema | Table |  Type  | Type Size | Aliased\n-------------+---------+--------+-------+--------+-----------+---------\nmy_count    |         |        |       | bigint |         8 | true\n_col1       |         |        |       | bigint |         8 | false\n(2 rows)\n```\n\nPrepare and describe a row count query:\n\n    PREPARE my_create FROM\n    CREATE TABLE foo AS SELECT * FROM nation;\n\n``` sql\nDESCRIBE OUTPUT my_create;\n```\n\n``` text\nColumn Name | Catalog | Schema | Table |  Type  | Type Size | Aliased\n-------------+---------+--------+-------+--------+-----------+---------\nrows        |         |        |       | bigint |         8 | false\n(1 row)\n```\n\n## See also\n\n`prepare`{.interpreted-text role=\"doc\"}\n", "doc_id": "cf075db0-8e6f-44b1-8de6-5e97de799a1b", "embedding": null, "doc_hash": "c2b5d6b596b82f7c9bacb1bfc50343237513360e8261b83973624337c52ae139", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/describe-output.md", "file_name": "describe-output.md"}, "node_info": {"start": 0, "end": 1824, "_node_type": "1"}, "relationships": {"1": "138c19485a3a39062cf9e5bf5d763628293f8d04"}}, "__type__": "1"}, "8123b4c7-e453-42cc-b189-6f0f0896f824": {"__data__": {"text": "# DESCRIBE\n\n## Synopsis\n\n``` text\nDESCRIBE table_name\n```\n\n## Description\n\n`DESCRIBE` is an alias for `show-columns`{.interpreted-text role=\"doc\"}.\n", "doc_id": "8123b4c7-e453-42cc-b189-6f0f0896f824", "embedding": null, "doc_hash": "c47fd3889c08e3ba6fa690f37d5105bf61e3421d978a48cc5ae28f08537a95c2", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/describe.md", "file_name": "describe.md"}, "node_info": {"start": 0, "end": 148, "_node_type": "1"}, "relationships": {"1": "3e4ae7b170bf476ad9044821008319ffb8a3c313"}}, "__type__": "1"}, "22445c7a-2a51-41b2-94e4-7afde869a605": {"__data__": {"text": "# EXECUTE\n\n## Synopsis\n\n``` text\nEXECUTE statement_name [ USING parameter1 [ , parameter2, ... ] ]\n```\n\n## Description\n\nExecutes a prepared statement with the name `statement_name`. Parameter\nvalues are defined in the `USING` clause.\n\n## Examples\n\nPrepare and execute a query with no parameters:\n\n    PREPARE my_select1 FROM\n    SELECT name FROM nation;\n\n``` sql\nEXECUTE my_select1;\n```\n\nPrepare and execute a query with two parameters:\n\n    PREPARE my_select2 FROM\n    SELECT name FROM nation WHERE regionkey = ? and nationkey < ?;\n\n``` sql\nEXECUTE my_select2 USING 1, 3;\n```\n\nThis is equivalent to:\n\n    SELECT name FROM nation WHERE regionkey = 1 AND nationkey < 3;\n\n## See also\n\n`prepare`{.interpreted-text role=\"doc\"}\n", "doc_id": "22445c7a-2a51-41b2-94e4-7afde869a605", "embedding": null, "doc_hash": "2fafeee668f4e5fa9b3e37b174f6bc30a9771b8b012b76a96c9c4cb49058f143", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/execute.md", "file_name": "execute.md"}, "node_info": {"start": 0, "end": 723, "_node_type": "1"}, "relationships": {"1": "50e0e9befd28ed9949c1518313e73d69eb519baf"}}, "__type__": "1"}, "6f607011-d6b6-4793-89c2-ee55be0926af": {"__data__": {"text": "# EXPLAIN ANALYZE\n\n## Synopsis\n\n``` text\nEXPLAIN ANALYZE [VERBOSE] statement\n```\n\n## Description\n\nExecute the statement and show the distributed execution plan of the\nstatement along with the cost of each operation.\n\nThe `VERBOSE` option will give more detailed information and low-level\nstatistics; understanding these may require knowledge of Trino internals\nand implementation details.\n\n\n!!!NOTE \n    The stats may not be entirely accurate, especially for queries that\n    complete quickly.\n\n## Examples\n\nIn the example below, you can see the CPU time spent in each stage, as\nwell as the relative cost of each plan node in the stage. Note that the\nrelative cost of the plan nodes is based on wall time, which may or may\nnot be correlated to CPU time. For each plan node you can see some\nadditional statistics (e.g: average input per node instance). Such\nstatistics are useful when one wants to detect data anomalies for a\nquery (e.g: skewness).\n\n```sql\nEXPLAIN ANALYZE SELECT count(*), clerk FROM orders\nWHERE orderdate > date '1995-01-01' GROUP BY clerk;\n```\n\n``` text\nQuery Plan\n-----------------------------------------------------------------------------------------------\nTrino version: version\nQueued: 374.17us, Analysis: 190.96ms, Planning: 179.03ms, Execution: 3.06s\nFragment 1 [HASH]\nCPU: 22.58ms, Scheduled: 96.72ms, Blocked 46.21s (Input: 23.06s, Output: 0.00ns), Input: 1000 rows (37.11kB); per task: avg.: 1000.00 std.dev.: 0.00, Output: 1000 rows (28.32kB)\nOutput layout: [clerk, count]\nOutput partitioning: SINGLE []\nProject[]\n\u2502   Layout: [clerk:varchar(15), count:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: 0B, network: 0B}\n\u2502   CPU: 8.00ms (3.51%), Scheduled: 63.00ms (15.11%), Blocked: 0.00ns (0.00%), Output: 1000 rows (28.32kB)\n\u2502   Input avg.: 15.63 rows, Input std.dev.: 24.36%\n\u2514\u2500 Aggregate[type = FINAL, keys = [clerk], hash = [$hashvalue]]\n\u2502   Layout: [clerk:varchar(15), $hashvalue:bigint, count:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: 0B}\n\u2502   CPU: 8.00ms (3.51%), Scheduled: 22.00ms (5.28%), Blocked: 0.00ns (0.00%), Output: 1000 rows (37.11kB)\n\u2502   Input avg.: 15.63 rows, Input std.dev.: 24.36%\n\u2502   count := count(\"count_0\")\n\u2514\u2500 LocalExchange[partitioning = HASH, hashColumn = [$hashvalue], arguments = [\"clerk\"]]\n\u2502   Layout: [clerk:varchar(15), count_0:bigint, $hashvalue:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: 0B, network: 0B}\n\u2502   CPU: 2.00ms (0.88%), Scheduled: 4.00ms (0.96%), Blocked: 23.15s (50.10%), Output: 1000 rows (37.11kB)\n\u2502   Input avg.: 15.63 rows, Input std.dev.: 793.73%\n\u2514\u2500 RemoteSource[sourceFragmentIds = [2]]\nLayout: [clerk:varchar(15), count_0:bigint, $hashvalue_1:bigint]\nCPU: 0.00ns (0.00%), Scheduled: 0.00ns (0.00%),", "doc_id": "6f607011-d6b6-4793-89c2-ee55be0926af", "embedding": null, "doc_hash": "3f3075a05cd01fc70caea4a78170c957a791864fa92574cb62c2c1431a4533fb", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain-analyze.md", "file_name": "explain-analyze.md"}, "node_info": {"start": 0, "end": 2716, "_node_type": "1"}, "relationships": {"1": "749d7ac379a27450e367352d4b92ded8eed698e1", "3": "8363113b-4e81-4571-b14f-66d900bbee55"}}, "__type__": "1"}, "8363113b-4e81-4571-b14f-66d900bbee55": {"__data__": {"text": "(0.00%), Scheduled: 0.00ns (0.00%), Blocked: 23.06s (49.90%), Output: 1000 rows (37.11kB)\nInput avg.: 15.63 rows, Input std.dev.: 793.73%\n\nFragment 2 [SOURCE]\nCPU: 210.60ms, Scheduled: 327.92ms, Blocked 0.00ns (Input: 0.00ns, Output: 0.00ns), Input: 1500000 rows (18.17MB); per task: avg.: 1500000.00 std.dev.: 0.00, Output: 1000 rows (37.11kB)\nOutput layout: [clerk, count_0, $hashvalue_2]\nOutput partitioning: HASH [clerk][$hashvalue_2]\nAggregate[type = PARTIAL, keys = [clerk], hash = [$hashvalue_2]]\n\u2502   Layout: [clerk:varchar(15), $hashvalue_2:bigint, count_0:bigint]\n\u2502   CPU: 30.00ms (13.16%), Scheduled: 30.00ms (7.19%), Blocked: 0.00ns (0.00%), Output: 1000 rows (37.11kB)\n\u2502   Input avg.: 818058.00 rows, Input std.dev.: 0.00%\n\u2502   count_0 := count(*)\n\u2514\u2500 ScanFilterProject[table = hive:sf1:orders, filterPredicate = (\"orderdate\" > DATE '1995-01-01')]\nLayout: [clerk:varchar(15), $hashvalue_2:bigint]\nEstimates: {rows: 1500000 (41.48MB), cpu: 35.76M, memory: 0B, network: 0B}/{rows: 816424 (22.58MB), cpu: 35.76M, memory: 0B, network: 0B}/{rows: 816424 (22.58MB), cpu: 22.58M, memory: 0B, network: 0B}\nCPU: 180.00ms (78.95%), Scheduled: 298.00ms (71.46%), Blocked: 0.00ns (0.00%), Output: 818058 rows (12.98MB)\nInput avg.: 1500000.00 rows, Input std.dev.: 0.00%\n$hashvalue_2 := combine_hash(bigint '0', COALESCE(\"$operator$hash_code\"(\"clerk\"), 0))\nclerk := clerk:varchar(15):REGULAR\norderdate := orderdate:date:REGULAR\nInput: 1500000 rows (18.17MB), Filtered: 45.46%, Physical Input: 4.51MB\n```\n\nWhen the `VERBOSE` option is used, some operators may report additional\ninformation. For example, the window function operator will output the\nfollowing:\n\n    EXPLAIN ANALYZE VERBOSE SELECT count(clerk) OVER() FROM orders\n    WHERE orderdate > date '1995-01-01';\n\n``` text\nQuery Plan\n-----------------------------------------------------------------------------------------------\n...\n\u2500 Window[]\n\u2502   Layout: [clerk:varchar(15), count:bigint]\n\u2502   CPU: 157.00ms (53.40%), Scheduled: 158.00ms (37.71%), Blocked: 0.00ns (0.00%), Output: 818058 rows (22.62MB)\n\u2502   metrics:\n\u2502     'CPU time distribution (s)' = {count=1.00, p01=0.16, p05=0.16, p10=0.16, p25=0.16, p50=0.16, p75=0.16, p90=0.16, p95=0.16, p99=0.16, min=0.16, max=0.16}\n\u2502     'Input rows distribution' = {count=1.00, p01=818058.00, p05=818058.00, p10=818058.00, p25=818058.00,", "doc_id": "8363113b-4e81-4571-b14f-66d900bbee55", "embedding": null, "doc_hash": "966bf1cbf83c3b12e617eaa2c2adc1b12fdee3642a239dab304678b99e36bf63", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain-analyze.md", "file_name": "explain-analyze.md"}, "node_info": {"start": 2685, "end": 5019, "_node_type": "1"}, "relationships": {"1": "749d7ac379a27450e367352d4b92ded8eed698e1", "2": "6f607011-d6b6-4793-89c2-ee55be0926af", "3": "8df1292f-7242-4c70-a166-2efe09ecb2a1"}}, "__type__": "1"}, "8df1292f-7242-4c70-a166-2efe09ecb2a1": {"__data__": {"text": "p10=818058.00, p25=818058.00, p50=818058.00, p75=818058.00, p90=818058.00, p95=818058.00, p99=818058.00, min=818058.00, max=818058.00}\n\u2502     'Scheduled time distribution (s)' = {count=1.00, p01=0.16, p05=0.16, p10=0.16, p25=0.16, p50=0.16, p75=0.16, p90=0.16, p95=0.16, p99=0.16, min=0.16, max=0.16}\n\u2502   Input avg.: 818058.00 rows, Input std.dev.: 0.00%\n\u2502   Active Drivers: [ 1 / 1 ]\n\u2502   Index size: std.dev.: 0.00 bytes, 0.00 rows\n\u2502   Index count per driver: std.dev.: 0.00\n\u2502   Rows per driver: std.dev.: 0.00\n\u2502   Size of partition: std.dev.: 0.00\n\u2502   count := count(\"clerk\") RANGE UNBOUNDED_PRECEDING CURRENT_ROW\n...\n```\n\n", "doc_id": "8df1292f-7242-4c70-a166-2efe09ecb2a1", "embedding": null, "doc_hash": "823e7d31252dc4aee1110600196fb819b9666b78bae4aeb9df8c192c0cf70087", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain-analyze.md", "file_name": "explain-analyze.md"}, "node_info": {"start": 5022, "end": 5646, "_node_type": "1"}, "relationships": {"1": "749d7ac379a27450e367352d4b92ded8eed698e1", "2": "8363113b-4e81-4571-b14f-66d900bbee55"}}, "__type__": "1"}, "81c04137-e576-4cee-a9a3-e0f5dd54bad1": {"__data__": {"text": "# EXPLAIN\n\n## Synopsis\n\n``` text\nEXPLAIN [ ( option [, ...] ) ] statement\n```\n\nwhere `option` can be one of:\n\n``` text\nFORMAT { TEXT | GRAPHVIZ | JSON }\nTYPE { LOGICAL | DISTRIBUTED | VALIDATE | IO }\n```\n\n## Description\n\nShow the logical or distributed execution plan of a statement, or\nvalidate the statement. The distributed plan is shown by default. Each\nplan fragment of the distributed plan is executed by a single or\nmultiple Trino nodes. Fragments separation represent the data exchange\nbetween Trino nodes. Fragment type specifies how the fragment is\nexecuted by Trino nodes and how the data is distributed between\nfragments:\n\n`SINGLE`\n\n:   Fragment is executed on a single node.\n\n`HASH`\n\n:   Fragment is executed on a fixed number of nodes with the input data\n    distributed using a hash function.\n\n`ROUND_ROBIN`\n\n:   Fragment is executed on a fixed number of nodes with the input data\n    distributed in a round-robin fashion.\n\n`BROADCAST`\n\n:   Fragment is executed on a fixed number of nodes with the input data\n    broadcasted to all nodes.\n\n`SOURCE`\n\n:   Fragment is executed on nodes where input splits are accessed.\n\n## Examples\n\n### EXPLAIN (TYPE LOGICAL)\n\nProcess the supplied query statement and create a logical plan in text\nformat:\n\n    EXPLAIN (TYPE LOGICAL) SELECT regionkey, count(*) FROM nation GROUP BY 1;\n\n``` text\nQuery Plan\n-----------------------------------------------------------------------------------------------------------------\nTrino version: version\nOutput[regionkey, _col1]\n\u2502   Layout: [regionkey:bigint, count:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}\n\u2502   _col1 := count\n\u2514\u2500 RemoteExchange[GATHER]\n\u2502   Layout: [regionkey:bigint, count:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}\n\u2514\u2500 Aggregate(FINAL)[regionkey]\n\u2502   Layout: [regionkey:bigint, count:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}\n\u2502   count := count(\"count_8\")\n\u2514\u2500 LocalExchange[HASH][$hashvalue] (\"regionkey\")\n\u2502   Layout: [regionkey:bigint, count_8:bigint, $hashvalue:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}\n\u2514\u2500 RemoteExchange[REPARTITION][$hashvalue_9]\n\u2502   Layout: [regionkey:bigint, count_8:bigint, $hashvalue_9:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}\n\u2514\u2500 Project[]\n\u2502   Layout: [regionkey:bigint, count_8:bigint, $hashvalue_10:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}\n\u2502   $hashvalue_10 := \"combine_hash\"(bigint '0', COALESCE(\"$operator$hash_code\"(\"regionkey\"), 0))\n\u2514\u2500 Aggregate(PARTIAL)[regionkey]\n\u2502   Layout: [regionkey:bigint, count_8:bigint]\n\u2502   count_8 := count(*)\n\u2514\u2500 TableScan[tpch:nation:sf0.01]\nLayout: [regionkey:bigint]\nEstimates: {rows: 25 (225B), cpu: 225, memory: 0B, network: 0B}\nregionkey := tpch:regionkey\n```\n\n### EXPLAIN", "doc_id": "81c04137-e576-4cee-a9a3-e0f5dd54bad1", "embedding": null, "doc_hash": "36ff5684e83a9dcb0d3e802dec075d87cba771982869ed10021cd65b952ec57f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 0, "end": 2795, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "3": "52ba728c-5a94-4340-ac94-de1a81f3887f"}}, "__type__": "1"}, "52ba728c-5a94-4340-ac94-de1a81f3887f": {"__data__": {"text": ":= tpch:regionkey\n```\n\n### EXPLAIN (TYPE LOGICAL, FORMAT JSON)\n\n::: warning\n::: title\nWarning\n:::\n\nThe output format is not guaranteed to be backward compatible across\nTrino versions.\n:::\n\nProcess the supplied query statement and create a logical plan in JSON\nformat:\n\n    EXPLAIN (TYPE LOGICAL, FORMAT JSON) SELECT regionkey, count(*) FROM nation GROUP BY 1;\n\n``` json\n{\n   \"id\": \"9\",\n   \"name\": \"Output\",\n   \"descriptor\": {\n      \"columnNames\": \"[regionkey, _col1]\"\n   },\n   \"outputs\": [\n      {\n         \"symbol\": \"regionkey\",\n         \"type\": \"bigint\"\n      },\n      {\n         \"symbol\": \"count\",\n         \"type\": \"bigint\"\n      }\n   ],\n   \"details\": [\n      \"_col1 := count\"\n   ],\n   \"estimates\": [\n      {\n         \"outputRowCount\": \"NaN\",\n         \"outputSizeInBytes\": \"NaN\",\n         \"cpuCost\": \"NaN\",\n         \"memoryCost\": \"NaN\",\n         \"networkCost\": \"NaN\"\n      }\n   ],\n   \"children\": [\n      {\n         \"id\": \"145\",\n         \"name\": \"RemoteExchange\",\n         \"descriptor\": {\n            \"type\": \"GATHER\",\n            \"isReplicateNullsAndAny\": \"\",\n            \"hashColumn\": \"\"\n         },\n         \"outputs\": [\n            {\n               \"symbol\": \"regionkey\",\n               \"type\": \"bigint\"\n            },\n            {\n               \"symbol\": \"count\",\n               \"type\": \"bigint\"\n            }\n         ],\n         \"details\": [\n\n         ],\n         \"estimates\": [\n            {\n               \"outputRowCount\": \"NaN\",\n               \"outputSizeInBytes\": \"NaN\",\n               \"cpuCost\": \"NaN\",\n               \"memoryCost\": \"NaN\",\n               \"networkCost\": \"NaN\"\n            }\n         ],\n         \"children\": [\n            {\n               \"id\": \"4\",\n               \"name\": \"Aggregate\",\n               \"descriptor\":", "doc_id": "52ba728c-5a94-4340-ac94-de1a81f3887f", "embedding": null, "doc_hash": "5031594f37278236aefb575de6dcbaca49b22447841053581eb73f7653da066f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 2764, "end": 4509, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "81c04137-e576-4cee-a9a3-e0f5dd54bad1", "3": "807b2e49-9214-4061-8efd-2d6d0924d0ee"}}, "__type__": "1"}, "807b2e49-9214-4061-8efd-2d6d0924d0ee": {"__data__": {"text": "              \"descriptor\": {\n                  \"type\": \"FINAL\",\n                  \"keys\": \"[regionkey]\",\n                  \"hash\": \"\"\n               },\n               \"outputs\": [\n                  {\n                     \"symbol\": \"regionkey\",\n                     \"type\": \"bigint\"\n                  },\n                  {\n                     \"symbol\": \"count\",\n                     \"type\": \"bigint\"\n                  }\n               ],\n               \"details\": [\n                  \"count := count(\\\"count_0\\\")\"\n               ],\n               \"estimates\": [\n                  {\n                     \"outputRowCount\": \"NaN\",\n                     \"outputSizeInBytes\": \"NaN\",\n                     \"cpuCost\": \"NaN\",\n                     \"memoryCost\": \"NaN\",\n                     \"networkCost\": \"NaN\"\n                  }\n               ],\n               \"children\": [\n                  {\n                     \"id\": \"194\",\n                     \"name\": \"LocalExchange\",\n                     \"descriptor\": {\n                        \"partitioning\": \"HASH\",\n                        \"isReplicateNullsAndAny\": \"\",\n                        \"hashColumn\": \"[$hashvalue]\",\n                        \"arguments\": \"[\\\"regionkey\\\"]\"\n                     },\n                     \"outputs\": [\n                        {\n                           \"symbol\": \"regionkey\",\n ", "doc_id": "807b2e49-9214-4061-8efd-2d6d0924d0ee", "embedding": null, "doc_hash": "e8cd7cee035eb8e58910e72b0a25dfbdb6071a1d9fee3a8adec0b02b1c60d379", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 4529, "end": 5881, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "52ba728c-5a94-4340-ac94-de1a81f3887f", "3": "6f89deb0-55ac-4b5c-933a-289ea5deaf78"}}, "__type__": "1"}, "6f89deb0-55ac-4b5c-933a-289ea5deaf78": {"__data__": {"text": "          \"symbol\": \"regionkey\",\n                           \"type\": \"bigint\"\n                        },\n                        {\n                           \"symbol\": \"count_0\",\n                           \"type\": \"bigint\"\n                        },\n                        {\n                           \"symbol\": \"$hashvalue\",\n                           \"type\": \"bigint\"\n                        }\n                     ],\n                     \"details\":[],\n                     \"estimates\": [\n                        {\n                           \"outputRowCount\": \"NaN\",\n                           \"outputSizeInBytes\": \"NaN\",\n                           \"cpuCost\": \"NaN\",\n                           \"memoryCost\": \"NaN\",\n                           \"networkCost\": \"NaN\"\n                        }\n                     ],\n                     \"children\": [\n                        {\n                           \"id\": \"200\",\n                           \"name\": \"RemoteExchange\",\n                           \"descriptor\": {\n                              \"type\": \"REPARTITION\",\n                              \"isReplicateNullsAndAny\": \"\",\n                              \"hashColumn\": \"[$hashvalue_1]\"\n                           },\n                           \"outputs\": [\n                 ", "doc_id": "6f89deb0-55ac-4b5c-933a-289ea5deaf78", "embedding": null, "doc_hash": "693d3a100606a684f0de5c6f9984937c5af20a6e22197b3f01592078003d94b5", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 5873, "end": 7146, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "807b2e49-9214-4061-8efd-2d6d0924d0ee", "3": "2899474e-70a5-4d8f-91cb-b5912c682fc4"}}, "__type__": "1"}, "2899474e-70a5-4d8f-91cb-b5912c682fc4": {"__data__": {"text": "[\n                              {\n                                 \"symbol\": \"regionkey\",\n                                 \"type\": \"bigint\"\n                              },\n                              {\n                                 \"symbol\": \"count_0\",\n                                 \"type\": \"bigint\"\n                              },\n                              {\n                                 \"symbol\": \"$hashvalue_1\",\n                                 \"type\": \"bigint\"\n                              }\n                           ],\n                           \"details\":[],\n                           \"estimates\": [\n                              {\n                                 \"outputRowCount\": \"NaN\",\n                                 \"outputSizeInBytes\": \"NaN\",\n                                 \"cpuCost\": \"NaN\",\n                                 \"memoryCost\": \"NaN\",\n                                 \"networkCost\": \"NaN\"\n                              }\n                           ],\n                           \"children\": [\n                              {\n                                 \"id\": \"226\",\n                                 \"name\": \"Project\",\n                         ", "doc_id": "2899474e-70a5-4d8f-91cb-b5912c682fc4", "embedding": null, "doc_hash": "51ea49fca0d96d391587b69405d7ce56aefced3f479761650286137b9fea2737", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 7167, "end": 8363, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "6f89deb0-55ac-4b5c-933a-289ea5deaf78", "3": "9c1c5efa-a030-4bc8-bd4e-0f7cd0f7c08c"}}, "__type__": "1"}, "9c1c5efa-a030-4bc8-bd4e-0f7cd0f7c08c": {"__data__": {"text": "                           \"descriptor\": {}\n                                 \"outputs\": [\n                                    {\n                                       \"symbol\": \"regionkey\",\n                                       \"type\": \"bigint\"\n                                    },\n                                    {\n                                       \"symbol\": \"count_0\",\n                                       \"type\": \"bigint\"\n                                    },\n                                    {\n                                       \"symbol\": \"$hashvalue_2\",\n                                       \"type\": \"bigint\"\n                                    }\n                                 ],\n                                 \"details\": [\n                                    \"$hashvalue_2 := combine_hash(bigint '0', COALESCE(\\\"$operator$hash_code\\\"(\\\"regionkey\\\"), 0))\"\n                                 ],\n                                 \"estimates\": [\n                                    {\n                                       \"outputRowCount\": \"NaN\",\n                                       \"outputSizeInBytes\": \"NaN\",\n                                       \"cpuCost\": \"NaN\",\n           ", "doc_id": "9c1c5efa-a030-4bc8-bd4e-0f7cd0f7c08c", "embedding": null, "doc_hash": "cf8400c5930b8c7b184cb13cdc9556c15c6ee7202b4bbea2e9a0f65b890430b7", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 8366, "end": 9576, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "2899474e-70a5-4d8f-91cb-b5912c682fc4", "3": "e5135386-3caa-4a3f-8dd1-7a7244f28117"}}, "__type__": "1"}, "e5135386-3caa-4a3f-8dd1-7a7244f28117": {"__data__": {"text": "\"cpuCost\": \"NaN\",\n                                       \"memoryCost\": \"NaN\",\n                                       \"networkCost\": \"NaN\"\n                                    }\n                                 ],\n                                 \"children\": [\n                                    {\n                                       \"id\": \"198\",\n                                       \"name\": \"Aggregate\",\n                                       \"descriptor\": {\n                                          \"type\": \"PARTIAL\",\n                                          \"keys\": \"[regionkey]\",\n                                          \"hash\": \"\"\n                                       },\n                                       \"outputs\": [\n                                          {\n                                             \"symbol\": \"regionkey\",\n                                             \"type\": \"bigint\"\n                                          },\n                                          {\n                                             \"symbol\": \"count_0\",\n                                             \"type\": \"bigint\"\n                                    ", "doc_id": "e5135386-3caa-4a3f-8dd1-7a7244f28117", "embedding": null, "doc_hash": "fe7ab11baf9068a48d613f4a61f846b8f278c6534874abb622382e87830d5a7a", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 9560, "end": 10724, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "9c1c5efa-a030-4bc8-bd4e-0f7cd0f7c08c", "3": "f84c4cea-b5e2-4ae0-b272-27cd5984eebb"}}, "__type__": "1"}, "f84c4cea-b5e2-4ae0-b272-27cd5984eebb": {"__data__": {"text": "                         }\n                                       ],\n                                       \"details\": [\n                                          \"count_0 := count(*)\"\n                                       ],\n                                       \"estimates\":[],\n                                       \"children\": [\n                                          {\n                                             \"id\": \"0\",\n                                             \"name\": \"TableScan\",\n                                             \"descriptor\": {\n                                                \"table\": \"hive:tpch_sf1_orc_part:nation\"\n                                             },\n                                             \"outputs\": [\n                                                {\n                                                   \"symbol\": \"regionkey\",\n                                                   \"type\": \"bigint\"\n                                                }\n                                             ],\n                                             \"details\": [\n                               ", "doc_id": "f84c4cea-b5e2-4ae0-b272-27cd5984eebb", "embedding": null, "doc_hash": "77bfba8777719575e1698354b59a9cab5254e534cd68d130823905a155ff68ea", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 10742, "end": 11878, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "e5135386-3caa-4a3f-8dd1-7a7244f28117", "3": "3041c0d5-6d1d-4621-ad3f-53102a814f95"}}, "__type__": "1"}, "3041c0d5-6d1d-4621-ad3f-53102a814f95": {"__data__": {"text": "                                    \"regionkey := regionkey:bigint:REGULAR\"\n                                             ],\n                                             \"estimates\": [\n                                                {\n                                                   \"outputRowCount\": 25,\n                                                   \"outputSizeInBytes\": 225,\n                                                   \"cpuCost\": 225,\n                                                   \"memoryCost\": 0,\n                                                   \"networkCost\": 0\n                                                }\n                                             ],\n                                             \"children\": []\n                                          }\n                                       ]\n                                    }\n                                 ]\n                              }\n                           ]\n                        }\n                     ]\n                  }\n               ]\n            }\n         ]\n      }\n   ]\n}\n```\n\n### EXPLAIN (TYPE DISTRIBUTED)\n\nProcess the supplied query statement and create a distributed plan", "doc_id": "3041c0d5-6d1d-4621-ad3f-53102a814f95", "embedding": null, "doc_hash": "349d678deabf690226cf0128bd885dc5eb72265ea4ffb32ff75d5036c0daaaf3", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 11879, "end": 13072, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "f84c4cea-b5e2-4ae0-b272-27cd5984eebb", "3": "66267e7b-95ed-42ee-bd41-512c8edad777"}}, "__type__": "1"}, "66267e7b-95ed-42ee-bd41-512c8edad777": {"__data__": {"text": "DISTRIBUTED)\n\nProcess the supplied query statement and create a distributed plan in\ntext format. The distributed plan splits the logical plan into stages,\nand therefore explicitly shows the data exchange between workers:\n\n    EXPLAIN (TYPE DISTRIBUTED) SELECT regionkey, count(*) FROM nation GROUP BY 1;\n\n``` text\nQuery Plan\n------------------------------------------------------------------------------------------------------\nTrino version: version\nFragment 0 [SINGLE]\nOutput layout: [regionkey, count]\nOutput partitioning: SINGLE []\nOutput[regionkey, _col1]\n\u2502   Layout: [regionkey:bigint, count:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}\n\u2502   _col1 := count\n\u2514\u2500 RemoteSource[1]\nLayout: [regionkey:bigint, count:bigint]\n\nFragment 1 [HASH]\nOutput layout: [regionkey, count]\nOutput partitioning: SINGLE []\nAggregate(FINAL)[regionkey]\n\u2502   Layout: [regionkey:bigint, count:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}\n\u2502   count := count(\"count_8\")\n\u2514\u2500 LocalExchange[HASH][$hashvalue] (\"regionkey\")\n\u2502   Layout: [regionkey:bigint, count_8:bigint, $hashvalue:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}\n\u2514\u2500 RemoteSource[2]\nLayout: [regionkey:bigint, count_8:bigint, $hashvalue_9:bigint]\n\nFragment 2 [SOURCE]\nOutput layout: [regionkey, count_8, $hashvalue_10]\nOutput partitioning: HASH [regionkey][$hashvalue_10]\nProject[]\n\u2502   Layout: [regionkey:bigint, count_8:bigint, $hashvalue_10:bigint]\n\u2502   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}\n\u2502   $hashvalue_10 := \"combine_hash\"(bigint '0', COALESCE(\"$operator$hash_code\"(\"regionkey\"), 0))\n\u2514\u2500 Aggregate(PARTIAL)[regionkey]\n\u2502   Layout: [regionkey:bigint, count_8:bigint]\n\u2502   count_8 := count(*)\n\u2514\u2500 TableScan[tpch:nation:sf0.01, grouped = false]\nLayout: [regionkey:bigint]\nEstimates: {rows: 25 (225B), cpu: 225, memory: 0B, network: 0B}\nregionkey := tpch:regionkey\n```\n\n### EXPLAIN (TYPE DISTRIBUTED, FORMAT JSON)\n\n::: warning\n::: title\nWarning\n:::\n\nThe output format is not guaranteed to be backward compatible across\nTrino versions.\n:::\n\nProcess the supplied query statement and create a distributed plan in\nJSON format. The distributed plan splits the logical plan into stages,\nand therefore explicitly shows the data exchange between workers:\n\n    EXPLAIN (TYPE DISTRIBUTED, FORMAT JSON) SELECT regionkey, count(*) FROM nation GROUP BY 1;\n\n``` json\n{\n   \"0\" : {\n      \"id\" : \"9\",\n      \"name\" : \"Output\",\n      \"descriptor\" : {\n         \"columnNames\" : \"[regionkey, _col1]\"\n      },\n      \"outputs\" : [ {\n         \"symbol\" : \"regionkey\",\n         \"type\" : \"bigint\"\n      }, {\n         \"symbol\" : \"count\",\n         \"type\" :", "doc_id": "66267e7b-95ed-42ee-bd41-512c8edad777", "embedding": null, "doc_hash": "039afcb29aa6c4cec9c7fd777cc2f27e08aeff9a71c370a64d2b889c413bd507", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 13002, "end": 15647, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "3041c0d5-6d1d-4621-ad3f-53102a814f95", "3": "b2cf7808-4912-405d-bc30-c573cd4e1f22"}}, "__type__": "1"}, "b2cf7808-4912-405d-bc30-c573cd4e1f22": {"__data__": {"text": ": \"count\",\n         \"type\" : \"bigint\"\n      } ],\n      \"details\" : [ \"_col1 := count\" ],\n      \"estimates\" : [ {\n         \"outputRowCount\" : \"NaN\",\n         \"outputSizeInBytes\" : \"NaN\",\n         \"cpuCost\" : \"NaN\",\n         \"memoryCost\" : \"NaN\",\n         \"networkCost\" : \"NaN\"\n      } ],\n      \"children\" : [ {\n         \"id\" : \"145\",\n         \"name\" : \"RemoteSource\",\n         \"descriptor\" : {\n            \"sourceFragmentIds\" : \"[1]\"\n         },\n         \"outputs\" : [ {\n            \"symbol\" : \"regionkey\",\n            \"type\" : \"bigint\"\n         }, {\n            \"symbol\" : \"count\",\n            \"type\" : \"bigint\"\n         } ],\n         \"details\" : [ ],\n         \"estimates\" : [ ],\n         \"children\" : [ ]\n      } ]\n   },\n   \"1\" : {\n      \"id\" : \"4\",\n      \"name\" : \"Aggregate\",\n      \"descriptor\" : {\n         \"type\" : \"FINAL\",\n         \"keys\" : \"[regionkey]\",\n         \"hash\" : \"[]\"\n      },\n      \"outputs\" : [ {\n         \"symbol\" : \"regionkey\",\n         \"type\" : \"bigint\"\n      }, {\n         \"symbol\" : \"count\",\n         \"type\" : \"bigint\"\n      } ],\n      \"details\" : [ \"count := count(\\\"count_0\\\")\" ],\n      \"estimates\" : [ {\n         \"outputRowCount\" : \"NaN\",\n         \"outputSizeInBytes\" : \"NaN\",\n         \"cpuCost\" : \"NaN\",\n         \"memoryCost\" : \"NaN\",\n         \"networkCost\" : \"NaN\"\n      } ],\n      \"children\" : [ {\n         \"id\" : \"194\",\n         \"name\" : \"LocalExchange\",\n         \"descriptor\" : {\n            \"partitioning\" : \"SINGLE\",\n            \"isReplicateNullsAndAny\" : \"\",\n            \"hashColumn\" : \"[]\",\n            \"arguments\" : \"[]\"\n         },\n         \"outputs\" : [ {\n            \"symbol\" : \"regionkey\",\n            \"type\" :", "doc_id": "b2cf7808-4912-405d-bc30-c573cd4e1f22", "embedding": null, "doc_hash": "1a1398ef78bcf83ac5cdc7b303440787058b871d805b8f94a4e520322fbdc122", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 15702, "end": 17353, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "66267e7b-95ed-42ee-bd41-512c8edad777", "3": "c16cd77b-fb22-4660-98f0-eaadf2a8f8a9"}}, "__type__": "1"}, "c16cd77b-fb22-4660-98f0-eaadf2a8f8a9": {"__data__": {"text": "\"regionkey\",\n            \"type\" : \"bigint\"\n         }, {\n            \"symbol\" : \"count_0\",\n            \"type\" : \"bigint\"\n         } ],\n         \"details\" : [ ],\n         \"estimates\" : [ {\n            \"outputRowCount\" : \"NaN\",\n            \"outputSizeInBytes\" : \"NaN\",\n            \"cpuCost\" : \"NaN\",\n            \"memoryCost\" : \"NaN\",\n            \"networkCost\" : \"NaN\"\n         } ],\n         \"children\" : [ {\n            \"id\" : \"227\",\n            \"name\" : \"Project\",\n            \"descriptor\" : { },\n            \"outputs\" : [ {\n               \"symbol\" : \"regionkey\",\n               \"type\" : \"bigint\"\n            }, {\n               \"symbol\" : \"count_0\",\n               \"type\" : \"bigint\"\n            } ],\n            \"details\" : [ ],\n            \"estimates\" : [ {\n               \"outputRowCount\" : \"NaN\",\n               \"outputSizeInBytes\" : \"NaN\",\n               \"cpuCost\" : \"NaN\",\n               \"memoryCost\" : \"NaN\",\n               \"networkCost\" : \"NaN\"\n            } ],\n            \"children\" : [ {\n               \"id\" : \"200\",\n               \"name\" : \"RemoteSource\",\n               \"descriptor\" : {\n                  \"sourceFragmentIds\" : \"[2]\"\n               },\n               \"outputs\" : [ {\n                  \"symbol\" : \"regionkey\",\n                  \"type\" : \"bigint\"\n               }, {\n                  \"symbol\" : \"count_0\",\n                  \"type\" : \"bigint\"\n               }, {\n                  \"symbol\" : \"$hashvalue\",\n                  \"type\" : \"bigint\"\n              ", "doc_id": "c16cd77b-fb22-4660-98f0-eaadf2a8f8a9", "embedding": null, "doc_hash": "cec5e3ed4aff41aa22db8fd62ea0f9823109e5a0683f2b6e1dea1ca251759d5d", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 17351, "end": 18832, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "b2cf7808-4912-405d-bc30-c573cd4e1f22", "3": "f9d918e4-94be-424b-ba50-e341aea92ecb"}}, "__type__": "1"}, "f9d918e4-94be-424b-ba50-e341aea92ecb": {"__data__": {"text": ": \"bigint\"\n               } ],\n               \"details\" : [ ],\n               \"estimates\" : [ ],\n               \"children\" : [ ]\n            } ]\n         } ]\n      } ]\n   },\n   \"2\" : {\n      \"id\" : \"226\",\n      \"name\" : \"Project\",\n      \"descriptor\" : { },\n      \"outputs\" : [ {\n         \"symbol\" : \"regionkey\",\n         \"type\" : \"bigint\"\n      }, {\n         \"symbol\" : \"count_0\",\n         \"type\" : \"bigint\"\n      }, {\n         \"symbol\" : \"$hashvalue_1\",\n         \"type\" : \"bigint\"\n      } ],\n      \"details\" : [ \"$hashvalue_1 := combine_hash(bigint '0', COALESCE(\\\"$operator$hash_code\\\"(\\\"regionkey\\\"), 0))\" ],\n      \"estimates\" : [ {\n         \"outputRowCount\" : \"NaN\",\n         \"outputSizeInBytes\" : \"NaN\",\n         \"cpuCost\" : \"NaN\",\n         \"memoryCost\" : \"NaN\",\n         \"networkCost\" : \"NaN\"\n      } ],\n      \"children\" : [ {\n         \"id\" : \"198\",\n         \"name\" : \"Aggregate\",\n         \"descriptor\" : {\n            \"type\" : \"PARTIAL\",\n            \"keys\" : \"[regionkey]\",\n            \"hash\" : \"[]\"\n         },\n         \"outputs\" : [ {\n            \"symbol\" : \"regionkey\",\n            \"type\" : \"bigint\"\n         }, {\n            \"symbol\" : \"count_0\",\n            \"type\" : \"bigint\"\n         } ],\n         \"details\" : [ \"count_0 := count(*)\" ],\n         \"estimates\" : [ ],\n         \"children\" : [ {\n            \"id\" : \"0\",\n            \"name\" : \"TableScan\",\n            \"descriptor\" : {\n               \"table\" : \"tpch:tiny:nation\"\n            },\n            \"outputs\" : [ {\n               \"symbol\" : \"regionkey\",\n               \"type\" : \"bigint\"\n            } ],\n            \"details\" : [ \"regionkey :=", "doc_id": "f9d918e4-94be-424b-ba50-e341aea92ecb", "embedding": null, "doc_hash": "14cb9144641fd845030d8a7273d675fe58a6722663f8fb8dcfb91c904fc335f6", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 18843, "end": 20449, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "c16cd77b-fb22-4660-98f0-eaadf2a8f8a9", "3": "c4969280-f679-467c-8b40-ab655393e4d5"}}, "__type__": "1"}, "c4969280-f679-467c-8b40-ab655393e4d5": {"__data__": {"text": "          \"details\" : [ \"regionkey := tpch:regionkey\" ],\n            \"estimates\" : [ {\n               \"outputRowCount\" : 25.0,\n               \"outputSizeInBytes\" : 225.0,\n               \"cpuCost\" : 225.0,\n               \"memoryCost\" : 0.0,\n               \"networkCost\" : 0.0\n            } ],\n            \"children\" : [ ]\n         } ]\n      } ]\n   }\n}\n```\n\n### EXPLAIN (TYPE VALIDATE)\n\nValidate the supplied query statement for syntactical and semantic\ncorrectness. Returns true if the statement is valid:\n\n    EXPLAIN (TYPE VALIDATE) SELECT regionkey, count(*) FROM nation GROUP BY 1;\n\n``` text\nValid\n-------\ntrue\n```\n\nIf the statement is not correct because a syntax error, such as an\nunknown keyword, is found the error message details the problem:\n\n    EXPLAIN (TYPE VALIDATE) SELET 1=0;\n\n``` text\nQuery 20220929_234840_00001_vjwxj failed: line 1:25: mismatched input 'SELET'.\nExpecting: 'ALTER', 'ANALYZE', 'CALL', 'COMMENT', 'COMMIT', 'CREATE',\n'DEALLOCATE', 'DELETE', 'DENY', 'DESC', 'DESCRIBE', 'DROP', 'EXECUTE',\n'EXPLAIN', 'GRANT', 'INSERT', 'MERGE', 'PREPARE', 'REFRESH', 'RESET',\n'REVOKE', 'ROLLBACK', 'SET', 'SHOW', 'START', 'TRUNCATE', 'UPDATE', 'USE',\n<query>\n```\n\nSimilarly if semantic issues are detected, such as an invalid object\nname `nations` instead of `nation`, the error message returns useful\ninformation:\n\n    EXPLAIN(TYPE VALIDATE) SELECT * FROM tpch.tiny.nations;\n\n``` text\nQuery 20220929_235059_00003_vjwxj failed: line 1:15: Table 'tpch.tiny.nations' does not exist\nSELECT * FROM tpch.tiny.nations\n```\n\n### EXPLAIN (TYPE IO)\n\nProcess the supplied query statement and create a plan with input and\noutput details about the accessed objects in JSON format:\n\n    EXPLAIN (TYPE IO, FORMAT JSON) INSERT INTO test_lineitem\n    SELECT * FROM lineitem WHERE shipdate = '2020-02-01' AND quantity > 10;\n\n``` text\nQuery Plan\n-----------------------------------\n{\ninputTableColumnInfos: [\n{\ntable: {\ncatalog: \"hive\",\nschemaTable: {\n   schema: \"tpch\",\n   table: \"test_orders\"\n}\n},\ncolumnConstraints: [\n{\n   columnName: \"orderkey\",\n   type: \"bigint\",\n   domain: {\n      nullsAllowed: false,\n      ranges: [\n         {\n            low: {\n               value: \"1\",\n               bound: \"EXACTLY\"\n            },\n            high: {\n               value: \"1\",\n       ", "doc_id": "c4969280-f679-467c-8b40-ab655393e4d5", "embedding": null, "doc_hash": "327c896e934f8e4095a3568fe028d26d0758ea1e06a3b04b1757c2c4860eff38", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 20437, "end": 22716, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "f9d918e4-94be-424b-ba50-e341aea92ecb", "3": "1ce17cd3-6ee4-4c36-a8b3-2c9aa5e603f2"}}, "__type__": "1"}, "1ce17cd3-6ee4-4c36-a8b3-2c9aa5e603f2": {"__data__": {"text": "       value: \"1\",\n               bound: \"EXACTLY\"\n            }\n         },\n         {\n            low: {\n               value: \"2\",\n               bound: \"EXACTLY\"\n            },\n            high: {\n               value: \"2\",\n               bound: \"EXACTLY\"\n            }\n         }\n      ]\n   }\n},\n{\n   columnName: \"processing\",\n   type: \"boolean\",\n   domain: {\n      nullsAllowed: false,\n      ranges: [\n         {\n            low: {\n               value: \"false\",\n               bound: \"EXACTLY\"\n            },\n            high: {\n               value: \"false\",\n               bound: \"EXACTLY\"\n            }\n         }\n      ]\n   }\n},\n{\n   columnName: \"custkey\",\n   type: \"bigint\",\n   domain: {\n      nullsAllowed: false,\n      ranges: [\n         {\n            low: {\n               bound: \"ABOVE\"\n            },\n            high: {\n               value: \"10\",\n               bound: \"EXACTLY\"\n            }\n         }\n      ]\n   }\n}\n],\nestimate: {\noutputRowCount: 2,\noutputSizeInBytes: 40,\ncpuCost: 40,\nmaxMemory: 0,\nnetworkCost: 0\n}\n}\n],\noutputTable: {\ncatalog: \"hive\",\nschemaTable: {\nschema: \"tpch\",\ntable: \"test_orders\"\n}\n},\nestimate: {\noutputRowCount: \"NaN\",\noutputSizeInBytes: \"NaN\",\ncpuCost: \"NaN\",\nmaxMemory: \"NaN\",\nnetworkCost: \"NaN\"\n}\n}\n```\n\n## See also\n\n`explain-analyze`{.interpreted-text role=\"doc\"}\n", "doc_id": "1ce17cd3-6ee4-4c36-a8b3-2c9aa5e603f2", "embedding": null, "doc_hash": "741e1c5f68233bab4a028aa718e0f0700a3a26bad57426cfa72884347e7192d6", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}, "node_info": {"start": 22713, "end": 24030, "_node_type": "1"}, "relationships": {"1": "95d36b23e4dbc89c2029ab325ee782b717a15197", "2": "c4969280-f679-467c-8b40-ab655393e4d5"}}, "__type__": "1"}, "cf84ba4f-f7af-48cf-9bfb-66df4287b04e": {"__data__": {"text": "---\ntitle: Overview\ndescription: DuneSQL is a ANSI SQL compliant query engine that follows the standard SQL syntax.\n---\n\n\n!!!warning \n    This section is a work in progress. If you have any questions, please reach out to us on [Discord](https://discord.gg/dunecom) \n<!--!!!note\n    Not quite sure what I am going to do with this whole section as we are mostly using very basic Select statements.\n    I think I can summarize this whole section on just one page. \n-->\n", "doc_id": "cf84ba4f-f7af-48cf-9bfb-66df4287b04e", "embedding": null, "doc_hash": "37944500047642fcc8b1b7ad7ad1c8a7f552f93a818bcab1343e4ac0db91e7ee", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 466, "_node_type": "1"}, "relationships": {"1": "c0e4570df74c2800c6d0175958794aaab6005e8a"}}, "__type__": "1"}, "c7c6980f-9c0a-408d-8410-eaad9d40c04e": {"__data__": {"text": "# INSERT\n\n## Synopsis\n\n``` text\nINSERT INTO table_name [ ( column [, ... ] ) ] query\n```\n\n## Description\n\nInsert new rows into a table.\n\nIf the list of column names is specified, they must exactly match the\nlist of columns produced by the query. Each column in the table not\npresent in the column list will be filled with a `null` value.\nOtherwise, if the list of columns is not specified, the columns produced\nby the query must exactly match the columns in the table being inserted\ninto.\n\n## Examples\n\nLoad additional rows into the `orders` table from the `new_orders`\ntable:\n\n    INSERT INTO orders\n    SELECT * FROM new_orders;\n\nInsert a single row into the `cities` table:\n\n    INSERT INTO cities VALUES (1, 'San Francisco');\n\nInsert multiple rows into the `cities` table:\n\n    INSERT INTO cities VALUES (2, 'San Jose'), (3, 'Oakland');\n\nInsert a single row into the `nation` table with the specified column\nlist:\n\n    INSERT INTO nation (nationkey, name, regionkey, comment)\n    VALUES (26, 'POLAND', 3, 'no comment');\n\nInsert a row without specifying the `comment` column. That column will\nbe `null`:\n\n    INSERT INTO nation (nationkey, name, regionkey)\n    VALUES (26, 'POLAND', 3);\n\n## See also\n\n`values`{.interpreted-text role=\"doc\"}\n", "doc_id": "c7c6980f-9c0a-408d-8410-eaad9d40c04e", "embedding": null, "doc_hash": "fedf94331aa325d067c6e83b40b61a149cfb7c5b426229502e69536bd6ce6b3c", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/insert.md", "file_name": "insert.md"}, "node_info": {"start": 0, "end": 1243, "_node_type": "1"}, "relationships": {"1": "96ff14aee8a5065612d649e60db2ed9f190ae2a6"}}, "__type__": "1"}, "f344de3d-aea4-432e-999a-39f8c30e3f2b": {"__data__": {"text": "# MATCH_RECOGNIZE\n\n## Synopsis\n\n``` text\nMATCH_RECOGNIZE (\n  [ PARTITION BY column [, ...] ]\n  [ ORDER BY column [, ...] ]\n  [ MEASURES measure_definition [, ...] ]\n  [ rows_per_match ]\n  [ AFTER MATCH skip_to ]\n  PATTERN ( row_pattern )\n  [ SUBSET subset_definition [, ...] ]\n  DEFINE variable_definition [, ...]\n  )\n```\n\n## Description\n\nThe `MATCH_RECOGNIZE` clause is an optional subclause of the `FROM`\nclause. It is used to detect patterns in a set of rows. Patterns of\ninterest are specified using row pattern syntax based on regular\nexpressions. The input to pattern matching is a table, a view or a\nsubquery. For each detected match, one or more rows are returned. They\ncontain requested information about the match.\n\nRow pattern matching is a powerful tool when analyzing complex sequences\nof events. The following examples show some of the typical use cases:\n\n-   in trade applications, tracking trends or identifying customers with\n    specific behavioral patterns\n-   in shipping applications, tracking packages through all possible\n    valid paths,\n-   in financial applications, detecting unusual incidents, which might\n    signal fraud\n\n## Example\n\nIn the following example, the pattern describes a V-shape over the\n`totalprice` column. A match is found whenever orders made by a customer\nfirst decrease in price, and then increase past the starting point:\n\n    SELECT * FROM orders MATCH_RECOGNIZE(\n         PARTITION BY custkey\n         ORDER BY orderdate\n         MEASURES\n                  A.totalprice AS starting_price,\n                  LAST(B.totalprice) AS bottom_price,\n                  LAST(U.totalprice) AS top_price\n         ONE ROW PER MATCH\n         AFTER MATCH SKIP PAST LAST ROW\n         PATTERN (A B+ C+ D+)\n         SUBSET U = (C, D)\n         DEFINE\n                  B AS totalprice < PREV(totalprice),\n                  C AS totalprice > PREV(totalprice) AND totalprice <= A.totalprice,\n                  D AS totalprice > PREV(totalprice)\n         )\n\nIn the following sections, all subclauses of the `MATCH_RECOGNIZE`\nclause are explained with this example query.\n\n## Partitioning and ordering\n\n``` sql\nPARTITION BY custkey\n```\n\nThe `PARTITION BY` clause allows you to break up the input table into\nseparate sections, that are independently processed for pattern\nmatching. Without a partition declaration, the whole input table is\nused. This behavior is analogous to the semantics of `PARTITION BY`\nclause in `window\nspecification<window_clause>`{.interpreted-text role=\"ref\"}. In the\nexample, the `orders` table is partitioned by the `custkey` value, so\nthat pattern matching is performed for all orders of a specific customer\nindependently from orders of other customers.\n\n``` sql\nORDER BY orderdate\n```\n\nThe optional `ORDER BY` clause is generally useful to allow", "doc_id": "f344de3d-aea4-432e-999a-39f8c30e3f2b", "embedding": null, "doc_hash": "bbbc4bdbc179af5cc176919e0212be7503cb743ee25b194d710d8d2748bd0802", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md", "file_name": "match-recognize.md"}, "node_info": {"start": 0, "end": 2804, "_node_type": "1"}, "relationships": {"1": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1", "3": "385b9c18-ab8f-48c0-a795-b237e2adbb79"}}, "__type__": "1"}, "385b9c18-ab8f-48c0-a795-b237e2adbb79": {"__data__": {"text": "optional `ORDER BY` clause is generally useful to allow matching on\nan ordered data set. For example, sorting the input by `orderdate`\nallows for matching on a trend of changes over time.\n\n## Row pattern measures {#row_pattern_measures}\n\nThe `MEASURES` clause allows to specify what information is retrieved\nfrom a matched sequence of rows.\n\n``` text\nMEASURES measure_expression AS measure_name [, ...]\n```\n\nA measure expression is a scalar expression whose value is computed\nbased on a match. In the example, three row pattern measures are\nspecified:\n\n`A.totalprice AS starting_price` returns the price in the first row of\nthe match, which is the only row associated with `A` according to the\npattern.\n\n`LAST(B.totalprice) AS bottom_price` returns the lowest price\n(corresponding to the bottom of the \\\"V\\\" in the pattern). It is the\nprice in the last row associated with `B`, which is the last row of the\ndescending section.\n\n`LAST(U.totalprice) AS top_price` returns the highest price in the\nmatch. It is the price in the last row associated with `C` or `D`, which\nis also the final row of the match.\n\nMeasure expressions can refer to the columns of the input table. They\nalso allow special syntax to combine the input information with the\ndetails of the match (see\n`pattern_recognition_expressions`{.interpreted-text role=\"ref\"}).\n\nEach measure defines an output column of the pattern recognition. The\ncolumn can be referenced with the `measure_name`.\n\nThe `MEASURES` clause is optional. When no measures are specified,\ncertain input columns (depending on\n`ROWS PER MATCH<rows_per_match>`{.interpreted-text role=\"ref\"} clause)\nare the output of the pattern recognition.\n\n## Rows per match {#rows_per_match}\n\nThis clause can be used to specify the quantity of output rows. There\nare two main options:\n\n    ONE ROW PER MATCH\n\nand\n\n``` sql\nALL ROWS PER MATCH\n```\n\n`ONE ROW PER MATCH` is the default option. For every match, a single row\nof output is produced. Output consists of `PARTITION BY` columns and\nmeasures. The output is also produced for empty matches, based on their\nstarting rows. Rows that are unmatched (that is, neither included in\nsome non-empty match, nor being the starting row of an empty match), are\nnot included in the output.\n\nFor `ALL ROWS PER MATCH`, every row of a match produces an output row,\nunless it is excluded from the output by the\n`exclusion_syntax`{.interpreted-text role=\"ref\"}. Output consists of\n`PARTITION BY` columns, `ORDER BY` columns, measures and remaining\ncolumns from the input table. By default, empty matches are shown and\nunmatched rows are skipped, similarly as with the `ONE ROW PER MATCH`\noption. However, this behavior can be changed by modifiers:\n\n    ALL ROWS PER MATCH SHOW EMPTY MATCHES\n\nshows empty matches and skips unmatched rows, like the default.\n\n``` sql\nALL ROWS PER MATCH OMIT EMPTY MATCHES\n```\n\nexcludes empty matches from the output.\n\n``` sql\nALL ROWS PER MATCH WITH UNMATCHED ROWS\n```\n\nshows empty matches and produces additional output row for each\nunmatched row.\n\nThere are special rules for computing row pattern measures for empty\nmatches and unmatched rows. They are explained in\n`empty_matches_and_unmatched_rows`{.interpreted-text role=\"ref\"}.\n\nUnmatched rows can only occur when the pattern does not allow an empty\nmatch. Otherwise, they are considered as starting rows of empty matches.\nThe option `ALL ROWS PER MATCH WITH UNMATCHED ROWS` is recommended", "doc_id": "385b9c18-ab8f-48c0-a795-b237e2adbb79", "embedding": null, "doc_hash": "a272fad183804d5f4161bcb767490692e064c9029701a0d165e80e24a7cb3e88", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md", "file_name": "match-recognize.md"}, "node_info": {"start": 2758, "end": 6189, "_node_type": "1"}, "relationships": {"1": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1", "2": "f344de3d-aea4-432e-999a-39f8c30e3f2b", "3": "040046f7-a507-4793-acf8-96ff143a40f4"}}, "__type__": "1"}, "040046f7-a507-4793-acf8-96ff143a40f4": {"__data__": {"text": "option `ALL ROWS PER MATCH WITH UNMATCHED ROWS` is recommended when\npattern recognition is expected to pass all input rows, and it is not\ncertain whether the pattern allows an empty match.\n\n## After match skip {#after_match_skip}\n\nThe `AFTER MATCH SKIP` clause specifies where pattern matching resumes\nafter a non-empty match is found.\n\nThe default option is:\n\n    AFTER MATCH SKIP PAST LAST ROW\n\nWith this option, pattern matching starts from the row after the last\nrow of the match. Overlapping matches are not detected.\n\nWith the following option, pattern matching starts from the second row\nof the match:\n\n    AFTER MATCH SKIP TO NEXT ROW\n\nIn the example, if a V-shape is detected, further overlapping matches\nare found, starting from consecutive rows on the descending slope of the\n\\\"V\\\". Skipping to the next row is the default behavior after detecting\nan empty match or unmatched row.\n\nThe following `AFTER MATCH SKIP` options allow to resume pattern\nmatching based on the components of the pattern. Pattern matching starts\nfrom the last (default) or first row matched to a certain row pattern\nvariable. It can be either a primary pattern variable (they are\nexplained in `row_pattern_syntax`{.interpreted-text role=\"ref\"}) or a\n`union variable<row_pattern_union_variables>`{.interpreted-text\nrole=\"ref\"}:\n\n    AFTER MATCH SKIP TO [ FIRST | LAST ] pattern_variable\n\nIt is forbidden to skip to the first row of the current match, because\nit results in an infinite loop. For example specifying\n`AFTER MATCH SKIP TO A` fails, because `A` is the first element of the\npattern, and jumping back to it creates an infinite loop. Similarly,\nskipping to a pattern variable which is not present in the match causes\nfailure.\n\nAll other options than the default `AFTER MATCH SKIP PAST LAST ROW`\nallow detection of overlapping matches. The combination of\n`ALL ROWS PER MATCH WITH UNMATCHED ROWS` with\n`AFTER MATCH SKIP PAST LAST ROW` is the only configuration that\nguarantees exactly one output row for each input row.\n\n## Row pattern syntax {#row_pattern_syntax}\n\nRow pattern is a form of a regular expression with some syntactical\nextensions specific to row pattern recognition. It is specified in the\n`PATTERN` clause:\n\n    PATTERN ( row_pattern )\n\nThe basic element of row pattern is a primary pattern variable. Like\npattern matching in character strings searches for characters, pattern\nmatching in row sequences searches for rows which can be \\\"labeled\\\"\nwith certain primary pattern variables. A primary pattern variable has a\nform of an identifier and is\n`defined<row_pattern_variable_definitions>`{.interpreted-text\nrole=\"ref\"} by a boolean condition. This condition determines whether a\nparticular input row can be mapped to this variable and take part in the\nmatch.\n\nIn the example `PATTERN (A B+ C+ D+)`, there are four primary pattern\nvariables: `A`, `B`, `C`, and `D`.\n\nRow pattern syntax includes the following usage:\n\n### concatenation\n\n``` text\nA B+ C+ D+\n```\n\nIt is a sequence of components without operators between them. All\ncomponents are matched in the same order as they are specified.\n\n### alternation\n\n``` text\nA | B | C\n```\n\nIt is a sequence of components separated by `|`. Exactly one of the\ncomponents is matched. In case when multiple components can be matched,\nthe leftmost matching component is chosen.\n\n### permutation\n\n``` text\nPERMUTE(A, B, C)\n```\n\nIt is equivalent to alternation of all permutations of its", "doc_id": "040046f7-a507-4793-acf8-96ff143a40f4", "embedding": null, "doc_hash": "5a6d1043528d757344ceef50e132d45073033fd35bc8b897b01fec69e7d0d1a1", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md", "file_name": "match-recognize.md"}, "node_info": {"start": 6184, "end": 9617, "_node_type": "1"}, "relationships": {"1": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1", "2": "385b9c18-ab8f-48c0-a795-b237e2adbb79", "3": "5c853bfe-675f-487f-86cc-e3bb8bad68e7"}}, "__type__": "1"}, "5c853bfe-675f-487f-86cc-e3bb8bad68e7": {"__data__": {"text": "C)\n```\n\nIt is equivalent to alternation of all permutations of its components.\nAll components are matched in some order. If multiple matches are\npossible for different orderings of the components, the match is chosen\nbased on the lexicographical order established by the order of\ncomponents in the `PERMUTE` list. In the above example, the most\npreferred option is `A B C`, and the least preferred option is `C B A`.\n\n### grouping\n\n``` text\n(A B C)\n```\n\n### partition start anchor\n\n``` text\n^\n```\n\n### partition end anchor\n\n``` text\n$\n```\n\n### empty pattern\n\n``` text\n()\n```\n\n### exclusion syntax {#exclusion_syntax}\n\n``` text\n{- row_pattern -}\n```\n\nExclusion syntax is used to specify portions of the match to exclude\nfrom the output. It is useful in combination with the\n`ALL ROWS PER MATCH` option, when only certain sections of the match are\ninteresting.\n\nIf you change the example to use `ALL ROWS PER MATCH`, and the pattern\nis modified to `PATTERN (A {- B+ C+ -} D+)`, the result consists of the\ninitial matched row and the trailing section of rows.\n\nSpecifying pattern exclusions does not affect the computation of\nexpressions in `MEASURES` and `DEFINE` clauses. Exclusions also do not\naffect pattern matching. They have the same semantics as regular\ngrouping with parentheses.\n\nIt is forbidden to specify pattern exclusions with the option\n`ALL ROWS PER MATCH WITH UNMATCHED ROWS`.\n\n### quantifiers\n\nPattern quantifiers allow to specify the desired number of repetitions\nof a sub-pattern in a match. They are appended after the relevant\npattern component:\n\n    (A | B)*\n\nThere are following row pattern quantifiers:\n\n-   zero or more repetitions:\n\n``` text\n*\n```\n\n-   one or more repetitions:\n\n``` text\n+\n```\n\n-   zero or one repetition:\n\n``` text\n?\n```\n\n-   exact number of repetitions, specified by a non-negative integer\n    number:\n\n``` text\n{n}\n```\n\n-   number of repetitions ranging between bounds, specified by\n    non-negative integer numbers:\n\n``` text\n{m, n}\n```\n\nSpecifying bounds is optional. If the left bound is omitted, it defaults\nto `0`. So, `{, 5}` can be described as \\\"between zero and five\nrepetitions\\\". If the right bound is omitted, the number of accepted\nrepetitions is unbounded. So, `{5, }` can be described as \\\"at least\nfive repetitions\\\". Also, `{,}` is equivalent to `*`.\n\nQuantifiers are greedy by default. It means that higher number of\nrepetitions is preferred over lower number. This behavior can be changed\nto reluctant by appending `?` immediately after the quantifier. With\n`{3, 5}`, 3 repetitions is the least desired option and 5 repetitions\n\\-- the most desired. With `{3, 5}?`, 3 repetitions are most desired.\nSimilarly, `?` prefers 1 repetition, while `??` prefers 0 repetitions.\n\n## Row pattern union variables {#row_pattern_union_variables}\n\nAs explained in `row_pattern_syntax`{.interpreted-text role=\"ref\"},\nprimary pattern variables are the basic elements of row pattern. In\naddition to primary pattern variables, you can define union variables.\nThey are introduced in the `SUBSET` clause:\n\n    SUBSET U = (C, D), ...\n\nIn the preceding example, union variable `U` is defined as", "doc_id": "5c853bfe-675f-487f-86cc-e3bb8bad68e7", "embedding": null, "doc_hash": "af7d542a412d00307c5764a8008bea18cd9e5e96091ff0588f31e9dfa97321fd", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md", "file_name": "match-recognize.md"}, "node_info": {"start": 9614, "end": 12748, "_node_type": "1"}, "relationships": {"1": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1", "2": "040046f7-a507-4793-acf8-96ff143a40f4", "3": "dbcef1c3-fb8b-41d6-afd8-476227742d84"}}, "__type__": "1"}, "dbcef1c3-fb8b-41d6-afd8-476227742d84": {"__data__": {"text": "D), ...\n\nIn the preceding example, union variable `U` is defined as union of\nprimary variables `C` and `D`. Union variables are useful in `MEASURES`,\n`DEFINE` and `AFTER MATCH SKIP` clauses. They allow you to refer to set\nof rows matched to either primary variable from a subset.\n\nWith the pattern: `PATTERN((A | B){5} C+)` it cannot be determined\nupfront if the match contains any `A` or any `B`. A union variable can\nbe used to access the last row matched to either `A` or `B`. Define\n`SUBSET U = (A, B)`, and the expression `LAST(U.totalprice)` returns the\nvalue of the `totalprice` column from the last row mapped to either `A`\nor `B`. Also, `AFTER MATCH SKIP TO LAST A` or\n`AFTER MATCH SKIP TO LAST B` can result in failure if `A` or `B` is not\npresent in the match. `AFTER MATCH SKIP TO LAST U` does not fail.\n\n## Row pattern variable definitions {#row_pattern_variable_definitions}\n\nThe `DEFINE` clause is where row pattern primary variables are defined.\nEach variable is associated with a boolean condition:\n\n    DEFINE B AS totalprice < PREV(totalprice), ...\n\nDuring pattern matching, when a certain variable is considered for the\nnext step of the match, the boolean condition is evaluated in context of\nthe current match. If the result is `true`, then the current row,\n\\\"labeled\\\" with the variable, becomes part of the match.\n\nIn the preceding example, assume that the pattern allows to match `B` at\nsome point. There are some rows already matched to some pattern\nvariables. Now, variable `B` is being considered for the current row.\nBefore the match is made, the defining condition for `B` is evaluated.\nIn this example, it is only true if the value of the `totalprice` column\nin the current row is lower than `totalprice` in the preceding row.\n\nThe mechanism of matching variables to rows shows the difference between\npattern matching in row sequences and regular expression matching in\ntext. In text, characters remain constantly in their positions. In row\npattern matching, a row can be mapped to different variables in\ndifferent matches, depending on the preceding part of the match, and\neven on the match number.\n\nIt is not required that every primary variable has a definition in the\n`DEFINE` clause. Variables not mentioned in the `DEFINE` clause are\nimplicitly associated with `true` condition, which means that they can\nbe matched to every row.\n\nBoolean expressions in the `DEFINE` clause allow the same special syntax\nas expressions in the `MEASURES` clause. Details are explained in\n`pattern_recognition_expressions`{.interpreted-text role=\"ref\"}.\n\n## Row pattern recognition expressions {#pattern_recognition_expressions}\n\nExpressions in `MEASURES<row_pattern_measures>`{.interpreted-text\nrole=\"ref\"} and\n`DEFINE<row_pattern_variable_definitions>`{.interpreted-text role=\"ref\"}\nclauses are scalar expressions evaluated over rows of the input table.\nThey support special syntax, specific to pattern recognition context.\nThey can combine input information with the information about the\ncurrent match. Special syntax allows to access pattern variables\nassigned to rows, browse rows based on how they are matched, and refer\nto the sequential number of the match.\n\n### pattern variable references\n\n``` sql\nA.totalprice\n\nU.orderdate\n\norderstatus\n```\n\nA column name prefixed with a pattern variable refers to values of this\ncolumn in all rows matched to this variable, or to any variable from the\nsubset in case of union variable. If a column name is not prefixed, it\nis considered as prefixed with the `universal pattern variable`, defined\nas", "doc_id": "dbcef1c3-fb8b-41d6-afd8-476227742d84", "embedding": null, "doc_hash": "03bc46db33d09afd30da4a0238eb5708a04ce2de3ce493a3a705ff56d2aae8ab", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md", "file_name": "match-recognize.md"}, "node_info": {"start": 12749, "end": 16310, "_node_type": "1"}, "relationships": {"1": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1", "2": "5c853bfe-675f-487f-86cc-e3bb8bad68e7", "3": "1a5ec9ec-fc58-46a0-8997-54483e531171"}}, "__type__": "1"}, "1a5ec9ec-fc58-46a0-8997-54483e531171": {"__data__": {"text": "it\nis considered as prefixed with the `universal pattern variable`, defined\nas union of all primary pattern variables. In other words, a\nnon-prefixed column name refers to all rows of the current match.\n\nIt is forbidden to prefix a column name with a table name in the pattern\nrecognition context.\n\n### classifier function\n\n``` sql\nCLASSIFIER()\n\nCLASSIFIER(A)\n\nCLASSIFIER(U)\n```\n\nThe `classifier` function returns the primary pattern variable\nassociated with the row. The return type is `varchar`. The optional\nargument is a pattern variable. It limits the rows of interest, the same\nway as with prefixed column references. The `classifier` function is\nparticularly useful with a union variable as the argument. It allows you\nto determine which variable from the subset actually matched.\n\n### match_number function\n\n``` sql\nMATCH_NUMBER()\n```\n\nThe `match_number` function returns the sequential number of the match\nwithin partition, starting from `1`. Empty matches are assigned\nsequential numbers as well as non-empty matches. The return type is\n`bigint`.\n\n### logical navigation functions\n\n``` sql\nFIRST(A.totalprice, 2)\n```\n\nIn the above example, the `first` function navigates to the first row\nmatched to pattern variable `A`, and then searches forward until it\nfinds two more occurrences of variable `A` within the match. The result\nis the value of the `totalprice` column in that row.\n\n``` sql\nLAST(A.totalprice, 2)\n```\n\nIn the above example, the `last` function navigates to the last row\nmatched to pattern variable `A`, and then searches backwards until it\nfinds two more occurrences of variable `A` within the match. The result\nis the value of the `totalprice` column in that row.\n\nWith the `first` and `last` functions the result is `null`, if the\nsearched row is not found in the mach.\n\nThe second argument is optional. The default value is `0`, which means\nthat by default these functions navigate to the first or last row of\ninterest. If specified, the second argument must be a non-negative\ninteger number.\n\n### physical navigation functions\n\n``` sql\nPREV(A.totalprice, 2)\n```\n\nIn the above example, the `prev` function navigates to the last row\nmatched to pattern variable `A`, and then searches two rows backward.\nThe result is the value of the `totalprice` column in that row.\n\n``` sql\nNEXT(A.totalprice, 2)\n```\n\nIn the above example, the `next` function navigates to the last row\nmatched to pattern variable `A`, and then searches two rows forward. The\nresult is the value of the `totalprice` column in that row.\n\nWith the `prev` and `next` functions, it is possible to navigate and\nretrieve values outside the match. If the navigation goes beyond\npartition bounds, the result is `null`.\n\nThe second argument is optional. The default value is `1`, which means\nthat by default these functions navigate to previous or next row. If\nspecified, the second argument must be a non-negative integer number.\n\n### nesting of navigation functions\n\nIt is possible to nest logical navigation functions within physical\nnavigation functions:\n\n``` sql\nPREV(FIRST(A.totalprice, 3), 2)\n```\n\nIn case of nesting, first the logical navigation is performed. It\nestablishes the starting row for the physical navigation. When both\nnavigation operations succeed, the value is retrieved from the\ndesignated row.\n\nPattern navigation functions require at least one column reference or\n`classifier` function inside of their first argument. The following\nexamples are correct:\n\n    LAST(\"pattern_variable_\" || CLASSIFIER())\n\n    NEXT(U.totalprice +", "doc_id": "1a5ec9ec-fc58-46a0-8997-54483e531171", "embedding": null, "doc_hash": "529ee7cf6cb0592e265bfe422d5a19414b2b2fb91db54014d990638e8b6f22bb", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md", "file_name": "match-recognize.md"}, "node_info": {"start": 16299, "end": 19835, "_node_type": "1"}, "relationships": {"1": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1", "2": "dbcef1c3-fb8b-41d6-afd8-476227742d84", "3": "b5bd0a6c-2ab4-4a52-ba6a-94e59ba84b98"}}, "__type__": "1"}, "b5bd0a6c-2ab4-4a52-ba6a-94e59ba84b98": {"__data__": {"text": "|| CLASSIFIER())\n\n    NEXT(U.totalprice + 10)\n\nThis is incorrect:\n\n    LAST(1)\n\nIt is also required that all column references and all `classifier`\ncalls inside a pattern navigation function are consistent in referred\npattern variables. They must all refer either to the same primary\nvariable, the same union variable, or to the implicit universal pattern\nvariable. The following examples are correct:\n\n    LAST(CLASSIFIER() = 'A' OR totalprice > 10) /* universal pattern variable */\n\n    LAST(CLASSIFIER(U) = 'A' OR U.totalprice > 10) /* pattern variable U */\n\nThis is incorrect:\n\n    LAST(A.totalprice + B.totalprice)\n\n### Aggregate functions\n\nIt is allowed to use aggregate functions in a row pattern recognition\ncontext. Aggregate functions are evaluated over all rows of the current\nmatch or over a subset of rows based on the matched pattern variables.\nThe `running and final semantics<running_and_final>`{.interpreted-text\nrole=\"ref\"} are supported, with `running` as the default.\n\nThe following expression returns the average value of the `totalprice`\ncolumn for all rows matched to pattern variable `A`:\n\n    avg(A.totalprice)\n\nThe following expression returns the average value of the `totalprice`\ncolumn for all rows matched to pattern variables from subset `U`:\n\n    avg(U.totalprice)\n\nThe following expression returns the average value of the `totalprice`\ncolumn for all rows of the match:\n\n    avg(totalprice)\n\n#### Aggregation arguments\n\nIn case when the aggregate function has multiple arguments, it is\nrequired that all arguments refer consistently to the same set of rows:\n\n    max_by(totalprice, tax) /* aggregate over all rows of the match */\n\n    max_by(CLASSIFIER(A), A.tax) /* aggregate over all rows matched to A */\n\nThis is incorrect:\n\n    max_by(A.totalprice, tax)\n\n    max_by(A.totalprice, A.tax + B.tax)\n\nIf an aggregate argument does not contain any column reference or\n`classifier` function, it does not refer to any pattern variable. In\nsuch a case other aggregate arguments determine the set of rows to\naggregate over. If none of the arguments contains a pattern variable\nreference, the universal row pattern variable is implicit. This means\nthat the aggregate function applies to all rows of the match:\n\n    count(1) /* aggregate over all rows of the match */\n\n    min_by(1, 2) /* aggregate over all rows of the match */\n\n    min_by(1, totalprice) /* aggregate over all rows of the match */\n\n    min_by(totalprice, 1) /* aggregate over all rows of the match */\n\n    min_by(A.totalprice, 1) /* aggregate over all rows matched to A */\n\n    max_by(1, A.totalprice) /* aggregate over all rows matched to A */\n\n#### Nesting of aggregate functions\n\nAggregate function arguments must not contain pattern navigation\nfunctions. Similarly, aggregate functions cannot be nested in pattern\nnavigation functions.\n\n#### Usage of the `classifier` and `match_number` functions\n\nIt is allowed to use the `classifier` and `match_number` functions in\naggregate function arguments. The following expression returns an array\ncontaining all matched pattern variables:\n\n    array_agg(CLASSIFIER())\n\nThis is particularly useful in combination with the option\n`ONE ROW PER MATCH`. It allows to get all the components of the match\nwhile keeping the output size reduced.\n\n#### Row pattern count aggregation\n\nLike other aggregate functions in a row pattern recognition context, the\n`count` function can be applied to all rows of the match, or to rows\nassociated with", "doc_id": "b5bd0a6c-2ab4-4a52-ba6a-94e59ba84b98", "embedding": null, "doc_hash": "71e413d28f43f39c67b4289632afcc388d28721ed5009f8d986274a828e54fbd", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md", "file_name": "match-recognize.md"}, "node_info": {"start": 19870, "end": 23341, "_node_type": "1"}, "relationships": {"1": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1", "2": "1a5ec9ec-fc58-46a0-8997-54483e531171", "3": "6c643b48-4521-47a0-b585-efca4c172b03"}}, "__type__": "1"}, "6c643b48-4521-47a0-b585-efca4c172b03": {"__data__": {"text": "function can be applied to all rows of the match, or to rows\nassociated with certain row pattern variables:\n\n    count(*), count() /* count all rows of the match */\n\n    count(totalprice) /* count non-null values of the totalprice column\n                         in all rows of the match */\n\n    count(A.totalprice) /* count non-null values of the totalprice column\n                           in all rows matched to A */\n\nThe `count` function in a row pattern recognition context allows special\nsyntax to support the `count(*)` behavior over a limited set of rows:\n\n    count(A.*) /* count rows matched to A */\n\n    count(U.*) /* count rows matched to pattern variables from subset U */\n\n### `RUNNING` and `FINAL` semantics {#running_and_final}\n\nDuring pattern matching in a sequence of rows, one row after another is\nexamined to determine if it fits the pattern. At any step, a partial\nmatch is known, but it is not yet known what rows will be added in the\nfuture or what pattern variables they will be mapped to. So, when\nevaluating a boolean condition in the `DEFINE` clause for the current\nrow, only the preceding part of the match (plus the current row) is\n\\\"visible\\\". This is the `running` semantics.\n\nWhen evaluating expressions in the `MEASURES` clause, the match is\ncomplete. It is then possible to apply the `final` semantics. In the\n`final` semantics, the whole match is \\\"visible\\\" as from the position\nof the final row.\n\nIn the `MEASURES` clause, the `running` semantics can also be applied.\nWhen outputting information row by row (as in `ALL ROWS PER MATCH`), the\n`running` semantics evaluate expressions from the positions of\nconsecutive rows.\n\nThe `running` and `final` semantics are denoted by the keywords:\n`RUNNING` and `FINAL`, preceding a logical navigation function `first`\nor `last`, or an aggregate function:\n\n    RUNNING LAST(A.totalprice)\n\n    FINAL LAST(A.totalprice)\n\n    RUNNING avg(A.totalprice)\n\n    FINAL count(A.*)\n\nThe `running` semantics is default in `MEASURES` and `DEFINE` clauses.\n`FINAL` can only be specified in the `MEASURES` clause.\n\nWith the option `ONE ROW PER MATCH`, row pattern measures are evaluated\nfrom the position of the final row in the match. Therefore, `running`\nand `final` semantics are the same.\n\n## Evaluating expressions in empty matches and unmatched rows {#empty_matches_and_unmatched_rows}\n\nAn empty match occurs when the row pattern is successfully matched, but\nno pattern variables are assigned. The following pattern produces an\nempty match for every row:\n\n    PATTERN(())\n\nWhen evaluating row pattern measures for an empty match:\n\n-   all column references return `null`\n-   all navigation operations return `null`\n-   `classifier` function returns `null`\n-   `match_number` function returns the sequential number of the match\n-   all aggregate functions are evaluated over an empty set of rows\n\nLike every match, an empty match has its starting row. All input values\nwhich are to be output along with the measures (as explained in\n`rows_per_match`{.interpreted-text role=\"ref\"}), are the values from the\nstarting row.\n\nAn unmatched row is a row that is neither part of any non-empty match\nnor the starting row of an empty match. With the option\n`ALL ROWS PER MATCH WITH UNMATCHED ROWS`, a single output row is\nproduced. In", "doc_id": "6c643b48-4521-47a0-b585-efca4c172b03", "embedding": null, "doc_hash": "de1205f17b87e422e60f613428768baf0656dce69be65fd7887dd8e75186b61d", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md", "file_name": "match-recognize.md"}, "node_info": {"start": 23314, "end": 26606, "_node_type": "1"}, "relationships": {"1": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1", "2": "b5bd0a6c-2ab4-4a52-ba6a-94e59ba84b98", "3": "b551807a-eeb7-4640-a6d7-600dba4154eb"}}, "__type__": "1"}, "b551807a-eeb7-4640-a6d7-600dba4154eb": {"__data__": {"text": "MATCH WITH UNMATCHED ROWS`, a single output row is\nproduced. In that row, all row pattern measures are `null`. All input\nvalues which are to be output along with the measures (as explained in\n`rows_per_match`{.interpreted-text role=\"ref\"}), are the values from the\nunmatched row. Using the `match_number` function as a measure can help\ndifferentiate between an empty match and unmatched row.\n", "doc_id": "b551807a-eeb7-4640-a6d7-600dba4154eb", "embedding": null, "doc_hash": "ee2a4b47628d196df6d031ac8c257baf9d41ed1d6420f0e84362c2717ca59cea", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md", "file_name": "match-recognize.md"}, "node_info": {"start": 26606, "end": 26998, "_node_type": "1"}, "relationships": {"1": "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1", "2": "6c643b48-4521-47a0-b585-efca4c172b03"}}, "__type__": "1"}, "4627ce52-5e65-4ace-8978-ec38cf99a421": {"__data__": {"text": "# MERGE\n\n## Synopsis\n\n``` text\nMERGE INTO target_table [ [ AS ]  target_alias ]\nUSING { source_table | query } [ [ AS ] source_alias ]\nON search_condition\nwhen_clause [...]\n```\n\nwhere `when_clause` is one of\n\n``` text\nWHEN MATCHED [ AND condition ]\n    THEN DELETE\n```\n\n``` text\nWHEN MATCHED [ AND condition ]\n    THEN UPDATE SET ( column = expression [, ...] )\n```\n\n``` text\nWHEN NOT MATCHED [ AND condition ]\n    THEN INSERT [ column_list ] VALUES (expression, ...)\n```\n\n## Description\n\nConditionally update and/or delete rows of a table and/or insert new\nrows into a table.\n\n`MERGE` supports an arbitrary number of `WHEN` clauses with different\n`MATCHED` conditions, executing the `DELETE`, `UPDATE` or `INSERT`\noperation in the first `WHEN` clause selected by the `MATCHED` state and\nthe match condition.\n\nFor each source row, the `WHEN` clauses are processed in order. Only the\nfirst first matching `WHEN` clause is executed and subsequent clauses\nare ignored. A `MERGE_TARGET_ROW_MULTIPLE_MATCHES` exception is raised\nwhen a single target table row matches more than one source row.\n\nIf a source row is not matched by any `WHEN` clause and there is no\n`WHEN NOT MATCHED` clause, the source row is ignored.\n\nIn `WHEN` clauses with `UPDATE` operations, the column value expressions\ncan depend on any field of the target or the source. In the\n`NOT MATCHED` case, the `INSERT` expressions can depend on any field of\nthe source.\n\n## Examples\n\nDelete all customers mentioned in the source table:\n\n    MERGE INTO accounts t USING monthly_accounts_update s\n        ON t.customer = s.customer\n        WHEN MATCHED\n            THEN DELETE\n\nFor matching customer rows, increment the purchases, and if there is no\nmatch, insert the row from the source table:\n\n    MERGE INTO accounts t USING monthly_accounts_update s\n        ON (t.customer = s.customer)\n        WHEN MATCHED\n            THEN UPDATE SET purchases = s.purchases + t.purchases\n        WHEN NOT MATCHED\n            THEN INSERT (customer, purchases, address)\n                  VALUES(s.customer, s.purchases, s.address)\n\n`MERGE` into the target table from the source table, deleting any\nmatching target row for which the source address is Centreville. For all\nother matching rows, add the source purchases and set the address to the\nsource address, if there is no match in the target table, insert the\nsource table row:\n\n    MERGE INTO accounts t USING monthly_accounts_update s\n        ON (t.customer = s.customer)\n        WHEN MATCHED AND s.address = 'Centreville'\n            THEN DELETE\n        WHEN MATCHED\n            THEN UPDATE\n                SET purchases = s.purchases + t.purchases, address = s.address\n        WHEN NOT MATCHED\n         ", "doc_id": "4627ce52-5e65-4ace-8978-ec38cf99a421", "embedding": null, "doc_hash": "343034a2fefec2ba3eafac5bef05f879385d7d8d983b07530e48ed25a38a0a6b", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/merge.md", "file_name": "merge.md"}, "node_info": {"start": 0, "end": 2706, "_node_type": "1"}, "relationships": {"1": "04d6e2e1e0c3fc9f807882e34c50e0f86946aec8", "3": "bb4e5517-6ad8-44b9-8279-60751190722c"}}, "__type__": "1"}, "bb4e5517-6ad8-44b9-8279-60751190722c": {"__data__": {"text": "    WHEN NOT MATCHED\n            THEN INSERT (customer, purchases, address)\n                  VALUES(s.customer, s.purchases, s.address)\n\n## Limitations\n\nAny connector can be used as a source table for a `MERGE` statement.\nOnly connectors which support the `MERGE` statement can be the target of\na merge operation. See the\n`connector documentation </connector>`{.interpreted-text role=\"doc\"} for\nmore information.\n", "doc_id": "bb4e5517-6ad8-44b9-8279-60751190722c", "embedding": null, "doc_hash": "2c3efe8f11c6f122d8655ef60dccc3b832f99d06625175c406f2c646ff6ee9e1", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/merge.md", "file_name": "merge.md"}, "node_info": {"start": 2676, "end": 3090, "_node_type": "1"}, "relationships": {"1": "04d6e2e1e0c3fc9f807882e34c50e0f86946aec8", "2": "4627ce52-5e65-4ace-8978-ec38cf99a421"}}, "__type__": "1"}, "190b7750-8e49-4601-952b-a55a4c1ab492": {"__data__": {"text": "# Row pattern recognition in window structures\n\nA window structure can be defined in the `WINDOW` clause or in the\n`OVER` clause of a window operation. In both cases, the window\nspecification can include row pattern recognition clauses. They are part\nof the window frame. The syntax and semantics of row pattern recognition\nin window are similar to those of the\n`MATCH_RECOGNIZE</sql/match-recognize>`{.interpreted-text role=\"doc\"}\nclause.\n\nThis section explains the details of row pattern recognition in window\nstructures, and highlights the similarities and the differences between\nboth pattern recognition mechanisms.\n\n## Window with row pattern recognition\n\n**Window specification:**\n\n``` text\n(\n[ existing_window_name ]\n[ PARTITION BY column [, ...] ]\n[ ORDER BY column [, ...] ]\n[ window_frame ]\n)\n```\n\n**Window frame:**\n\n``` text\n[ MEASURES measure_definition [, ...] ]\nframe_extent\n[ AFTER MATCH skip_to ]\n[ INITIAL | SEEK ]\n[ PATTERN ( row_pattern ) ]\n[ SUBSET subset_definition [, ...] ]\n[ DEFINE variable_definition [, ...] ]\n```\n\nGenerally, a window frame specifies the `frame_extent`, which defines\nthe \\\"sliding window\\\" of rows to be processed by a window function. It\ncan be defined in terms of `ROWS`, `RANGE` or `GROUPS`.\n\nA window frame with row pattern recognition involves many other\nsyntactical components, mandatory or optional, and enforces certain\nlimitations on the `frame_extent`.\n\n**Window frame with row pattern recognition:**\n\n``` text\n[ MEASURES measure_definition [, ...] ]\nROWS BETWEEN CURRENT ROW AND frame_end\n[ AFTER MATCH skip_to ]\n[ INITIAL | SEEK ]\nPATTERN ( row_pattern )\n[ SUBSET subset_definition [, ...] ]\nDEFINE variable_definition [, ...]\n```\n\n## Description of the pattern recognition clauses\n\nThe `frame_extent` with row pattern recognition must be defined in terms\nof `ROWS`. The frame start must be at the `CURRENT ROW`, which limits\nthe allowed frame extent values to the following:\n\n    ROWS BETWEEN CURRENT ROW AND CURRENT ROW\n\n    ROWS BETWEEN CURRENT ROW AND <expression> FOLLOWING\n\n    ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n\nFor every input row processed by the window, the portion of rows\nenclosed by the `frame_extent` limits the search area for row pattern\nrecognition. Unlike in `MATCH_RECOGNIZE`, where the pattern search can\nexplore all rows until the partition end, and all rows of the partition\nare available for computations, in window structures the pattern\nmatching can neither match rows nor retrieve input values outside the\nframe.\n\nBesides the `frame_extent`, pattern matching requires the `PATTERN` and\n`DEFINE` clauses.\n\nThe `PATTERN` clause specifies a row pattern, which is a form of a\nregular expression with some syntactical extensions. The row pattern\nsyntax is similar to the\n`row pattern syntax in MATCH_RECOGNIZE<row_pattern_syntax>`{.interpreted-text\nrole=\"ref\"}. However, the anchor patterns `^` and `$` are not allowed in\na window specification.\n\nThe `DEFINE` clause defines the row pattern primary variables in terms\nof boolean conditions that must be satisfied. It is similar to the\n`DEFINE clause of MATCH_RECOGNIZE<row_pattern_variable_definitions>`{.interpreted-text\nrole=\"ref\"}. The only difference is that the window syntax does not\nsupport the `MATCH_NUMBER` function.\n\nThe", "doc_id": "190b7750-8e49-4601-952b-a55a4c1ab492", "embedding": null, "doc_hash": "59f9da6bbae89f46d17061218ca5a8600fc33584c9457c6c2524c9a817d2397e", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/pattern-recognition-in-window.md", "file_name": "pattern-recognition-in-window.md"}, "node_info": {"start": 0, "end": 3274, "_node_type": "1"}, "relationships": {"1": "6993eebd2537d70993e0c65b5b0846eb4623564b", "3": "9b6edfbe-edba-4d54-b6f5-163e3337a45f"}}, "__type__": "1"}, "9b6edfbe-edba-4d54-b6f5-163e3337a45f": {"__data__": {"text": "window syntax does not\nsupport the `MATCH_NUMBER` function.\n\nThe `MEASURES` clause is syntactically similar to the\n`MEASURES clause of MATCH_RECOGNIZE<row_pattern_measures>`{.interpreted-text\nrole=\"ref\"}. The only limitation is that the `MATCH_NUMBER` function is\nnot allowed. However, the semantics of this clause differs between\n`MATCH_RECOGNIZE` and window. While in `MATCH_RECOGNIZE` every measure\nproduces an output column, the measures in window should be considered\nas **definitions** associated with the window structure. They can be\ncalled over the window, in the same manner as regular window functions:\n\n    SELECT cust_key, value OVER w, label OVER w\n        FROM orders\n        WINDOW w AS (\n                     PARTITION BY cust_key\n                     ORDER BY order_date\n                     MEASURES\n                            RUNNING LAST(total_price) AS value,\n                            CLASSIFIER() AS label\n                     ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n                     PATTERN (A B+ C+)\n                     DEFINE\n                            B AS B.value < PREV (B.value),\n                            C AS C.value > PREV (C.value)\n                    )\n\nMeasures defined in a window can be referenced in the `SELECT` clause\nand in the `ORDER BY` clause of the enclosing query.\n\nThe `RUNNING` and `FINAL` keywords are allowed in the `MEASURES` clause.\nThey can precede a logical navigation function `FIRST` or `LAST`, or an\naggregate function. However, they have no effect. Every computation is\nperformed from the position of the final row of the match, so the\nsemantics is effectively `FINAL`.\n\nThe `AFTER MATCH SKIP` clause has the same syntax as the\n`AFTER MATCH SKIP clause of MATCH_RECOGNIZE<after_match_skip>`{.interpreted-text\nrole=\"ref\"}.\n\nThe `INITIAL` or `SEEK` modifier is specific to row pattern recognition\nin window. With `INITIAL`, which is the default, the pattern match for\nan input row can only be found starting from that row. With `SEEK`, if\nthere is no match starting from the current row, the engine tries to\nfind a match starting from subsequent rows within the frame. As a\nresult, it is possible to associate an input row with a match which is\ndetached from that row.\n\nThe `SUBSET` clause is used to define `union variables\n<row_pattern_union_variables>`{.interpreted-text role=\"ref\"} as sets of\nprimary pattern variables. You can use union variables to refer to a set\nof rows matched to any primary pattern variable from the subset:\n\n    SUBSET U = (A, B)\n\nThe following expression returns the `total_price` value", "doc_id": "9b6edfbe-edba-4d54-b6f5-163e3337a45f", "embedding": null, "doc_hash": "1f2da82b8161acc3c7220dab2dd1b2b195fa56d65e773c5f001c1f19177f3f36", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/pattern-recognition-in-window.md", "file_name": "pattern-recognition-in-window.md"}, "node_info": {"start": 3217, "end": 5810, "_node_type": "1"}, "relationships": {"1": "6993eebd2537d70993e0c65b5b0846eb4623564b", "2": "190b7750-8e49-4601-952b-a55a4c1ab492", "3": "82c85b93-3e95-49f5-8250-0e6b541343cd"}}, "__type__": "1"}, "82c85b93-3e95-49f5-8250-0e6b541343cd": {"__data__": {"text": "(A, B)\n\nThe following expression returns the `total_price` value from the last\nrow matched to either `A` or `B`:\n\n    LAST(U.total_price)\n\nIf you want to refer to all rows of the match, there is no need to\ndefine a `SUBSET` containing all pattern variables. There is an implicit\n*universal pattern variable* applied to any non prefixed column name and\nany `CLASSIFIER` call without an argument. The following expression\nreturns the `total_price` value from the last matched row:\n\n    LAST(total_price)\n\nThe following call returns the primary pattern variable of the first\nmatched row:\n\n    FIRST(CLASSIFIER())\n\nIn window, unlike in `MATCH_RECOGNIZE`, you cannot specify\n`ONE ROW PER MATCH` or `ALL ROWS PER MATCH`. This is because all calls\nover window, whether they are regular window functions or measures, must\ncomply with the window semantics. A call over window is supposed to\nproduce exactly one output row for every input row. And so, the output\nmode of pattern recognition in window is a combination of\n`ONE ROW PER MATCH` and `WITH UNMATCHED ROWS`.\n\n## Processing input with row pattern recognition\n\nPattern recognition in window processes input rows in two different\ncases:\n\n-   upon a row pattern measure call over the window:\n\n        some_measure OVER w\n\n-   upon a window function call over the window:\n\n        sum(total_price) OVER w\n\nThe output row produced for each input row, consists of:\n\n-   all values from the input row\n-   the value of the called measure or window function, computed with\n    respect to the pattern match associated with the row\n\nProcessing the input can be described as the following sequence of\nsteps:\n\n-   Partition the input data accordingly to `PARTITION BY`\n\n-   Order each partition by the `ORDER BY` expressions\n\n-   \n\n    For every row of the ordered partition:\n\n    :   \n\n        If the row is \\'skipped\\' by a match of some previous row:\n\n        :   -   For a measure, produce a one-row output as for an\n                unmatched row\n            -   For a window function, evaluate the function over an\n                empty frame and produce a one-row output\n\n        Otherwise:\n\n        :   -   Determine the frame extent\n            -   Try match the row pattern starting from the current row\n                within the frame extent\n            -   If no match is found, and `SEEK` is specified, try to\n                find a match starting from subsequent rows within the\n                frame extent\n\n            If no match is found:\n\n            :   -   For a measure, produce a one-row output for an\n                    unmatched row\n                -   For a window function, evaluate the function over an\n                    empty frame and produce a one-row output\n\n            Otherwise:\n\n            :   -   For a measure,", "doc_id": "82c85b93-3e95-49f5-8250-0e6b541343cd", "embedding": null, "doc_hash": "6695986847f8ffc87b627d9eb7c830024fc295e47580a734b5dfa003e6882670", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/pattern-recognition-in-window.md", "file_name": "pattern-recognition-in-window.md"}, "node_info": {"start": 5812, "end": 8600, "_node_type": "1"}, "relationships": {"1": "6993eebd2537d70993e0c65b5b0846eb4623564b", "2": "9b6edfbe-edba-4d54-b6f5-163e3337a45f", "3": "0f3770c9-28d1-48de-9ec4-43fcbae071e6"}}, "__type__": "1"}, "0f3770c9-28d1-48de-9ec4-43fcbae071e6": {"__data__": {"text": "         :   -   For a measure, produce a one-row output for the\n                    match\n                -   For a window function, evaluate the function over a\n                    frame limited to the matched rows sequence and\n                    produce a one-row output\n                -   Evaluate the `AFTER MATCH SKIP` clause, and mark the\n                    \\'skipped\\' rows\n\n## Empty matches and unmatched rows\n\nIf no match can be associated with a particular input row, the row is\n*unmatched*. This happens when no match can be found for the row. This\nalso happens when no match is attempted for the row, because it is\nskipped by the `AFTER MATCH SKIP` clause of some preceding row. For an\nunmatched row, every row pattern measure is `null`. Every window\nfunction is evaluated over an empty frame.\n\nAn *empty match* is a successful match which does not involve any\npattern variables. In other words, an empty match does not contain any\nrows. If an empty match is associated with an input row, every row\npattern measure for that row is evaluated over an empty sequence of\nrows. All navigation operations and the `CLASSIFIER` function return\n`null`. Every window function is evaluated over an empty frame.\n\nIn most cases, the results for empty matches and unmatched rows are the\nsame. A constant measure can be helpful to distinguish between them:\n\nThe following call returns `'matched'` for every matched row, including\nempty matches, and `null` for every unmatched row:\n\n    matched OVER (\n                  ...\n                  MEASURES 'matched' AS matched\n                  ...\n                 )\n", "doc_id": "0f3770c9-28d1-48de-9ec4-43fcbae071e6", "embedding": null, "doc_hash": "07c42940b3d5a6f55b5615b51f922ea312a083939e159c357381408028322ec9", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/pattern-recognition-in-window.md", "file_name": "pattern-recognition-in-window.md"}, "node_info": {"start": 8626, "end": 10239, "_node_type": "1"}, "relationships": {"1": "6993eebd2537d70993e0c65b5b0846eb4623564b", "2": "82c85b93-3e95-49f5-8250-0e6b541343cd"}}, "__type__": "1"}, "6999b07a-a95c-40bf-85fd-7feb395c939c": {"__data__": {"text": "# PREPARE\n\n## Synopsis\n\n``` text\nPREPARE statement_name FROM statement\n```\n\n## Description\n\nPrepares a statement for execution at a later time. Prepared statements\nare queries that are saved in a session with a given name. The statement\ncan include parameters in place of literals to be replaced at execution\ntime. Parameters are represented by question marks.\n\n## Examples\n\nPrepare a select query:\n\n    PREPARE my_select1 FROM\n    SELECT * FROM nation;\n\nPrepare a select query that includes parameters. The values to compare\nwith `regionkey` and `nationkey` will be filled in with the\n`execute`{.interpreted-text role=\"doc\"} statement:\n\n    PREPARE my_select2 FROM\n    SELECT name FROM nation WHERE regionkey = ? AND nationkey < ?;\n\nPrepare an insert query:\n\n    PREPARE my_insert FROM\n    INSERT INTO cities VALUES (1, 'San Francisco');\n\n## See also\n\n`execute`{.interpreted-text role=\"doc\"},\n`deallocate-prepare`{.interpreted-text role=\"doc\"},\n`describe-input`{.interpreted-text role=\"doc\"},\n`describe-output`{.interpreted-text role=\"doc\"}\n", "doc_id": "6999b07a-a95c-40bf-85fd-7feb395c939c", "embedding": null, "doc_hash": "f122f3ecc3628c681ecf826c67c223b3318a22f91b46af0d0ec605f4608d9da7", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/prepare.md", "file_name": "prepare.md"}, "node_info": {"start": 0, "end": 1042, "_node_type": "1"}, "relationships": {"1": "549295068b5590e149f4567700f54dc3e37e7dc2"}}, "__type__": "1"}, "0faf15cd-5b8e-4dfc-beb2-bdc1e42f598d": {"__data__": {"text": "# REFRESH MATERIALIZED VIEW\n\n## Synopsis\n\n``` text\nREFRESH MATERIALIZED VIEW view_name\n```\n\n## Description\n\nInitially populate or refresh the data stored in the materialized view\n`view_name`. The materialized view must be defined with\n`create-materialized-view`{.interpreted-text role=\"doc\"}. Data is\nretrieved from the underlying tables accessed by the defined query.\n\nThe initial population of the materialized view is typically processing\nintensive since it reads the data from the source tables and performs\nphysical write operations.\n\nThe refresh operation can be less intensive, if the underlying data has\nnot changed and the connector has implemented a mechanism to be aware of\nthat. The specific implementation and performance varies by connector\nused to create the materialized view.\n\n## See also\n\n-   `create-materialized-view`{.interpreted-text role=\"doc\"}\n-   `drop-materialized-view`{.interpreted-text role=\"doc\"}\n-   `show-create-materialized-view`{.interpreted-text role=\"doc\"}\n", "doc_id": "0faf15cd-5b8e-4dfc-beb2-bdc1e42f598d", "embedding": null, "doc_hash": "d67887d343cbb86912820177b365fd4354f11c603803ca52b41ad3a3213a9e8f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/refresh-materialized-view.md", "file_name": "refresh-materialized-view.md"}, "node_info": {"start": 0, "end": 993, "_node_type": "1"}, "relationships": {"1": "b0cd1db956ebfe5c1cd8be18bd57dfe901bbee01"}}, "__type__": "1"}, "03541a3b-1099-423c-b573-d2ffe824ecb3": {"__data__": {"text": "# RESET SESSION\n\n## Synopsis\n\n``` text\nRESET SESSION name\nRESET SESSION catalog.name\n```\n\n## Description\n\nReset a\n`session property <session-properties-definition>`{.interpreted-text\nrole=\"ref\"} value to the default value.\n\n## Examples\n\n``` sql\nRESET SESSION optimize_hash_generation;\nRESET SESSION hive.optimized_reader_enabled;\n```\n\n## See also\n\n`set-session`{.interpreted-text role=\"doc\"},\n`show-session`{.interpreted-text role=\"doc\"}\n", "doc_id": "03541a3b-1099-423c-b573-d2ffe824ecb3", "embedding": null, "doc_hash": "d0fed6accb08fd728bf8836b17ee05409ada49f6b71807e749f6fabe465a34e2", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/reset-session.md", "file_name": "reset-session.md"}, "node_info": {"start": 0, "end": 438, "_node_type": "1"}, "relationships": {"1": "abbef2a85ac74b6b4d06a927e94b5ceea0ae00ef"}}, "__type__": "1"}, "f997fd22-eb0f-48a1-9be4-3be3a5ce880a": {"__data__": {"text": "# SELECT\n\n## Synopsis\n\n``` text\n[ WITH [ RECURSIVE ] with_query [, ...] ]\nSELECT [ ALL | DISTINCT ] select_expression [, ...]\n[ FROM from_item [, ...] ]\n[ WHERE condition ]\n[ GROUP BY [ ALL | DISTINCT ] grouping_element [, ...] ]\n[ HAVING condition]\n[ WINDOW window_definition_list]\n[ { UNION | INTERSECT | EXCEPT } [ ALL | DISTINCT ] select ]\n[ ORDER BY expression [ ASC | DESC ] [, ...] ]\n[ OFFSET count [ ROW | ROWS ] ]\n[ LIMIT { count | ALL } ]\n[ FETCH { FIRST | NEXT } [ count ] { ROW | ROWS } { ONLY | WITH TIES } ]\n```\n\nwhere `from_item` is one of\n\n``` text\ntable_name [ [ AS ] alias [ ( column_alias [, ...] ) ] ]\n```\n\n``` text\nfrom_item join_type from_item\n  [ ON join_condition | USING ( join_column [, ...] ) ]\n```\n\n``` text\ntable_name [ [ AS ] alias [ ( column_alias [, ...] ) ] ]\n  MATCH_RECOGNIZE pattern_recognition_specification\n    [ [ AS ] alias [ ( column_alias [, ...] ) ] ]\n```\n\nFor detailed description of `MATCH_RECOGNIZE` clause, see `pattern\nrecognition in FROM clause</sql/match-recognize>`{.interpreted-text\nrole=\"doc\"}.\n\n``` text\nTABLE (table_function_invocation) [ [ AS ] alias [ ( column_alias [, ...] ) ] ]\n```\n\nFor description of table functions usage, see\n`table functions</functions/table>`{.interpreted-text role=\"doc\"}.\n\nand `join_type` is one of\n\n``` text\n[ INNER ] JOIN\nLEFT [ OUTER ] JOIN\nRIGHT [ OUTER ] JOIN\nFULL [ OUTER ] JOIN\nCROSS JOIN\n```\n\nand `grouping_element` is one of\n\n``` text\n()\nexpression\nGROUPING SETS ( ( column [, ...] ) [, ...] )\nCUBE ( column [, ...] )\nROLLUP ( column [, ...] )\n```\n\n## Description\n\nRetrieve rows from zero or more tables.\n\n## WITH clause\n\nThe `WITH` clause defines named relations for use within a query. It\nallows flattening nested queries or simplifying subqueries. For example,\nthe following queries are equivalent:\n\n    SELECT a, b\n    FROM (\n      SELECT a, MAX(b) AS b FROM t GROUP BY a\n    ) AS x;\n\n    WITH x AS (SELECT a, MAX(b) AS b FROM t GROUP BY a)\n    SELECT a, b FROM x;\n\nThis also works with multiple subqueries:\n\n    WITH\n      t1 AS (SELECT a, MAX(b) AS b FROM x GROUP BY a),\n      t2 AS (SELECT a, AVG(d) AS d FROM y GROUP BY a)\n    SELECT t1.*, t2.*\n    FROM t1\n    JOIN t2 ON t1.a = t2.a;\n\nAdditionally, the relations within a `WITH` clause can chain:\n\n    WITH\n      x AS (SELECT a FROM t),\n      y AS (SELECT a AS b FROM x),\n      z AS (SELECT b AS c FROM y)\n    SELECT c FROM z;\n\n::: warning\n::: title\nWarning\n:::\n\nCurrently, the SQL for the `WITH` clause will be inlined anywhere the\nnamed relation is used. This means that if the relation is used more\nthan once and the query is non-deterministic, the results may be\ndifferent each", "doc_id": "f997fd22-eb0f-48a1-9be4-3be3a5ce880a", "embedding": null, "doc_hash": "ff9db9ff92020ecb428d15e8bd600e55582fcd3bd9d21f30fcfd63af7c3e433f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 0, "end": 2633, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "3": "51d7ec80-d8b2-47f6-a5f6-febff2788e49"}}, "__type__": "1"}, "51d7ec80-d8b2-47f6-a5f6-febff2788e49": {"__data__": {"text": "once and the query is non-deterministic, the results may be\ndifferent each time.\n:::\n\n## WITH RECURSIVE clause\n\nThe `WITH RECURSIVE` clause is a variant of the `WITH` clause. It\ndefines a list of queries to process, including recursive processing of\nsuitable queries.\n\n::: warning\n::: title\nWarning\n:::\n\nThis feature is experimental only. Proceed to use it only if you\nunderstand potential query failures and the impact of the recursion\nprocessing on your workload.\n:::\n\nA recursive `WITH`-query must be shaped as a `UNION` of two relations.\nThe first relation is called the *recursion base*, and the second\nrelation is called the *recursion step*. Trino supports recursive\n`WITH`-queries with a single recursive reference to a `WITH`-query from\nwithin the query. The name `T` of the query `T` can be mentioned once in\nthe `FROM` clause of the recursion step relation.\n\nThe following listing shows a simple example, that displays a commonly\nused form of a single query in the list:\n\n``` text\nWITH RECURSIVE t(n) AS (\n    VALUES (1)\n    UNION ALL\n    SELECT n + 1 FROM t WHERE n < 4\n)\nSELECT sum(n) FROM t;\n```\n\nIn the preceding query the simple assignment `VALUES (1)` defines the\nrecursion base relation. `SELECT n + 1 FROM t WHERE n < 4` defines the\nrecursion step relation. The recursion processing performs these steps:\n\n-   recursive base yields `1`\n-   first recursion yields `1 + 1 = 2`\n-   second recursion uses the result from the first and adds one:\n    `2 + 1 = 3`\n-   third recursion uses the result from the second and adds one again:\n    `3 + 1 = 4`\n-   fourth recursion aborts since `n = 4`\n-   this results in `t` having values `1`, `2`, `3` and `4`\n-   the final statement performs the sum operation of these elements\n    with the final result value `10`\n\nThe types of the returned columns are those of the base relation.\nTherefore it is required that types in the step relation can be coerced\nto base relation types.\n\nThe `RECURSIVE` clause applies to all queries in the `WITH` list, but\nnot all of them must be recursive. If a `WITH`-query is not shaped\naccording to the rules mentioned above or it does not contain a\nrecursive reference, it is processed like a regular `WITH`-query. Column\naliases are mandatory for all the queries in the recursive `WITH` list.\n\nThe following limitations apply as a result of following the SQL\nstandard and due to implementation choices, in addition to `WITH` clause\nlimitations:\n\n-   only single-element recursive cycles are supported. Like in regular\n    `WITH`-queries, references to previous queries in the `WITH` list\n    are allowed. References to following queries are forbidden.\n-   usage of outer joins, set operations, limit clause, and others is\n    not always allowed in the step relation\n-   recursion depth is fixed, defaults to `10`, and doesn\\'t depend on\n    the actual query results\n\nYou can adjust the recursion depth with the `session property\n</sql/set-session>`{.interpreted-text role=\"doc\"} `max_recursion_depth`.\nWhen changing the value consider that the size of the query plan growth\nis quadratic with the recursion depth.\n\n## SELECT clause\n\nThe `SELECT` clause specifies the output of the query. Each\n`select_expression` defines a column or columns to be included in the\nresult.\n\n``` text\nSELECT [ ALL |", "doc_id": "51d7ec80-d8b2-47f6-a5f6-febff2788e49", "embedding": null, "doc_hash": "8e42428248d55522d3be9bda0548953241601d59f167006041a4b9ab3291018b", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 2570, "end": 5853, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "f997fd22-eb0f-48a1-9be4-3be3a5ce880a", "3": "005fa866-df7d-41f3-a7f3-53c40e586e18"}}, "__type__": "1"}, "005fa866-df7d-41f3-a7f3-53c40e586e18": {"__data__": {"text": "to be included in the\nresult.\n\n``` text\nSELECT [ ALL | DISTINCT ] select_expression [, ...]\n```\n\nThe `ALL` and `DISTINCT` quantifiers determine whether duplicate rows\nare included in the result set. If the argument `ALL` is specified, all\nrows are included. If the argument `DISTINCT` is specified, only unique\nrows are included in the result set. In this case, each output column\nmust be of a type that allows comparison. If neither argument is\nspecified, the behavior defaults to `ALL`.\n\n### Select expressions\n\nEach `select_expression` must be in one of the following forms:\n\n``` text\nexpression [ [ AS ] column_alias ]\n```\n\n``` text\nrow_expression.* [ AS ( column_alias [, ...] ) ]\n```\n\n``` text\nrelation.*\n```\n\n``` text\n*\n```\n\nIn the case of `expression [ [ AS ] column_alias ]`, a single output\ncolumn is defined.\n\nIn the case of `row_expression.* [ AS ( column_alias [, ...] ) ]`, the\n`row_expression` is an arbitrary expression of type `ROW`. All fields of\nthe row define output columns to be included in the result set.\n\nIn the case of `relation.*`, all columns of `relation` are included in\nthe result set. In this case column aliases are not allowed.\n\nIn the case of `*`, all columns of the relation defined by the query are\nincluded in the result set.\n\nIn the result set, the order of columns is the same as the order of\ntheir specification by the select expressions. If a select expression\nreturns multiple columns, they are ordered the same way they were\nordered in the source relation or row type expression.\n\nIf column aliases are specified, they override any preexisting column or\nrow field names:\n\n    SELECT (CAST(ROW(1, true) AS ROW(field1 bigint, field2 boolean))).* AS (alias1, alias2);\n\n``` text\nalias1 | alias2\n--------+--------\n     1 | true\n(1 row)\n```\n\nOtherwise, the existing names are used:\n\n    SELECT (CAST(ROW(1, true) AS ROW(field1 bigint, field2 boolean))).*;\n\n``` text\nfield1 | field2\n--------+--------\n     1 | true\n(1 row)\n```\n\nand in their absence, anonymous columns are produced:\n\n    SELECT (ROW(1, true)).*;\n\n``` text\n_col0 | _col1\n-------+-------\n    1 | true\n(1 row)\n```\n\n## GROUP BY clause\n\nThe `GROUP BY` clause divides the output of a `SELECT` statement into\ngroups of rows containing matching values. A simple `GROUP BY` clause\nmay contain any expression composed of input columns or it may be an\nordinal number selecting an output column by position (starting at one).\n\nThe following queries are equivalent. They both group the output by the\n`nationkey` input column with the first query using the ordinal position\nof the output column and the second query using the input column name:\n\n    SELECT count(*), nationkey FROM customer GROUP BY 2;\n\n    SELECT count(*), nationkey FROM customer GROUP BY nationkey;\n\n`GROUP BY` clauses can group output by input column names not appearing\nin the output of a select statement. For example, the following query\ngenerates row counts for the `customer` table using the input column\n`mktsegment`:\n\n    SELECT count(*) FROM customer GROUP BY mktsegment;\n\n``` text\n_col0\n-------\n29968\n30142\n30189\n29949\n29752\n(5 rows)\n```\n\nWhen a `GROUP BY` clause is used in a `SELECT` statement all output\nexpressions must be either aggregate functions or columns present in the\n`GROUP BY` clause.\n\n### Complex", "doc_id": "005fa866-df7d-41f3-a7f3-53c40e586e18", "embedding": null, "doc_hash": "23cb7c4c7c79490a06f705bd917b4f232cb8c77ab06d9698565afbe8e263fd94", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 5872, "end": 9152, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "51d7ec80-d8b2-47f6-a5f6-febff2788e49", "3": "aa93ca9a-7809-45cf-b36b-02ef893c06bb"}}, "__type__": "1"}, "aa93ca9a-7809-45cf-b36b-02ef893c06bb": {"__data__": {"text": "or columns present in the\n`GROUP BY` clause.\n\n### Complex grouping operations {#complex_grouping_operations}\n\nTrino also supports complex aggregations using the `GROUPING SETS`,\n`CUBE` and `ROLLUP` syntax. This syntax allows users to perform analysis\nthat requires aggregation on multiple sets of columns in a single query.\nComplex grouping operations do not support grouping on expressions\ncomposed of input columns. Only column names are allowed.\n\nComplex grouping operations are often equivalent to a `UNION ALL` of\nsimple `GROUP BY` expressions, as shown in the following examples. This\nequivalence does not apply, however, when the source of data for the\naggregation is non-deterministic.\n\n### GROUPING SETS\n\nGrouping sets allow users to specify multiple lists of columns to group\non. The columns not part of a given sublist of grouping columns are set\nto `NULL`. :\n\n    SELECT * FROM shipping;\n\n``` text\norigin_state | origin_zip | destination_state | destination_zip | package_weight\n--------------+------------+-------------------+-----------------+----------------\nCalifornia   |      94131 | New Jersey        |            8648 |             13\nCalifornia   |      94131 | New Jersey        |            8540 |             42\nNew Jersey   |       7081 | Connecticut       |            6708 |            225\nCalifornia   |      90210 | Connecticut       |            6927 |           1337\nCalifornia   |      94131 | Colorado          |           80302 |              5\nNew York     |      10002 | New Jersey        |            8540 |              3\n(6 rows)\n```\n\n`GROUPING SETS` semantics are demonstrated by this example query:\n\n    SELECT origin_state, origin_zip, destination_state, sum(package_weight)\n    FROM shipping\n    GROUP BY GROUPING SETS (\n        (origin_state),\n        (origin_state, origin_zip),\n        (destination_state));\n\n``` text\norigin_state | origin_zip | destination_state | _col0\n--------------+------------+-------------------+-------\nNew Jersey   | NULL       | NULL              |   225\nCalifornia   | NULL       | NULL              |  1397\nNew York     | NULL       | NULL              |     3\nCalifornia   |      90210 | NULL              |  1337\nCalifornia   |      94131 | NULL              |    60\nNew Jersey   |       7081 | NULL              |   225\nNew York     |      10002 | NULL              |     3\nNULL         | NULL    ", "doc_id": "aa93ca9a-7809-45cf-b36b-02ef893c06bb", "embedding": null, "doc_hash": "fc95fc56d101b01fcf2b60e5495eddecbbddde493dd15999678fe217db8011a0", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 9149, "end": 11524, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "005fa866-df7d-41f3-a7f3-53c40e586e18", "3": "afd4eadd-04ba-4d97-92ee-5438461e7c04"}}, "__type__": "1"}, "afd4eadd-04ba-4d97-92ee-5438461e7c04": {"__data__": {"text": "   3\nNULL         | NULL       | Colorado          |     5\nNULL         | NULL       | New Jersey        |    58\nNULL         | NULL       | Connecticut       |  1562\n(10 rows)\n```\n\nThe preceding query may be considered logically equivalent to a\n`UNION ALL` of multiple `GROUP BY` queries:\n\n    SELECT origin_state, NULL, NULL, sum(package_weight)\n    FROM shipping GROUP BY origin_state\n\n    UNION ALL\n\n    SELECT origin_state, origin_zip, NULL, sum(package_weight)\n    FROM shipping GROUP BY origin_state, origin_zip\n\n    UNION ALL\n\n    SELECT NULL, NULL, destination_state, sum(package_weight)\n    FROM shipping GROUP BY destination_state;\n\nHowever, the query with the complex grouping syntax (`GROUPING SETS`,\n`CUBE` or `ROLLUP`) will only read from the underlying data source once,\nwhile the query with the `UNION ALL` reads the underlying data three\ntimes. This is why queries with a `UNION ALL` may produce inconsistent\nresults when the data source is not deterministic.\n\n### CUBE\n\nThe `CUBE` operator generates all possible grouping sets (i.e. a power\nset) for a given set of columns. For example, the query:\n\n    SELECT origin_state, destination_state, sum(package_weight)\n    FROM shipping\n    GROUP BY CUBE (origin_state, destination_state);\n\nis equivalent to:\n\n    SELECT origin_state, destination_state, sum(package_weight)\n    FROM shipping\n    GROUP BY GROUPING SETS (\n        (origin_state, destination_state),\n        (origin_state),\n        (destination_state),\n        ()\n    );\n\n``` text\norigin_state | destination_state | _col0\n--------------+-------------------+-------\nCalifornia   | New Jersey        |    55\nCalifornia   | Colorado          |     5\nNew York     | New Jersey        |     3\nNew Jersey   | Connecticut       |   225\nCalifornia   | Connecticut       |  1337\nCalifornia   | NULL              |  1397\nNew York     | NULL              |     3\nNew Jersey   | NULL              |   225\nNULL         | New Jersey        |    58\nNULL         | Connecticut       |  1562\nNULL         | Colorado          |     5\nNULL         | NULL              |  1625\n(12 rows)\n```\n\n### ROLLUP\n\nThe `ROLLUP` operator generates all possible subtotals for a given set\nof columns. For example, the query:\n\n    SELECT origin_state, origin_zip, sum(package_weight)\n    FROM shipping\n    GROUP BY ROLLUP (origin_state, origin_zip);\n\n``` text\norigin_state | origin_zip | _col2\n--------------+------------+-------\nCalifornia   |      94131", "doc_id": "afd4eadd-04ba-4d97-92ee-5438461e7c04", "embedding": null, "doc_hash": "949b011b82c922c08ecef4105b3b26e1ba0011065775aa51066cd522c15cf84c", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 11564, "end": 14011, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "aa93ca9a-7809-45cf-b36b-02ef893c06bb", "3": "9bff07a0-2971-4253-bd25-6344bb9de53d"}}, "__type__": "1"}, "9bff07a0-2971-4253-bd25-6344bb9de53d": {"__data__": {"text": "  |      94131 |    60\nCalifornia   |      90210 |  1337\nNew Jersey   |       7081 |   225\nNew York     |      10002 |     3\nCalifornia   | NULL       |  1397\nNew York     | NULL       |     3\nNew Jersey   | NULL       |   225\nNULL         | NULL       |  1625\n(8 rows)\n```\n\nis equivalent to:\n\n    SELECT origin_state, origin_zip, sum(package_weight)\n    FROM shipping\n    GROUP BY GROUPING SETS ((origin_state, origin_zip), (origin_state), ());\n\n### Combining multiple grouping expressions\n\nMultiple grouping expressions in the same query are interpreted as\nhaving cross-product semantics. For example, the following query:\n\n    SELECT origin_state, destination_state, origin_zip, sum(package_weight)\n    FROM shipping\n    GROUP BY\n        GROUPING SETS ((origin_state, destination_state)),\n        ROLLUP (origin_zip);\n\nwhich can be rewritten as:\n\n    SELECT origin_state, destination_state, origin_zip, sum(package_weight)\n    FROM shipping\n    GROUP BY\n        GROUPING SETS ((origin_state, destination_state)),\n        GROUPING SETS ((origin_zip), ());\n\nis logically equivalent to:\n\n    SELECT origin_state, destination_state, origin_zip, sum(package_weight)\n    FROM shipping\n    GROUP BY GROUPING SETS (\n        (origin_state, destination_state, origin_zip),\n        (origin_state, destination_state)\n    );\n\n``` text\norigin_state | destination_state | origin_zip | _col3\n--------------+-------------------+------------+-------\nNew York     | New Jersey        |      10002 |     3\nCalifornia   | New Jersey        |      94131 |    55\nNew Jersey   | Connecticut       |       7081 |   225\nCalifornia   | Connecticut       |      90210 |  1337\nCalifornia   | Colorado          |      94131 |     5\nNew York     | New Jersey        | NULL       |     3\nNew Jersey   | Connecticut       | NULL       |   225\nCalifornia   | Colorado          | NULL       |     5\nCalifornia   | Connecticut       | NULL       |  1337\nCalifornia   | New Jersey        | NULL       |    55\n(10 rows)\n```\n\nThe `ALL` and `DISTINCT` quantifiers determine whether duplicate\ngrouping sets each produce distinct output rows. This is particularly\nuseful when multiple complex grouping sets are combined in the same\nquery. For example, the following query:\n\n    SELECT origin_state, destination_state, origin_zip, sum(package_weight)\n    FROM shipping\n    GROUP BY ALL\n        CUBE (origin_state, destination_state),\n        ROLLUP (origin_state, origin_zip);\n\nis equivalent", "doc_id": "9bff07a0-2971-4253-bd25-6344bb9de53d", "embedding": null, "doc_hash": "2eaae2f6ff8db116f35d48514d0f7721d0ebc3a9fb3e4dd15e22b58143745ad8", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 14017, "end": 16468, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "afd4eadd-04ba-4d97-92ee-5438461e7c04", "3": "05205551-e89b-42b3-b428-70c806071d01"}}, "__type__": "1"}, "05205551-e89b-42b3-b428-70c806071d01": {"__data__": {"text": "   ROLLUP (origin_state, origin_zip);\n\nis equivalent to:\n\n    SELECT origin_state, destination_state, origin_zip, sum(package_weight)\n    FROM shipping\n    GROUP BY GROUPING SETS (\n        (origin_state, destination_state, origin_zip),\n        (origin_state, origin_zip),\n        (origin_state, destination_state, origin_zip),\n        (origin_state, origin_zip),\n        (origin_state, destination_state),\n        (origin_state),\n        (origin_state, destination_state),\n        (origin_state),\n        (origin_state, destination_state),\n        (origin_state),\n        (destination_state),\n        ()\n    );\n\nHowever, if the query uses the `DISTINCT` quantifier for the `GROUP BY`:\n\n    SELECT origin_state, destination_state, origin_zip, sum(package_weight)\n    FROM shipping\n    GROUP BY DISTINCT\n        CUBE (origin_state, destination_state),\n        ROLLUP (origin_state, origin_zip);\n\nonly unique grouping sets are generated:\n\n    SELECT origin_state, destination_state, origin_zip, sum(package_weight)\n    FROM shipping\n    GROUP BY GROUPING SETS (\n        (origin_state, destination_state, origin_zip),\n        (origin_state, origin_zip),\n        (origin_state, destination_state),\n        (origin_state),\n        (destination_state),\n        ()\n    );\n\nThe default set quantifier is `ALL`.\n\n### GROUPING operation\n\n`grouping(col1, ..., colN) -> bigint`\n\nThe grouping operation returns a bit set converted to decimal,\nindicating which columns are present in a grouping. It must be used in\nconjunction with `GROUPING SETS`, `ROLLUP`, `CUBE` or `GROUP BY` and its\narguments must match exactly the columns referenced in the corresponding\n`GROUPING SETS`, `ROLLUP`, `CUBE` or `GROUP BY` clause.\n\nTo compute the resulting bit set for a particular row, bits are assigned\nto the argument columns with the rightmost column being the least\nsignificant bit. For a given grouping, a bit is set to 0 if the\ncorresponding column is included in the grouping and to 1 otherwise. For\nexample, consider the query below:\n\n    SELECT origin_state, origin_zip, destination_state, sum(package_weight),\n           grouping(origin_state, origin_zip, destination_state)\n    FROM shipping\n    GROUP BY GROUPING SETS (\n        (origin_state),\n        (origin_state, origin_zip),\n        (destination_state)\n    );\n\n``` text\norigin_state | origin_zip | destination_state | _col3 | _col4\n--------------+------------+-------------------+-------+-------\nCalifornia   | NULL       | NULL              |  1397 |     3\nNew Jersey   | NULL       | NULL              |   225 |     3\nNew York     | NULL      ", "doc_id": "05205551-e89b-42b3-b428-70c806071d01", "embedding": null, "doc_hash": "78bb01095b0f954c51930d2efef4888f0f7fa1eae6cb5c5d2081712235f1d62b", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 16429, "end": 19013, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "9bff07a0-2971-4253-bd25-6344bb9de53d", "3": "4904b7c6-a6b6-4412-a7cc-0998aabcbce5"}}, "__type__": "1"}, "4904b7c6-a6b6-4412-a7cc-0998aabcbce5": {"__data__": {"text": "    3\nNew York     | NULL       | NULL              |     3 |     3\nCalifornia   |      94131 | NULL              |    60 |     1\nNew Jersey   |       7081 | NULL              |   225 |     1\nCalifornia   |      90210 | NULL              |  1337 |     1\nNew York     |      10002 | NULL              |     3 |     1\nNULL         | NULL       | New Jersey        |    58 |     6\nNULL         | NULL       | Connecticut       |  1562 |     6\nNULL         | NULL       | Colorado          |     5 |     6\n(10 rows)\n```\n\nThe first grouping in the above result only includes the `origin_state`\ncolumn and excludes the `origin_zip` and `destination_state` columns.\nThe bit set constructed for that grouping is `011` where the most\nsignificant bit represents `origin_state`.\n\n## HAVING clause\n\nThe `HAVING` clause is used in conjunction with aggregate functions and\nthe `GROUP BY` clause to control which groups are selected. A `HAVING`\nclause eliminates groups that do not satisfy the given conditions.\n`HAVING` filters groups after groups and aggregates are computed.\n\nThe following example queries the `customer` table and selects groups\nwith an account balance greater than the specified value:\n\n    SELECT count(*), mktsegment, nationkey,\n           CAST(sum(acctbal) AS bigint) AS totalbal\n    FROM customer\n    GROUP BY mktsegment, nationkey\n    HAVING sum(acctbal) > 5700000\n    ORDER BY totalbal DESC;\n\n``` text\n_col0 | mktsegment | nationkey | totalbal\n-------+------------+-----------+----------\n 1272 | AUTOMOBILE |        19 |  5856939\n 1253 | FURNITURE  |        14 |  5794887\n 1248 | FURNITURE  |         9 |  5784628\n 1243 | FURNITURE  |        12 |  5757371\n 1231 | HOUSEHOLD  |         3 |  5753216\n 1251 | MACHINERY  |         2 |  5719140\n 1247 | FURNITURE  |         8 |  5701952\n(7 rows)\n```\n\n## WINDOW clause {#window_clause}\n\nThe `WINDOW` clause is used to define named window specifications. The\ndefined named window specifications can be referred to in the `SELECT`\nand `ORDER BY` clauses of the enclosing query:\n\n    SELECT orderkey, clerk, totalprice,\n          rank() OVER w AS rnk\n    FROM orders\n    WINDOW w AS (PARTITION BY clerk ORDER BY totalprice DESC)\n    ORDER BY count() OVER w, clerk, rnk\n\nThe window definition list of `WINDOW` clause can contain one or\nmultiple named window specifications of the form\n\n``` none\nwindow_name AS", "doc_id": "4904b7c6-a6b6-4412-a7cc-0998aabcbce5", "embedding": null, "doc_hash": "164d96225913e477a8778df817f7e73ac820be18c92249ba81e90f588e58b83f", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 19046, "end": 21407, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "05205551-e89b-42b3-b428-70c806071d01", "3": "58ca41ae-0eeb-43e5-af1a-428f8f77367d"}}, "__type__": "1"}, "58ca41ae-0eeb-43e5-af1a-428f8f77367d": {"__data__": {"text": "or\nmultiple named window specifications of the form\n\n``` none\nwindow_name AS (window_specification)\n```\n\nA window specification has the following components:\n\n-   The existing window name, which refers to a named window\n    specification in the `WINDOW` clause. The window specification\n    associated with the referenced name is the basis of the current\n    specification.\n-   The partition specification, which separates the input rows into\n    different partitions. This is analogous to how the `GROUP BY` clause\n    separates rows into different groups for aggregate functions.\n-   The ordering specification, which determines the order in which\n    input rows will be processed by the window function.\n-   The window frame, which specifies a sliding window of rows to be\n    processed by the function for a given row. If the frame is not\n    specified, it defaults to `RANGE UNBOUNDED PRECEDING`, which is the\n    same as `RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW`. This\n    frame contains all rows from the start of the partition up to the\n    last peer of the current row. In the absence of `ORDER BY`, all rows\n    are considered peers, so\n    `RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW` is equivalent to\n    `BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING`. The window\n    frame syntax supports additional clauses for row pattern\n    recognition. If the row pattern recognition clauses are specified,\n    the window frame for a particular row consists of the rows matched\n    by a pattern starting from that row. Additionally, if the frame\n    specifies row pattern measures, they can be called over the window,\n    similarly to window functions. For more details, see\n    `Row pattern recognition in window structures\n    </sql/pattern-recognition-in-window>`{.interpreted-text role=\"doc\"}.\n\nEach window component is optional. If a window specification does not\nspecify window partitioning, ordering or frame, those components are\nobtained from the window specification referenced by the\n`existing window name`, or from another window specification in the\nreference chain. In case when there is no `existing window name`\nspecified, or none of the referenced window specifications contains the\ncomponent, the default value is used.\n\n## Set operations\n\n`UNION` `INTERSECT` and `EXCEPT` are all set operations. These clauses\nare used to combine the results of more than one select statement into a\nsingle result set:\n\n``` text\nquery UNION [ALL | DISTINCT] query\n```\n\n``` text\nquery INTERSECT [ALL | DISTINCT] query\n```\n\n``` text\nquery EXCEPT [ALL | DISTINCT] query\n```\n\nThe argument `ALL` or `DISTINCT` controls which rows are included in the\nfinal result set. If the argument `ALL` is specified all rows are\nincluded even if the rows are identical. If the argument `DISTINCT` is\nspecified only unique rows are included in the combined result set. If\nneither is specified, the behavior defaults to `DISTINCT`.\n\nMultiple set operations are processed left to right, unless the order is\nexplicitly specified via parentheses. Additionally, `INTERSECT` binds\nmore tightly than `EXCEPT` and `UNION`. That means\n`A UNION B INTERSECT C EXCEPT D` is the same as\n`A UNION (B INTERSECT C) EXCEPT D`.\n\n### UNION clause\n\n`UNION` combines all the rows that are in the result set from the first\nquery with those that are in the result set for the second query. The\nfollowing is an example of one of the simplest possible", "doc_id": "58ca41ae-0eeb-43e5-af1a-428f8f77367d", "embedding": null, "doc_hash": "f3c01257593150ca6864a779d078d14d236405b15112df3fcce40605247a2dd9", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 21354, "end": 24788, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "4904b7c6-a6b6-4412-a7cc-0998aabcbce5", "3": "fdd64274-085a-473f-9581-29668a3365a3"}}, "__type__": "1"}, "fdd64274-085a-473f-9581-29668a3365a3": {"__data__": {"text": "the second query. The\nfollowing is an example of one of the simplest possible `UNION` clauses.\nIt selects the value `13` and combines this result set with a second\nquery that selects the value `42`:\n\n    SELECT 13\n    UNION\n    SELECT 42;\n\n``` text\n_col0\n-------\n   13\n   42\n(2 rows)\n```\n\nThe following query demonstrates the difference between `UNION` and\n`UNION ALL`. It selects the value `13` and combines this result set with\na second query that selects the values `42` and `13`:\n\n    SELECT 13\n    UNION\n    SELECT * FROM (VALUES 42, 13);\n\n``` text\n_col0\n-------\n   13\n   42\n(2 rows)\n```\n\n    SELECT 13\n    UNION ALL\n    SELECT * FROM (VALUES 42, 13);\n\n``` text\n_col0\n-------\n   13\n   42\n   13\n(2 rows)\n```\n\n### INTERSECT clause\n\n`INTERSECT` returns only the rows that are in the result sets of both\nthe first and the second queries. The following is an example of one of\nthe simplest possible `INTERSECT` clauses. It selects the values `13`\nand `42` and combines this result set with a second query that selects\nthe value `13`. Since `42` is only in the result set of the first query,\nit is not included in the final results.:\n\n    SELECT * FROM (VALUES 13, 42)\n    INTERSECT\n    SELECT 13;\n\n``` text\n_col0\n-------\n   13\n(2 rows)\n```\n\n### EXCEPT clause\n\n`EXCEPT` returns the rows that are in the result set of the first query,\nbut not the second. The following is an example of one of the simplest\npossible `EXCEPT` clauses. It selects the values `13` and `42` and\ncombines this result set with a second query that selects the value\n`13`. Since `13` is also in the result set of the second query, it is\nnot included in the final result.:\n\n    SELECT * FROM (VALUES 13, 42)\n    EXCEPT\n    SELECT 13;\n\n``` text\n_col0\n-------\n  42\n(2 rows)\n```\n\n## ORDER BY clause\n\nThe `ORDER BY` clause is used to sort a result set by one or more output\nexpressions:\n\n``` text\nORDER BY expression [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [, ...]\n```\n\nEach expression may be composed of output columns, or it may be an\nordinal number selecting an output column by position, starting at one.\nThe `ORDER BY` clause is evaluated after any `GROUP BY` or `HAVING`\nclause, and before any `OFFSET`, `LIMIT` or `FETCH FIRST` clause. The\ndefault null ordering is `NULLS LAST`, regardless of the ordering\ndirection.\n\nNote that, following the SQL specification, an `ORDER BY` clause only\naffects the order of rows for queries that immediately contain the\nclause. Trino follows that specification, and drops redundant usage of\nthe clause to avoid negative performance impacts.\n\nIn the following example, the clause only applies to the select\nstatement.\n\n``` SQL\nINSERT INTO some_table\nSELECT * FROM another_table\nORDER BY field;\n```\n\nSince tables in SQL are inherently unordered, and the `ORDER BY` clause\nin this case does not result in any difference, but negatively impacts\nperformance of running the overall insert statement, Trino skips the\nsort operation.\n\nAnother example where the `ORDER BY` clause is redundant, and does not\naffect the outcome of the overall", "doc_id": "fdd64274-085a-473f-9581-29668a3365a3", "embedding": null, "doc_hash": "8799c47d999438f587a827d84369c63e960d0637c58be6838abf27e04d9cbef3", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 24792, "end": 27834, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "58ca41ae-0eeb-43e5-af1a-428f8f77367d", "3": "13beae33-5993-4ad5-b38b-1f38405dfa47"}}, "__type__": "1"}, "13beae33-5993-4ad5-b38b-1f38405dfa47": {"__data__": {"text": "clause is redundant, and does not\naffect the outcome of the overall statement, is a nested query:\n\n``` SQL\nSELECT *\nFROM some_table\n    JOIN (SELECT * FROM another_table ORDER BY field) u\n    ON some_table.key = u.key;\n```\n\nMore background information and details can be found in [a blog post\nabout this\noptimization](https://trino.io/blog/2019/06/03/redundant-order-by.html).\n\n## OFFSET clause\n\nThe `OFFSET` clause is used to discard a number of leading rows from the\nresult set:\n\n``` text\nOFFSET count [ ROW | ROWS ]\n```\n\nIf the `ORDER BY` clause is present, the `OFFSET` clause is evaluated\nover a sorted result set, and the set remains sorted after the leading\nrows are discarded:\n\n    SELECT name FROM nation ORDER BY name OFFSET 22;\n\n``` text\nname\n----------------\nUNITED KINGDOM\nUNITED STATES\nVIETNAM\n(3 rows)\n```\n\nOtherwise, it is arbitrary which rows are discarded. If the count\nspecified in the `OFFSET` clause equals or exceeds the size of the\nresult set, the final result is empty.\n\n## LIMIT or FETCH FIRST clause {#limit-clause}\n\nThe `LIMIT` or `FETCH FIRST` clause restricts the number of rows in the\nresult set.\n\n``` text\nLIMIT { count | ALL }\n```\n\n``` text\nFETCH { FIRST | NEXT } [ count ] { ROW | ROWS } { ONLY | WITH TIES }\n```\n\nThe following example queries a large table, but the `LIMIT` clause\nrestricts the output to only have five rows (because the query lacks an\n`ORDER BY`, exactly which rows are returned is arbitrary):\n\n    SELECT orderdate FROM orders LIMIT 5;\n\n``` text\norderdate\n------------\n1994-07-25\n1993-11-12\n1992-10-06\n1994-01-04\n1997-12-28\n(5 rows)\n```\n\n`LIMIT ALL` is the same as omitting the `LIMIT` clause.\n\nThe `FETCH FIRST` clause supports either the `FIRST` or `NEXT` keywords\nand the `ROW` or `ROWS` keywords. These keywords are equivalent and the\nchoice of keyword has no effect on query execution.\n\nIf the count is not specified in the `FETCH FIRST` clause, it defaults\nto `1`:\n\n    SELECT orderdate FROM orders FETCH FIRST ROW ONLY;\n\n``` text\norderdate\n------------\n1994-02-12\n(1 row)\n```\n\nIf the `OFFSET` clause is present, the `LIMIT` or `FETCH FIRST` clause\nis evaluated after the `OFFSET` clause:\n\n    SELECT * FROM (VALUES 5, 2, 4, 1, 3) t(x) ORDER BY x OFFSET 2 LIMIT 2;\n\n``` text\nx\n---\n3\n4\n(2 rows)\n```\n\nFor the `FETCH FIRST` clause, the argument `ONLY` or `WITH TIES`\ncontrols which rows are included in the result set.\n\nIf the argument `ONLY` is specified, the result set is limited to the\nexact number of leading rows determined by the count.\n\nIf the argument `WITH TIES` is specified, it is required that the\n`ORDER BY` clause be present. The result set consists of the same set of\nleading rows and all of the rows in the same peer group as the last of\nthem (\\'ties\\') as established by the ordering in the `ORDER BY` clause.\nThe result set is sorted:\n\n    SELECT name, regionkey\n    FROM nation\n    ORDER", "doc_id": "13beae33-5993-4ad5-b38b-1f38405dfa47", "embedding": null, "doc_hash": "d7338d4a35ffdab3776ee274d73f368aa802cd0ca1395ba65354662dbbed0471", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 27843, "end": 30706, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "fdd64274-085a-473f-9581-29668a3365a3", "3": "33a40ddb-0a7e-4a06-b617-084a29e40815"}}, "__type__": "1"}, "33a40ddb-0a7e-4a06-b617-084a29e40815": {"__data__": {"text": "  SELECT name, regionkey\n    FROM nation\n    ORDER BY regionkey FETCH FIRST ROW WITH TIES;\n\n``` text\nname    | regionkey\n------------+-----------\nETHIOPIA   |         0\nMOROCCO    |         0\nKENYA      |         0\nALGERIA    |         0\nMOZAMBIQUE |         0\n(5 rows)\n```\n\n## TABLESAMPLE\n\nThere are multiple sample methods:\n\n`BERNOULLI`\n\n:   Each row is selected to be in the table sample with a probability of\n    the sample percentage. When a table is sampled using the Bernoulli\n    method, all physical blocks of the table are scanned and certain\n    rows are skipped (based on a comparison between the sample\n    percentage and a random value calculated at runtime).\n\n    The probability of a row being included in the result is independent\n    from any other row. This does not reduce the time required to read\n    the sampled table from disk. It may have an impact on the total\n    query time if the sampled output is processed further.\n\n`SYSTEM`\n\n:   This sampling method divides the table into logical segments of data\n    and samples the table at this granularity. This sampling method\n    either selects all the rows from a particular segment of data or\n    skips it (based on a comparison between the sample percentage and a\n    random value calculated at runtime).\n\n    The rows selected in a system sampling will be dependent on which\n    connector is used. For example, when used with Hive, it is dependent\n    on how the data is laid out on HDFS. This method does not guarantee\n    independent sampling probabilities.\n\n::: note\n::: title\nNote\n:::\n\nNeither of the two methods allow deterministic bounds on the number of\nrows returned.\n:::\n\nExamples:\n\n    SELECT *\n    FROM users TABLESAMPLE BERNOULLI (50);\n\n    SELECT *\n    FROM users TABLESAMPLE SYSTEM (75);\n\nUsing sampling with joins:\n\n    SELECT o.*, i.*\n    FROM orders o TABLESAMPLE SYSTEM (10)\n    JOIN lineitem i TABLESAMPLE BERNOULLI (40)\n      ON o.orderkey = i.orderkey;\n\n## UNNEST\n\n`UNNEST` can be used to expand an `array_type`{.interpreted-text\nrole=\"ref\"} or `map_type`{.interpreted-text role=\"ref\"} into a relation.\nArrays are expanded into a single column:\n\n    SELECT * FROM UNNEST(ARRAY[1,2]) AS t(number);\n\n``` text\nnumber\n--------\n     1\n     2\n(2 rows)\n```\n\nMaps are expanded into two columns (key, value):\n\n    SELECT * FROM UNNEST(\n            map_from_entries(\n                ARRAY[\n                    ('SQL',1974),\n                    ('Java', 1995)\n                ]\n            )\n    ) AS t(language, first_appeared_year);\n\n``` text\nlanguage | first_appeared_year\n----------+---------------------\nSQL      |     ", "doc_id": "33a40ddb-0a7e-4a06-b617-084a29e40815", "embedding": null, "doc_hash": "957deae27e28b77cc1977661371ccc4ede84a1c88351692a744ebc962bab9dd3", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 30727, "end": 33337, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "13beae33-5993-4ad5-b38b-1f38405dfa47", "3": "6f50a509-cf53-46ac-9233-917a0f68ff1c"}}, "__type__": "1"}, "6f50a509-cf53-46ac-9233-917a0f68ff1c": {"__data__": {"text": "     |                1974\nJava     |                1995\n(2 rows)\n```\n\n`UNNEST` can be used in combination with an `ARRAY` of\n`row_type`{.interpreted-text role=\"ref\"} structures for expanding each\nfield of the `ROW` into a corresponding column:\n\n    SELECT *\n    FROM UNNEST(\n            ARRAY[\n                ROW('Java',  1995),\n                ROW('SQL' , 1974)],\n            ARRAY[\n                ROW(false),\n                ROW(true)]\n    ) as t(language,first_appeared_year,declarative);\n\n``` text\nlanguage | first_appeared_year | declarative\n----------+---------------------+-------------\nJava     |                1995 | false\nSQL      |                1974 | true\n(2 rows)\n```\n\n`UNNEST` can optionally have a `WITH ORDINALITY` clause, in which case\nan additional ordinality column is added to the end:\n\n    SELECT a, b, rownumber\n    FROM UNNEST (\n        ARRAY[2, 5],\n        ARRAY[7, 8, 9]\n         ) WITH ORDINALITY AS t(a, b, rownumber);\n\n``` text\na   | b | rownumber\n------+---+-----------\n  2 | 7 |         1\n  5 | 8 |         2\nNULL | 9 |         3\n(3 rows)\n```\n\n`UNNEST` returns zero entries when the array/map is empty:\n\n    SELECT * FROM UNNEST (ARRAY[]) AS t(value);\n\n``` text\nvalue\n-------\n(0 rows)\n```\n\n`UNNEST` returns zero entries when the array/map is null:\n\n    SELECT * FROM UNNEST (CAST(null AS ARRAY(integer))) AS t(number);\n\n``` text\nnumber\n--------\n(0 rows)\n```\n\n`UNNEST` is normally used with a `JOIN`, and can reference columns from\nrelations on the left side of the join:\n\n    SELECT student, score\n    FROM (\n       VALUES\n          ('John', ARRAY[7, 10, 9]),\n          ('Mary', ARRAY[4, 8, 9])\n    ) AS tests (student, scores)\n    CROSS JOIN UNNEST(scores) AS t(score);\n\n``` text\nstudent | score\n---------+-------\nJohn    |     7\nJohn    |    10\nJohn    |     9\nMary    |     4\nMary    |     8\nMary    |     9\n(6 rows)\n```\n\n`UNNEST` can also be used with multiple arguments, in which case they\nare expanded into multiple columns, with as many rows as the highest\ncardinality argument (the other columns are padded with nulls):\n\n    SELECT numbers, animals, n, a\n    FROM (\n      VALUES\n        (ARRAY[2, 5], ARRAY['dog', 'cat',", "doc_id": "6f50a509-cf53-46ac-9233-917a0f68ff1c", "embedding": null, "doc_hash": "13a4c5d0e2089b8145a616a11a0eeee023536a72e2901b3ae5dfc1b2ae75654a", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 33374, "end": 35539, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "33a40ddb-0a7e-4a06-b617-084a29e40815", "3": "6c175b95-8b08-42cb-8a4c-d26359be0d7a"}}, "__type__": "1"}, "6c175b95-8b08-42cb-8a4c-d26359be0d7a": {"__data__": {"text": "    (ARRAY[2, 5], ARRAY['dog', 'cat', 'bird']),\n        (ARRAY[7, 8, 9], ARRAY['cow', 'pig'])\n    ) AS x (numbers, animals)\n    CROSS JOIN UNNEST(numbers, animals) AS t (n, a);\n\n``` text\nnumbers  |     animals      |  n   |  a\n-----------+------------------+------+------\n[2, 5]    | [dog, cat, bird] |    2 | dog\n[2, 5]    | [dog, cat, bird] |    5 | cat\n[2, 5]    | [dog, cat, bird] | NULL | bird\n[7, 8, 9] | [cow, pig]       |    7 | cow\n[7, 8, 9] | [cow, pig]       |    8 | pig\n[7, 8, 9] | [cow, pig]       |    9 | NULL\n(6 rows)\n```\n\n`LEFT JOIN` is preferable in order to avoid losing the the row\ncontaining the array/map field in question when referenced columns from\nrelations on the left side of the join can be empty or have `NULL`\nvalues:\n\n    SELECT runner, checkpoint\n    FROM (\n       VALUES\n          ('Joe', ARRAY[10, 20, 30, 42]),\n          ('Roger', ARRAY[10]),\n          ('Dave', ARRAY[]),\n          ('Levi', NULL)\n    ) AS marathon (runner, checkpoints)\n    LEFT JOIN UNNEST(checkpoints) AS t(checkpoint) ON TRUE;\n\n``` text\nrunner | checkpoint\n--------+------------\nJoe    |         10\nJoe    |         20\nJoe    |         30\nJoe    |         42\nRoger  |         10\nDave   |       NULL\nLevi   |       NULL\n(7 rows)\n```\n\nNote that in case of using `LEFT JOIN` the only condition supported by\nthe current implementation is `ON TRUE`.\n\n## Joins\n\nJoins allow you to combine data from multiple relations.\n\n### CROSS JOIN\n\nA cross join returns the Cartesian product (all combinations) of two\nrelations. Cross joins can either be specified using the explit\n`CROSS JOIN` syntax or by specifying multiple relations in the `FROM`\nclause.\n\nBoth of the following queries are equivalent:\n\n    SELECT *\n    FROM nation\n    CROSS JOIN region;\n\n    SELECT *\n    FROM nation, region;\n\nThe `nation` table contains 25 rows and the `region` table contains 5\nrows, so a cross join between the two tables produces 125 rows:\n\n    SELECT n.name AS nation, r.name AS region\n    FROM nation AS n\n    CROSS JOIN region AS r\n    ORDER BY 1, 2;\n\n``` text\nnation     |   region\n----------------+-------------\nALGERIA        | AFRICA\nALGERIA        | AMERICA\nALGERIA        | ASIA\nALGERIA        | EUROPE\nALGERIA        | MIDDLE EAST\nARGENTINA      | AFRICA\nARGENTINA      | AMERICA\n...\n(125", "doc_id": "6c175b95-8b08-42cb-8a4c-d26359be0d7a", "embedding": null, "doc_hash": "0545dfc0a177430c33c10dc97632284320b59a4cc4c5626377d5d87aad7dc59c", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 35511, "end": 37791, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "6f50a509-cf53-46ac-9233-917a0f68ff1c", "3": "9021442b-6c62-4412-bfba-f5e3381d0bfd"}}, "__type__": "1"}, "9021442b-6c62-4412-bfba-f5e3381d0bfd": {"__data__": {"text": "     | AMERICA\n...\n(125 rows)\n```\n\n### LATERAL\n\nSubqueries appearing in the `FROM` clause can be preceded by the keyword\n`LATERAL`. This allows them to reference columns provided by preceding\n`FROM` items.\n\nA `LATERAL` join can appear at the top level in the `FROM` list, or\nanywhere within a parenthesized join tree. In the latter case, it can\nalso refer to any items that are on the left-hand side of a `JOIN` for\nwhich it is on the right-hand side.\n\nWhen a `FROM` item contains `LATERAL` cross-references, evaluation\nproceeds as follows: for each row of the `FROM` item providing the\ncross-referenced columns, the `LATERAL` item is evaluated using that row\nset\\'s values of the columns. The resulting rows are joined as usual\nwith the rows they were computed from. This is repeated for set of rows\nfrom the column source tables.\n\n`LATERAL` is primarily useful when the cross-referenced column is\nnecessary for computing the rows to be joined:\n\n    SELECT name, x, y\n    FROM nation\n    CROSS JOIN LATERAL (SELECT name || ' :-' AS x)\n    CROSS JOIN LATERAL (SELECT x || ')' AS y);\n\n### Qualifying column names\n\nWhen two relations in a join have columns with the same name, the column\nreferences must be qualified using the relation alias (if the relation\nhas an alias), or with the relation name:\n\n    SELECT nation.name, region.name\n    FROM nation\n    CROSS JOIN region;\n\n    SELECT n.name, r.name\n    FROM nation AS n\n    CROSS JOIN region AS r;\n\n    SELECT n.name, r.name\n    FROM nation n\n    CROSS JOIN region r;\n\nThe following query will fail with the error\n`Column 'name' is ambiguous`:\n\n    SELECT name\n    FROM nation\n    CROSS JOIN region;\n\n## Subqueries\n\nA subquery is an expression which is composed of a query. The subquery\nis correlated when it refers to columns outside of the subquery.\nLogically, the subquery will be evaluated for each row in the\nsurrounding query. The referenced columns will thus be constant during\nany single evaluation of the subquery.\n\n::: note\n::: title\nNote\n:::\n\nSupport for correlated subqueries is limited. Not every standard form is\nsupported.\n:::\n\n### EXISTS\n\nThe `EXISTS` predicate determines if a subquery returns any rows:\n\n    SELECT name\n    FROM nation\n    WHERE EXISTS (\n         SELECT *\n         FROM region\n         WHERE region.regionkey = nation.regionkey\n    );\n\n### IN\n\nThe `IN` predicate determines if any values produced by the subquery are\nequal to the provided expression. The result of `IN` follows the\nstandard rules for nulls. The subquery must produce exactly one column:\n\n    SELECT name\n    FROM nation\n    WHERE regionkey IN (\n         SELECT regionkey\n         FROM region\n         WHERE name = 'AMERICA' OR name = 'AFRICA'\n    );\n\n### Scalar subquery\n\nA scalar subquery is a non-correlated subquery that returns zero or one\nrow. It is an error for the subquery to produce more than one row. The\nreturned value is `NULL` if the subquery produces no rows:\n\n    SELECT name\n    FROM nation\n    WHERE regionkey = (SELECT max(regionkey) FROM", "doc_id": "9021442b-6c62-4412-bfba-f5e3381d0bfd", "embedding": null, "doc_hash": "51306be527c22bbc96289dc121eada57e44060df0cec3bfae610038f3b7bf292", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 37805, "end": 40816, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "6c175b95-8b08-42cb-8a4c-d26359be0d7a", "3": "5801ddc5-ab39-480e-9650-814d4d2c89ba"}}, "__type__": "1"}, "5801ddc5-ab39-480e-9650-814d4d2c89ba": {"__data__": {"text": "FROM nation\n    WHERE regionkey = (SELECT max(regionkey) FROM region);\n\n::: note\n::: title\nNote\n:::\n\nCurrently only single column can be returned from the scalar subquery.\n:::\n", "doc_id": "5801ddc5-ab39-480e-9650-814d4d2c89ba", "embedding": null, "doc_hash": "d0f7cfba77c46480fa7572936d66e70a99e0d22bd21ab41819e80e5796e61c38", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}, "node_info": {"start": 40772, "end": 40948, "_node_type": "1"}, "relationships": {"1": "f68dac6bdd5ca8d920200669a808ce2f38342e60", "2": "9021442b-6c62-4412-bfba-f5e3381d0bfd"}}, "__type__": "1"}, "fa1f91df-6225-4383-9b65-37c3b4127ea2": {"__data__": {"text": "# SHOW CATALOGS\n\n## Synopsis\n\n``` text\nSHOW CATALOGS [ LIKE pattern ]\n```\n\n## Description\n\nList the available catalogs.\n\n`Specify a pattern <like_operator>`{.interpreted-text role=\"ref\"} in the\noptional `LIKE` clause to filter the results to the desired subset. For\nexample, the following query allows you to find catalogs that begin with\n`t`:\n\n    SHOW CATALOGS LIKE 't%'\n", "doc_id": "fa1f91df-6225-4383-9b65-37c3b4127ea2", "embedding": null, "doc_hash": "baa286177214045164e1602b45aa4087edbddaba706cb335e0f8c17ee7257014", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-catalogs.md", "file_name": "show-catalogs.md"}, "node_info": {"start": 0, "end": 373, "_node_type": "1"}, "relationships": {"1": "16ca6f86583488a6d995bf6b9ebc65c54927017e"}}, "__type__": "1"}, "96c4e3b1-cc77-4839-a5c4-00fdd95f940b": {"__data__": {"text": "# SHOW COLUMNS\n\n## Synopsis\n\n``` text\nSHOW COLUMNS FROM table [ LIKE pattern ]\n```\n\n## Description\n\nList the columns in a `table` along with their data type and other\nattributes.\n\n`Specify a pattern <like_operator>`{.interpreted-text role=\"ref\"} in the\noptional `LIKE` clause to filter the results to the desired subset. For\nexample, the following query allows you to find columns ending in `key`:\n\n    SHOW COLUMNS FROM nation LIKE '%key'\n", "doc_id": "96c4e3b1-cc77-4839-a5c4-00fdd95f940b", "embedding": null, "doc_hash": "c41efeb587b45092702f45f2768e6559e2b35e844e894c14e4b9ad0130ee44ef", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-columns.md", "file_name": "show-columns.md"}, "node_info": {"start": 0, "end": 440, "_node_type": "1"}, "relationships": {"1": "cf8d1ce1afc681f25b26aa6d4465f545543454b2"}}, "__type__": "1"}, "52932894-feb3-48d3-b03f-a06ef50604d3": {"__data__": {"text": "# SHOW CREATE MATERIALIZED VIEW\n\n## Synopsis\n\n``` text\nSHOW CREATE MATERIALIZED VIEW view_name\n```\n\n## Description\n\nShow the SQL statement that creates the specified materialized view\n`view_name`.\n\n## See also\n\n-   `create-materialized-view`{.interpreted-text role=\"doc\"}\n-   `drop-materialized-view`{.interpreted-text role=\"doc\"}\n-   `refresh-materialized-view`{.interpreted-text role=\"doc\"}\n", "doc_id": "52932894-feb3-48d3-b03f-a06ef50604d3", "embedding": null, "doc_hash": "279d7c7e568b0f3ecc5d586efc6a5e3c9f5759b915971e9441c51935bbe9fec3", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-materialized-view.md", "file_name": "show-create-materialized-view.md"}, "node_info": {"start": 0, "end": 393, "_node_type": "1"}, "relationships": {"1": "b2846ac788b66d5edb228c099391b2677705c859"}}, "__type__": "1"}, "5b4c9bb9-5cea-4352-9ce6-ec4c2a343e73": {"__data__": {"text": "# SHOW CREATE TABLE\n\n## Synopsis\n\n``` text\nSHOW CREATE TABLE table_name\n```\n\n## Description\n\nShow the SQL statement that creates the specified table.\n\n## Examples\n\nShow the SQL that can be run to create the `orders` table:\n\n    SHOW CREATE TABLE sf1.orders;\n\n``` text\nCreate Table\n-----------------------------------------\nCREATE TABLE tpch.sf1.orders (\norderkey bigint,\norderstatus varchar,\ntotalprice double,\norderdate varchar\n)\nWITH (\nformat = 'ORC',\npartitioned_by = ARRAY['orderdate']\n)\n(1 row)\n```\n\n## See also\n\n`create-table`{.interpreted-text role=\"doc\"}\n", "doc_id": "5b4c9bb9-5cea-4352-9ce6-ec4c2a343e73", "embedding": null, "doc_hash": "aef93ce1cb2dbeae17be317cdb75b802532fc12a902caf9acc2c8605ed447d8e", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-table.md", "file_name": "show-create-table.md"}, "node_info": {"start": 0, "end": 563, "_node_type": "1"}, "relationships": {"1": "8d53adfef0c6cf93e1ff25759d5514747b3ab794"}}, "__type__": "1"}, "babc3d13-5673-461c-b3ec-2711cb46902c": {"__data__": {"text": "# SHOW CREATE VIEW\n\n## Synopsis\n\n``` text\nSHOW CREATE VIEW view_name\n```\n\n## Description\n\nShow the SQL statement that creates the specified view.\n\n## See also\n\n`create-view`{.interpreted-text role=\"doc\"}\n", "doc_id": "babc3d13-5673-461c-b3ec-2711cb46902c", "embedding": null, "doc_hash": "950e948c87b55e73d0818d9db0772e6dc0acac1b6ee184084dff8f036406e274", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-view.md", "file_name": "show-create-view.md"}, "node_info": {"start": 0, "end": 204, "_node_type": "1"}, "relationships": {"1": "9d076c2fdc9d99eb241f667da6671ada777b3b6e"}}, "__type__": "1"}, "f1ba7a0e-9bc2-4989-9927-51b14e0f6343": {"__data__": {"text": "# SHOW FUNCTIONS\n\n## Synopsis\n\n``` text\nSHOW FUNCTIONS [ LIKE pattern ]\n```\n\n## Description\n\nList all the functions available for use in queries. For each function\nreturned, the following information is displayed:\n\n-   Function name\n-   Return type\n-   Argument types\n-   Function type\n-   Deterministic\n-   Description\n\n`Specify a pattern <like_operator>`{.interpreted-text role=\"ref\"} in the\noptional `LIKE` clause to filter the results to the desired subset. For\nexample, the following query allows you to find functions beginning with\n`array`:\n\n    SHOW FUNCTIONS LIKE 'array%';\n\n`SHOW FUNCTIONS` works with built-in functions as well as with `custom\nfunctions </develop/functions>`{.interpreted-text role=\"doc\"}. In the\nfollowing example, three custom functions beginning with `cf` are\navailable:\n\n``` text\nSHOW FUNCTIONS LIKE 'cf%';\n\n     Function      | Return Type | Argument Types | Function Type | Deterministic |               Description\n ------------------+-------------+----------------+---------------+---------------+-----------------------------------------\n cf_getgroups      | varchar     |                | scalar        | true          | Returns the current session's groups\n cf_getprincipal   | varchar     |                | scalar        | true          | Returns the current session's principal\n cf_getuser        | varchar     |                | scalar        | true          | Returns the current session's user\n```\n", "doc_id": "f1ba7a0e-9bc2-4989-9927-51b14e0f6343", "embedding": null, "doc_hash": "ebeaa40fc500ce8898e26e403e015a6d80f7bbb919e0b39fef1a536d1227e1e1", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-functions.md", "file_name": "show-functions.md"}, "node_info": {"start": 0, "end": 1443, "_node_type": "1"}, "relationships": {"1": "e55bf918e7d312377ca19e115df19f7bf18033da"}}, "__type__": "1"}, "2c8fb682-6e00-4d10-a313-12d57b114d9d": {"__data__": {"text": "SHOW SCHEMAS\n\n## Synopsis\n\n``` text\nSHOW SCHEMAS [ FROM catalog ] [ LIKE pattern ]\n```\n\n## Description\n\nList the schemas in `catalog` or in the current catalog.\n\n`Specify a pattern <like_operator>`{.interpreted-text role=\"ref\"} in the\noptional `LIKE` clause to filter the results to the desired subset. For\nexample, the following query allows you to find schemas that have `3` as\nthe third character:\n\n    SHOW SCHEMAS FROM tpch LIKE '__3%'\n", "doc_id": "2c8fb682-6e00-4d10-a313-12d57b114d9d", "embedding": null, "doc_hash": "43b23ff81f75e3085c7bceb1f3c06ff888eedebca83f6ec1aa911f581866fc0a", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-schemas.md", "file_name": "show-schemas.md"}, "node_info": {"start": 0, "end": 441, "_node_type": "1"}, "relationships": {"1": "2d488b6677a66d4503b9f49ba6878fb344f61f90"}}, "__type__": "1"}, "bbe73472-de83-4c36-881b-74024c76352e": {"__data__": {"text": "# SHOW SESSION\n\n## Synopsis\n\n``` text\nSHOW SESSION [ LIKE pattern ]\n```\n\n## Description\n\nList the current\n`session properties <session-properties-definition>`{.interpreted-text\nrole=\"ref\"}.\n\n`Specify a pattern <like_operator>`{.interpreted-text role=\"ref\"} in the\noptional `LIKE` clause to filter the results to the desired subset. For\nexample, the following query allows you to find session properties that\nbegin with `query`:\n\n    SHOW SESSION LIKE 'query%'\n\n## See also\n\n`reset-session`{.interpreted-text role=\"doc\"},\n`set-session`{.interpreted-text role=\"doc\"}\n", "doc_id": "bbe73472-de83-4c36-881b-74024c76352e", "embedding": null, "doc_hash": "9154d4011e543bc3fbc7469e8caf92188760e2567b3a4db8d171dc463ac5b1bb", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-session.md", "file_name": "show-session.md"}, "node_info": {"start": 0, "end": 565, "_node_type": "1"}, "relationships": {"1": "8a3f654706292a82d0fe36909ba8407a9ee6f166"}}, "__type__": "1"}, "57343cdb-88f3-4eb9-b389-a10d589328de": {"__data__": {"text": "# SHOW STATS\n\n## Synopsis\n\n``` text\nSHOW STATS FOR table\nSHOW STATS FOR ( query )\n```\n\n## Description\n\nReturns approximated statistics for the named table or for the results\nof a query. Returns `NULL` for any statistics that are not populated or\nunavailable on the data source.\n\nStatistics are returned as a row for each column, plus a summary row for\nthe table (identifiable by a `NULL` value for `column_name`). The\nfollowing table lists the returned columns and what statistics they\nrepresent. Any additional statistics collected on the data source, other\nthan those listed here, are not included.\n\n  Column                    Description                                                  Notes\n  ------------------------- ------------------------------------------------------------ ----------------------------------------------------------------------------------------------------\n  `column_name`             The name of the column                                       `NULL` in the table summary row\n  `data_size`               The total size in bytes of all of the values in the column   `NULL` in the table summary row. Available for columns of textual types (`CHAR`, `VARCHAR`, etc)\n  `distinct_values_count`   The estimated number of distinct values in the column m      `NULL` in the table summary row\n  `nulls_fractions`         The portion of the values in the column that are `NULL`      `NULL` in the table summary row.\n  `row_count`               The estimated number of rows in the table                    `NULL` in column statistic rows\n  `low_value`               The lowest value found in this column                        `NULL` in the table summary row. Available for columns of numeric types (`BIGINT`, `DECIMAL`, etc)\n  `high_value`              The highest value found in this column                       `NULL` in the table summary row. Available for columns of numeric types (`BIGINT`, `DECIMAL`, etc)\n", "doc_id": "57343cdb-88f3-4eb9-b389-a10d589328de", "embedding": null, "doc_hash": "56edf1a006027025c61bb965d3206caf811c23f8339d14a21477f83969be3de0", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-stats.md", "file_name": "show-stats.md"}, "node_info": {"start": 0, "end": 1934, "_node_type": "1"}, "relationships": {"1": "ce365e6c157eb365fde71d972ee493f1660789fc"}}, "__type__": "1"}, "488858f6-cd0d-43a2-9fed-59327c3bf46e": {"__data__": {"text": "# SHOW TABLES\n\n## Synopsis\n\n``` text\nSHOW TABLES [ FROM schema ] [ LIKE pattern ]\n```\n\n## Description\n\nList the tables in `schema` or in the current schema.\n\n`Specify a pattern <like_operator>`{.interpreted-text role=\"ref\"} in the\noptional `LIKE` clause to filter the results to the desired subset.. For\nexample, the following query allows you to find tables that begin with\n`p`:\n\n    SHOW TABLES FROM tpch.tiny LIKE 'p%';\n", "doc_id": "488858f6-cd0d-43a2-9fed-59327c3bf46e", "embedding": null, "doc_hash": "bddcaf769e623cf42cbe6f366a5b8a037877309fdcf7a87fa55fc5ff37243098", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-tables.md", "file_name": "show-tables.md"}, "node_info": {"start": 0, "end": 423, "_node_type": "1"}, "relationships": {"1": "097b18888685db3b4562b73d73275d5346264fa5"}}, "__type__": "1"}, "7409b460-f6b9-42a7-bc30-ebfc80dc088d": {"__data__": {"text": "# UPDATE\n\n## Synopsis\n\n``` text\nUPDATE table_name SET [ ( column = expression [, ... ] ) ] [ WHERE condition ]\n```\n\n## Description\n\nUpdate selected columns values in existing rows in a table.\n\nThe columns named in the `column = expression` assignments will be\nupdated for all rows that match the `WHERE` condition. The values of all\ncolumn update expressions for a matching row are evaluated before any\ncolumn value is changed. When the type of the expression and the type of\nthe column differ, the usual implicit CASTs, such as widening numeric\nfields, are applied to the `UPDATE` expression values.\n\n## Examples\n\nUpdate the status of all purchases that haven\\'t been assigned a ship\ndate:\n\n    UPDATE\n      purchases\n    SET\n      status = 'OVERDUE'\n    WHERE\n      ship_date IS NULL;\n\nUpdate the account manager and account assign date for all customers:\n\n    UPDATE\n      customers\n    SET\n      account_manager = 'John Henry',\n      assign_date = now();\n\nUpdate the manager to be the name of the employee who matches the\nmanager ID:\n\n    UPDATE\n      new_hires\n    SET\n      manager = (\n        SELECT\n          e.name\n        FROM\n          employees e\n        WHERE\n          e.employee_id = new_hires.manager_id\n      );\n\n## Limitations\n\nSome connectors have limited or no support for `UPDATE`. See connector\ndocumentation for more details.\n", "doc_id": "7409b460-f6b9-42a7-bc30-ebfc80dc088d", "embedding": null, "doc_hash": "b7f8b93f6698e026cd25cccc1c0323299853a4d9cf123b81a6c35c40a00f48bb", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/update.md", "file_name": "update.md"}, "node_info": {"start": 0, "end": 1349, "_node_type": "1"}, "relationships": {"1": "6368f797c590508363076d28a49b64d5eb433091"}}, "__type__": "1"}, "ffceaa65-f346-476e-a27b-c7b8eac146a3": {"__data__": {"text": "# USE\n\n## Synopsis\n\n``` text\nUSE catalog.schema\nUSE schema\n```\n\n## Description\n\nUpdate the session to use the specified catalog and schema. If a catalog\nis not specified, the schema is resolved relative to the current\ncatalog.\n\n## Examples\n\n``` sql\nUSE hive.finance;\nUSE information_schema;\n```\n", "doc_id": "ffceaa65-f346-476e-a27b-c7b8eac146a3", "embedding": null, "doc_hash": "c7efa497d7ae42860913c26f2b6fc25b1e244649c5975e242d1f611328b8c562", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/use.md", "file_name": "use.md"}, "node_info": {"start": 0, "end": 295, "_node_type": "1"}, "relationships": {"1": "7afa618ea49b3ff559ca5ccfa3514e799fbd7fc4"}}, "__type__": "1"}, "016647e5-1dc2-4afd-99d0-e745b235a1cb": {"__data__": {"text": "# VALUES\n\n## Synopsis\n\n``` text\nVALUES row [, ...]\n```\n\nwhere `row` is a single expression or\n\n``` text\n( column_expression [, ...] )\n```\n\n## Description\n\nDefines a literal inline table.\n\n`VALUES` can be used anywhere a query can be used (e.g., the `FROM`\nclause of a `select`{.interpreted-text role=\"doc\"}, an\n`insert`{.interpreted-text role=\"doc\"}, or even at the top level).\n`VALUES` creates an anonymous table without column names, but the table\nand columns can be named using an `AS` clause with column aliases.\n\n## Examples\n\nReturn a table with one column and three rows:\n\n    VALUES 1, 2, 3\n\nReturn a table with two columns and three rows:\n\n    VALUES\n        (1, 'a'),\n        (2, 'b'),\n        (3, 'c')\n\nReturn table with column `id` and `name`:\n\n    SELECT * FROM (\n        VALUES\n            (1, 'a'),\n            (2, 'b'),\n            (3, 'c')\n    ) AS t (id, name)\n\nCreate a new table with column `id` and `name`:\n\n    CREATE TABLE example AS\n    SELECT * FROM (\n        VALUES\n            (1, 'a'),\n            (2, 'b'),\n            (3, 'c')\n    ) AS t (id, name)\n\n## See also\n\n`insert`{.interpreted-text role=\"doc\"}, `select`{.interpreted-text\nrole=\"doc\"}\n", "doc_id": "016647e5-1dc2-4afd-99d0-e745b235a1cb", "embedding": null, "doc_hash": "c9a63b92faa67b3fd8fc7f8aa24e93349d1d54e197a49550ebba42c0c3c239d6", "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/values.md", "file_name": "values.md"}, "node_info": {"start": 0, "end": 1171, "_node_type": "1"}, "relationships": {"1": "74fa64853c91471be07cbd3bd65bea9bb9dff866"}}, "__type__": "1"}, "008073fa-830b-46e7-bb1d-18d275925ba4": {"__data__": {"text": "# Datatypes\n\nDuneSQL has a set of built-in data types, described below.\n\nImplicit Conversion and Casting to other datatypes is described in [the conversion function documentation](Functions-and-operators/conversion.md).\n\n## Boolean\n\n### `BOOLEAN`\n\nThis type captures boolean values `true` and `false`.\n\n## Integer\n\n### `TINYINT`\n\nA 8-bit signed two\\'s complement integer with a minimum value of `-2^7`\nand a maximum value of `2^7 - 1`.\n\n### `SMALLINT`\n\nA 16-bit signed two\\'s complement integer with a minimum value of\n`-2^15` and a maximum value of `2^15 - 1`.\n\n### `INTEGER`\n\nA 32-bit signed two\\'s complement integer with a minimum value of\n`-2^31` and a maximum value of `2^31 - 1`. The name `INT` is also\navailable for this type.\n\n### `BIGINT`\n\nA 64-bit signed two\\'s complement integer with a minimum value of\n`-2^63` and a maximum value of `2^63 - 1`.\n\n### `UINT256` (Dune SQL)\n\nA 256-bit unsigned integer with a minimum value of 0 and a maximum value of 2^256 - 1. This data type can represent only non-negative integers, including very large positive integers, as well as zero. Since there is no sign bit, all 256 bits can be used to represent the magnitude of the number. This data type is commonly used in EVM smart contracts to represent balances and other quantities.\n\n### `INT256` (Dune SQL)\n\nA 256-bit signed two's complement integer with a minimum value of -2^255 and a maximum value of 2^255 - 1. This data type can represent a wide range of values, including very large negative and positive integers, as well as zero.\n\nThis data type is commonly used in EVM smart contracts to represent balances and other quantities, more specifically when the value can be negative. \n\n\n\n\n\n## Floating-point\n\n### `REAL`\n\nA real is a 32-bit inexact, variable-precision implementing the IEEE\nStandard 754 for Binary Floating-Point Arithmetic.\n\nExample literals: `REAL '10.3'`, `REAL '10.3e0'`, `REAL '1.03e1'`\n\n### `DOUBLE`\n\nA double is a 64-bit inexact, variable-precision implementing the IEEE\nStandard 754 for Binary Floating-Point Arithmetic.\n\nExample literals: `DOUBLE '10.3'`, `DOUBLE '1.03e1'`, `10.3e0`, `1.03e1`\n\n## Fixed-precision\n\n### `DECIMAL`\n\nA fixed precision decimal number. Precision up to 38 digits is supported\nbut performance is best up to 18 digits.\n\nThe decimal type takes two literal parameters:\n\n-   **precision** - total number of digits\n-   **scale** - number of digits in fractional part. Scale is optional\n    and defaults to 0.\n\nExample type definitions: `DECIMAL(10,3)`, `DECIMAL(20)`\n\nExample literals: `DECIMAL '10.3'`, `DECIMAL '1234567890'`, `1.1`\n\n## String\n\n### `VARCHAR`\n\nVariable length character data with an optional maximum length.\n\nExample type definitions: `varchar`, `varchar(20)`\n\nSQL statements support simple literal, as well as Unicode usage:\n\n-   literal string : `'Hello winter !'`\n-   Unicode string with default escape character:\n    `U&'Hello winter \\2603 !'`\n-   Unicode string with custom escape character:\n    `U&'Hello winter #2603 !' UESCAPE '#'`\n\nA Unicode string is prefixed with `U&` and requires an escape", "doc_id": "008073fa-830b-46e7-bb1d-18d275925ba4", "embedding": null, "doc_hash": "892f18cf033458e322382a2b4fb84724274a816bb487bb7d2479739496dce7e8", "extra_info": {"file_path": "docs/query/DuneSQL-reference/datatypes.md", "file_name": "datatypes.md"}, "node_info": {"start": 0, "end": 3068, "_node_type": "1"}, "relationships": {"1": "9a8056fb6210281fa3ccc658a5a7899d0d2973e7", "3": "8367c16b-b179-4b55-bff0-54ef356f0908"}}, "__type__": "1"}, "8367c16b-b179-4b55-bff0-54ef356f0908": {"__data__": {"text": "Unicode string is prefixed with `U&` and requires an escape character\nbefore any Unicode character usage with 4 digits. In the examples above\n`\\2603` and `#2603` represent a snowman character. Long Unicode codes\nwith 6 digits require usage of the plus symbol before the code. For\nexample, you need to use `\\+01F600` for a grinning face emoji.\n\n### `CHAR`\n\nFixed length character data. A `CHAR` type without length specified has\na default length of 1. A `CHAR(x)` value always has `x` characters. For\nexample, casting `dog` to `CHAR(7)` adds 4 implicit trailing spaces.\nLeading and trailing spaces are included in comparisons of `CHAR`\nvalues. As a result, two character values with different lengths\n(`CHAR(x)` and `CHAR(y)` where `x != y`) will never be equal.\n\nExample type definitions: `char`, `char(20)`\n\n### `VARBINARY`\n\nVariable length binary data. In Dune, we store addresses, hashes, calldata and logs as `varbinary` data types.\n\n\nSQL statements support usage of binary data with the prefix `0x`. The\nbinary data has to use hexadecimal format. For example, the binary form\nof `eh?` is `X'65683F'`.\n\nWe have built custom functions to make it easier to work with varbinaries in DuneSQL. Check the [varbinary functions](/docs/query/DuneSQL-reference/Functions-and-operators/varbinary/) page for more information.\n\n```sql\n    Select * from ethereum.transactions where \"from\" = 0xc8ebccc5f5689fa8659d83713341e5ad19349448\n```\n\n### `JSON`\n\nJSON value type, which can be a JSON object, a JSON array, a JSON\nnumber, a JSON string, `true`, `false` or `null`.\n\n## Date and time\n\nSee also [`date and time functions`](/docs/query/DuneSQL-reference/Functions-and-operators/conversion/).\n\n### `DATE`\n\nCalendar date (year, month, day).\n\nExample: `DATE '2001-08-22'`\n\n### `TIME`\n\n`TIME` is an alias for `TIME(3)` (millisecond precision).\n\n### `TIME(P)`\n\nTime of day (hour, minute, second) without a time zone with `P` digits\nof precision for the fraction of seconds. A precision of up to 12\n(picoseconds) is supported.\n\nExample: `TIME '01:02:03.456'`\n\n### `TIME WITH TIME ZONE`\n\nTime of day (hour, minute, second, millisecond) with a time zone. Values\nof this type are rendered using the time zone from the value. Time zones\nare expressed as the numeric UTC offset value:\n```sql\n    SELECT TIME '01:02:03.456 -08:00';\n    -- 1:02:03.456-08:00\n```\n### `TIMESTAMP`\n\n`TIMESTAMP` is an alias for `TIMESTAMP(3)` (millisecond precision).\n\n### `TIMESTAMP(P)`\n\nCalendar date and time of day without a time zone with `P` digits of\nprecision for the fraction of seconds. A precision of up to 12\n(picoseconds) is supported. This type is effectively a combination of\nthe `DATE` and `TIME(P)` types.\n\n`TIMESTAMP(P) WITHOUT TIME ZONE` is an equivalent name.\n\nTimestamp values can be constructed with the `TIMESTAMP` literal\nexpression. Alternatively, language constructs such as\n`localtimestamp(p)`, or a number of `date and time functions and\noperators </functions/datetime>`{.interpreted-text role=\"doc\"} can\nreturn timestamp", "doc_id": "8367c16b-b179-4b55-bff0-54ef356f0908", "embedding": null, "doc_hash": "9f701b1e18d461273ff7373c6ad6adbd8566bcf6c5d03c21e7da99e83811f7f3", "extra_info": {"file_path": "docs/query/DuneSQL-reference/datatypes.md", "file_name": "datatypes.md"}, "node_info": {"start": 3019, "end": 6023, "_node_type": "1"}, "relationships": {"1": "9a8056fb6210281fa3ccc658a5a7899d0d2973e7", "2": "008073fa-830b-46e7-bb1d-18d275925ba4", "3": "c051edd3-9f84-44e5-9ceb-351062c7f0f5"}}, "__type__": "1"}, "c051edd3-9f84-44e5-9ceb-351062c7f0f5": {"__data__": {"text": "role=\"doc\"} can\nreturn timestamp values.\n\nCasting to lower precision causes the value to be rounded, and not\ntruncated. Casting to higher precision appends zeros for the additional\ndigits.\n\nThe following examples illustrate the behavior:\n\n```sql\n    SELECT TIMESTAMP '2020-06-10 15:55:23';\n    -- 2020-06-10 15:55:23\n\n    SELECT TIMESTAMP '2020-06-10 15:55:23.383345';\n    -- 2020-06-10 15:55:23.383345\n\n    SELECT typeof(TIMESTAMP '2020-06-10 15:55:23.383345');\n    -- timestamp(6)\n\n    SELECT cast(TIMESTAMP '2020-06-10 15:55:23.383345' as TIMESTAMP(1));\n     -- 2020-06-10 15:55:23.4\n\n    SELECT cast(TIMESTAMP '2020-06-10 15:55:23.383345' as TIMESTAMP(12));\n    -- 2020-06-10 15:55:23.383345000000\n```\n\n### `TIMESTAMP WITH TIME ZONE` {#timestamp-with-time-zone-data-type}\n\n`TIMESTAMP WITH TIME ZONE` is an alias for `TIMESTAMP(3) WITH TIME ZONE`\n(millisecond precision).\n\n### `TIMESTAMP(P) WITH TIME ZONE`\n\nInstant in time that includes the date and time of day with `P` digits\nof precision for the fraction of seconds and with a time zone. Values of\nthis type are rendered using the time zone from the value. Time zones\ncan be expressed in the following ways:\n\n-   `UTC`, with `GMT`, `Z`, or `UT` usable as aliases for UTC.\n-   `+hh:mm` or `-hh:mm` with `hh:mm` as an hour and minute offset from\n    UTC. Can be written with or without `UTC`, `GMT`, or `UT` as an\n    alias for UTC.\n-   An [IANA time zone name](https://www.iana.org/time-zones).\n\nThe following examples demonstrate some of these syntax options:\n```sql\n    SELECT TIMESTAMP '2001-08-22 03:04:05.321 UTC';\n    -- 2001-08-22 03:04:05.321 UTC\n\n    SELECT TIMESTAMP '2001-08-22 03:04:05.321 -08:30';\n    -- 2001-08-22 03:04:05.321 -08:30\n\n    SELECT TIMESTAMP '2001-08-22 03:04:05.321 GMT-08:30';\n    -- 2001-08-22 03:04:05.321 -08:30\n\n    SELECT TIMESTAMP '2001-08-22 03:04:05.321 America/New_York';\n    -- 2001-08-22 03:04:05.321 America/New_York\n```\n### `INTERVAL YEAR TO MONTH`\n\nSpan of years and months.\n\nExample: `INTERVAL '3' MONTH`\n\n### `INTERVAL DAY TO SECOND`\n\nSpan of days, hours, minutes, seconds and milliseconds.\n\nExample: `INTERVAL '2' DAY`\n\n## Structural\n\n### `ARRAY` \n\nAn array of the given component type.\n\nExample: `ARRAY[1, 2, 3]`\n\n### `MAP` \n\nA map between the given component types.\n\nExample: `MAP(ARRAY['foo', 'bar'], ARRAY[1, 2])`\n\n### `ROW` \n\nA structure made up of fields that allows mixed types. The fields may be\nof any SQL type.\n\nBy default, row fields are not named, but names can be assigned.\n\nExample: `CAST(ROW(1, 2e0) AS", "doc_id": "c051edd3-9f84-44e5-9ceb-351062c7f0f5", "embedding": null, "doc_hash": "748477cca52ce991353daed02f7749611878c3e741f31f835561bd1331b19659", "extra_info": {"file_path": "docs/query/DuneSQL-reference/datatypes.md", "file_name": "datatypes.md"}, "node_info": {"start": 6044, "end": 8565, "_node_type": "1"}, "relationships": {"1": "9a8056fb6210281fa3ccc658a5a7899d0d2973e7", "2": "8367c16b-b179-4b55-bff0-54ef356f0908", "3": "e8e90b63-1811-400f-9446-1ffe3aa554d5"}}, "__type__": "1"}, "e8e90b63-1811-400f-9446-1ffe3aa554d5": {"__data__": {"text": "assigned.\n\nExample: `CAST(ROW(1, 2e0) AS ROW(x BIGINT, y DOUBLE))`\n\nNamed row fields are accessed with field reference operator (`.`).\n\nExample: `CAST(ROW(1, 2.0) AS ROW(x BIGINT, y DOUBLE)).x`\n\nNamed or unnamed row fields are accessed by position with the subscript\noperator (`[]`). The position starts at `1` and must be a constant.\n\nExample: `ROW(1, 2.0)[1]`\n\n## Network address\n\n### `IPADDRESS` \n\nAn IP address that can represent either an IPv4 or IPv6 address.\nInternally, the type is a pure IPv6 address. Support for IPv4 is handled\nusing the *IPv4-mapped IPv6 address* range\n(`4291#section-2.5.5.2`{.interpreted-text role=\"rfc\"}). When creating an\n`IPADDRESS`, IPv4 addresses will be mapped into that range. When\nformatting an `IPADDRESS`, any address within the mapped range will be\nformatted as an IPv4 address. Other addresses will be formatted as IPv6\nusing the canonical format defined in `5952`{.interpreted-text\nrole=\"rfc\"}.\n\nExamples: `IPADDRESS '10.0.0.1'`, `IPADDRESS '2001:db8::1'`\n\n## UUID\n\n### `UUID` \n\nThis type represents a UUID (Universally Unique IDentifier), also known\nas a GUID (Globally Unique IDentifier), using the format defined in\n`4122`{.interpreted-text role=\"rfc\"}.\n\nExample: `UUID '12151fd2-7586-11e9-8f9e-2a86e4085a59'`\n\n## HyperLogLog\n\nCalculating the approximate distinct count can be done much more cheaply\nthan an exact count using the\n[HyperLogLog](https://en.wikipedia.org/wiki/HyperLogLog) data sketch.\nSee `/functions/hyperloglog`{.interpreted-text role=\"doc\"}.\n\n### `HyperLogLog` \n\nA HyperLogLog sketch allows efficient computation of\n`approx_distinct`{.interpreted-text role=\"func\"}. It starts as a sparse\nrepresentation, switching to a dense representation when it becomes more\nefficient.\n\n### `P4HyperLogLog` \n\nA P4HyperLogLog sketch is similar to\n`hyperloglog_type`{.interpreted-text role=\"ref\"}, but it starts (and\nremains) in the dense representation.\n\n## SetDigest\n\n### `SetDigest` \n\nA SetDigest (setdigest) is a data sketch structure used in calculating\n[Jaccard similarity\ncoefficient](https://en.wikipedia.org/wiki/Jaccard_index) between two\nsets.\n\nSetDigest encapsulates the following components:\n\n-   [HyperLogLog](https://en.wikipedia.org/wiki/HyperLogLog)\n-   [MinHash with a single hash\n    function](http://en.wikipedia.org/wiki/MinHash#Variant_with_a_single_hash_function)\n\nThe HyperLogLog structure is used for the approximation of the distinct\nelements in the original set.\n\nThe MinHash structure is used to store a low memory footprint signature\nof the original set. The similarity of any two sets is estimated by\ncomparing their signatures.\n\nSetDigests are additive, meaning they can be merged together.\n\n## Quantile digest\n\n### `QDigest` \n\nA quantile digest (qdigest) is a summary structure which captures the\napproximate distribution of data for a given input set, and can be\nqueried to retrieve approximate quantile values from the distribution.\nThe level of accuracy for a qdigest is", "doc_id": "e8e90b63-1811-400f-9446-1ffe3aa554d5", "embedding": null, "doc_hash": "288950d1f7754f23cecf49ba449c2e3f0257e3db0b3614cba845a7be143b78e8", "extra_info": {"file_path": "docs/query/DuneSQL-reference/datatypes.md", "file_name": "datatypes.md"}, "node_info": {"start": 8559, "end": 11513, "_node_type": "1"}, "relationships": {"1": "9a8056fb6210281fa3ccc658a5a7899d0d2973e7", "2": "c051edd3-9f84-44e5-9ceb-351062c7f0f5", "3": "ec907295-3f60-490f-bb72-afd907111571"}}, "__type__": "1"}, "ec907295-3f60-490f-bb72-afd907111571": {"__data__": {"text": "quantile values from the distribution.\nThe level of accuracy for a qdigest is tunable, allowing for more\nprecise results at the expense of space.\n\nA qdigest can be used to give approximate answer to queries asking for\nwhat value belongs at a certain quantile. A useful property of qdigests\nis that they are additive, meaning they can be merged together without\nlosing precision.\n\nA qdigest may be helpful whenever the partial results of\n`approx_percentile` can be reused. For example, one may be interested in\na daily reading of the 99th percentile values that are read over the\ncourse of a week. Instead of calculating the past week of data with\n`approx_percentile`, `qdigest`s could be stored daily, and quickly\nmerged to retrieve the 99th percentile value.\n\n## T-Digest\n\n### `TDigest` \n\nA T-digest (tdigest) is a summary structure which, similarly to qdigest,\ncaptures the approximate distribution of data for a given input set. It\ncan be queried to retrieve approximate quantile values from the\ndistribution.\n\nTDigest has the following advantages compared to QDigest:\n\n-   higher performance\n-   lower memory usage\n-   higher accuracy at high and low percentiles\n\nT-digests are additive, meaning they can be merged together.\n", "doc_id": "ec907295-3f60-490f-bb72-afd907111571", "embedding": null, "doc_hash": "71855566c0994755fbaba8b73c9a3f4d15f8d41d93ee3de0207287dafe84f2ea", "extra_info": {"file_path": "docs/query/DuneSQL-reference/datatypes.md", "file_name": "datatypes.md"}, "node_info": {"start": 11473, "end": 12702, "_node_type": "1"}, "relationships": {"1": "9a8056fb6210281fa3ccc658a5a7899d0d2973e7", "2": "e8e90b63-1811-400f-9446-1ffe3aa554d5"}}, "__type__": "1"}, "979d2728-fb1e-4741-8eae-4bb17fd22aa3": {"__data__": {"text": "---\ntitle: DuneSQL Overview\ndescription: Dune utilizes a fork of TrinoSQL to power DuneSQL. DuneSQL is a custom built query engine that is optimized for blockchain data.\n---\n\n**DuneSQL is a custom-built query engine designed for efficient analysis of blockchain data. Based on the open-source TrinoSQL engine, it incorporates additional optimizations to handle blockchain-specific requirements.**\n\n## [Functions and Operators](Functions-and-operators/index.md)\n\nDuneSQL provides a wide array of functions and operators that enable you to perform various operations on your data. These include arithmetic, string manipulation, date and time calculations, and much more.\n\n## [Data Types](datatypes.md)\n\nDuneSQL supports a variety of data types, including numeric, string, date, time, and boolean. Additionally, DuneSQL introduces custom data types and functions to better handle unique aspects of blockchain data, such as varbinary data types for addresses and hashes, as well as int256 and uint256 data types for large numeric values.\n\n## [SQL Statement Syntax](SQL-statement-syntax/index.md) \n\nDuneSQL follows the standard SQL syntax, which consists of a series of clauses that define how data should be retrieved, manipulated, or stored. Commonly used clauses include SELECT, FROM, WHERE, GROUP BY, ORDER BY, and LIMIT. Each clause serves a specific purpose and can be combined to create complex queries that meet your data analysis needs.\n\nSince DuneSQL is administrated by Dune, all `create`, `update`, `delete`, `drop` and other administrative statements are disabled. This is to ensure that the data in the database is not modified in any way.  \nHowever, you can [query queries](../query-a-query.md) in DuneSQL to replace the ability to create views and tables. We are also working on features that will allow you to schedule queries to run on a regular basis to replace the ability to create scheduled tasks. \n", "doc_id": "979d2728-fb1e-4741-8eae-4bb17fd22aa3", "embedding": null, "doc_hash": "cca27238189a5a0b07e529d09d1e23f7211423a8fb2134a668c8af27844c4444", "extra_info": {"file_path": "docs/query/DuneSQL-reference/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 1916, "_node_type": "1"}, "relationships": {"1": "773276682d7d34e3c64b738e27fb2877edd71df7"}}, "__type__": "1"}, "9455f95b-9925-44ef-a016-acf1d825a598": {"__data__": {"text": "# Reserved keywords\n\nThe following table lists all of the keywords that are reserved in\nDuneSQL, along with their status in the SQL standard. These reserved\nkeywords must be quoted (using double quotes) in order to be used as an\nidentifier.\n\nFor example to query the transactions table for all transactions from a specific address you would use the following query with `from` in double quotes:   \n```sql\nSelect * from ethereum.transactions \nwhere \"from\" = 0xc8ebccc5f5689fa8659d83713341e5ad19349448\n```\n\n## Reserved keywords\n\n| Keyword       | SQL:2016  |\n| --------------- | --------- |\n| `ALTER`         | reserved  |\n| `AND`           | reserved  |\n| `AS`            | reserved  |\n| `BETWEEN`       | reserved  |\n| `BY`            | reserved  |\n| `CASE`          | reserved  |\n| `CAST`          | reserved  |\n| `CONSTRAINT`    | reserved  |\n| `CREATE`        | reserved  |\n| `CROSS`         | reserved  |\n| `CUBE`          | reserved  |\n| `CURRENT_CATALOG` | reserved |\n| `CURRENT_DATE`  | reserved  |\n| `CURRENT_PATH`  | reserved  |\n| `CURRENT_ROLE`  | reserved  |\n| `CURRENT_SCHEMA` | reserved |\n| `CURRENT_TIME`  | reserved  |\n| `CURRENT_TIMESTAMP` | reserved |\n| `CURRENT_USER`  | reserved  |\n| `DEALLOCATE`    | reserved  |\n| `DELETE`        | reserved  |\n| `DESCRIBE`      | reserved  |\n| `DISTINCT`      | reserved  |\n| `DROP`          | reserved  |\n| `ELSE`          | reserved  |\n| `END`           | reserved  |\n| `ESCAPE`        | reserved  |\n| `EXCEPT`        | reserved  |\n| `EXECUTE`       | reserved  |\n| `EXISTS`        | reserved  |\n| `EXTRACT`       | reserved  |\n| `FALSE`         | reserved  |\n| `FOR`           | reserved  |\n| `FROM`          | reserved  |\n| `FULL`          | reserved  |\n| `GROUP`         | reserved  |\n| `GROUPING`      | reserved  |\n| `HAVING`        | reserved  |\n| `IN`            | reserved  |\n| `INNER`         | reserved  |\n| `INSERT`        | reserved  |\n| `INTERSECT`     | reserved  |\n| `INTO`          | reserved  |\n| `IS`            | reserved  |\n| `JOIN`         ", "doc_id": "9455f95b-9925-44ef-a016-acf1d825a598", "embedding": null, "doc_hash": "f2f43e2b7aa5a90d73d7df393e08901f21e546ee3a16e6a89fd5bce3dd767402", "extra_info": {"file_path": "docs/query/DuneSQL-reference/reserved-keywords.md", "file_name": "reserved-keywords.md"}, "node_info": {"start": 0, "end": 2018, "_node_type": "1"}, "relationships": {"1": "a8cbb69a63ddd8d563d3c5ba325d3da01e26a906", "3": "ea73ad8b-612a-4cf5-8264-e8a66aa90545"}}, "__type__": "1"}, "ea73ad8b-612a-4cf5-8264-e8a66aa90545": {"__data__": {"text": "| reserved  |\n| `JOIN`          | reserved  |\n| `JSON_ARRAY`    | reserved  |\n| `JSON_EXISTS`   | reserved  |\n| `JSON_OBJECT`   | reserved  |\n| `JSON_QUERY`    | reserved  |\n| `JSON_VALUE`    | reserved  |\n| `LEFT`          | reserved  |\n| `LIKE`          | reserved  |\n| `LISTAGG`       | reserved  |\n| `LOCALTIME`     | reserved  |\n| `LOCALTIMESTAMP` | reserved |\n| `NATURAL`       | reserved  |\n| `NORMALIZE`     | reserved  |\n| `NOT`           | reserved  |\n| `NULL`          | reserved  |\n| `ON`            | reserved  |\n| `OR`            | reserved  |\n| `ORDER`         | reserved  |\n| `OUTER`         | reserved  |\n| `PREPARE`       | reserved  |\n| `RECURSIVE`     | reserved  |\n| `RIGHT`         | reserved  |\n| `ROLLUP`        | reserved  |\n| `SELECT`        | reserved  |\n| `SKIP`          | reserved  |\n| `TABLE`         | reserved  |\n| `THEN`          | reserved  |\n| `TRIM`          | reserved  |\n| `TRUE`          | reserved  |\n| `UESCAPE`       | reserved  |\n| `UNION`         | reserved  |\n| `UNNEST`        | reserved  |\n| `USING`         | reserved  |\n| `VALUES`        | reserved  |\n| `WHEN`          | reserved  |\n| `WHERE`         | reserved  |\n| `WITH`          | reserved  |                                \n", "doc_id": "ea73ad8b-612a-4cf5-8264-e8a66aa90545", "embedding": null, "doc_hash": "1fe926a61cd940659004eaa13ec4de6d4b35c79500c3397974fd1ddaf4d925cd", "extra_info": {"file_path": "docs/query/DuneSQL-reference/reserved-keywords.md", "file_name": "reserved-keywords.md"}, "node_info": {"start": 1987, "end": 3217, "_node_type": "1"}, "relationships": {"1": "a8cbb69a63ddd8d563d3c5ba325d3da01e26a906", "2": "9455f95b-9925-44ef-a016-acf1d825a598"}}, "__type__": "1"}, "58b280b5-1856-43ee-ab38-d4aadfc3eca3": {"__data__": {"text": "---\ntitle: PostgreSQL\ndescription: Dune is sunsetting PostgreSQL. Support for PostgreSQL will be removed on 15/07/2023. Please migrate your queries to DuneSQL.\n---\n\n!!! warning \"Sunsetting PostgreSQL\"\n    Dune is sunsetting PostgreSQL. Support for PostgreSQL will be removed on **15/07/2023**. Please migrate your queries to DuneSQL.\n\n## PostgreSQL\n\nOur PostgreSQL database and query engine are the oldest parts of Dune Analytics. PostgreSQL does not scale well and therefore we are deprecating it.  \nPostgres is an entirely different database than our V2 database and therefore the data you can query is different.  \n\nPostgreSQL is still in production and will be supported until **15/07/2023**. After that date, PostgreSQL will be removed from production and all queries need to be migrated to DuneSQL.\n\nYou can read more about PostgreSQL in the [PostgreSQL documentation](https://www.postgresql.org/docs/).\n\n### Migrating from PostgreSQL\n\nMigrating queries from PostgreSQL to DuneSQL is a bit more difficult. The two query engines query different data and therefore the queries are very different. Additionally the way you would write queries in the index-heavy PostgreSQL is very different from the way you would write queries in the columnar DuneSQL. Learn more about this in the [data storage section](../storage.md).\n\n| **Description**                                                                       | **V1 - PostgreSQL**                                                                                          | **V2 - Dune SQL**                                                                                                                                                                                                                                                                                           |\n|---------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **`bytea2numeric`, or casting hex/bytea to a number**                                 | `bytea2numeric` (bytea)                                                                                      | `bytearray_to_integer` (hex)  ", "doc_id": "58b280b5-1856-43ee-ab38-d4aadfc3eca3", "embedding": null, "doc_hash": "50ad0012d330012744179c5e4ca77954212d1ac9e35795d4d8b6baa9a3f1f9fc", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 0, "end": 2562, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "3": "90612da4-2571-4908-b270-54ca9eeeb078"}}, "__type__": "1"}, "90612da4-2571-4908-b270-54ca9eeeb078": {"__data__": {"text": "    | `bytearray_to_integer` (hex)   `bytearray_to_bigint` (hex)   `bytearray_to_decimal` (hex)   `bytearray_to_uint256` (hex)   `bytearray_to_int256` (hex)   More details on [Byte Array to Numeric Functions](#byte-array-to-numeric-functions)                                                                |\n| **Doing math or numeric operations on a column, like value in ethereum.transactions** | sum(value)                                                                                                   | sum(cast(value as double)) *soon this won't be needed as UINT and INT columns are added automatically.*                                                                                                                                                                                                     |\n| **0 vs 1 array based indexing**                                                       | 1 indexed                                                                                                    | 1 indexed                                                                                                                                                                                                                                                                                                   |\n|", "doc_id": "90612da4-2571-4908-b270-54ca9eeeb078", "embedding": null, "doc_hash": "71ac69ac0c016b4aa49f48f95da46886e6cdc86d6e918a27c639f4fb3b95d9c1", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 2535, "end": 3850, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "58b280b5-1856-43ee-ab38-d4aadfc3eca3", "3": "4d15162c-7f3c-479d-9ba9-bae5f5b62251"}}, "__type__": "1"}, "4d15162c-7f3c-479d-9ba9-bae5f5b62251": {"__data__": {"text": "                 |\n| **Implicit type conversions between character and numeric types**                     | Available                                                                                                    | [Not available](https://trino.io/docs/current/functions/conversion.html)                                                                                                                                                                                                                                    |\n| **Addresses**                                                                         | `\\x2A7D...`(bytea)  Works in Postgres                                                                        | `0x2a7d...` (Byte array)    No escape quotes should be used, and the literal does __not__ need to be lowercased.                                                                                                                                                                                            |\n| **Selecting keyword columns is different**                                            | \"from\"                                                                                                       | \"from\"                           ", "doc_id": "4d15162c-7f3c-479d-9ba9-bae5f5b62251", "embedding": null, "doc_hash": "85a8d93362669749b896008e36e262894a89a6af1a50373e1379d22fac2ea99c", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 3876, "end": 5135, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "90612da4-2571-4908-b270-54ca9eeeb078", "3": "8bb3cc4d-d0a6-429a-a91f-79c504107831"}}, "__type__": "1"}, "8bb3cc4d-d0a6-429a-a91f-79c504107831": {"__data__": {"text": "                                                                                                                                                                                                                                                                                              |\n| **Alias naming is different**                                                         | as \"daily active users\"                                                                                      | as \"daily active users\"                                                                                                                                                                                                                                                                                     |\n| **Exponentiation notation**                                                           | `x/10^y` or `x * 1e123`                                                                                      | `x*power(10,y)` or `x * 1e123`                                                                                ", "doc_id": "8bb3cc4d-d0a6-429a-a91f-79c504107831", "embedding": null, "doc_hash": "37a1e822b02b996ce37ba1d42c1bb0707fe4dd2bd6cc13894022e466ca11a602", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 5139, "end": 6241, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "4d15162c-7f3c-479d-9ba9-bae5f5b62251", "3": "053dbaea-71f6-4756-b7c1-de736a5b1eb6"}}, "__type__": "1"}, "053dbaea-71f6-4756-b7c1-de736a5b1eb6": {"__data__": {"text": "                                                                                                                                                                                                                 |\n| **Interval argument has different syntax**                                            | `Interval '1day'`                                                                                            | `Interval '1' day`                                                                                                                                                                                                                                                                                          |\n| **Generate_series () is now sequence ()**                                             | `generate_series('2022-05-15', CURRENT_DATE, '1 day')`                                                       | [`unnest(sequence(date('2022-01-01'), date('2022-02-01'), interval '7' day))`](https://dune.com/queries/1764158?d=11)   Has a 10000 values limit, and must go in the FROM statement not the SELECT.                                                                                                         |\n| **Handling decimals for prices.usd**          ", "doc_id": "053dbaea-71f6-4756-b7c1-de736a5b1eb6", "embedding": null, "doc_hash": "bc69fac02950d8abcf0569d274cdc0c8b1f9af34a7dc2b638e91d10aef28f295", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 6242, "end": 7507, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "8bb3cc4d-d0a6-429a-a91f-79c504107831", "3": "a488ce4f-ff80-43a7-ac05-579cfc86232d"}}, "__type__": "1"}, "a488ce4f-ff80-43a7-ac05-579cfc86232d": {"__data__": {"text": "decimals for prices.usd**                                                  | Don\u2019t use `prices.usd decimals`                                                                              | Replaced by `tokens_[blockchain].erc20.decimals`                                                                                                                                                                                                                                                            |\n| **Define NULL array**                                                                 | ` NULL::integer[]`                                                                                           | `CAST(NULL AS ARRAY<int>))`                                                                                                                                                                                                                                                                                 |\n| **encoding strings to hex**                                                           | `encode(string, 'hex')`                                     ", "doc_id": "a488ce4f-ff80-43a7-ac05-579cfc86232d", "embedding": null, "doc_hash": "314fb7bee78aef22bcc9eaca1d0426c6a7d22b2181fa18e95c3a10095f6a69c9", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 7485, "end": 8628, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "053dbaea-71f6-4756-b7c1-de736a5b1eb6", "3": "4b20769e-929c-4ebc-8c35-66b017022e94"}}, "__type__": "1"}, "4b20769e-929c-4ebc-8c35-66b017022e94": {"__data__": {"text": "                                                                    | `hex(string)`  *available soon                                                                                                                                                                                                                                                                              |\n| **Get json object differences**                                                       | `(takerOutputUpdate->'deltaWei'->'value') decode(substring((addressSet->'baseAsset')::TEXT, 4,40), 'hex')`   | `json_query(json_query(takerOutputUpdate, 'lax $.deltaWei' omit quotes), 'lax $.value')`                                                                                                                                                                                                                    |\n| **Group by an alias**                                                                 | `SELECT date_trunc('hour',evt_block_time) as col1, COUNT(*) FROM erc721_ethereum evt_Transfer GROUP BY col1` | `GROUP BY date_trunc('hour',evt_block_time)`Or: `GROUP BY 1, 2`                                                                                                                                                    ", "doc_id": "4b20769e-929c-4ebc-8c35-66b017022e94", "embedding": null, "doc_hash": "f9f2fd7b5156f8e3863f7f591b84aefe48a95be7b0e220c7e8b5101e64861d68", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 8652, "end": 9939, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "a488ce4f-ff80-43a7-ac05-579cfc86232d", "3": "22d842d4-920b-468b-af0e-fe9192305a01"}}, "__type__": "1"}, "22d842d4-920b-468b-af0e-fe9192305a01": {"__data__": {"text": "                                                                                                            |\n| **Explicit date/time casting**                                                        | `'2021-08-08 17:00'::timestamp`                                                                              | `cast('2021-08-08 17:00' as timestamp)`  Or, `timestamp '2021-08-08 17:00'`  There are [many helper functions for casting to date/time types](https://trino.io/docs/current/functions/datetime.html?highlight=date), such as `date(\u20182022-01-01\u2019)`                                                           |\n| **Checking if an item exists in an array**                                            | `value = ANY (array)`                                                                                        | [`contains(array, value)` or `contains_sequence(array, array[values])`](https://trino.io/docs/current/functions/array.html#contains)                                                                                                                                                                        |\n| **Explode**                                                                           | `SELECT unnest(array) FROM table`                                                                            | `SELECT vals.val FROM table1, unnest(arrayFromTable1) as vals(val)`  you have to use `unnest` with a", "doc_id": "22d842d4-920b-468b-af0e-fe9192305a01", "embedding": null, "doc_hash": "97d405e5c4481e89c5b038a12fec227647d255abbde384a3a88f168ab210fe54", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 9940, "end": 11357, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "4b20769e-929c-4ebc-8c35-66b017022e94", "3": "04f89cb8-5a4c-4142-bcbf-017ce28aaa26"}}, "__type__": "1"}, "04f89cb8-5a4c-4142-bcbf-017ce28aaa26": {"__data__": {"text": "as vals(val)`  you have to use `unnest` with a `cross join`, as described in this [blog post](https://theleftjoin.com/how-to-explode-arrays-with-presto/).                                                                                            |\n| **Median**                                                                            | `PERCENTILE_CONT(0.5) WITHIN GROUP(ORDER BY x)`                                                              | `approx_percentile(x, 0.5)`                                                                                                                                                                                                                                                                                 |\n| **Using \u201cis True/False\u201d**                                                             | `X is true`                                                                                                  | `X = true`                                                                                                                                                                                                                     ", "doc_id": "04f89cb8-5a4c-4142-bcbf-017ce28aaa26", "embedding": null, "doc_hash": "e69ae4716f0d07fc3c3ba1c28e108153059848b86556f8c65b3240044400ceee", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 11321, "end": 12496, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "22d842d4-920b-468b-af0e-fe9192305a01", "3": "ba6105d3-0e3b-4a3d-bd57-58406b2bd4cc"}}, "__type__": "1"}, "ba6105d3-0e3b-4a3d-bd57-58406b2bd4cc": {"__data__": {"text": "                                                                                                |\n| **String Data Type**                                                                  | `varchar`                                                                                                    | `varchar`                                                                                                                                                                                                                                                                                                   |\n| **Casting as Strings**                                                                | `cast([xxx] as string)`                                                                                      | `cast([xxx] as varchar)`                                                                                                                                                                                                                                                    ", "doc_id": "ba6105d3-0e3b-4a3d-bd57-58406b2bd4cc", "embedding": null, "doc_hash": "f5c08dc89240f38f94bb50f39af6ab8d7fb52435b32a6752a7effcd5d0880df7", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 12534, "end": 13604, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "04f89cb8-5a4c-4142-bcbf-017ce28aaa26", "3": "a031b799-fc06-4f77-b7c1-2d4e80c44de8"}}, "__type__": "1"}, "a031b799-fc06-4f77-b7c1-2d4e80c44de8": {"__data__": {"text": "                                                   |\n| **`left()` is no longer a method available for returning substrings**                 | `left([string],[length])`                                                                                    | `substr([string], [start], [length])`    [Returns varchar; Positions start with 1, so use `1` for length if you want to replicate left() functionality](https://trino.io/docs/current/functions/string.html?highlight=substr#substring) `left(somestring, somenumber) -> substr(somestring, 0, somenumber)` |\n| **Aggregate Functions**                                                               | `array_agg(col)`, `array_agg(distinct(col))`                                                                 | `array_agg(col)`, `array_agg(distinct(col))`                                                                                                                                                                                                                                                                |\n| **user generated views**                                                              | create view dune_user_generated.table                                                                        | each query is a view, like [query_1747157](https://dune.com/queries/1747157)                                                                                                      ", "doc_id": "a031b799-fc06-4f77-b7c1-2d4e80c44de8", "embedding": null, "doc_hash": "722ebd88ee4a440e98b2fb2547a5d9bf6c393e522d7c9240bab2029ec4c6b422", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 13605, "end": 15043, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "ba6105d3-0e3b-4a3d-bd57-58406b2bd4cc", "3": "f27b4114-9cce-4bd2-8c10-894dde93b2d7"}}, "__type__": "1"}, "f27b4114-9cce-4bd2-8c10-894dde93b2d7": {"__data__": {"text": "                                                                                                                                             |\n| **event logs topic indexing**                                                         | topic 1,2,3,4                                                                                                | topic 0,1,2,3                                                                                                                                                                                                                                                                                               |\n", "doc_id": "f27b4114-9cce-4bd2-8c10-894dde93b2d7", "embedding": null, "doc_hash": "f7b74c6eeb2bea8ffd0b72af62464969b89bd4b314d4d3533274fec2674e0ab4", "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}, "node_info": {"start": 15024, "end": 15670, "_node_type": "1"}, "relationships": {"1": "ee3d8f95624e46759068e987fde30203bcfd1802", "2": "a031b799-fc06-4f77-b7c1-2d4e80c44de8"}}, "__type__": "1"}, "159ed8b6-7c68-434b-8849-97e6f859a59d": {"__data__": {"text": "---\ntitle: SparkSQL\ndescription: Dune is sunsetting SparkSQL. Support for SparkSQL will be removed on 2023-07-31. Please migrate your queries to DuneSQL.\n---\n\n!!! warning \"Warning\"\n\n    Dune is sunsetting SparkSQL. Support for SparkSQL will be removed on **15/07/2023**. Please migrate your queries to DuneSQL.\n\n## SparkSQL\n\nSparkSQL is a query engine that is based on Apache Spark.  \nThis Query engine already runs on our V2 database, so the data you can query is the same as with DuneSQL.  \nUnfortunately SparkSQL is not a good fit for our use case and therefore we are deprecating it.\n\nSparkSQL is still in production and will be supported until **15/07/2023**. After that date, SparkSQL will be removed from production and all queries need to be migrated to DuneSQL.\n\nYou can read more about SparkSQL in the [SparkSQL documentation](https://spark.apache.org/docs/latest/sql-ref.html).\n\n### Migrating from SparkSQL\n\nMigrating queries from SparkSQL to DuneSQL is somewhat easy. The two query engines query the same data and therefore the queries are very similar.\n\n| **Description**                                                                       | **V2 - Spark SQL**                                                                        | **V2 - Dune SQL**                                                                                                                                                                                                                                                                                           |\n|---------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **`bytea2numeric`, or casting hex/bytea to a number**                                 | `bytea2numeric_v3` (string)                                                               | `bytearray_to_integer` (hex)   `bytearray_to_bigint` (hex)   `bytearray_to_decimal` (hex)   `bytearray_to_uint256` (hex)   `bytearray_to_int256` (hex)   More details on [Byte", "doc_id": "159ed8b6-7c68-434b-8849-97e6f859a59d", "embedding": null, "doc_hash": "fb6284b9999f9b17f795833edfc395164fe66abf0b86c4cd5912d0470906ba01", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 0, "end": 2391, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "3": "18b1776e-3547-46a3-b00a-590ceed5981e"}}, "__type__": "1"}, "18b1776e-3547-46a3-b00a-590ceed5981e": {"__data__": {"text": "(hex)   More details on [Byte Array to Numeric Functions](#byte-array-to-numeric-functions)                                                                |\n| **Doing math or numeric operations on a column, like value in ethereum.transactions** | sum(value)                                                                                | sum(cast(value as double)) *soon this won't be needed as UINT and INT columns are added automatically.*                                                                                                                                                                                                     |\n| **0 vs 1 array based indexing**                                                       | 0 indexed                                                                                 | 1 indexed                                                                                                                                                                                                                                                                                                   |\n| **Implicit type conversions between character and numeric types**                     | Available                                                                                 | [Not", "doc_id": "18b1776e-3547-46a3-b00a-590ceed5981e", "embedding": null, "doc_hash": "6e3c407f15b78172fd6f1c7399bd938b9203b12cd4c9a02681d0b4678b1a0c61", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 2369, "end": 3680, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "159ed8b6-7c68-434b-8849-97e6f859a59d", "3": "476c7178-5d7e-4f18-bcf6-f04cc6fbe218"}}, "__type__": "1"}, "476c7178-5d7e-4f18-bcf6-f04cc6fbe218": {"__data__": {"text": "                 | [Not available](https://trino.io/docs/current/functions/conversion.html)                                                                                                                                                                                                                                    |\n| **Addresses**                                                                         | `0x2a7d...` (string)  Has to be lowercase in Spark.  Can be done via `lower('0x2A7D...')` | `0x2a7d...` (Byte array)    No escape quotes should be used, and the literal does __not__ need to be lowercased.                                                                                                                                                                                            |\n| **Selecting keyword columns is different**                                            | \\`from\\`                                                                                  | \"from\"                                                                                                                                                                                                                                        ", "doc_id": "476c7178-5d7e-4f18-bcf6-f04cc6fbe218", "embedding": null, "doc_hash": "dfe3504023b25dbabea214e6bb02abc52f2d4f50cff9107b465b9b985a3beae3", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 3699, "end": 4924, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "18b1776e-3547-46a3-b00a-590ceed5981e", "3": "c8508c12-7bc8-4e13-b688-bb068e58f950"}}, "__type__": "1"}, "c8508c12-7bc8-4e13-b688-bb068e58f950": {"__data__": {"text": "                                                                                 |\n| **Alias naming is different**                                                         | as \\`daily active user\\`                                                                  | as \"daily active users\"                                                                                                                                                                                                                                                                                     |\n| **Exponentiation notation**                                                           | `x*power(10,y)` or `x*1e123`                                                              | `x*power(10,y)` or `x * 1e123`                                                                                                                                                                                                                                                                              |\n| **Interval argument has different syntax**                                          ", "doc_id": "c8508c12-7bc8-4e13-b688-bb068e58f950", "embedding": null, "doc_hash": "ecc105f844e30efb5aa86fed350e7fbc057a86f28c3b04f60ae83c2ae5c5f886", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 4930, "end": 6067, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "476c7178-5d7e-4f18-bcf6-f04cc6fbe218", "3": "bfc01fdc-b24d-42a4-9744-96ea79c1e030"}}, "__type__": "1"}, "bfc01fdc-b24d-42a4-9744-96ea79c1e030": {"__data__": {"text": "                     | `Interval '1 day'`                                                                        | `Interval '1' day`                                                                                                                                                                                                                                                                                          |\n| **Generate_series () is now sequence ()**                                             | `explode(sequence(to_date('2022-01-01'), to_date('2022-02-01'), interval 1 day))`         | [`unnest(sequence(date('2022-01-01'), date('2022-02-01'), interval '7' day))`](https://dune.com/queries/1764158?d=11)   Has a 10000 values limit, and must go in the FROM statement not the SELECT.                                                                                                         |\n| **Handling decimals for prices.usd**                                                  | Replaced by `prices.tokens decimals`                                                      | Replaced by `tokens_[blockchain].erc20.decimals`                                                                                                                                                                           ", "doc_id": "bfc01fdc-b24d-42a4-9744-96ea79c1e030", "embedding": null, "doc_hash": "4f270ffdb14234a6b93727c49dba64fe0bc66eb1ef4d5fa29fb369c29df259ef", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 6068, "end": 7370, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "c8508c12-7bc8-4e13-b688-bb068e58f950", "3": "057ea006-052c-43c7-b559-3da5071c11f2"}}, "__type__": "1"}, "057ea006-052c-43c7-b559-3da5071c11f2": {"__data__": {"text": "                                                                                                    |\n| **Define NULL array**                                                                 | `CAST(NULL AS ARRAY<int>))`                                                               | `CAST(NULL AS ARRAY<int>))`                                                                                                                                                                                                                                                                                 |\n| **encoding strings to hex**                                                           | `hex(string)`                                                                             | `hex(string)`  *available soon                                                                                                                                                                                                                                                                              |\n| **Get json object differences**                   ", "doc_id": "057ea006-052c-43c7-b559-3da5071c11f2", "embedding": null, "doc_hash": "3d0c85afc920dadb5c8b11c27aa85571d4d65aa4e2a3ab17bab8f5458153c284", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 7371, "end": 8493, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "bfc01fdc-b24d-42a4-9744-96ea79c1e030", "3": "c8f8bc7d-eaa0-4e47-9e05-7b3fc986563b"}}, "__type__": "1"}, "c8f8bc7d-eaa0-4e47-9e05-7b3fc986563b": {"__data__": {"text": "                                                      | `get_json_object(get_json_object(takerOutputUpdate,'\\(.deltaWei'),'\\).value')'0x'`        | `json_query(json_query(takerOutputUpdate, 'lax $.deltaWei' omit quotes), 'lax $.value')`                                                                                                                                                                                                                    |\n| **Group by an alias**                                                                 | Same as PostgreSQL                                                                        | `GROUP BY date_trunc('hour',evt_block_time)`Or: `GROUP BY 1, 2`                                                                                                                                                                                                                                             |\n| **Explicit date/time casting**                                                        | `cast('2021-08-08 17:00' as timestamp)`                                                   | `cast('2021-08-08 17:00' as timestamp)`  Or, `timestamp '2021-08-08 17:00'`  There are [many helper functions for casting to date/time types](https://trino.io/docs/current/functions/datetime.html?highlight=date), such as `date(\u20182022-01-01\u2019)`       ", "doc_id": "c8f8bc7d-eaa0-4e47-9e05-7b3fc986563b", "embedding": null, "doc_hash": "e85cb0c56df4454af7f7a4164aaf7ec802bab9b1d31dde93471cbd96eba70ec3", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 8494, "end": 9858, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "057ea006-052c-43c7-b559-3da5071c11f2", "3": "881da39c-bb87-43fc-b28c-a113775284bf"}}, "__type__": "1"}, "881da39c-bb87-43fc-b28c-a113775284bf": {"__data__": {"text": "                                                          |\n| **Checking if an item exists in an array**                                            | `array_contains(array, value)`                                                            | [`contains(array, value)` or `contains_sequence(array, array[values])`](https://trino.io/docs/current/functions/array.html#contains)                                                                                                                                                                        |\n| **Explode**                                                                           | `SELECT explode(array) FROM table`                                                        | `SELECT vals.val FROM table1, unnest(arrayFromTable1) as vals(val)`  you have to use `unnest` with a `cross join`, as described in this [blog post](https://theleftjoin.com/how-to-explode-arrays-with-presto/).                                                                                            |\n| **Median**                                                                            | `PERCENTILE_CONT(0.5) WITHIN GROUP(ORDER BY x)`                                           | `approx_percentile(x, 0.5)`                                                                                                                      ", "doc_id": "881da39c-bb87-43fc-b28c-a113775284bf", "embedding": null, "doc_hash": "8bbcd8302dc2865c7722eaf64a3669047c5b2618eecd7b075f4cd59b27858f19", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 9859, "end": 11214, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "c8f8bc7d-eaa0-4e47-9e05-7b3fc986563b", "3": "72824150-4557-47be-bf7c-d6079f5e716f"}}, "__type__": "1"}, "72824150-4557-47be-bf7c-d6079f5e716f": {"__data__": {"text": "                                                                                                                                                                              |\n| **Using \u201cis True/False\u201d**                                                             | `X is true`                                                                               | `X = true`                                                                                                                                                                                                                                                                                                  |\n| **String Data Type**                                                                  | `string`                                                                                  | `varchar`                                                                                                                                                                                                          ", "doc_id": "72824150-4557-47be-bf7c-d6079f5e716f", "embedding": null, "doc_hash": "1676e5eca61006f5e8d51e27fc483543a0dc452450e150d34ef2865a545c14b0", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 11215, "end": 12268, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "881da39c-bb87-43fc-b28c-a113775284bf", "3": "acc865b8-cb8f-40f4-bf25-b1f90a58c9f1"}}, "__type__": "1"}, "acc865b8-cb8f-40f4-bf25-b1f90a58c9f1": {"__data__": {"text": "                                                                                                            |\n| **Casting as Strings**                                                                | `cast([xxx] as string)`                                                                   | `cast([xxx] as varchar)`                                                                                                                                                                                                                                                                                    |\n| **`left()` is no longer a method available for returning substrings**                 | `left([string],[length])`                                                                 | `substr([string], [start], [length])`    [Returns varchar; Positions start with 1, so use `1` for length if you want to replicate left() functionality](https://trino.io/docs/current/functions/string.html?highlight=substr#substring) `left(somestring, somenumber) -> substr(somestring, 0, somenumber)` |\n| **Aggregate Functions**                                                               | `array_agg(col)` or `collect_list(col)`, `collect_set(col)` or `array_agg(distinct(col))` | `array_agg(col)`, `array_agg(distinct(col))`                                                                                                            ", "doc_id": "acc865b8-cb8f-40f4-bf25-b1f90a58c9f1", "embedding": null, "doc_hash": "ec35e3ee5c06e7d289705a614770f119549b392df46d0cf037897e1534a5e8c4", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 12269, "end": 13681, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "72824150-4557-47be-bf7c-d6079f5e716f", "3": "e75a0a1f-c403-481e-9109-689fa794b93c"}}, "__type__": "1"}, "e75a0a1f-c403-481e-9109-689fa794b93c": {"__data__": {"text": "                                                                                                                                                                       |\n| **user generated views**                                                              | none                                                                                      | each query is a view, like [query_1747157](https://dune.com/queries/1747157)                                                                                                                                                                                                                                |\n| **event logs topic indexing**                                                         | topic 1,2,3,4                                                                             | topic 0,1,2,3                                                                                                                                                                                                                                                                 ", "doc_id": "e75a0a1f-c403-481e-9109-689fa794b93c", "embedding": null, "doc_hash": "a5a15e9ac5dc352cbaf3202b1665339f3e37496150fd513a62bdd01819d911c5", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 13682, "end": 14787, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "acc865b8-cb8f-40f4-bf25-b1f90a58c9f1", "3": "55f24f37-e59b-40c1-a5f9-d461deb0b0c5"}}, "__type__": "1"}, "55f24f37-e59b-40c1-a5f9-d461deb0b0c5": {"__data__": {"text": "                                                 |\n\n", "doc_id": "55f24f37-e59b-40c1-a5f9-d461deb0b0c5", "embedding": null, "doc_hash": "78bd92e05593a2d1b1647f603709739dc18da2affc4fcea5b680654f1f9f78bf", "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}, "node_info": {"start": 14768, "end": 14820, "_node_type": "1"}, "relationships": {"1": "04168beb41d762f692d99c7628c8e7f66188d41c", "2": "e75a0a1f-c403-481e-9109-689fa794b93c"}}, "__type__": "1"}, "2160814b-742e-455e-bab7-fd0b057c2ad7": {"__data__": {"text": "---\ntitle: Overview\ndescription: This Page describes the old query engines that will soon be depreceated. SparkSQL and PostgresSQL will be replaced by DuneSQL.   \n---\n\n## Dune's Query Engines\n\nDune currently supports three different query engines:  \n\n- DuneSQL  \n- SparkSQL  \n- PostgreSQL  \n\nThe SparkSQL and PostgreSQL query engines are being deprecated and will be replaced by DuneSQL.  \n\nYou can read more about the decisions to sunset the old query engines in the [announcement post](https://dune.com/blog/introducing-dune-sql).\n\n## Sunsetting Schedule\n\nThe following tables shows the schedule for the sunsetting of the old query engines.\n\n### SparkSQL\n\n| Date          | 11/4/2023            | 30/05/2023              | 15/06/2023     | 15/07/2023          |\n|---------------|----------------------|-------------------------|----------------|---------------------|\n|**SparkSQL**   | Sunsetting Kickoff   | Drop from data explorer | Edits disabled | End of Service      |\n\n\n### PostgreSQL\n\n| Date          | 11/4/2023            | 16/05/2023              | 15/06/2023     | 15/07/2023          |\n|---------------|----------------------|-------------------------|----------------|---------------------|\n|**PostgreSQL** | Sunsetting Kickoff   | Drop from data explorer | Edits disabled | End of Service      |\n\n\n\n## What this means for you\n\nYou will unfortunately need to migrate your queries from SparkSQL or PostgreSQL to DuneSQL. If you don't migrate your queries, you queries will cease to update on **15/07/2023** and you will no longer be able to edit them without migrating them to DuneSQL. \n\n### Migrating your queries\n\nIf you are using SparkSQL or PostgreSQL, you will need to migrate your queries to DuneSQL by **15/07/2023**.  \n\nTo migrate your queries from SparkSQL or PostgreSQL to DuneSQL, you can use the [DuneSQL migration tool](migration-tool.md).  \nThis tool will automatically convert your queries to DuneSQL. The Tool is based on GPT4 and still under active development, we will share updates as we make progress.\n\nYou can read about the Syntax differences between the engines in the respective sections of SparkSQL and PostgreSQL.\n\n<div class=\"cards grid\" markdown>\n\n- [:octicons-arrow-right-24: SparkSQL](SparkSQL.md)\n- [:octicons-arrow-right-24: PostgreSQL](PostgreSQL.md)\n\n</div>\n\n\n### What happens to non-migrated queries?\nAfter **15/07/2023**, queries running on either SparkSQL or PostgreSQL will no longer be updated. You will still be able to access the data from your queries, but there won't be any new data added to your query results and they will stop executing. Query code will still be available to you, but you will not be able to edit it.\n\n## FAQ\n\n??? question \"What is DuneSQL?\"\n\n    DuneSQL is a powerful distributed SQL query engine, based on Trino, that is designed to address the limitations of the old query engines and provide a more modern and flexible solution.\n\n??? question \"Why another query engine?\"\n\n    DuneSQL was created to address the limitations of the old query engines, such as performance and scalability issues, as well as to provide a more modern and flexible solution. DuneSQL gives Dune full control over storage, execution, and query planning, which allows us to provide a faster, more", "doc_id": "2160814b-742e-455e-bab7-fd0b057c2ad7", "embedding": null, "doc_hash": "7a19030698b0e7146735e152417a853cf72975076d42292fabaa189cfb629c9c", "extra_info": {"file_path": "docs/query/Old-Query-Engines/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 3252, "_node_type": "1"}, "relationships": {"1": "e9b826d0877608e104fd6ca7c1177f78c2651ccd", "3": "7012149e-cc50-4656-875f-64908ec4b6df"}}, "__type__": "1"}, "7012149e-cc50-4656-875f-64908ec4b6df": {"__data__": {"text": "execution, and query planning, which allows us to provide a faster, more reliable, and more scalable service.\n\n??? question \"What are the main differences between DuneSQL and the old query engines?\"\n\n    Some of the main differences between DuneSQL and the old query engines are:\n\n    - DuneSQL is designed for scalability, whereas the old query engines have struggled with scaling issues in the past.\n    - with DuneSQL, we control the entire stack, from the database to the query engine, which allows us to provide a more stable and reliable service.\n    - DuneSQL has a simplified syntax that makes it easier to write and read queries.\n\n??? question \"Why a fork of Trino?\"\n\n    DuneSQL is a fork of Trino (formerly known as PrestoSQL) that has been customized to meet the specific needs of Dune. Trino is a powerful distributed SQL query engine that is widely used in the industry, and by forking it, Dune was able to leverage its proven technology while also adding its own unique features and improvements.\n\n??? question \"What happens to the existing queries that I have already migrated?\"\n\n    If you have already migrated your queries to DuneSQL, they will continue to work as before and you won't need to take any additional action.\n\n??? question \"Will Postgres and SparkSQL still be around for a while?\"\n\n    PostgreSQL and SparkSQL are being deprecated and will be replaced by DuneSQL. After **15/07/2023**, queries running on either SparkSQL or PostgreSQL will no longer be updated. You will still be able to access the data from your queries, but there won't be any new data added to your query results and they will stop executing. Query code will still be available to you, but you will not be able to edit it.\n\n??? question \"What happens with Spellbook? Can I still contribute?\"\n\n    Spellbook is still a valuable tool for Dune and will continue to be used. You can still contribute to Spellbook by submitting pull requests on the project's GitHub repository. We are working on migrating Spellbook to DuneSQL. The Spellbook code will be migrated to DuneSQL by the Dune Team. The preminary timeline for a first version of Spellbook on DuneSQL is **30/05/2023**.\n \n\n### Timeline\n\n??? question \"When do Spark Queries stop working?\"\n\n    SparkSQL queries will stop being updated on **15/07/2023**.\n\n??? question \"When do Postgres Queries stop working?\"\n\n    PostgreSQL queries will stop being updated on **15/07/2023**.\n\n### Migration\n\n??? question \"How can I migrate existing Queries?\"\n\n    To migrate your queries from SparkSQL or PostgreSQL to DuneSQL, you can use the [DuneSQL migration tool](migration-tool.md). This tool will automatically convert your queries to DuneSQL.\n\n??? question \"Can I get help to migrate existing queries?\"\n\n    Please direct your questions in the #DuneSQL Channel in the [Dune Discord](discord.gg/dunecom).\n\n", "doc_id": "7012149e-cc50-4656-875f-64908ec4b6df", "embedding": null, "doc_hash": "df1ab8f844b8f9878b9b1de7f1c2f00465846587ffdc40f23a9659cfa179743f", "extra_info": {"file_path": "docs/query/Old-Query-Engines/index.md", "file_name": "index.md"}, "node_info": {"start": 3180, "end": 6032, "_node_type": "1"}, "relationships": {"1": "e9b826d0877608e104fd6ca7c1177f78c2651ccd", "2": "2160814b-742e-455e-bab7-fd0b057c2ad7"}}, "__type__": "1"}, "a19b8444-4406-4246-a90e-cc941b3b16c8": {"__data__": {"text": "---\ntitle: Migration tool\ndescription: The Dune Migration tool will help you migrate your queries from SparkSQL and PostgreSQL to DuneSQL.\n---\n\n# Migration tool\n\nMigrating your queries from SparkSQL and PostgreSQL to DuneSQL can be a tedious task. The Dune Migration tool will help you migrate your queries from SparkSQL and PostgreSQL to DuneSQL. \n\nWe are still working on integrating GPT4 into the tool, so it is not yet able to migrate a majority queries. However, it will still save you a lot of time.\n\nThe tool is open source and available in this [github repo](https://github.com/duneanalytics/harmonizer/). Contributions are very welcome!\n\n## How to use the tool\n\nWhenever you are ready to migrate your queries, the tool will be available to you in the Dune Query Editor.  \n\nWhenever you open a query running on SparkSQL or PostgreSQL, you will see a banner at the bottom of the query editor. Simply click on \"Migrate to DuneSQL\" and the tool will automatically convert your query to DuneSQL.\n\n![Migration banner](../images/migration-banner.jpeg)\n\nYou can also always access the tool by opening the settings menu in the query editor and clicking on \"Migrate to DuneSQL\".\n\n![Migration options](../images/migration-option.jpeg)\n\n## Limitations\n\n!!! warning \"Warning\"\n\n    The tool is still under active development and has quite a few limitations.  \n    We are working hard behind the scenes to improve the tool and will share updates as we make progress.  \n\n**Known issues**\n\n- The tool doesn't really know what your query is doing, so it will not be able to migrate all queries.\n- The tool is not able to migrate queries that use UDFs.\n- The tool is not able to accurately migrate queries that have a lot of casts().\n- THe tool doesn't really know about the changes in our abstractions, e.g. if you used single chain dex.trades, you will now need to specify the chain within the query with e.g. ``where blockchain = 'ethereum'``.\n- The tool is not able to migrate queries with ``dune_user_generated`` tables\n\nIn general, the tool is not yet able to migrate queries that are too complex. If you have a complex query, you will need to debug the outputs of the tool and make the necessary changes.\n\nHowever, the tool takes care of a lot of table name changes and other minor changes, so **it will still save you a lot of time**.\n\n\n## Further resources\n\nFor guidance on how to manually migrate your queries or debug the migration tool results, you can read the following articles:\n\n- [SparkSQL](SparkSQL.md)\n- [PostgreSQL](PostgreSQL.md)\n", "doc_id": "a19b8444-4406-4246-a90e-cc941b3b16c8", "embedding": null, "doc_hash": "d1c0f03517e64d520de439d8b13dd0e483e4a6457ffa6e3d5502d9327937368f", "extra_info": {"file_path": "docs/query/Old-Query-Engines/migration-tool.md", "file_name": "migration-tool.md"}, "node_info": {"start": 0, "end": 2541, "_node_type": "1"}, "relationships": {"1": "8c9031686dfe23473f2d31c75d2b325a3fc9a9dd"}}, "__type__": "1"}, "1ad451cb-c5c2-4b4a-a16e-5b1b0e6a3747": {"__data__": {"text": "---\ntitle: DuneSQL migration\ndescription: Documentation regarding the changes to DuneSQL on March 2nd, 2023\n---    \n\n## DuneSQL Alpha Deprecation and Data Type Changes\nDuneSQL officially exited its alpha stage on March 2nd, 2023.\n\n#### What changed?\nDuneSQL now uses the same data types as the underlying EVM blockchain. This means that we now store addresses, transactions hashes and other encoded data(transaction data,trace instructions, log topics & data) as `varbinary` datatype.      \n\nAdditionally, we now support `uint256` and `int256` allowing full wei-level precision calculations.  \n\nFurthermore, we have corrected an ancient mistake in our database -  we now store logs with the correct topic indexing. This means that columns in `<blockchain>.logs` table are now indexed from 0 instead of 1. `Topic1` changed to `Topic0`, `Topic2` changed to `Topic1`, etc.\n\nLast, we have modified the `from_hex` native function so that it will transform varchar to varbinary, base58 decoding it if the string starts with `0x`.\n\n#### What does this mean for me?\n\nFirst of all, switching to the `varbinary` datatype should significantly(\u224830%) improve the speed of your queries!\n\nSecondly, we can get rid of all string casts and conversions, which should make your queries more readable and easier to maintain. All addresses, hashes, and other encoded data are now stored as `varbinary` and can be used directly in your queries. No more `lower()` casting or string encasing. You can simply query for `0x1234...` instead of `'0x1234...'` or `lower('0x1234...')`.  \n\nThirdly, with the introduction of `uint256` and `int256` we can now perform full wei-level precision calculations. This means that you can now query for the exact amount of tokens transferred in a transaction, instead of the rounded value.  \n\nFinally, we have corrected the indexing of logs topics. This means that Dune now matches the indexing of logs topics with the rest of the blockchain ecosystem.\n\n#### What do I need to do?\n\nWe have appended a comment `-- dunesql_alpha_deprecated` to any query which had incompatible functions. This comment allows the query to be ran against the old data types until March 23, 2023. We urge you to remove the comment and convert your query to use compatible functions before the deprecation date.\n\nMore specifically, you will need to:\n\n1. Remove the `-- dunesql_alpha_deprecated` comment from your query\n2. Adjust all occurences of `0x`strings to fit the new data types. For example, `'0x1234...'` should be changed to `0x1234...` and all `lower()` casts should be removed.  \nIf you used any other operator on string columns, you will need to adjust them to the new approaches of working with `varbinary` columns. They are documented in the [DuneSQL documentation](https://dune.com/docs/reference/dune-v2/query-engine/#byte-array-functions-in-dune-sql). \n3. If you used any `varchar -> double`, `varchar -> decimals` or `varchar -> bigint` casts, you can now remove them. This is not strictly necessary, but it will make your query more readable and easier to maintain.\n4. If your query used any columns from logs tables, you will need to adjust the indexing of topics. `Topic1` changed to `Topic0`, `Topic2` changed to `Topic1`, etc. (Note: These should have been automatically converted in your previous DuneSQL queries.)\n5. If you used the [query a query functionality](docs/query/dunesql/#query-a-query), you will need to remove all `--dunesql_alpha_deprecated` comments from all involved queries and", "doc_id": "1ad451cb-c5c2-4b4a-a16e-5b1b0e6a3747", "embedding": null, "doc_hash": "5953a623e2aabfe063d9db07c90464fb8f2d73b5f088b293628248291d1a149e", "extra_info": {"file_path": "docs/query/dunesql-changes.md", "file_name": "dunesql-changes.md"}, "node_info": {"start": 0, "end": 3505, "_node_type": "1"}, "relationships": {"1": "b746db3c8f1522c6026ac33c398ab33f79471031", "3": "714e2964-44a6-40b5-9b72-42c2956c848b"}}, "__type__": "1"}, "714e2964-44a6-40b5-9b72-42c2956c848b": {"__data__": {"text": "remove all `--dunesql_alpha_deprecated` comments from all involved queries and ensure they can all run properly, starting at the lowest level and working your way up. \n\n#### What if I don't do anything?\n\nIf you don't remove the `-- dunesql_alpha_deprecated` comment from your query, it will continue to run against the old data types until March 23, 2023. After that date, your query will no longer run and you will need to update it to use compatible functions.\n\n#### Common Errors and Fixes\n| Error | Example | Solution |\n|---|---|---|\n| Needing to cast varchar to varbinary | `Cannot apply operator: varbinary = varchar(X)` or `Cannot apply operator: varchar = varbinary at` | `from_hex(x)` |\n| Casting to uint256 | `Cannot apply operator: UINT256 = varchar(7) at`  | `cast(xxx as uint256)` |\n| Use bytearray_subtring |`Unexpected parameters (varbinary, integer, integer) for function substring. Expected: substring(varchar(x), bigint), substring(varchar(x), bigint, bigint), substring(char(x), bigint), substring(char(x), bigint, bigint) at`  | `substring(data, 3, 16)` would be `bytearray_substring(data, 1, 8)` |\n| Use `bytearray_substring` and `bytearray_starts_with` instead of LIKE expression | `Left side of LIKE expression must evaluate to a varchar (actual: varbinary) at` | `bytearray_starts_with(varbinary, expression)` |\n \n#### Changes\n\n\n| Description | Previous behavior | New behavior | Breaking query/anti-pattern | Fixed query |\n|---|---|---|---|---|\n| 0x-literals change type to varbinary | 0x-literals had type varchar. I.e., 0xabCD = \u20180xabcd\u2019, and typeof(0xabcd) = \u2018varchar\u2019 | 0x-literals have type varbinary. I.e. 0xabCD = X\u2019abcd\u2019, and typeof(0xabcd) = \u2018varbinary\u2019 | select * from ethereum.logs where tx_hash = \u20180xabcdef\u2019 | select * from ethereum.logs where tx_hash = 0xabcdef |\n| Byte array type columns of base tables and decoded tables now have varbinary type. Example byte array columns are hash, to, from, block_hash, tx_hash, evt_tx_hash, contract_address, call_tx_hash, data, topic0, topic1. This changes the way byte arrays are indexed, as you now index by bytes, instead of by hexadecimal digits. | Byte array type columns had type varchar and were represented as 0x-prefixed hex strings. Byte arrays are indexed by hexadecimal digits instead of by the natural byte position, after accounting for the 0x-prefix. | Byte array type columns have type varbinary. Bytes are indexed with their natural position. | select substring(data, 3, 16) from ethereum.transactions limit 10 -- start at characther 3 to skip 0x-prefix, and read 16 hex characters to get 8 bytes | select bytearray_substring(data, 1, 8) from ethereum.transactions limit 10 -- read 8 bytes |\n| Numeric columns with potentially larger numbers are stored as UINT256 or INT256. | Numeric columns with potentially large  numbers were stored as strings. They would need to be cast to bigint or double before they could be used for arithmetic. | Numeric columns are stored as UINT256 or INT256. They show up as UINT256 or INT256 in the data explorer instead of VARCHAR. | select sum(cast(amount as double)) from aave_ethereum.AToken_call_transfer where call_success = true | select sum(amount) from", "doc_id": "714e2964-44a6-40b5-9b72-42c2956c848b", "embedding": null, "doc_hash": "fc526bf8c2341f1a13bd974ee3147e2110e38e0d6d714c1915869d378b8040c7", "extra_info": {"file_path": "docs/query/dunesql-changes.md", "file_name": "dunesql-changes.md"}, "node_info": {"start": 3436, "end": 6623, "_node_type": "1"}, "relationships": {"1": "b746db3c8f1522c6026ac33c398ab33f79471031", "2": "1ad451cb-c5c2-4b4a-a16e-5b1b0e6a3747", "3": "65f891c2-38db-41c2-adf7-4e9419e28994"}}, "__type__": "1"}, "65f891c2-38db-41c2-adf7-4e9419e28994": {"__data__": {"text": "where call_success = true | select sum(amount) from aave_ethereum.AToken_call_transfer where call_success = true -- no longer required to cast to double |\n| The logs.topicX columns are renamed to be topic0, topic1, topic2, topic3 | The topic columns of logs tables were named topic1, topic2, topic3, topic4. | The topic columns of logs tables are renamed to topic0, topic1, topic2, topic3. | select topic1, topic2, topic3, topic4 from ethereum.logs limit 10 | select topic0, topic1, topic2, topic3 from ethereum.logs limit 10 |\n| Decoded tables no longer automatically coerce breaking type changes on contract updates. It is very rare for contract updates to do breaking type changes. | We would automatically convert values with different data types to the same, either implicitly using Spark, or with a couple of explicit rules. | We no longer automatically coerce breaking type changes of contract updates. These need to be handled manually. |  |  |\n\n", "doc_id": "65f891c2-38db-41c2-adf7-4e9419e28994", "embedding": null, "doc_hash": "6b1c9bfea897e6547274166d5adca75abfb7e999c2daae48dc68b14f2c92d455", "extra_info": {"file_path": "docs/query/dunesql-changes.md", "file_name": "dunesql-changes.md"}, "node_info": {"start": 6642, "end": 7596, "_node_type": "1"}, "relationships": {"1": "b746db3c8f1522c6026ac33c398ab33f79471031", "2": "714e2964-44a6-40b5-9b72-42c2956c848b"}}, "__type__": "1"}, "321b9cb7-45b5-4ec0-a7bd-b4e80638e846": {"__data__": {"text": "---\ntitle: Query\ndescription: Dune utilizes a fork of TrinoSQL to power DuneSQL. DuneSQL is a custom built query engine that is optimized for blockchain data.   \n---\n\n**Querying for blockchain data on Dune is powered by DuneSQL, a custom-built query engine designed for efficient analysis of blockchain data.**\n\n## DuneSQL Features\n\nDuneSQL offers several useful features for working with blockchain data:\n\n1. **[Blockchain varbinary data types](DuneSQL-reference/datatypes.md#varbinary)**: Designed for storing addresses, hashes, and other encoded data.\n2. **[Native support for uint256 and int256 data types](DuneSQL-reference/datatypes.md#UINT256)**: Ideal for handling large numbers commonly found in blockchain data, with built-in functions for ease of use.\n3. **[Columnar storage format](storage.md)** Optimized for fast reads, this format organizes data in columns rather than rows, enabling quick access to single columns for aggregation or filtering.\n4. **[Querying a query](query-a-query.md)**: DuneSQL allows you to query a query, which is great for creating reusable queries, building up complex queries, and reusing queries as views.\n\n## Using DuneSQL\n\nDuneSQL is our query engine for blockchain data. It is a fork of TrinoSQL, which is an open-source, distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes.\n\nWe have created extensive documentation for DuneSQL, which you can find in the [DuneSQL Reference](DuneSQL-reference/index.md) section of our documentation. Here you will be able to find:\n\n<div class=\"cards grid\" markdown>\n\n-   #### Functions and operators\n\n    ---\n\n    A reference guide to DuneSQL functions and operators.\n  \n    [:octicons-arrow-right-24: Functions and operators](DuneSQL-reference/Functions-and-operators/index.md)\n\n-   #### SQL statement reference\n\n    ---\n\n    A reference guide to DuneSQL syntax and statements.\n  \n    [:octicons-arrow-right-24: SQL statement reference](DuneSQL-reference/SQL-statement-syntax/index.md)\n\n-   #### Data types\n\n    ---\n\n    A reference guide to DuneSQL data types.\n  \n    [:octicons-arrow-right-24: Data types](DuneSQL-reference/datatypes.md)\n\n-   #### Reserved keywords\n\n    ---\n\n    A list of reserved keywords in DuneSQL.\n  \n    [:octicons-arrow-right-24: Reserved keywords](DuneSQL-reference/reserved-keywords.md)\n\n</div>\n\n\n## Writing efficient queries\n\nAn efficient query-writing process requires knowledge of how DuneSQL and data storage works.\n\n<div class=\"cards grid\" markdown>\n\n- [:octicons-arrow-right-24: Writing efficient queries](writing-efficient-queries.md)\n\n</div>\n\n## Querying a query\n\nDuneSQL allows you to query a query, which is great for creating reusable queries, building up complex queries, and reusing queries as views.\n\n<div class=\"cards grid\" markdown>\n\n- [:octicons-arrow-right-24: Querying a query](query-a-query.md)\n\n</div>\n\n### Resources and Support\n\nFor assistance with DuneSQL, consider the following resources:\n\n- Google search for TrinoSQL-related queries\n- Talk to your favorite AI assistant about TrinoSQL-related questions\n- [the official Trino docs - Functions and Operators](https://trino.io/docs/current/functions.html)\n\nJoin our #dune-sql Discord channel to connect with our team and the community for help and", "doc_id": "321b9cb7-45b5-4ec0-a7bd-b4e80638e846", "embedding": null, "doc_hash": "314f0b1f0f83482c55dd1dc0873bf0b68d08d7c6aa017098bd8a05d7320b0bf5", "extra_info": {"file_path": "docs/query/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 3315, "_node_type": "1"}, "relationships": {"1": "2d828ecde9b0b3efe4bfac0a52eeb11a75d45169", "3": "8301d2c4-ae88-45ae-80ac-a01872901a9d"}}, "__type__": "1"}, "8301d2c4-ae88-45ae-80ac-a01872901a9d": {"__data__": {"text": "our #dune-sql Discord channel to connect with our team and the community for help and support.\n\n### Feedback and Suggestions\n\nWe appreciate your feedback and suggestions for improvement. Please email us at dunesql-feedback@dune.com with any concerns or ideas for optimization.\n\n", "doc_id": "8301d2c4-ae88-45ae-80ac-a01872901a9d", "embedding": null, "doc_hash": "719e39050fada0c6f9ec1b7f0cdc859620075c53cd99845d40901648c3bdf9d9", "extra_info": {"file_path": "docs/query/index.md", "file_name": "index.md"}, "node_info": {"start": 3230, "end": 3508, "_node_type": "1"}, "relationships": {"1": "2d828ecde9b0b3efe4bfac0a52eeb11a75d45169", "2": "321b9cb7-45b5-4ec0-a7bd-b4e80638e846"}}, "__type__": "1"}, "2f9bb95a-f856-4fd5-9528-ee4e33c3b664": {"__data__": {"text": "---\ntitle: Query a Query\ndescription: The \"Query a Query\" feature in DuneSQL allows you to use an existing query as a view in another query. This powerful functionality enables you to create reusable queries, build complex queries, and take advantage of existing queries as views.\n---\n\n## Overview\n\nThe \"Query a Query\" feature in DuneSQL allows you to use an existing query as a view in another query. This powerful functionality enables you to create reusable queries, build complex queries, and take advantage of existing queries as views. \n\n!!! info\n    All upstream queries are executed as functional SQL views, which means that they will be executed every time they are queried. This means there currently is no performance benefit to using the \"Query a Query\" feature.\n## Using Query a Query\n\nTo use the \"Query a Query\" feature, you will need the queryID of the query you want to use as a view. The queryID can be found in the URL of a query. For example, if the URL of a query is [https://dune.com/queries/1746191](https://dune.com/queries/1746191), the queryID would be `1746191`.\n\nOnce you have the queryID, you can use it in your new query using the following syntax:\n\n```sql\nselect * from query_<queryID>\n```\n\nFor example, if you want to use the query with queryID 1746191 as a view in your new query, you would write: \n\n```sql\nselect * from query_1746191 \n```\n\n## Limitations\n\nThere are some important limitations and requirements to consider when using the \"Query a Query\" feature:\n\n1. **Named output columns**: All output columns of the query being queried must be named. For example, you cannot query `select 1` or `select count(*) from ethereum.transactions`, but you can query `select 1 as v` and `select count(*) as total from ethereum.transactions`.\n2. **Parameterized queries**: Parameterized queries are not supported for the \"Query a Query\" feature.\n3. **Saved queries**: Only saved queries can be used with the \"Query a Query\" feature.\n4. **Archived queries**: Archived queries cannot be queried.\n5. **Dune SQL**: Only queries written in Dune SQL can be queried.\n\n!!! Tip\n    Querying private queries is a [premium feature](https://dune.com/pricing) only. You can't query private queries with a free or plus account. \n\n## Best Practices\n\nWhen using the \"Query a Query\" feature, consider the following best practices:\n\n1. **Naming conventions**: Ensure that your queries follow a consistent naming convention for output columns. This will make it easier to understand and reuse queries as views.\n2. **Documentation**: Provide clear documentation and comments for your queries, especially when they are intended to be used as views in other queries.\n3. **Modularity**: Break down complex queries into smaller, reusable components. This will make your queries more maintainable and easier to understand.\n4. **Version control**: If you need to update a query that is being used as a view in other queries, consider creating a new version of the query instead of modifying the existing one. This will help prevent unexpected changes in dependent queries.\n5. **Forking** If you use the query of another user as a view in your query, consider forking the query instead of querying it. That way, you will not be affected by changes made to the original query. On the other hand, you will also not be able to benefit from any improvements made to the original query.\n\n\n\n\n", "doc_id": "2f9bb95a-f856-4fd5-9528-ee4e33c3b664", "embedding": null, "doc_hash": "d8ceb4c82fbe62b83b81a5b97c4f828a3c6446df95110c5b3958f7b861268db6", "extra_info": {"file_path": "docs/query/query-a-query.md", "file_name": "query-a-query.md"}, "node_info": {"start": 0, "end": 3385, "_node_type": "1"}, "relationships": {"1": "370acb5cf3546337e11094d1cf3ab0fe82e3f9f5"}}, "__type__": "1"}, "15d841cf-8400-4e86-bb7a-ae08cc454849": {"__data__": {"text": "---\ntitle: Storage\ndescription: Learn more about the differences and thinking behind our V2 database structure.\n---\n\n<!--!!!note \n    This section should probably be rewritten into \"how to write efficient queries\" or something like that.\n    The data layout is relevant in this context, but the focus should be on how to write efficient queries.\n-->\n\nOn a very high level, databases read data from storage into memory in order to allow that data to be operated on, in our case to transform and return blockchain data according to your Dune query\u2019s logic. \n\nRead speed, the time it takes to load data from storage to memory, is an essential constraint of databases. In computer science this is referred to as [I/O bound](https://en.wikipedia.org/wiki/I/O_bound), and it\u2019s one of the main challenges we are looking to tackle with our transition to a data lake in Dune V2 and separating storage and compute.\n\nLet\u2019s see how this happens.\n\n## Row oriented databases\n\nDatabases store data in pages, which traditionally contain rows of information.\n\nMultiple pages make one data file and a table will consist of one or more data files.\n\n![row oriented database (PostgreSQL)](images/row-oriented.png)\n\nWhen retrieving data from storage in order to operate on said data, a database will read data into memory by the page. Page size and the number of pages loaded are key bottlenecks for query speed as the number and size of pages loaded means longer read times and more waiting for your query results to be returned.\n\nSince traditional databases store pages by row, they are best suited for retrieving all columns of one row or data from multiple sequential rows.\n\nWhether we are looking to retrieve all columns from row 10 or column 3 from rows 11-25, our queries will be fast as only one page will need to be read into memory.\n\nIn contrast, querying for data which is stored in many different logical rows and therefore different physical pages is an expensive operation, as all the pages must be read from disk.\n\nMost of the queries we run on Dune today are aggregation of data points in a column over thousands if not millions of rows.\n\nThis is because each of our rows is based on one transaction or trace from the blockchains we\u2019re querying.\n\nSo for example, if we want to see all the swaps between ETH and USDC in the last month, transactions will be spread across thousands of transactions and thus thousands of rows - but the data will all be within one column of each of these rows.\n\nThus, in a row-oriented database, we end up loading many pages with unneeded data as we query for one column across thousands or millions of rows.\n\nIn PostgreSQL, we use indexes to look for specific subsets of data rather than reading entire pages/tables filled with extraneous data.\n\nThis leads to very fast and efficient Queries, but is limited to indexed columns.\n\nSince every new index created for a table is a new database file, it is harder to update and maintain the table at scale.\n\nTherefore, Dune V2 runs on column-oriented, rather than row-oriented tables.\n\n\n## Column oriented database\n\n![column oriented database (Spark)](images/column-oriented.png)\n\nIn Dune V2, we store our data on AWS S3 using the [parquet file format](https://github.com/apache/parquet-format).\n\nParquet is sometimes described as a hybrid approach between row-oriented databases and column-oriented databases since a table still consists of multiple parquet files which are themselves partitioned by rows.\n\nInside of the parquet files, though, the pages themselves contain columns instead of rows.\n\nPages are stored within row groups which partition the data by rows inside the parquet files.\n\nThus, the database is still roughly stored in a row oriented format but the individual values are stored in column orientation inside pages.\n\n![schematic view of parquet files](images/parquet.png)\n\nEven though the database at large is somewhat row-oriented, when we actually want to read data we are reading from column-oriented pages and thus are reading pages", "doc_id": "15d841cf-8400-4e86-bb7a-ae08cc454849", "embedding": null, "doc_hash": "8989437674f2cf45e3300528825b119268fe68b00a5e1ed78bb7383fc00632a1", "extra_info": {"file_path": "docs/query/storage.md", "file_name": "storage.md"}, "node_info": {"start": 0, "end": 4025, "_node_type": "1"}, "relationships": {"1": "09278556c8740eaac8985264d09e4f8b5429e714", "3": "b6772a80-ab2d-470f-a963-0c757238fa15"}}, "__type__": "1"}, "b6772a80-ab2d-470f-a963-0c757238fa15": {"__data__": {"text": "when we actually want to read data we are reading from column-oriented pages and thus are reading pages into memory by column.\n\nIn contrast, should we try to query for all columns of specific logical rows, we have to access lots of different pages as the data of one logical row is no longer stored in one page, but rather distributed across lots of different pages.\n\nTo better understand rows vs columns, check out this video on the differences:\n\n![type:video]([https://youtu.be/Vw1fCeD06YI](https://youtu.be/Vw1fCeD06YI))\n\n\n### To index, or not to index?\n\nWe were sometimes able to mimic the efficiency of column-based data in V1\u2019s PostgreSQL by creating large amounts of structured subset data in the form of indexes, but for now this doesn't scale.\n\nEach parquet file has a footer that contains `min/max` values for every column stored within.\n\nThis pattern is repeated on a column chunk level, which stores this metadata for the columns within a specific row group within the parquet file.\n\n![schematic view of mix/max values](images/minmax-schema.jpg)\n\nUsing these `min/max` values, both on a file level and on a column chunk level allows the database to efficiently skip over entire parquet files or column chunks within parquet files while scanning through a table. For the min/max values to be useful, and the chunk skipping to work, the column must be correlated with the sorting of the file.\n\nUnfortunately, the `min/max` values of strings are oftentimes not very useful.\n\nFor example, `tx_hash` strings and `address` strings in blockchain systems are not suited well for this kind of `min/max` data gathering since they are randomly generated.\n\nSo if we sort tables by `block_time` (which we do in almost all circumstances), we can\u2019t effectively `min/max` by `tx_hash` or `address` strings as these data won\u2019t be sequentially ordered.\n\nThat means the database won't be able to skip files or column chunks based on these strings, and Queries that reference them will therefore be quite inefficient since all related pages will need to be read into memory.\n\nThat said, since the Query engine at large is still able to read through individual columns in which these strings are stored very efficiently, most of the time this won't make a big difference in your Query execution speed.\n\nThe performance cost is mostly relevant for base tables like `ethereum.transactions`, `bnb.logs`, `erc20_ethereum.erc20_evt_transfer`, etc. which contain very large datasets that aren\u2019t pre-filtered.\n\nA notable exception to this is the Solana dataset `account_activity`_,_ which is ordered by `account_keys` rather than `block_time` like the EVM-based datasets.\n\nThis allows us to utilize the `min/max` values for the `account_keys` when building Queries based on [raw Solana data](../data-tables/raw/solana/index.md).\n\n## Dune V2 Query examples\n\nEquipped with the above knowledge, let's look at how some Queries on Dune V2 work.\n\n### Querying for transaction hashes\n\n```sql\n\nSelect * from ethereum.transactions\nwhere hash = 0xce1f1a2dd0c10fcf9385d14bc92c686c210e4accf00a3fe7ec2b5db7a5499cff\n\n```\n\nBased on the way our parquet file system works, this Query is very inefficient.\n\nOur only filter condition here is a `hash` string so we\u2019re asking the query engine to read all pages that store `tx_hash` column data.\n\nThe engine can skip a few column chunks where the `min/max` value stored in the parquet file footer is `0xa0 - 0xcd`, but those will be a rare exception.\n\nGiven we\u2019re doing a full scan over the entire history of Ethereum Mainnet", "doc_id": "b6772a80-ab2d-470f-a963-0c757238fa15", "embedding": null, "doc_hash": "9206ede800c63b28c8c30621e0e7c27ee68fa3dbcfb90cfbed00448bfafba74d", "extra_info": {"file_path": "docs/query/storage.md", "file_name": "storage.md"}, "node_info": {"start": 3940, "end": 7477, "_node_type": "1"}, "relationships": {"1": "09278556c8740eaac8985264d09e4f8b5429e714", "2": "15d841cf-8400-4e86-bb7a-ae08cc454849", "3": "41862796-570a-47db-937b-c9c26b4865ce"}}, "__type__": "1"}, "41862796-570a-47db-937b-c9c26b4865ce": {"__data__": {"text": "we\u2019re doing a full scan over the entire history of Ethereum Mainnet (billions of rows) to search for one `hash`, it's pretty impressive that this Query only takes about 6 minutes to run.\n\nSince querying for \u2018hash\u2019 is a very common part of a Wizard\u2019s workflow, let's think about how we can make this faster.\n\nTo do that, we just have to search based on a column that has sequential \u2018min/max\u2019 values so our query engine can skip over most pages/column chunks.\n\nBoth \u2018block_time\u2019 and \u2018block_number\u2019 are useful for this purpose.\n\n```sql\n\nSelect * from ethereum.transactions\n\nwhere block_number = 14854616\n\nand hash = 0xce1f1a2dd0c10fcf9385d14bc92c686c210e4accf00a3fe7ec2b5db7a5499cff\n\n```\n\nThis Query is still not as fast as in PostgreSQL, where we can make use of [B-tree indexes](https://en.wikipedia.org/wiki/B-tree), but with a runtime of 13 seconds, we\u2019re pretty close.\n\nAgain, by using our `where` clause to filter by block number, we\u2019re leveraging the V2 engine\u2019s ability to read the parquet file footers\u2019 \u2018min/max\u2019 values and skip those that are out of bounds.\n\nOnce a parquet file that meets our condition is found, the engine simply loads into memory the relatively few pages from the column chunk with a `min` lower and a `max` greater than our specified `block_number` before finding a match to our \u2018hash\u2019 condition.\n\nSince we are selecting all entries from the logical row in this Query, we actually need to access a few other pages as well, but this is a reasonably efficient operation if we only do this for a few rows.\n\n**Lesson:** Define your conditions in a way in which the database is able to work with \u2018min/max\u2019 values of files and columns chunks so it can efficiently find the logical row(s) you need.\n\n\n### Aggregating data over a large amount of logical rows\n\nThis is mainly a case study to illustrate how efficient DuneV2 is in aggregating data over a large set of logical rows.\n\n```sql\n\nSelect avg(gas_used) from ethereum.transactions\n\n```\n\nThis Query runs in an **amazing** 7 seconds.\n\nThis is mainly due to the fact that V2 doesn\u2019t have to read the entire table since all this data is stored together in column-oriented pages across parquet files.\n\nIn V1\u2019s PostgreSQL, each page we read into memory would have contained a lot of unneeded data.\n\nIn Dune V2, we can just read the data that we actually need.\n\n**Lesson:** Querying for data across a large amount of logical rows is now much more efficient and a lot of Queries that were formerly sheer impossible due to timing out are now able to be executed.\n\nAnother good example to illustrate this is [@hildobby's](https://twitter.com/hildobby_) [Ethereum Overview](https://dune.com/hildobby/ethereum) Dashboard.\n\n\n## We\u2019ll keep innovating\n\nSome Queries that were heavily indexed on our V1 database might feel a bit awkward in Dune V2.\n\nThis is especially the case for `erc20` event transfer tables, `ethereum.transactions`, `ethereum.logs` and their counterparts on other blockchains.\n\nThis is a tradeoff we made to enable blockchain analytics on a large scale basis.\n\nWe will continue to keep innovating on these datasets and our database architecture to make every Query run as fast as possible on V2. Hopefully now you understand why Queries for data like `tx_hash` will be slow due to the tradeoffs we\u2019ve made.\n\nIf you have any feedback or run into trouble with the new system, our #dune-sql Discord channel is the best place", "doc_id": "41862796-570a-47db-937b-c9c26b4865ce", "embedding": null, "doc_hash": "9056c8a7e49703887e8911344f261999c01364cc0aa870badbcca234738ffb83", "extra_info": {"file_path": "docs/query/storage.md", "file_name": "storage.md"}, "node_info": {"start": 7508, "end": 10911, "_node_type": "1"}, "relationships": {"1": "09278556c8740eaac8985264d09e4f8b5429e714", "2": "b6772a80-ab2d-470f-a963-0c757238fa15", "3": "a6e93cd6-10b7-4daf-a196-5b5c2c706362"}}, "__type__": "1"}, "a6e93cd6-10b7-4daf-a196-5b5c2c706362": {"__data__": {"text": "with the new system, our #dune-sql Discord channel is the best place to get help from our team and Wizard community when Google fails you.\n\nAs you come across issues or identify areas of improvement, please send us an email at [dunesql-feedback@dune.com](mailto:dunesql-feedback@dune.com) and we\u2019ll work with you to update and optimize!\n", "doc_id": "a6e93cd6-10b7-4daf-a196-5b5c2c706362", "embedding": null, "doc_hash": "809853455ada57a101a226a7f68f4f160f29d113acc1ffee71a81d0982e4e4ed", "extra_info": {"file_path": "docs/query/storage.md", "file_name": "storage.md"}, "node_info": {"start": 10899, "end": 11236, "_node_type": "1"}, "relationships": {"1": "09278556c8740eaac8985264d09e4f8b5429e714", "2": "41862796-570a-47db-937b-c9c26b4865ce"}}, "__type__": "1"}, "dec85e87-a690-4e04-948f-eea61422cdbc": {"__data__": {"text": "---\ntitle: Syntax Differences\ndescription: This page provides a guide for migrating queries from Postgres to Dune SQL and from SparkSQL to DuneSQL.   \n---\n\n\n## Syntax and operator differences\n\nThe syntax and keyword operator differences between Postgres, Spark, and Dune SQL are quite minimal, here are a few key ones:\n\n### Syntax Comparison\n\n| **Description** | **V1 - PostgreSQL** | **V2 - Spark SQL** | **V2 - Dune SQL** |\n| --- | --- | --- | --- |\n| **`bytea2numeric`, or casting hex/bytea to a number** | `bytea2numeric` (bytea) | `bytea2numeric_v3` (string) | `bytearray_to_integer` (hex) <br> `bytearray_to_bigint` (hex) <br> `bytearray_to_decimal` (hex) <br> `bytearray_to_uint256` (hex) <br> `bytearray_to_int256` (hex) <br> More details on [Byte Array to Numeric Functions](#byte-array-to-numeric-functions)|\n| **Doing math or numeric operations on a column, like value in ethereum.transactions** | sum(value) | sum(value) | sum(cast(value as double)) *soon this won't be needed as UINT and INT columns are added automatically.* |\n| **0 vs 1 array based indexing** | 1 indexed | 0 indexed | 1 indexed |\n| **Implicit type conversions between character and numeric types** | Available | Available | [Not available](https://trino.io/docs/current/functions/conversion.html) |\n| **Addresses** | `\\x2A7D...`(bytea)<br><br>Works in Postgres | `0x2a7d...` (string)<br><br>Has to be lowercase in Spark.<br><br>Can be done via `lower('0x2A7D...')` | `0x2a7d...` (Byte array) <br><br> No escape quotes should be used, and the literal does __not__ need to be lowercased. |\n| **Selecting keyword columns is different** | \"from\" | \\`from\\` | \"from\" |\n| **Alias naming is different** | as \"daily active users\" | as \\`daily active user\\` | as \"daily active users\" |\n| **Exponentiation notation** | `x/10^y` or `x * 1e123` | `x*power(10,y)` or `x*1e123` | `x*power(10,y)` or `x * 1e123` |\n| **Interval argument has different syntax** | `Interval '1day'` | `Interval '1 day'` | `Interval '1' day` |\n| **Generate_series () is now sequence ()** | `generate_series('2022-05-15', CURRENT_DATE, '1 day')` | `explode(sequence(to_date('2022-01-01'), to_date('2022-02-01'), interval 1 day))` | [`unnest(sequence(date('2022-01-01'), date('2022-02-01'), interval '7' day))`](https://dune.com/queries/1764158?d=11)<br><br> Has a 10000 values limit, and must go in the FROM statement not the SELECT. |\n| **Handling decimals for prices.usd** | Don\u2019t use `prices.usd decimals` | Replaced by `prices.tokens decimals` | Replaced by `tokens_[blockchain].erc20.decimals` |\n| **Define NULL array** |` NULL::integer[]` | `CAST(NULL AS ARRAY&lt;int&gt;))` | `CAST(NULL AS ARRAY&lt;int&gt;))` |\n| **encoding strings to hex** | `encode(string, 'hex')` |", "doc_id": "dec85e87-a690-4e04-948f-eea61422cdbc", "embedding": null, "doc_hash": "ca7af56067c08eaf426c00516ebd679295cf073805b72feb15befe19ff9eb4bb", "extra_info": {"file_path": "docs/query/syntax-differences.md", "file_name": "syntax-differences.md"}, "node_info": {"start": 0, "end": 2722, "_node_type": "1"}, "relationships": {"1": "f98eee6afad0958bd913b26f2c39da3fe7663e33", "3": "8228e574-a7b8-4f7e-b4fd-476071f35ab5"}}, "__type__": "1"}, "8228e574-a7b8-4f7e-b4fd-476071f35ab5": {"__data__": {"text": "**encoding strings to hex** | `encode(string, 'hex')` | `hex(string)` | `hex(string)`<br><br>*available soon |\n| **Get json object differences** | `(takerOutputUpdate->'deltaWei'->'value') decode(substring((addressSet->'baseAsset')::TEXT, 4,40), 'hex')` | `get_json_object(get_json_object(takerOutputUpdate,'\\(.deltaWei'),'\\).value')'0x'` | `json_query(json_query(takerOutputUpdate, 'lax $.deltaWei' omit quotes), 'lax $.value')` |\n| **Group by an alias** | `SELECT date_trunc('hour',evt_block_time) as col1, COUNT(*) FROM erc721_ethereum evt_Transfer GROUP BY col1` | Same as PostgreSQL | `GROUP BY date_trunc('hour',evt_block_time)`Or: `GROUP BY 1, 2` |\n| **Explicit date/time casting** | `'2021-08-08 17:00'::timestamp` | `cast('2021-08-08 17:00' as timestamp)` | `cast('2021-08-08 17:00' as timestamp)`<br><br>Or, `timestamp '2021-08-08 17:00'`<br><br>There are [many helper functions for casting to date/time types](https://trino.io/docs/current/functions/datetime.html?highlight=date), such as `date(\u20182022-01-01\u2019)` |\n| **Checking if an item exists in an array** | `value = ANY (array)` | `array_contains(array, value)` | [`contains(array, value)` or `contains_sequence(array, array[values])`](https://trino.io/docs/current/functions/array.html#contains) |\n| **Explode** | `SELECT unnest(array) FROM table` | `SELECT explode(array) FROM table` | `SELECT vals.val FROM table1, unnest(arrayFromTable1) as vals(val)`<br><br>you have to use `unnest` with a `cross join`, as described in this [blog post](https://theleftjoin.com/how-to-explode-arrays-with-presto/). |\n| **Median** | `PERCENTILE_CONT(0.5) WITHIN GROUP(ORDER BY x)` | `PERCENTILE_CONT(0.5) WITHIN GROUP(ORDER BY x)` | `approx_percentile(x, 0.5)` |\n| **Using \u201cis True/False\u201d** | `X is true` | `X is true` | `X = true` |\n| **String Data Type** | `varchar` | `string` | `varchar` |\n| **Casting as Strings** | `cast([xxx] as string)` | `cast([xxx] as string)` | `cast([xxx] as varchar)` |\n| **`left()` is no longer a method available for returning substrings** | `left([string],[length])` | `left([string],[length])` | `substr([string], [start], [length])` <br><br> [Returns varchar; Positions start with 1, so use `1` for length if you want to replicate left() functionality](https://trino.io/docs/current/functions/string.html?highlight=substr#substring) `left(somestring, somenumber) -> substr(somestring, 0, somenumber)`|\n| **Aggregate Functions** | `array_agg(col)`, `array_agg(distinct(col))` | `array_agg(col)` or `collect_list(col)`, `collect_set(col)` or `array_agg(distinct(col))` | `array_agg(col)`, `array_agg(distinct(col))` |\n| **user generated views** | create view", "doc_id": "8228e574-a7b8-4f7e-b4fd-476071f35ab5", "embedding": null, "doc_hash": "7e62dec728fbaf1a48ce45eaaa3724ea3ce9e2067b750b4e360c90a34f665489", "extra_info": {"file_path": "docs/query/syntax-differences.md", "file_name": "syntax-differences.md"}, "node_info": {"start": 2675, "end": 5316, "_node_type": "1"}, "relationships": {"1": "f98eee6afad0958bd913b26f2c39da3fe7663e33", "2": "dec85e87-a690-4e04-948f-eea61422cdbc", "3": "8463d18c-eaab-4228-9aa1-007a34b8d84b"}}, "__type__": "1"}, "8463d18c-eaab-4228-9aa1-007a34b8d84b": {"__data__": {"text": "|\n| **user generated views** | create view dune_user_generated.table | none | each query is a view, like [query_1747157](https://dune.com/queries/1747157) |\n| **event logs topic indexing** | topic 1,2,3,4 | topic 1,2,3,4 | topic 0,1,2,3 |\n", "doc_id": "8463d18c-eaab-4228-9aa1-007a34b8d84b", "embedding": null, "doc_hash": "0a39d4c5f2f268e34ea78271cc54f2e78952499904b38cbe8d82119e7c5fa8d0", "extra_info": {"file_path": "docs/query/syntax-differences.md", "file_name": "syntax-differences.md"}, "node_info": {"start": 5322, "end": 5561, "_node_type": "1"}, "relationships": {"1": "f98eee6afad0958bd913b26f2c39da3fe7663e33", "2": "8228e574-a7b8-4f7e-b4fd-476071f35ab5"}}, "__type__": "1"}, "5c3988e1-c86c-439b-8410-da4b4649e412": {"__data__": {"text": "---\ntitle: How to Write Efficient Queries on DuneSQL\ndescription: Get the most out of DuneSQL by writing efficient queries.\n---\n\n**Writing efficient queries is essential for getting the most out of DuneSQL. This guide will help you understand how to write efficient queries on DuneSQL.**\n\n## DuneSQL architecture\n\nDuneSQL is a TrinoSQL-based query engine designed for handling data stored in a columnar format on Dune.com. In Dune, the data is stored using the parquet file format, which combines row-oriented and column-oriented approaches. Understanding the nuances of parquet file storage and how it impacts query efficiency is essential for creating optimized queries on DuneSQL.\n\n### Parquet Files and Columnar Storage\n\nIn parquet files, the data is partitioned by rows into multiple parquet files, and within each file, the data is further partitioned into row groups. However, the pages inside row groups store data in columns rather than rows. As a result, the database appears row-oriented at a higher level, but it reads data from column-oriented pages when accessing specific values.\n\n![schematic view of parquet files](images/parquet.png)\n\nWhen querying for specific columns, this structure allows for efficient data access. On the other hand, if a query requires all columns of specific logical rows, multiple pages must be accessed since the data of one logical row is distributed across different pages.\n\n![column oriented database (Spark)](images/column-oriented.png)\n\n### Min/Max Values and Efficient Queries\n\nEach parquet file has a footer containing min/max values for every column stored within. This pattern is also repeated on a row group level, which stores metadata for columns within a specific row group. These min/max values enable the database to efficiently skip entire parquet files or row groups within files while scanning through a table, provided that the column is correlated with the file's sorting.\n\nHowever, the min/max values of strings, such as tx_hash strings and address strings in blockchain systems, are often not helpful, as they are randomly generated and not sequentially ordered. As a result, queries that reference these strings will be inefficient since all related pages need to be read into memory.\n\n### Writing Efficient Queries\n\nTo write efficient queries on DuneSQL, it's crucial to use filter conditions based on columns that are sequentially ordered and correlated with the file's sorting. Columns like `block_time` and `block_number` are suitable for this purpose. For instance, consider the following optimized query:\n\n```sql\nSELECT * FROM ethereum.transactions\nWHERE block_number = 14854616\nAND hash = 0xce1f1a2dd0c10fcf9385d14bc92c686c210e4accf00a3fe7ec2b5db7a5499cff;\n```\n\nBy including the block_number column in the query, the engine can narrow down the search to a specific block, reducing the amount of data scanned and considerably speeding up the query.\n\n### Exceptions\nA notable exception to the general rule of using sequentially ordered columns is the Solana dataset `account_activity`, which is ordered by `account_keys` rather than `block_time`. This allows for utilizing the min/max values for `account_keys` when building queries based on raw Solana data.\n\n## Additional Tips for Writing Efficient Queries on DuneSQL\n\nIn addition to leveraging the columnar storage format and using sequentially ordered columns, as discussed in the previous section, here are more tips to help you write efficient queries on DuneSQL with TrinoSQL:\n\n1. **Limit the columns in the SELECT clause**: Only request the columns you need, as it reduces the amount of data the query engine needs to process.\n\n2. **Use the LIMIT clause**: If you're only interested in a specific number of rows, use the LIMIT clause to avoid processing more data than necessary.\n\n3. **Leverage partition pruning**: If your data is partitioned, use partition keys in the WHERE clause to help", "doc_id": "5c3988e1-c86c-439b-8410-da4b4649e412", "embedding": null, "doc_hash": "2797d24bf710137459fd95fd1a84cf0be41b840a6f7f18078bc1eb08476e9c08", "extra_info": {"file_path": "docs/query/writing-efficient-queries.md", "file_name": "writing-efficient-queries.md"}, "node_info": {"start": 0, "end": 3920, "_node_type": "1"}, "relationships": {"1": "b76f2e2ce98ded7830f3c0abda7404f624838fc7", "3": "518e1fff-47b9-4fd7-b5ad-101bd0e7c6a9"}}, "__type__": "1"}, "518e1fff-47b9-4fd7-b5ad-101bd0e7c6a9": {"__data__": {"text": "If your data is partitioned, use partition keys in the WHERE clause to help the query engine prune unnecessary partitions and reduce the amount of data scanned.\n\n4. **Filter early and use predicate pushdown**: Apply filters as early as possible in the query to reduce the amount of data being processed. This takes advantage of predicate pushdown, which pushes filter conditions down to the storage layer, reducing the amount of data read from storage.\n\n5. **Use window functions**: Window functions can be more efficient than self-joins or subqueries for computing aggregations over a set of rows related to the current row.\n\n6. **Avoid using DISTINCT when possible**: DISTINCT can be computationally expensive, especially on large datasets. If you can use GROUP BY or other aggregation methods to achieve the same result, it may improve query performance. Try using approx_distinct instead.\n\n7. **Optimize subqueries**: Subqueries can sometimes cause performance issues. Consider using Common Table Expressions (CTEs) or rewriting the query using JOINs to optimize subqueries.\n\n8. **Use the EXPLAIN command**: The EXPLAIN command shows the query execution plan, which can help you understand the underlying operations and optimize your query. Analyze the output of EXPLAIN to identify potential bottlenecks or improvements.\n\n9. **Optimize data types**: Use appropriate data types for your columns, as it can improve query performance by reducing the amount of data processed. For example, varbinary operations are faster that varchar so be careful casting around too much.\n\nBy following these tips, you can write more efficient queries on DuneSQL with TrinoSQL and optimize the performance of your data processing tasks. Remember that DuneSQL's unique structure, such as the parquet file format and columnar storage, should be taken into account when optimizing your queries to fully benefit from the system's capabilities.\n", "doc_id": "518e1fff-47b9-4fd7-b5ad-101bd0e7c6a9", "embedding": null, "doc_hash": "ba8ca30b1e924bc331ddc01bfa6e602cf2ddca222837f20f09778cf0531119e8", "extra_info": {"file_path": "docs/query/writing-efficient-queries.md", "file_name": "writing-efficient-queries.md"}, "node_info": {"start": 3845, "end": 5771, "_node_type": "1"}, "relationships": {"1": "b76f2e2ce98ded7830f3c0abda7404f624838fc7", "2": "5c3988e1-c86c-439b-8410-da4b4649e412"}}, "__type__": "1"}, "f239beac-6aeb-4487-95be-3e785fe81fc2": {"__data__": {"text": "---\ntitle: Quickstart\ndescription: Get started on Dune in five minutes!\n---\n<p align=\"center\">\n  <img src=\"../images/quickstart-cover.jpeg\" alt=\"A beautiful dashboard\" title=\"Dashboard\" /><br />\n  <em>The world's blockchain data at your fingertips!</em>\n</p>\n\n\n### Welcome to Dune\n\n\nThis guide will help you get started on Dune in five minutes. We'll walk you through how to:\n\n1. Query blockchain data\n2. Create a visualization\n3. Present your data\n\nDune has many more features, but these are the basics you'll need to get started. If you're looking for more advanced guides, check out the [Analytics Guidelines](analytics_guidelines.md) and [Data Tables](data-tables/index.md) sections.\n\n**Prerequisites:**   \n- You'll need to have a Dune account to follow along. If you don't have one, you can [sign up here](https://dune.com/auth/register).  \n- We also recommend you have a basic understanding of SQL and Blockchain concepts.\n\n### 1. Query blockchain data\n\nTo query for blockchain data on Dune you'll need to:\n\n1. Create a new query\n2. Write some SQL\n3. Run the query\n4. Name and save the query\n\n```sql\n--Query to get Ethereum's unique daily active users and passive users  in 2023\n\nSELECT  \n--truncate time to day\ndate_trunc('day', block_time) AS time,\n-- count distinct addresses that sent a transactions\nCOUNT(distinct \"from\") AS users,\n-- count distinct addresses that received a transaction\nCOUNT(distinct \"to\") AS receiving_addresses\nFROM ethereum.transactions\nWHERE block_time > DATE '2023-01-01'\nGROUP BY 1\n```\n\n**[Direct link to query here.](https://dune.com/queries/2335378)**  \n\n<div style=\"position: relative; padding-bottom: calc(66.66666666666666% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/gT2ctqjvwIuX5xUXPx5S?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Dashboards\"></iframe></div>\n\n\n\n### 2. Create a visualization\n\nTo create a visualization you'll need to:\n\n1. Create a new visualization\n2. Select the type of visualization you want to create\n3. Choose the data source for the x and y axis\n4. adjust the visualization settings\n\nIn our example below, we'll create a line chart to visualize the number of unique daily active users and passive users on Ethereum in 2023. Additionally, we format the axis label and tick label to `0a`to make the numbers more readable.\n\n<div style=\"position: relative; padding-bottom: calc(66.66666666666666% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/nNxDjw8vBmp34u3aNU0R?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Dashboards\"></iframe></div>\n\n\n### 3. Present your data\n\nTo present your data you'll need to:\n\n1. Create a new dashboard\n2. Add a visualization to the dashboard\n3. Adjust the layout of the dashboard\n4. Name and save the dashboard\n\n<div style=\"position: relative; padding-bottom: calc(66.66666666666666% + 41px); height: 0;\"><iframe src=\"https://demo.arcade.software/xTAXmlo0nCL0FOn38hW9?embed\" frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen", "doc_id": "f239beac-6aeb-4487-95be-3e785fe81fc2", "embedding": null, "doc_hash": "7ab65a7c058bd87607c4ac47a2d9110ea4b0da021525af6d7fa9c3de061e975a", "extra_info": {"file_path": "docs/quickstart.md", "file_name": "quickstart.md"}, "node_info": {"start": 0, "end": 3250, "_node_type": "1"}, "relationships": {"1": "fa30bc56f2755065c0ff02de0019982df9854e56", "3": "3e92e13a-d602-4266-ab2a-73c20414e517"}}, "__type__": "1"}, "3e92e13a-d602-4266-ab2a-73c20414e517": {"__data__": {"text": "frameborder=\"0\" loading=\"lazy\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;color-scheme: light;\" title=\"Creating a dashboard\"></iframe></div>\n\n\n### Recap\n\n**Congratulations, you've just queried blockchain data, created a visualization, and presented your data on Dune!**\n\nYou can now share your dashboard with the world.\n\nWe'll take care of updating this dashboard whenever somebody looks at it, so you don't have to worry about keeping it up to date.\n\n### Next steps\n\nCheck out these resources to learn more about Dune:\n\n- [Dune Official Getting Started Video Series](https://www.youtube.com/watch?v=S-cctFmR828&list=PLK3b5d4iK10ext4v-GBySekaA8-GP8quD&index=1) to learn how the data flows and how to navigate the Dune app to create queries, visualizations, and dashboards. \n\n- [Weekly Web3 SQL problems](https://daodatadesign.notion.site/Web3-SQL-Weekly-0bababb5e59a412bb73594c512db8cc1) to learn wizard tips and tricks in byte-sized bits. Covers things like token balances, protocol integrations, product metrics, and much more.\n\n- [All Ethereum and SQL Basics](https://web3datadegens.substack.com/p/a-basic-wizard-guide-to-dune-sql) to learn all the basic SQL concepts and Ethereum tables you'll need in your analysis.\n\n- For pure SQL practice, try going through the \"easy\" problems [on hackerrank](https://www.hackerrank.com/domains/sql).\n\nJoin the community and learn together [in Discord](https://discord.com/invite/ErrzwBz) by participating in the `#\ud83d\udc25\ufe31beginners` and `#\ud83d\ude4b\ufe31query-questions` channels\n\nAnd when you feel ready to do advanced analysis, check out the [next guide](analytics_guidelines.md)", "doc_id": "3e92e13a-d602-4266-ab2a-73c20414e517", "embedding": null, "doc_hash": "1f2615250e236f47a9bd0b93689e093529445c22a812278b5e8c686fcbce7e8e", "extra_info": {"file_path": "docs/quickstart.md", "file_name": "quickstart.md"}, "node_info": {"start": 3198, "end": 4886, "_node_type": "1"}, "relationships": {"1": "fa30bc56f2755065c0ff02de0019982df9854e56", "2": "f239beac-6aeb-4487-95be-3e785fe81fc2"}}, "__type__": "1"}, "42b98d55-b4a7-42a4-a633-c416a3248775": {"__data__": {"text": "---\ntitle: Citing Dune\ndescription: Learn about how to correctly reference and cite Dune queries and dashboards\n---\n\n# Citing Dune\n\n<p align=\"center\">\n  <img src=\"../images/galaxy-brain.png\" alt=\"Be fair \" title=\"Galaxy Brain\" /><br />\n  <em>Be the Galaxy Brain!</em>\n</p>\n\n   \n   \nContent on Dune is first and foremost the product of the creators (\"Wizards\") who build the Queries, Visualizations, and Dashboards we reference and share.\n\nAny mention or use of data or Visualizations you find on our platform should reference Dune as the source of such information and include a Dune logo, a direct link to dune.com and a reference to credit the creator(s) of the specific Query, Dashboard, or Data.\n\nCrediting should be done as follows:\n\n_\"[@rchen8](https://dune.com/rchen8) via_ [_OpenSea monthly volume (Ethereum)_](https://dune.com/queries/3469/6913)_\"._\n\nIf you're referencing a Dashboard, you can find the creator's User Name as well as the Dashboard's name at the top left of the page.\n\nThe link to the users profile can be found by clicking their User Name:\n\n![find dune user and dashboard name](images/find-dune-user-and-dashboard-name.png)\n\nLikewise, you can find their User Name/Profile link and the Query/Visualization name at the top left side of a Query page:\n\n![find user and query visualization name](images/find-user-and-query-visualization-name.png)\n\n\n## Limitations of Commercial Use\nDo note that any form of copying, transmitting, transferring, modifying or creating derivative works from the original Queries and the public Dashboard or wrapping them in a white label manner for free or resale is strictly prohibited.\n\nSimilarly, reproducing, sublicensing, transferring, duplicating, copying, selling, reselling, or any other forms of exploiting any portion, use or access to Dune without the express written permission by Dune is not allowed.", "doc_id": "42b98d55-b4a7-42a4-a633-c416a3248775", "embedding": null, "doc_hash": "869b14b73ea0836f8edf774860361f8364fc629a4a78a8700208948a468ce02c", "extra_info": {"file_path": "docs/resources/citing-dune.md", "file_name": "citing-dune.md"}, "node_info": {"start": 0, "end": 1864, "_node_type": "1"}, "relationships": {"1": "44ab32cf40b2001706c247122acb08c8c33340b3"}}, "__type__": "1"}, "fc91a4ae-2d20-4918-8218-fa856f7db604": {"__data__": {"text": "---\ntitle: Find a Wizard\ndescription: Dune bounties empower projects and wizards to collaborate through $$ incentives.\n---\n\nWhile Dune has created the tools to make extract knowledge from crypto data, it's through the skills and bravery of our community of Wizards that data is surfaced and made understandable for projects and the public alike.\n\nMany of our Wizards are looking for ways to earn money and build their reputation in the space.\n\n## The problem: Wizards + Projects != \u2728\ud83d\udcca\n\nProjects need data, Wizards want jobs. It's hard for one to find the other.\n\nAnalytics tasks have been spread out between Twitter, Discord, Gitcoin, Layer3, Notion boards and a few other dark and hidden places. \n\nIt's hard for **Wizards** to keep track of all these locations they should look for jobs and there's unnecessary friction in the application and work-delivery process. \n\nFor **Projects**, the lack of organization makes it exceedingly hard to find the right Wizard for the job and introduces unnecessary overhead in the management process.\n\nFundamentally, this problem is solved through the creation of one marketplace for helping Wizards and Projects make the data flow.\n\nThis one solution should be able to handle:\n\n- task creation \n- the application process\n- communication\n- reputation\n- payments\n\nand it should be web3 native.\n\n**Thankfully this marketplace exists!**\n\n## The solution: Dune Bounties\n\nLeveraging [dework.xyz](https://www.dework.xyz), we've set up a bounty board to manage our Dune internal bounty programs - and we've set it up so it's accessible for other projects and organizations to make use of this infrastructure!\n\nDework describes itself as a \u201cweb3 native Trello with payments and credentialing\". \n\nWhat exactly does that mean?\n\nLet's hear what Lonis, co-founder of Dework, has to say:\n\n![type:video](https://www.youtube.com/embed/hyOLRGurjDc)\n\nDework offers infrastructure for us to write out tasks on our own [board](https://app.dework.xyz/dune/board) and allows other organizations to seamlessly connect with Dune Wizards by simply specifying \u201cDune Analytics\u201d as Skill.\n\nAll open tasks that have the Dune Analytics Skill attached will appear in the [Dune hub](https://app.dework.xyz/hubs/dune), making it easy for Wizards to find tasks that need their skills.\n\n## For projects in need of Wizards\n\n**If you are an organization in need of web3 analytics, it\u2019s now easier than ever to connect with Dune Wizards!**\n\n\n=== \"Self Serve\"\n\n    [Dework's Documentation](https://dework.gitbook.io/product-docs/guides-for-orgs/getting-started-on-dework) is the best in-depth resource for getting started, but here's a short breakdown for convenience:\n\n    1. **Create an organization**\n\n        If you don\u2019t have a Dework organization yet, the first step is to create one.\n        \n        At a minimum, we recommend including a description, an icon and a link to your socials so Wizards know who they are working with.\n\n        We also strongly recommend setting up the [Discord integrations](https://dework.gitbook.io/product-docs/guides-for-orgs/connecting-to-discord) to allow for easy communication with the chosen Applicants.\n        \n    2. **Define tasks**\n\n        After completing the initial setup, you can start creating tasks for anything, but to work with Dune Wizards, you'll want to define tasks with the **\"Dune Analytics\" Skill\"**.\n        \n ", "doc_id": "fc91a4ae-2d20-4918-8218-fa856f7db604", "embedding": null, "doc_hash": "78753da7082ed8523ca51922b7132053efd19781504914e57b2d4a1dae6147ce", "extra_info": {"file_path": "docs/resources/dune-bounties.md", "file_name": "dune-bounties.md"}, "node_info": {"start": 0, "end": 3377, "_node_type": "1"}, "relationships": {"1": "2d2de793bd7a82c664d96928dec3587425dd4522", "3": "49258516-ddfb-4482-91e1-053bd7774eea"}}, "__type__": "1"}, "49258516-ddfb-4482-91e1-053bd7774eea": {"__data__": {"text": "Analytics\" Skill\"**.\n        \n        Once you have created a task, the task will be: \n        \n        1. in your board\n        2. in the [Dune hub](https://app.dework.xyz/hubs/dune). \n        \n        From there on out, people can find your open task and apply or compete.\n        Additionally, you should share the task link with your community to get more applicants.\n\n    3.  **Choose an applicant**\n\n        If you have defined a task that needs to be assigned to someone, you will get notifications within Dework and can vet the applicant using their work history, GitHub profile and any other attached information on their profile.\n        \n        We strongly recommend spending time and effort vetting your applicants to have a smooth bounty process.\n\n        Once you choose an applicant to work with, they'll become a Dework \"contributor\" to your project.\n\n    4.  **Review the work**\n\n        Once the Wizard applicant you have chosen has submitted their work, you can start reviewing the completed task. If it is satisfactory, you mark the task as done and initiate the payment process.\n\n    5.  **Pay your contributor**\n\n        Dework integrates with Metamask, Gnosis Safe, Utopia Labs and even Phantom wallet for Solana based payments. You can choose whatever works best for you and your Wizard contributor here.\n\n\n=== \"Supported approach\"\n\n    1. **Fill in this Typeform**  \n    \n    We know setting up Dework, defining bounties, and managing your contributors can be quite a challenge.\n    \n    Reach out to us by clicking the button below and filling out our Typeform and we'll happily assist you in onboarding and running successful bounties.\n    \n    <button data-tf-popup=\"DtX4jqkd\" data-tf-size=\"100\" style=\"all:unset;font-family:Helvetica,Arial,sans-serif;display:inline-block;max-width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;background-color:#0445AF;color:#FFFFFF;font-size:20px;border-radius:25px;padding:0 33px;font-weight:bold;height:50px;cursor:pointer;line-height:50px;text-align:center;margin:0;text-decoration:none;\">Typeform</button><script src=\"//embed.typeform.com/next/embed.js\"></script>\n\n\n\n\n\n\n## For Wizards looking for work\n\nIf you are a Wizard or a aspiring Wizard, join the Dune Analytics organization on Dework and start looking for tasks:\n\n- [On our board](https://app.dework.xyz/dune/board)\n- [On the Dune hub](https://app.dework.xyz/hubs/dune)\n\nBe sure to complete your profile with relevant links to your socials, GitHub and Dune profile so organizations can easily assess your skills and decide you're a perfect fit (the easier it is for them to see what you can do, the more likely they'll hire you!).\n\n## Some notes about working on Dune\n\nDune can roughly be separated into two parts:\n\n- The **App Layer**\n- The **Data Layer**. \n\nIn the **App Layer**, you can find [Queries](../app/query-editor/index.md), [Visualizations](../app/visualizations/index.md) and [Dashboards](../app/dashboards.md). \n\nEverything in the App Layer is public by default and can be utilized by", "doc_id": "49258516-ddfb-4482-91e1-053bd7774eea", "embedding": null, "doc_hash": "05b7e2ac997ded9666cb924a9519950cdf141e297d6ac29c22ce60b3245777c8", "extra_info": {"file_path": "docs/resources/dune-bounties.md", "file_name": "dune-bounties.md"}, "node_info": {"start": 3357, "end": 6399, "_node_type": "1"}, "relationships": {"1": "2d2de793bd7a82c664d96928dec3587425dd4522", "2": "fc91a4ae-2d20-4918-8218-fa856f7db604", "3": "8d277df4-9aba-4b40-b2f6-1b89cb459b2c"}}, "__type__": "1"}, "8d277df4-9aba-4b40-b2f6-1b89cb459b2c": {"__data__": {"text": "\n\nEverything in the App Layer is public by default and can be utilized by other Wizards, but the work produced in the App Layer is not very persistent and most importantly doesn't enable other Wizard analysts to easily build on top of this work.\n\nDune's **Data Layer** allows you and the Wizards you work with to produce scalable and persistent work by standardizing and normalizing data. \n\nWe call this data layer [Spellbook](../data-tables/spellbook/index.md).  \n\nA good example of the power of working in the Dune **Data Layer** is OpenSea's standardization and normalization of [all NFT trades across all chains and versions](https://dune.com/spellbook#!/model/model.spellbook.opensea_trades).\n\nBy transforming their raw data and adding it to the `opensea.trades` table inside of Spellbook, 2 things can happen:\n\n1. Every Dune Wizard can easily work with OpenSea's data as it's cleaned and standardized.\n2. The data can be referenced in other Spellbook tables (\"Spells\") like `nft.trades`; this makes it even more likely that Wizards will incorporate OpenSea data into their work as the `nft.trades` table contains data from all marketplaces across all chains.\n\nIn this way, a project like yours working in the Spellbook Data Layer can get a lot of leverage not only from whatever data analysis projects and visualizations you commission, but by making it more likely other Wizards will find and use your data, build it into their Dashboards, and generate interest in your project. \n\nThough not necessarily required for your project, getting your data normalized, standardized and possibly inserted into one of our sector level tables like `nft.trades` is definitely recommended!\n\nOnce that is done, people working in the **App layer** will have a much easier time building good queries, visualizations and dashboards since the hardest data engineering parts are already taken care of.  \n\nIf this all sounds confusing to you, don't worry we can advise you in this process!\n\nReach out via the [Typeform](https://form.typeform.com/to/DtX4jqkd) in the \"Supported approach\" tab above, or ask about building your project in Spellbook in our [#spellbook Discord channel](https://discord.com/channels/757637422384283659/999683200563564655)!\n\n**TL;DR**\nWe suggest working in this order so your data flows efficiently:\n\n1. Build Spells in the Data Layer to take care of the data engineering\n2. Build cool stuff in the App Layer to surface findings\n\n## Dune Bounties FAQ\n\n!!! example  \"I want to create a requests but how much should I pay/offer?\"\n\n    Dune is an open platform on which you can build all kinds of analysis, Dashboards and Spells, so the official answer here is the dreaded \"it depends.\"\n\n    Going rates for Freelance Dune Wizards seem to be anywhere between \\$30-\\$100 per hour.\n\n    And you can always ask in our [#bounty-questions Discord](https://discord.com/channels/757637422384283659/1025371996277706792) or fill out the [Typeform](https://form.typeform.com/to/DtX4jqkd) in the \"Supported approach\" tab above to get some help on this! \n\n!!! example  \"Does Dune take a cut of bounty payments?\"\n\n    Dune does not take a cut in any bounty payments.\n\n!!! example  \"I don't have time/capacity to do this myself, can you run this for me?\"\n\n    In some cases, the Dune team can actually run entire bounty campaigns/contests for you, but we can't offer this for every organization.\n\n    Fill out the [Typeform](https://form.typeform.com/to/DtX4jqkd) in the \"Supported approach\" tab above and we'll let you know what we can do to help!", "doc_id": "8d277df4-9aba-4b40-b2f6-1b89cb459b2c", "embedding": null, "doc_hash": "1bc577696d195dd3b2bff2dcb0e358c3edc43edd34ce69a2abde6613f2088b58", "extra_info": {"file_path": "docs/resources/dune-bounties.md", "file_name": "dune-bounties.md"}, "node_info": {"start": 6361, "end": 9906, "_node_type": "1"}, "relationships": {"1": "2d2de793bd7a82c664d96928dec3587425dd4522", "2": "49258516-ddfb-4482-91e1-053bd7774eea", "3": "46f1e19d-72c1-4951-9047-9e103db524ec"}}, "__type__": "1"}, "46f1e19d-72c1-4951-9047-9e103db524ec": {"__data__": {"text": "\"Supported approach\" tab above and we'll let you know what we can do to help! \n\n!!! example  \"How do Wizards get paid for bounties?\"\n\n    Dework has a native payment feature. Wizards simply connect their wallet in their Dework profile and will get paid as soon as the bounty is paid out by the Project that created the task.\n\n!!! example  \"Can I run contests on Dework?\"\n\n    You can indeed run contests on Dework, they are called \"multiple submissions.\"\n\n    You can learn more in [Dework's documentation](https://dework.gitbook.io/product-docs/fundamentals/task-types-and-assignee-gating#multiple-submissions).\n\n    After running contests it often makes sense to give one of the winners a follow-up task to reconcile the best ideas of all submitted dashboards into one final version.\n\n!!! example  \"Is all of this public?\"\n\n    Dework allows you to define tasks privately and publicly, if you wanted to you could for example limit tasks for only members of your Discord.\n\n!!! example  \"How do I choose the right applicant?\"\n\n    You can click on any profile in Dework to see what the Credentials of the person are.\n\n    For example:  \n    [https://app.dework.xyz/profile/hamzat_iii](https://app.dework.xyz/profile/hamzat_iii)\n\n!!! example  \"What's your recommend approach to organizing bounties for my Project and needs?\"\n\n    Our advice is to first run specific tasks for adding your data to [Spellbook](../data-tables/spellbook/index.md) first and run a    Dashboard design contest afterwards.\n\n    This way, your data will be easily accessible to any Dune Wizard in any Queries and Dashboards they imagine\n\n    Then, by running a contest for Dashboard designs using Dework's \"multiple submissions\" feature, you'll ensure specific  Dashboards you want are created while also leaving room to be surprised by our Wizard's creativity.\n\n", "doc_id": "46f1e19d-72c1-4951-9047-9e103db524ec", "embedding": null, "doc_hash": "c7af069b862a2a4566ba897273ed1cf46468a5031b5c13435698f3a1223c004c", "extra_info": {"file_path": "docs/resources/dune-bounties.md", "file_name": "dune-bounties.md"}, "node_info": {"start": 9889, "end": 11726, "_node_type": "1"}, "relationships": {"1": "2d2de793bd7a82c664d96928dec3587425dd4522", "2": "8d277df4-9aba-4b40-b2f6-1b89cb459b2c"}}, "__type__": "1"}, "d9715b24-c189-48e2-8032-b7f0bffcc5d9": {"__data__": {"text": "---\ntitle: Resources\ndescription: Resources for Dune Wizards\n---\n\nA collection of resources for the Dune community.\n\n<div class=\"cards grid\" markdown>\n\n-   #### Citing Dune\n\n    A guide to citing Dune in your research papers or projects.\n  \n    [:octicons-arrow-right-24: Citing Dune](citing-dune.md)\n\n-   #### Find a Wizard\n\n    Discover and connect with skilled builders and researchers in the Ethereum ecosystem.\n  \n    [:octicons-arrow-right-24: Find a Wizard](dune-bounties.md)\n\n-   #### Press Kit\n\n    Logos, images, and other resources to use when writing about or promoting Dune Analytics.\n  \n    [:octicons-arrow-right-24: Press Kit](press-kit.md)\n\n-   #### Support & Feedback\n\n    Have questions or feedback about Dune Analytics? Get in touch with the team here.\n  \n    [:octicons-arrow-right-24: Support & Feedback](support-feedback.md)\n\n</div>", "doc_id": "d9715b24-c189-48e2-8032-b7f0bffcc5d9", "embedding": null, "doc_hash": "cfdd456c1ce7e5da8dd14fc770ad1700f7a13f0cdafb0ca22f63c2c27cdf69f9", "extra_info": {"file_path": "docs/resources/index.md", "file_name": "index.md"}, "node_info": {"start": 0, "end": 855, "_node_type": "1"}, "relationships": {"1": "a6fbf783f9cb3b304136a43e5f783991de2efd39"}}, "__type__": "1"}, "113cae10-7e20-45cf-bea4-c5317d21c168": {"__data__": {"text": "---\ntitle: Press Kit\ndescription: Gain access to Dune's brand assets\n---\n\n# Press Kit\n\n## Primary - Standard Logo\n\nThis is the primary Dune logo. It should be used in this format whenever possible.\n\n![Dune horizontal logo cover](images/dune-horizontal-logo-cover.png)\n\n<div class=\"cards grid\" markdown>\n- [dune-standard-logo.svg](images/dune-standard-logo.svg)\n- [dune-standard-logo@2x.png](images/dune-standard-logo@2x.png)\n- [dune-standard-logo-dark.svg](images/dune-standard-logo-dark.svg)\n- [dune-standard-logo-dark@2x.png](images/dune-standard-logo-dark@2x.png)\n</div>\n\n## Vertical logo\n\n![Dune vertical logo cover](images/dune-vertical-logo-cover.png)\n\n<div class=\"cards grid\" markdown>\n- [dune-vertical-logo.svg](images/dune-vertical-logo.svg)\n- [dune-vertical-logo@2x.png](images/dune-vertical-logo@2x.png)\n- [dune-vertical-logo-dark.svg](images/dune-vertical-logo.svg)\n- [dune-vertical-logo-dark@2x.png](images/dune-vertical-logo-dark@2x.png)\n</div>\n\n## Icon only\n\n![Dune icon only](images/dune-icon-only.svg)\n\n<div class=\"cards grid\" markdown>\n- [dune-icon-only.svg](images/dune-icon-only.svg)\n- [dune-icon-only@2x.png](images/dune-icon-only@2x.png)\n</div>\n\n## Complete set of all logos\n\n<div class=\"cards grid\" markdown>\n- [Dune-logo-Full.zip](images/Dune-logo-Full.zip)\n</div>", "doc_id": "113cae10-7e20-45cf-bea4-c5317d21c168", "embedding": null, "doc_hash": "4d195deced991d8cbe21b9732779daebffc56bf48c8b5101e2c0c1ef503e49a6", "extra_info": {"file_path": "docs/resources/press-kit.md", "file_name": "press-kit.md"}, "node_info": {"start": 0, "end": 1288, "_node_type": "1"}, "relationships": {"1": "510f55d8602316b1644265e636c6f243122bfc91"}}, "__type__": "1"}, "febba113-1e89-4071-ab9d-2d863a169583": {"__data__": {"text": "---\ntitle: Support & Feedback\ndescription: Here's the best way to get help if you can't find the answers you're looking for in our docs!\n---\n\n## How to Get Support\n\nIf you can't seem to find the help you're looking for, here's the best way to get it:\n\n### 1. Try searching using the Search bar above\n\nWe know you probably did that already but just in case\n\n### 2. Discord!\n\nWe have a very active community of Dune Wizards in our Discord. If you're not already a member, you can join by clicking the button below:\n\n<a href=\"https://discord.gg/dunecom\" target=\"_blank\" class=\"button button--primary button--lg\">Join Discord</a>\n\n\n## How to Leave Feedback\n\nFor general Dune app feedback, [leave a suggestion on our Canny board here](https://feedback.dune.com/).\n\nIf you're working with any of our public repositories (e.g. Spellbook), you can also open a Github issue.\n\nFor Docs feedback fixes or additions, click the pencil icon to the right of the page title and open a GitHub issue or submit a pull request:\n\n![edit docs pencil](images/edit-docs-pencil.png)\n\n## Account issues\nFor any issues related to your account, billing or any other administrative problems, please send an email to [support@dune.com](mailto:support@dune.com).\n", "doc_id": "febba113-1e89-4071-ab9d-2d863a169583", "embedding": null, "doc_hash": "24fb112a03ee8bbaadcb31bc60abccccc90e6d8c94e28da3a5de65212a2206c2", "extra_info": {"file_path": "docs/resources/support-feedback.md", "file_name": "support-feedback.md"}, "node_info": {"start": 0, "end": 1232, "_node_type": "1"}, "relationships": {"1": "7315845a94cddef314e2b305c18b02404f6746f3"}}, "__type__": "1"}}, "docstore/ref_doc_info": {"1ec67adafad93061c867a7daf5ef065d61813b7c": {"doc_ids": ["05cf5184-7ed8-4a70-85ca-7796343a9b01", "d6eff9df-5d7a-4796-bc26-b5ee81f78a68"], "extra_info": {"file_path": "docs/analytics_guidelines.md", "file_name": "analytics_guidelines.md"}}, "ed7858fd27a03a1c2fb01c5578b8d90c812970fe": {"doc_ids": ["a7fd5883-860d-4b47-b7a6-38a1cbfcd413"], "extra_info": {"file_path": "docs/api/FAQ/functionality.md", "file_name": "functionality.md"}}, "6a1f69ff7b6a45db2de4b23dada647440c48b859": {"doc_ids": ["05e700b9-ff3a-46e0-b856-9221c2c01aa3"], "extra_info": {"file_path": "docs/api/api-reference/authentication.md", "file_name": "authentication.md"}}, "e163cfecc89b678ef8edaf2b20c177cc64780689": {"doc_ids": ["2d5f888a-209e-412f-b0e9-30359a548e82"], "extra_info": {"file_path": "docs/api/api-reference/cancel-execution.md", "file_name": "cancel-execution.md"}}, "8f45a4884bae7d5dbf5d348d00b346174b97b489": {"doc_ids": ["7375fe59-7889-4ba3-811f-ece549008c8c"], "extra_info": {"file_path": "docs/api/api-reference/errors.md", "file_name": "errors.md"}}, "688974d536678972e8fb78b96fb8be87efb7924a": {"doc_ids": ["7e84a302-a2c6-4b59-bfb3-283219831e53", "8c43348c-be78-4117-aa38-9710127375d9"], "extra_info": {"file_path": "docs/api/api-reference/execute-query-id.md", "file_name": "execute-query-id.md"}}, "e881b5fd2dba254153fa35adb717e87b5836c7d2": {"doc_ids": ["4ad40ed5-411d-42a1-8795-25f6bdb5f933", "72a14ea9-fcd3-4077-8efc-dcd55f764aa8", "1f6eea81-afeb-40d3-aca3-fbe397732ec8"], "extra_info": {"file_path": "docs/api/api-reference/execution-results.md", "file_name": "execution-results.md"}}, "ff6356498de3c813a24924cdbf9114f8ece22faa": {"doc_ids": ["819de6ee-508e-424c-bee2-cb5a43e44a48", "2edf009c-9de9-4f36-a121-92db089881ab"], "extra_info": {"file_path": "docs/api/api-reference/execution-status.md", "file_name": "execution-status.md"}}, "2e80efa87b8cb5f49f56c4de80054b778742df38": {"doc_ids": ["dda94b1a-37b4-412c-8bd1-92955465b22c"], "extra_info": {"file_path": "docs/api/api-reference/index.md", "file_name": "index.md"}}, "a9712c14dfb54f2187c0a0f38786cb41561f67df": {"doc_ids": ["b89ced50-f684-4511-a841-c2c7a8853e15", "5b8663f5-e876-4e0c-b936-e7f901a94ec7"], "extra_info": {"file_path": "docs/api/api-reference/latest_results.md", "file_name": "latest_results.md"}}, "5e341cb077901a100270cb1d379e5df790964168": {"doc_ids": ["c3d93dce-932c-42c6-8ed5-6908cb9c10dd", "935a5bf8-686f-4acd-a70e-216403e75ff5"], "extra_info": {"file_path": "docs/api/faq.md", "file_name": "faq.md"}}, "6da9912dfa407c2655de68449c7f8dc8f22e0e2f": {"doc_ids": ["763d2b2e-c051-46b4-8568-de07572e0151"], "extra_info": {"file_path": "docs/api/index.md", "file_name": "index.md"}}, "541485deeceabc7677192a2f588ee381e138c038": {"doc_ids": ["b3582480-0df3-444a-8ab1-459b424b4a21"], "extra_info": {"file_path": "docs/api/quick-start/.api-use-cases.md", "file_name": ".api-use-cases.md"}}, "42c22f3ee37a352f736947c39d56dc934443a34e": {"doc_ids": ["7f96947e-a62b-40d3-a3d2-0607e6098717", "4179b3f5-8577-4f2a-8397-64fefe61b52c"], "extra_info": {"file_path": "docs/api/quick-start/api-js.md", "file_name": "api-js.md"}}, "81d66ca829f3f244a5f8fceb32fe05ec6b10a389": {"doc_ids": ["70f5f376-a252-45e4-9ec5-96bdbdb9ab93", "db20b10a-2cb4-4c67-a8d2-6aa6c8be0089", "c66e3977-4027-47c2-b496-e191e996c0f1", "61d7795d-2a48-4b70-9e2f-d606df97780e", "743f3699-bbe4-4ac1-9a73-08f3cefef767", "9ef186eb-cf32-4e7e-92ed-3d98ecc0f9d3", "37d0b15e-a7ba-4f3b-86ef-fa9a9a8248b3"], "extra_info": {"file_path": "docs/api/quick-start/api-py.md", "file_name": "api-py.md"}}, "65788ed3a52740a5d20a43ca5641bf4038899151": {"doc_ids": ["519d0f3f-8c1c-45e0-8b5b-7985829bdcf6"], "extra_info": {"file_path": "docs/api/quick-start/community-clients.md", "file_name": "community-clients.md"}}, "8dc010af0db2fcc9db9f9c23db6ed3a2f5644e39": {"doc_ids": ["8fd7274f-8d46-4cd6-973e-9a975d17b8c9", "bdf217ca-d262-4c92-8357-92adaf1e493b"], "extra_info": {"file_path": "docs/api/quick-start/index.md", "file_name": "index.md"}}, "fb6e1495c297e2c98d22e485362addc5f4086d7b": {"doc_ids": ["b9bbb261-4cb7-4b7d-a5fb-4489f077c5c8", "50732a05-df51-4e8e-9546-a75340544c1d"], "extra_info": {"file_path": "docs/api/write-api.md", "file_name": "write-api.md"}}, "1ef7f1624e04f49dda014356fec5109184fd5ac9": {"doc_ids": ["a83f8ec6-4060-4fd2-8499-22b0008e8808"], "extra_info": {"file_path": "docs/app/dashboards.md", "file_name": "dashboards.md"}}, "efe2d8928da28dcac2206c5aaabcc0269cd911cd": {"doc_ids": ["8750ca7f-6588-40b7-9082-5775d7d93f84", "2dc178c5-ae63-4b32-837b-9d422ec96e17", "a3bf8534-fa35-4d0b-b07e-3c52d80339bd"], "extra_info": {"file_path": "docs/app/decoding-contracts.md", "file_name": "decoding-contracts.md"}}, "f0ebb4e9a8e3ba41efa0a590709f9def98cb48c5": {"doc_ids": ["2af4e6b7-3d2f-44ca-84a5-a6fbd5d3bbe1"], "extra_info": {"file_path": "docs/app/embeds.md", "file_name": "embeds.md"}}, "fc98b150ec32caa79b409a81a22df8f1c9d29970": {"doc_ids": ["1d5818de-df6a-43e5-b869-386e83fd3415"], "extra_info": {"file_path": "docs/app/index.md", "file_name": "index.md"}}, "75fdb7ce0c015bdb6192677d1a04da8080373b32": {"doc_ids": ["f8246d4e-ae76-4c23-9693-2b2818f0863d", "d561730d-93ee-4b45-b723-870826b628b4"], "extra_info": {"file_path": "docs/app/query-editor/data-explorer.md", "file_name": "data-explorer.md"}}, "6e8399335ad01ebf5bc8c610ad9a8cd928437f60": {"doc_ids": ["b37e8d45-bcf3-4bcf-999c-d5f3647c1f3e"], "extra_info": {"file_path": "docs/app/query-editor/index.md", "file_name": "index.md"}}, "be9bc7a8dc64606386116f4514bd22682be4921d": {"doc_ids": ["1f92112a-651d-40fc-9066-389909366c25", "57846725-b06b-4935-90bd-e6c67a549c26"], "extra_info": {"file_path": "docs/app/query-editor/query-scheduler.md", "file_name": "query-scheduler.md"}}, "12dbbe33d490e31bbf50851055623592349db141": {"doc_ids": ["b3be340a-d2b5-4fe8-b375-1c661132b8cb", "c07ac0ae-0067-4d4d-842b-fa15ae190b68"], "extra_info": {"file_path": "docs/app/query-editor/query-window.md", "file_name": "query-window.md"}}, "e603e7e87a17aeb00f17727731f1dbfb611eb121": {"doc_ids": ["902c7cc8-ab57-420e-bc5b-6d83e2d9748f"], "extra_info": {"file_path": "docs/app/query-editor/version-history.md", "file_name": "version-history.md"}}, "5ae1301cc542880d92f78213d959b10a0a2868e7": {"doc_ids": ["b19fe1a0-d685-4692-8f4a-2542490a5f91", "05078c76-7257-4dd9-90b8-06c2f41c65ed"], "extra_info": {"file_path": "docs/app/teams.md", "file_name": "teams.md"}}, "9f8de3b5c2fb0d2f94ff7a4f3f5f2c33255ff8cc": {"doc_ids": ["e1b52bc8-dde9-4cea-8133-5a6107a3b7db", "0bdb0904-80b6-4b63-bbdd-0b9242191e87", "aa3b2ddf-596b-4f7f-83cb-10ea1c0de835"], "extra_info": {"file_path": "docs/app/visualizations/charts-graphs.md", "file_name": "charts-graphs.md"}}, "c54cdf811912bf0d1b093377bb878115a1c7559a": {"doc_ids": ["a6850047-8ac0-4c91-b2ad-da55471ef0bf"], "extra_info": {"file_path": "docs/app/visualizations/counters.md", "file_name": "counters.md"}}, "b6dde3875b506f0d450a3f8b9a50728329973410": {"doc_ids": ["fee71c90-2d4d-4f64-8dcf-651544d1bb04"], "extra_info": {"file_path": "docs/app/visualizations/index.md", "file_name": "index.md"}}, "e0cf334a6611aab79be64eada67f526c545e65dd": {"doc_ids": ["693b903e-6743-4d1d-be52-9ea9ce5c8d40"], "extra_info": {"file_path": "docs/app/visualizations/tables.md", "file_name": "tables.md"}}, "02de8b5c5cf82beb550cb7373a766ec393999aa4": {"doc_ids": ["9afd63ca-98e6-49e7-ae49-7466ac597092"], "extra_info": {"file_path": "docs/data-tables/community/flashbots/arbitrages.md", "file_name": "arbitrages.md"}}, "b04767a5b3481e7dc5d3fd5a34d3b27a19875aab": {"doc_ids": ["20f0d466-9944-49e2-aff3-674d6f167b52"], "extra_info": {"file_path": "docs/data-tables/community/flashbots/index.md", "file_name": "index.md"}}, "82a6b008f7988e12a413c401a38b423aed1b854b": {"doc_ids": ["b040e289-cec8-4900-a28e-3e6073f6d396", "554b3218-f5e6-4611-9edc-55a30c8cd66f"], "extra_info": {"file_path": "docs/data-tables/community/flashbots/liquidations.md", "file_name": "liquidations.md"}}, "98e09188b958147c3d6bc7ea404bf3cd9b4c4df1": {"doc_ids": ["cadc3249-2231-48bf-b80d-451402044792", "33a1322f-d516-4332-b2e3-43449d291066"], "extra_info": {"file_path": "docs/data-tables/community/flashbots/mev_summary.md", "file_name": "mev_summary.md"}}, "20215a3c1c7147517a946a03fe51e5b219211688": {"doc_ids": ["f273704c-11d1-4a41-807f-0e66d7072d80"], "extra_info": {"file_path": "docs/data-tables/community/flashbots/sandwiched-swaps.md", "file_name": "sandwiched-swaps.md"}}, "2ae98d5f1e2d0b0467799fcb1fc9bd4b794803d7": {"doc_ids": ["afd26714-7d65-4168-bd98-0f4794f08e36"], "extra_info": {"file_path": "docs/data-tables/community/flashbots/sandwiches.md", "file_name": "sandwiches.md"}}, "37ee1ab8a924f48d373c8d3915cf04d056a9ac2a": {"doc_ids": ["854c7191-ebb6-4594-be0c-b6e66a741a74"], "extra_info": {"file_path": "docs/data-tables/community/index.md", "file_name": "index.md"}}, "53dd871c76c7b89720ebfb5b249ebe8bdb0f69e8": {"doc_ids": ["5c8059f1-1401-4f54-ac6b-1301b07d4d2d", "1279dbd0-37cb-4f67-949b-7dab1b7ca70d"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/ask-events.md", "file_name": "ask-events.md"}}, "289fdcc7bb684cb250ebb6c44e8e64e8240df2c5": {"doc_ids": ["a2fc14f8-20f2-48ba-bac4-db154a32aba5", "49d365f1-e2f0-4f56-8c0f-9db721174c8a"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/asks.md", "file_name": "asks.md"}}, "931ad55b2927da963c205adc9283abdccc064f0c": {"doc_ids": ["89f93007-789a-4127-bbd3-0e154e59ae15"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/attribute-keys.md", "file_name": "attribute-keys.md"}}, "2a6f7d19dc780c431987c6ecf37dcc6ad21ac4b6": {"doc_ids": ["541b6c04-b8f0-4cf6-bd3b-ecd0242f5e60"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/attributes.md", "file_name": "attributes.md"}}, "e39e6325eee6099ae006fe360d3deabc3ecb97ec": {"doc_ids": ["8053d478-544d-438c-a923-753619cf6bc2", "dd514643-e072-463f-8241-aa6879f935f2"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/bid-events.md", "file_name": "bid-events.md"}}, "e193f392c8bf7ebbb52bce2abb2f050810796ba4": {"doc_ids": ["4a3d6c75-2992-4386-9e85-a113c95eb4cc", "8702ae4e-4d6f-4132-b6a7-fb60864c10fc"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/bids.md", "file_name": "bids.md"}}, "12b396288e590ffc0362e7d51ba2bf194980cf88": {"doc_ids": ["3c14273b-380d-4fe1-babd-c1078638dd16", "c10d08d1-558b-4ed9-8c0e-c1e64ea2d08d"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/collection-floor-ask-events.md", "file_name": "collection-floor-ask-events.md"}}, "3b7d233595bfeff028b98d61a84fe66cdeae663c": {"doc_ids": ["5dc29253-a690-4b39-ba33-f11a5a8dbbb4", "66ec64ae-11f6-48a1-a238-672c41ac062c"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/collection-top-bid-events.md", "file_name": "collection-top-bid-events.md"}}, "6944cccd045271bb98ad1db1f322bc71b7a63115": {"doc_ids": ["f74e5e13-75f3-4481-9898-eae14123c143", "fb750b13-8f7e-442f-9660-575bb7200a71"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/collections.md", "file_name": "collections.md"}}, "e360a49dd06db3a0d936fecb9de73d34719da9d2": {"doc_ids": ["8c5abd63-edd2-4b05-95d9-809d33f1a84f"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/index.md", "file_name": "index.md"}}, "0651df3c0cc49a752054e4604f91e922493abae2": {"doc_ids": ["e16a6454-c0d0-42e2-837e-ba24f94d19b7", "e9acfd82-4baf-4e66-9ef6-1d3e1dfde643"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/sales.md", "file_name": "sales.md"}}, "9624e926c5a83e17eb6fe1fe7a2ffaf0e8a714bb": {"doc_ids": ["45c832d7-e5e6-4592-9b1a-ded4634ea5bb"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/token-attributes.md", "file_name": "token-attributes.md"}}, "370c8923e15916e05edcb8e1a1879cbc37601680": {"doc_ids": ["52cd6ab5-df3f-403d-88a0-4e2ff6566230", "a64b5701-3647-4d70-9cdd-6fccf7d7025b"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/token-floor-ask-events.md", "file_name": "token-floor-ask-events.md"}}, "67fb5f46a65071875838118624d06d4ed15a010c": {"doc_ids": ["094ea4bd-b58b-4ad3-a0b1-6b46e21693a6", "5f2b026e-2155-45d9-a336-1b0dac2b671c"], "extra_info": {"file_path": "docs/data-tables/community/reservoir/tokens.md", "file_name": "tokens.md"}}, "8ac25b1c3280d05c59576e696bcd034c11ad1635": {"doc_ids": ["d1b62e87-c568-4ffc-996c-a53396b512a2", "a5035c45-c2f8-429f-b5ac-cdae104270fc"], "extra_info": {"file_path": "docs/data-tables/decoded/evm/call-tables.md", "file_name": "call-tables.md"}}, "3bbfb8391058b4049afe30bcaa711ab70c115862": {"doc_ids": ["4b95ea82-1432-450f-89c7-c63ed469e0c5", "f23b28b3-5c9b-4320-b9fd-f0f96646de5e"], "extra_info": {"file_path": "docs/data-tables/decoded/evm/event-logs.md", "file_name": "event-logs.md"}}, "ed15f18ac6d87a916a49197c931e955d77bef99f": {"doc_ids": ["e826487b-6088-4659-b119-450fcd0ddc72", "6eabf164-4859-4803-9e08-3848f21425ca", "2d08803e-0110-4ed1-a2f9-9053d30947e4", "3a94ec9b-c779-4c1d-aaf3-01dc71515bf5"], "extra_info": {"file_path": "docs/data-tables/decoded/evm/index.md", "file_name": "index.md"}}, "d4a21cab679cd538a27b55474d5e5acfdc44b848": {"doc_ids": ["064bc582-56a7-4eac-b273-f2c34ffc0f32"], "extra_info": {"file_path": "docs/data-tables/decoded/index.md", "file_name": "index.md"}}, "9fc9b94a80404af3d46f3ac3c761a5f8df00a645": {"doc_ids": ["64809586-c097-44c3-8194-c55ff1b5ec96"], "extra_info": {"file_path": "docs/data-tables/decoded/solana/idl-tables.md", "file_name": "idl-tables.md"}}, "c184523682f190fefdd4ceb314550e8cd2fb5648": {"doc_ids": ["7da876af-eabb-4f89-b033-69c12c012f20", "3183cef5-7201-42fc-811c-22387e99f946", "14b9cea9-28cf-4846-9ec4-d17880048ce2"], "extra_info": {"file_path": "docs/data-tables/index.md", "file_name": "index.md"}}, "a64c22f8cf2a4269a785f12ef963236cd939ee16": {"doc_ids": ["76c81058-80ac-43d9-81a7-d98d3f356e7b", "03cfe848-fdc8-426f-bffd-3e369a87706b", "7deb9cbf-533e-4c40-86da-4dbfdcbf6fd7"], "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/blocks.md", "file_name": "blocks.md"}}, "46d72f633611ea3d8528ad61981d9057ad748792": {"doc_ids": ["fd3dbbc0-894c-46f5-8802-096b46cf7264"], "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/index.md", "file_name": "index.md"}}, "5c689c9c40fef2d51e1273867b9f8f2dbf57dd77": {"doc_ids": ["7955af9e-815e-4466-b428-f08ba067ff7a", "8f333e4d-44c3-4e6f-b2fc-30368d0cfed8", "733d348f-c230-4e91-acdb-f51d889dd601"], "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/inputs.md", "file_name": "inputs.md"}}, "98836337801044fe47e1f9675805d35799fe40c7": {"doc_ids": ["5915644c-4f41-41c0-a7f5-891f5bdd6318", "9b7ee9a7-ab2d-48c5-941f-90e821ef792d"], "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/outputs.md", "file_name": "outputs.md"}}, "460797ef1dd00cc2de7eebf75c628486a95f868f": {"doc_ids": ["53f65dde-c43c-47df-9b81-8e17db2fb70f", "9666ebfc-0745-49f2-a45d-d62236189929", "22ddc996-f92b-4b11-9c62-85a3bf248ece", "c3e89e0c-d6bd-4fe9-a98d-8198a8e1fd9f", "f574a492-08a8-44f2-89b5-ba22876e1aa5", "4c153586-19d9-44df-87ba-d1e4bd8dcbde"], "extra_info": {"file_path": "docs/data-tables/raw/bitcoin/transactions.md", "file_name": "transactions.md"}}, "7d1af784439981fa4387d660eaf2c2d0f3d1973d": {"doc_ids": ["f26f48b4-e594-4019-809b-806b8ea6b149", "06121cdf-c16a-49ba-a0ae-b221f343e48c"], "extra_info": {"file_path": "docs/data-tables/raw/evm/blocks.md", "file_name": "blocks.md"}}, "1e0cc5749df2e5e1cf7a2ea52d712364e36f2ec6": {"doc_ids": ["6c861a1c-8acf-4aaf-8243-2a7208ebfb52", "c1ebf3ed-884d-48fd-a6a3-a0934dbef765"], "extra_info": {"file_path": "docs/data-tables/raw/evm/event-logs.md", "file_name": "event-logs.md"}}, "fd71e1bfe6e282bf0326070e42576b034847f203": {"doc_ids": ["47680fc0-fa44-4ce3-9a59-e7aa5540931c"], "extra_info": {"file_path": "docs/data-tables/raw/evm/index.md", "file_name": "index.md"}}, "a3cd7362b146852b1c8e39b11f0ab90571b01186": {"doc_ids": ["01f07a90-184d-4356-aca9-06f1708545dd", "22304e58-2267-4292-a3ea-4630e87bcf4d", "853dbd37-d6f1-4a7c-931c-fca8cace01c2", "2a250e28-5ef0-4329-8dfb-6f402694dd09"], "extra_info": {"file_path": "docs/data-tables/raw/evm/traces.md", "file_name": "traces.md"}}, "1cb7db9df2541410c506b5bb60849d2f2d0f7d32": {"doc_ids": ["62c37351-a198-4c61-a644-0d021f1b481b", "bbd9b67d-6800-43f0-a1c3-f303b0b13044", "ba9606d9-5384-476d-9a55-1b342d8ab0fe"], "extra_info": {"file_path": "docs/data-tables/raw/evm/transactions.md", "file_name": "transactions.md"}}, "221ca909151ea84cfde102e709e67e090f0b60da": {"doc_ids": ["29e8792f-68ea-433a-9737-983c1767998b", "b811a527-a404-4cce-812b-a27c32c606ef"], "extra_info": {"file_path": "docs/data-tables/raw/evm/withdrawals.md", "file_name": "withdrawals.md"}}, "513f7e01ad1d2a060f4b3fc64d0a0768b3292171": {"doc_ids": ["90fef2e3-98d4-43d5-8777-193e134da1ad", "26ff6998-e343-4710-989d-b6004c159320"], "extra_info": {"file_path": "docs/data-tables/raw/index.md", "file_name": "index.md"}}, "eb99779273e4d5e649ce7ed9a6bb892b66f7ba64": {"doc_ids": ["2e2de33b-4989-4684-8161-a325cacf504e", "532ff16d-3776-42c0-a119-93f6f898b8d0"], "extra_info": {"file_path": "docs/data-tables/raw/solana/account-activity.md", "file_name": "account-activity.md"}}, "56919e8e56101797085f0ac142cb1e86d3dfefc6": {"doc_ids": ["d37305b4-20fb-40cc-b88f-47509b714a15"], "extra_info": {"file_path": "docs/data-tables/raw/solana/blocks.md", "file_name": "blocks.md"}}, "b4ad10650e8eac5e709c087fa3b569ea10ef018a": {"doc_ids": ["97dbe69d-8295-40af-af47-950c84aa10bc"], "extra_info": {"file_path": "docs/data-tables/raw/solana/index.md", "file_name": "index.md"}}, "d57c71b5ef37f03cfcff7ef6f2775a8d517a145a": {"doc_ids": ["143ee9d7-38be-4782-a5b7-e318cd9f72ae"], "extra_info": {"file_path": "docs/data-tables/raw/solana/instruction-calls.md", "file_name": "instruction-calls.md"}}, "066d1391242cf88445c8d7eb218fdd8306eee8a8": {"doc_ids": ["4cef0b77-f8aa-41a6-a7ea-8f7795bdad5e"], "extra_info": {"file_path": "docs/data-tables/raw/solana/rewards.md", "file_name": "rewards.md"}}, "cb8ec41e4c1e66765fa2cc8bf7a2b05a8b1133e7": {"doc_ids": ["c86fa5d8-ecba-4e2b-92c3-ff7e75678280", "e732f692-cd36-4f56-b895-b30fec0e963e", "748eae3f-125c-4029-a851-fd809d2c6697", "57e41555-12f3-4770-82d9-f0aad1b6412a", "c3916487-3131-4d50-adf5-9fa53486bf77", "afaca212-91ca-4b9a-98bf-fab669e3328d", "6e708be5-e0aa-4428-8549-d8152a28cf43"], "extra_info": {"file_path": "docs/data-tables/raw/solana/transactions.md", "file_name": "transactions.md"}}, "0d64e4202485d0f5aa45c05ef5e329a651e33cf5": {"doc_ids": ["278dc771-dfcf-4ca3-a5de-b7f2a6b78e8b", "9e035d68-9ea5-45a7-b068-b60a772d41f6", "3342e4f8-6172-42e5-bf5f-9af21d06d8f7", "90849325-0bc1-4513-8447-9828f136d15e", "40e1be1d-46ef-423c-94a3-78b9a259608a", "250b3bb1-506b-4362-9929-e6833bb0120a"], "extra_info": {"file_path": "docs/data-tables/raw/solana/vote-transactions.md", "file_name": "vote-transactions.md"}}, "06c0b39d09ed42720b55d3bbe0dbaf4ac24e8a38": {"doc_ids": ["8d10a680-acc6-41de-9572-045e687528e5", "e32797e1-c383-44f7-b5b8-b224348fd87e", "8fa4d92f-fb35-4c30-9319-eb77734dfdbe"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/1-do-some-prerequisites and-set-up-Spellbook-dbt.md", "file_name": "1-do-some-prerequisites and-set-up-Spellbook-dbt.md"}}, "f043f3380d1f2e3bdb20217f6665d1cf95860ab8": {"doc_ids": ["803f4148-56ab-43bd-ab3c-f1d462b909c4", "e960c0c7-a8a3-4093-989c-23dee3b19f66"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/2-set-up-your-file-structure-for-SQL-schema-and-source-files.md", "file_name": "2-set-up-your-file-structure-for-SQL-schema-and-source-files.md"}}, "0ee3e4c07af94ede0ae8cecd50917977db44d7e8": {"doc_ids": ["f6ab8d66-b8d4-4268-953b-d29ac73ffd01"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/3-identify-and-define-sources.md", "file_name": "3-identify-and-define-sources.md"}}, "a21fee5e6788aef76f96cfd5e128ec3b8be3caf7": {"doc_ids": ["f754d93d-64c7-424c-b9c3-f656cff42e51", "425e6521-cb82-4b62-9f2a-b14a778a969d", "1c725a50-f148-437d-a78d-60e09043751b"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/4-define-expectations-with-schema-and-tests.md", "file_name": "4-define-expectations-with-schema-and-tests.md"}}, "d92e82a6719b8794e1b2d28b212ea63ea03ef218": {"doc_ids": ["1fa2cdc6-b813-4957-a709-ff3cbc08b525", "2c1b56d2-9571-424e-a805-24f96feffccc", "a3dc409f-41a5-4adb-b7bb-ab5fd4ead5d9", "f0399098-01e3-46d7-b6ac-cec7bfff6215"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/5-write-your-spell-as-SELECT-statement.md", "file_name": "5-write-your-spell-as-SELECT-statement.md"}}, "3e2403e32ef0f367e18352da3695a88684dba3f8": {"doc_ids": ["b833923a-83e9-4f66-b827-bda4969a8438", "897cb772-962f-464d-b84a-e1e6dd034784"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/6-configure-alias-and-materialization-strategy.md", "file_name": "6-configure-alias-and-materialization-strategy.md"}}, "cefef4718b805070345764e7a6bb54afe738f236": {"doc_ids": ["d8c4454d-fd05-4a31-9902-3426c258e8d3"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/7-make-a-pull-request-get-merged-become-an-archwizard.md", "file_name": "7-make-a-pull-request-get-merged-become-an-archwizard.md"}}, "2168413a22fcc28b3ee9b9ae6ce4c2c77266e951": {"doc_ids": ["3fee16fb-0df8-46da-91e8-56b07412c687", "98880794-3419-4e65-b782-cc284bac55ef"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/daily-aggregation.md", "file_name": "daily-aggregation.md"}}, "fc66b7490b3ef2a06eab0ee1846e6ff62eca48df": {"doc_ids": ["c63449e2-18fa-480b-a4ba-6923ac2f3f3a", "dde2f544-2a17-4009-ba5f-46181e5043e5"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/final-day-balance.md", "file_name": "final-day-balance.md"}}, "283cccbb1c96b4ef412c449e542b348230110de1": {"doc_ids": ["66676581-3a48-45ae-b38b-5b0ca6596d5c"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/index.md", "file_name": "index.md"}}, "c641e41c03008b2290c54aaa4544847d1bd5d8ac": {"doc_ids": ["0009ad3c-86d1-448b-96bf-f207288296e8", "c565b9de-ddb9-4e36-96d5-c6efc59c9ca6", "d695faf3-3c93-45b6-95f0-42eced039888"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/reformatted.md", "file_name": "reformatted.md"}}, "23a3e62f3f2acb009592e6b5b57db1faa03b59d2": {"doc_ids": ["65b3424e-539c-458a-bf2a-78dd3c48e473"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/Example Spell Models/rolling-sum.md", "file_name": "rolling-sum.md"}}, "21045d21783395b894914b57930b2f2aa791975b": {"doc_ids": ["9dc54506-73e0-4c75-a463-3125a74c1ea3"], "extra_info": {"file_path": "docs/data-tables/spellbook/contributing/index.md", "file_name": "index.md"}}, "eefab96eb5b30e083cfbbf70a8f94370d27df740": {"doc_ids": ["736879d9-b9bb-4566-9ebb-98e72a32451f", "52b32d33-a3f9-4b95-89a6-274b0051d061", "2e421799-71d3-4791-99c7-eed2588d0807"], "extra_info": {"file_path": "docs/data-tables/spellbook/index.md", "file_name": "index.md"}}, "d6dbc002044115ecc482e398d504f15ac752c9a6": {"doc_ids": ["cf21b248-0263-4557-ad99-5db6494f6ae2"], "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/dex.trades.md", "file_name": "dex.trades.md"}}, "c2f8dcf099a14b0c2fee340828b861470b856884": {"doc_ids": ["2e53f527-e982-4f58-9c6a-bcaa40d19f8e"], "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/index.md", "file_name": "index.md"}}, "0beeece78fed944f13822510497b29d6e3f60ea3": {"doc_ids": ["8945383e-2707-45c1-bfde-2f01e19fef6a", "02d9b2c2-3638-4aaf-8c58-a6492d177be7"], "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/labels.md", "file_name": "labels.md"}}, "d109bf6f8b57ebd0329491439a533b66201c9535": {"doc_ids": ["3d0d22e2-d02d-4fe4-91a8-68e71a31607d", "ea70a347-9a43-44b5-8515-3842fe4aa913", "3aa20ee2-d4ae-4f34-a70a-cc8f952c3f40"], "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/nft.trades.md", "file_name": "nft.trades.md"}}, "1c85bc511dc511c37c3ecf59b3dd59f24e415731": {"doc_ids": ["60ce5d98-016a-4d00-9298-9194f34006bd", "9f5e04f2-bb2b-4998-ae29-e58ecf350e6d"], "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/prices.md", "file_name": "prices.md"}}, "b9bf45d386b7abfd56184bdf9f902d4080a313ad": {"doc_ids": ["9f6decb0-2e10-4d40-b469-793011e914fb"], "extra_info": {"file_path": "docs/data-tables/spellbook/top-tables/tokens.md", "file_name": "tokens.md"}}, "823815552e9904bbecd26edfe8aeb78a9a46ff4a": {"doc_ids": ["4c84d6d9-e4dc-4aba-a965-54b66090abc3"], "extra_info": {"file_path": "docs/index.md", "file_name": "index.md"}}, "1c0086e721dbdfb14ccb34937b80956eb381a0e7": {"doc_ids": ["3a3fa97d-ec3c-400c-840f-d7823bc6b16b", "75906804-8f96-4425-ad10-f2d7002b5730", "fa1627f6-6980-4c7c-b3b9-b3a97d4b21f4", "2e74faaf-829a-4ab6-8aa1-242cad4b2030", "e85b27c2-453e-475a-b4ad-4a6cb8ba9179", "3564b2a1-d50c-4b38-8602-0b88d4815c01"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/aggregate.md", "file_name": "aggregate.md"}}, "74bb533a5510cec6582906aeaa72cf76c6e215cb": {"doc_ids": ["3e40e01a-4376-4920-a2bb-1d73943b0d87", "5114300e-fbcb-4f90-b9a2-1bdd3f568c87", "2c37b66a-16d4-4143-9b73-6afd0ecd807d", "267e9a02-9646-40ee-9338-87d1b8b32956", "8c1b88cd-a6b1-40b1-b4c0-13f466ba7657", "f432c8b4-798e-436f-9703-5aab4d6f057d"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/array.md", "file_name": "array.md"}}, "95a4df97cd4b186da3008e46be33463ce5bbdb2b": {"doc_ids": ["1149e5ff-31ff-47fb-957b-5aa9f2281193", "d34ea9fb-0042-4b14-8749-a71c78cf17e1"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/binary.md", "file_name": "binary.md"}}, "11c2231859919e5c426286139b4f8a646f01f196": {"doc_ids": ["3b65d3aa-bef9-42cb-8ab7-95996283b08f", "1d223c54-9d43-470d-8f40-c55c063cf828"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/bitwise.md", "file_name": "bitwise.md"}}, "1c8201fa333751c86b68ffeb9bde3b9ed43e6d74": {"doc_ids": ["251d9477-3963-4237-bc9d-d87fae787294", "3df3f45b-a21b-4e3c-82af-097cc4e90d4e", "daf89df2-2d36-43ac-9caa-d54fb1b3f233"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/comparison.md", "file_name": "comparison.md"}}, "f7dc87a714740bc664e069b2703bde045e1b864a": {"doc_ids": ["0081dda6-832e-478d-96a2-ce3db5e92d03", "c82cab1b-0979-469a-8f4e-3be408d0e4e6"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/conditional.md", "file_name": "conditional.md"}}, "57218f210fc19c7aaa4905608df8dedf4a5a9eb1": {"doc_ids": ["156219dc-882e-4497-9c64-9f5bb59a7845"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/conversion.md", "file_name": "conversion.md"}}, "702dc3e4a27955421bc6547a65cd6d15ef07b272": {"doc_ids": ["a5c63800-a8a3-43ab-8c49-df5330025ea5", "02ba00a8-ed4b-4619-869f-12f6ca0a6330", "7eadf116-90df-4bba-a7b0-a6d97641274a", "e7e6193e-f910-4454-8ea4-e6116a382a0a", "650945f8-b90c-423f-90be-d4060c5f240f", "390680d0-5366-4669-a91c-bc9b35b38940", "ad891fee-0d1f-418b-8f1f-06130585c458", "b71e0166-ac13-48c9-9d31-4ef1985eb777", "6df20991-9e56-4946-ace0-45cb7b15e139", "ec7028d0-6bce-476e-ad45-d51f4e8e70a3"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/datetime.md", "file_name": "datetime.md"}}, "f6ba683c6473cd3a6df1fa8c3e908339794669e9": {"doc_ids": ["32161ec0-3cab-4004-9732-f5d583a56ca2"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/decimal.md", "file_name": "decimal.md"}}, "83e70db047942a49741ea84000ab3d37820dd24a": {"doc_ids": ["fa3a9d81-7d4d-4e45-80d9-444f08dbc65f"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/hyperloglog.md", "file_name": "hyperloglog.md"}}, "54df972ad7f2dbdfd18a315f51bc502a5e1a24be": {"doc_ids": ["476dcb35-8d4e-4344-b342-b24ea700104d"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/index.md", "file_name": "index.md"}}, "c7c50dfaeab91cad40cbb455d832b860e3e220f1": {"doc_ids": ["af0ef1bd-1d2e-4f7e-a376-c8972fce5e52", "ff3b0afa-e047-42b3-a473-80f522823b5d", "1ddf2704-0cf9-4719-8ebb-3957684e955c", "1e5b77ec-d0c1-4ff6-ac44-6ee4f3ba1f1d", "0124ba20-1aa1-4873-847f-487f9bd5f391", "4a8e1008-069e-47ef-b4cc-2673f7663c00", "862043aa-d260-4902-a0c3-0a63be34df97", "4b6d0f99-5078-4c3d-aeee-0a7187cf6d96", "6fd0a250-a461-4f06-8771-c8002258d3e8", "27cc0b9f-3e38-4725-a175-f7fec59bd7a7", "cf05d3d8-3e40-405a-b5fe-b55575048fbf", "c06fd51f-2158-4dae-95ad-31ae45dd7880", "7e594392-2881-4bf3-8145-63edcf45c152", "ca741a93-427f-42d7-b452-a06ae456198b", "ae995665-7d65-4af0-b5b6-7be34fb7434d", "7090f775-2cc2-4d5a-b83a-42fe9ae7a357", "128ae49c-a2c7-4c0b-a1b8-5002f0e27d81", "05f5e274-02a6-437b-8658-577a517c7754", "fc9a7b07-aac7-4a96-8d2f-f6c109d82ffb", "ccbade4c-6b85-4876-9354-cbf51ad71298"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/json.md", "file_name": "json.md"}}, "f40cd9380740eff0176ae51621e285600bdff08f": {"doc_ids": ["a5c40de4-ebb3-473a-a373-60327f589248", "72a1a59d-0f7f-4cd1-888a-bd8cb19d0fd9"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/lambda.md", "file_name": "lambda.md"}}, "a6862ae86aeebd0d2a552f49918a5c585d690125": {"doc_ids": ["3f718723-b803-46ee-b34b-515fc2bf63c1", "786d4d9d-b0d8-4d83-b860-49c9e2872db4", "aa76c0b9-a63c-4023-8251-a9e0ae4af85e", "421b0b9d-87cb-4d4d-a04a-4e9e4ffbbd85", "080b4e9a-c148-4fcd-96f8-cf8f3d14576e", "06b249ba-50af-4a2b-98f0-47cb73af850b", "b8ef17ac-6b0c-4f52-90ab-42d21d068f11", "83ade6fc-f559-4b19-b909-e32a53e0ba7e", "0d25c5d7-a26d-4ea1-b4a5-696f569d50b5", "9247f59f-6218-4ebe-8efe-3990f4ccfc44"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md", "file_name": "list-by-topic.md"}}, "3835cf4523eb2e570be91df2075436476b9df2a0": {"doc_ids": ["991fc9d6-8cd4-45cb-986a-273a4be18677", "c79cb631-9334-4f74-929a-302aba46aa37", "7aa6553a-d662-4300-b24a-bebb1b3c9966", "1086a26c-c8a2-4b93-a381-555673ddcc8c", "6b822332-752c-4865-9c14-aeca89ec6091", "bcf61072-3ca2-4852-a9bd-f1ea0486a6dd", "a93c4ede-134c-4389-8b9b-5bfeba630a6a", "3b8f9544-0db4-49df-9eec-2f16be0fa94a", "563221d2-b46c-4ddb-a62a-3c13a6c618dc", "fe89d6a5-3c1c-4d65-bce4-be1b9470ca35"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/list.md", "file_name": "list.md"}}, "605b5e82f33cc49ee0315b1c79c10859aa611738": {"doc_ids": ["6e715757-924a-4eaa-a77f-595f0628af0e"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/logical.md", "file_name": "logical.md"}}, "93ac7374f6bfe9dfe845be7ad99c32b028be673c": {"doc_ids": ["642490c5-dd0c-4d98-82ee-1307a410939f", "af0d9b97-d3b5-4cb8-9c97-cad1cea92b24", "0706f04f-e140-4531-9afb-ca892cdf1b5b"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/map.md", "file_name": "map.md"}}, "99d7b566516d0df3047c5f6ad9f1de74e264bba8": {"doc_ids": ["afa87745-b32b-4940-a142-b37ce9ab7856", "880d9436-52fb-4385-8363-4aa27ccaa1d7", "bde8c9d0-e68f-4d69-933a-11c18cb39a57"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/math.md", "file_name": "math.md"}}, "1a20d4e9546875ebc47b2265f675fece5d271bfd": {"doc_ids": ["c50c54b7-a9b8-4e82-806d-11513062d2f9", "49e9c908-27b7-4869-924c-5308798bb17c"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/ml.md", "file_name": "ml.md"}}, "4b95232cca47456f08d70378bc8527b6dc416f37": {"doc_ids": ["e6edbcb1-58e9-4e0e-8f45-0377d79209ba"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/qdigest.md", "file_name": "qdigest.md"}}, "6cd0bce7108b1e2da0267c6f0229a8c4b9dd86db": {"doc_ids": ["72e2f566-3403-46f4-8cf9-8f1ae8a8cbe7", "28fbd09a-5a46-4e5e-b26b-11183bff01c1", "3a502aef-b32f-4bcc-b315-30cb40b8e95b"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/regexp.md", "file_name": "regexp.md"}}, "c0c03f3d7fc8050052ab5378ab24ec56aa189b89": {"doc_ids": ["45ebac77-fb68-46b5-834c-c2a62ac314aa", "707a707c-784b-4b2e-b56c-6291a4ea08a9", "abaa565c-8620-4cd9-9f1f-25313a0b6f5b"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/setdigest.md", "file_name": "setdigest.md"}}, "5e40d91595902954d6cfd8b4060f62d358fc47a3": {"doc_ids": ["22b5ea76-02af-405f-bee0-d5a3c0c5c49f", "d3b98b06-604b-4c2a-8a16-bf41b5c32505", "fdfe23ee-66c0-413b-b702-1a6f416e205e", "e068dc45-9190-4f6b-8ee7-d9709798a220"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/string.md", "file_name": "string.md"}}, "b941e25beab4714a2991c561a8045df5a671467e": {"doc_ids": ["ad243e5d-adbb-4603-9156-fa2c15434de4"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/system.md", "file_name": "system.md"}}, "865cf46b429b4adeee71193b63c30921809f4bb8": {"doc_ids": ["37da259f-40d4-459e-93b8-3984a452ce0a"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/table.md", "file_name": "table.md"}}, "95bd3a3ff0209fd9511fac413a38c1a56818775d": {"doc_ids": ["fe0e73d8-ab73-40f1-875b-14cfed8e1f78"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/tdigest.md", "file_name": "tdigest.md"}}, "cb0006c38d2b16470cfc3402d02a2eb66a6cb9d4": {"doc_ids": ["04171a41-dc7d-4865-9c22-41ae9ce2d1d6"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/teradata.md", "file_name": "teradata.md"}}, "9d7c7cbf680009058d6fa27fda32323e8be11c81": {"doc_ids": ["ff5ea6c8-6d98-4ec0-8b4a-c06bb2dfb38e"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/url.md", "file_name": "url.md"}}, "aa0adab1a07c50fc3f1a38830c026e002e5cb7e0": {"doc_ids": ["3f871c8a-e01b-431a-8079-d74421b1ca53"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/uuid.md", "file_name": "uuid.md"}}, "fa15efb471b788d149d1993c822fa18ea619a49c": {"doc_ids": ["febc905c-c65d-46d7-a64a-d68d275f4cc7", "e4035023-6fdb-40af-9e53-ff486ea8d5f4"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/varbinary.md", "file_name": "varbinary.md"}}, "863bfb8affce16421dfdefe28fd7e85ab66f8e61": {"doc_ids": ["855530bb-74f6-47ed-83f9-2ede21784336", "9daa592b-8b7b-4006-9630-aa6d6a58e9b5"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/Functions-and-operators/window.md", "file_name": "window.md"}}, "3ae8c3a974d6f57476d54c5070b003581677d03f": {"doc_ids": ["08711a83-754a-4069-a058-04da6c960cc0"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/alter-materialized-view.md", "file_name": "alter-materialized-view.md"}}, "2267eb40d6bc0cf1e7b8eee28bd8c5acf05c342a": {"doc_ids": ["18ba54ed-8318-4f01-824b-6888d954cc39", "07ae1165-0d60-40fa-af5a-ed64313b06f2"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/alter-table.md", "file_name": "alter-table.md"}}, "420e8cf9959cc5896252761eb2a396c43d712daf": {"doc_ids": ["b2d95a78-9934-4761-8b0a-527589b47693"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/alter-view.md", "file_name": "alter-view.md"}}, "972293085b68603417c72038f245e4c2652e50da": {"doc_ids": ["ccf7ae75-94ff-4d0f-bd65-177281bff8dd"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/analyze.md", "file_name": "analyze.md"}}, "75261e68400d3d3c28eec769c722bf8206dfce99": {"doc_ids": ["7333f29b-6762-4e30-961c-9bfaf2c2fb6b", "0ad3b069-5d4c-4330-b73f-fe648a169fe9"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/create-materialized-view.md", "file_name": "create-materialized-view.md"}}, "6df4e3127c93f09bdae012d6ea0679cb85edbc34": {"doc_ids": ["716c710a-8559-4208-9fa8-a091bacd8cce"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/create-table-as.md", "file_name": "create-table-as.md"}}, "58608d569516c575d0314b0529ec02e2d565dce0": {"doc_ids": ["0453c618-7209-47d4-983e-85c81c4118f5"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/create-table.md", "file_name": "create-table.md"}}, "c9b150ac1b55d595a22ca441f225bf76260144f3": {"doc_ids": ["b81d0fd4-43ed-4458-b1b2-60df6b5b63e1"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/create-view.md", "file_name": "create-view.md"}}, "fe8ba53394a005842201e62311b5aba3ca1bce5b": {"doc_ids": ["a76f6bd5-8e0f-4dc8-b997-bd890289e967"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/delete.md", "file_name": "delete.md"}}, "ca0402ec5262d2a05eadabc76f234ea726a10c2f": {"doc_ids": ["73aade9a-e941-433f-9146-0babc895bf40"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/describe-input.md", "file_name": "describe-input.md"}}, "138c19485a3a39062cf9e5bf5d763628293f8d04": {"doc_ids": ["cf075db0-8e6f-44b1-8de6-5e97de799a1b"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/describe-output.md", "file_name": "describe-output.md"}}, "3e4ae7b170bf476ad9044821008319ffb8a3c313": {"doc_ids": ["8123b4c7-e453-42cc-b189-6f0f0896f824"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/describe.md", "file_name": "describe.md"}}, "50e0e9befd28ed9949c1518313e73d69eb519baf": {"doc_ids": ["22445c7a-2a51-41b2-94e4-7afde869a605"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/execute.md", "file_name": "execute.md"}}, "749d7ac379a27450e367352d4b92ded8eed698e1": {"doc_ids": ["6f607011-d6b6-4793-89c2-ee55be0926af", "8363113b-4e81-4571-b14f-66d900bbee55", "8df1292f-7242-4c70-a166-2efe09ecb2a1"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain-analyze.md", "file_name": "explain-analyze.md"}}, "95d36b23e4dbc89c2029ab325ee782b717a15197": {"doc_ids": ["81c04137-e576-4cee-a9a3-e0f5dd54bad1", "52ba728c-5a94-4340-ac94-de1a81f3887f", "807b2e49-9214-4061-8efd-2d6d0924d0ee", "6f89deb0-55ac-4b5c-933a-289ea5deaf78", "2899474e-70a5-4d8f-91cb-b5912c682fc4", "9c1c5efa-a030-4bc8-bd4e-0f7cd0f7c08c", "e5135386-3caa-4a3f-8dd1-7a7244f28117", "f84c4cea-b5e2-4ae0-b272-27cd5984eebb", "3041c0d5-6d1d-4621-ad3f-53102a814f95", "66267e7b-95ed-42ee-bd41-512c8edad777", "b2cf7808-4912-405d-bc30-c573cd4e1f22", "c16cd77b-fb22-4660-98f0-eaadf2a8f8a9", "f9d918e4-94be-424b-ba50-e341aea92ecb", "c4969280-f679-467c-8b40-ab655393e4d5", "1ce17cd3-6ee4-4c36-a8b3-2c9aa5e603f2"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md", "file_name": "explain.md"}}, "c0e4570df74c2800c6d0175958794aaab6005e8a": {"doc_ids": ["cf84ba4f-f7af-48cf-9bfb-66df4287b04e"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/index.md", "file_name": "index.md"}}, "96ff14aee8a5065612d649e60db2ed9f190ae2a6": {"doc_ids": ["c7c6980f-9c0a-408d-8410-eaad9d40c04e"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/insert.md", "file_name": "insert.md"}}, "5a6a130c9f4255ffabfa887ab24a92d0fd8bb8c1": {"doc_ids": ["f344de3d-aea4-432e-999a-39f8c30e3f2b", "385b9c18-ab8f-48c0-a795-b237e2adbb79", "040046f7-a507-4793-acf8-96ff143a40f4", "5c853bfe-675f-487f-86cc-e3bb8bad68e7", "dbcef1c3-fb8b-41d6-afd8-476227742d84", "1a5ec9ec-fc58-46a0-8997-54483e531171", "b5bd0a6c-2ab4-4a52-ba6a-94e59ba84b98", "6c643b48-4521-47a0-b585-efca4c172b03", "b551807a-eeb7-4640-a6d7-600dba4154eb"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md", "file_name": "match-recognize.md"}}, "04d6e2e1e0c3fc9f807882e34c50e0f86946aec8": {"doc_ids": ["4627ce52-5e65-4ace-8978-ec38cf99a421", "bb4e5517-6ad8-44b9-8279-60751190722c"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/merge.md", "file_name": "merge.md"}}, "6993eebd2537d70993e0c65b5b0846eb4623564b": {"doc_ids": ["190b7750-8e49-4601-952b-a55a4c1ab492", "9b6edfbe-edba-4d54-b6f5-163e3337a45f", "82c85b93-3e95-49f5-8250-0e6b541343cd", "0f3770c9-28d1-48de-9ec4-43fcbae071e6"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/pattern-recognition-in-window.md", "file_name": "pattern-recognition-in-window.md"}}, "549295068b5590e149f4567700f54dc3e37e7dc2": {"doc_ids": ["6999b07a-a95c-40bf-85fd-7feb395c939c"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/prepare.md", "file_name": "prepare.md"}}, "b0cd1db956ebfe5c1cd8be18bd57dfe901bbee01": {"doc_ids": ["0faf15cd-5b8e-4dfc-beb2-bdc1e42f598d"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/refresh-materialized-view.md", "file_name": "refresh-materialized-view.md"}}, "abbef2a85ac74b6b4d06a927e94b5ceea0ae00ef": {"doc_ids": ["03541a3b-1099-423c-b573-d2ffe824ecb3"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/reset-session.md", "file_name": "reset-session.md"}}, "f68dac6bdd5ca8d920200669a808ce2f38342e60": {"doc_ids": ["f997fd22-eb0f-48a1-9be4-3be3a5ce880a", "51d7ec80-d8b2-47f6-a5f6-febff2788e49", "005fa866-df7d-41f3-a7f3-53c40e586e18", "aa93ca9a-7809-45cf-b36b-02ef893c06bb", "afd4eadd-04ba-4d97-92ee-5438461e7c04", "9bff07a0-2971-4253-bd25-6344bb9de53d", "05205551-e89b-42b3-b428-70c806071d01", "4904b7c6-a6b6-4412-a7cc-0998aabcbce5", "58ca41ae-0eeb-43e5-af1a-428f8f77367d", "fdd64274-085a-473f-9581-29668a3365a3", "13beae33-5993-4ad5-b38b-1f38405dfa47", "33a40ddb-0a7e-4a06-b617-084a29e40815", "6f50a509-cf53-46ac-9233-917a0f68ff1c", "6c175b95-8b08-42cb-8a4c-d26359be0d7a", "9021442b-6c62-4412-bfba-f5e3381d0bfd", "5801ddc5-ab39-480e-9650-814d4d2c89ba"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/select.md", "file_name": "select.md"}}, "16ca6f86583488a6d995bf6b9ebc65c54927017e": {"doc_ids": ["fa1f91df-6225-4383-9b65-37c3b4127ea2"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-catalogs.md", "file_name": "show-catalogs.md"}}, "cf8d1ce1afc681f25b26aa6d4465f545543454b2": {"doc_ids": ["96c4e3b1-cc77-4839-a5c4-00fdd95f940b"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-columns.md", "file_name": "show-columns.md"}}, "b2846ac788b66d5edb228c099391b2677705c859": {"doc_ids": ["52932894-feb3-48d3-b03f-a06ef50604d3"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-materialized-view.md", "file_name": "show-create-materialized-view.md"}}, "8d53adfef0c6cf93e1ff25759d5514747b3ab794": {"doc_ids": ["5b4c9bb9-5cea-4352-9ce6-ec4c2a343e73"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-table.md", "file_name": "show-create-table.md"}}, "9d076c2fdc9d99eb241f667da6671ada777b3b6e": {"doc_ids": ["babc3d13-5673-461c-b3ec-2711cb46902c"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-view.md", "file_name": "show-create-view.md"}}, "e55bf918e7d312377ca19e115df19f7bf18033da": {"doc_ids": ["f1ba7a0e-9bc2-4989-9927-51b14e0f6343"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-functions.md", "file_name": "show-functions.md"}}, "2d488b6677a66d4503b9f49ba6878fb344f61f90": {"doc_ids": ["2c8fb682-6e00-4d10-a313-12d57b114d9d"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-schemas.md", "file_name": "show-schemas.md"}}, "8a3f654706292a82d0fe36909ba8407a9ee6f166": {"doc_ids": ["bbe73472-de83-4c36-881b-74024c76352e"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-session.md", "file_name": "show-session.md"}}, "ce365e6c157eb365fde71d972ee493f1660789fc": {"doc_ids": ["57343cdb-88f3-4eb9-b389-a10d589328de"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-stats.md", "file_name": "show-stats.md"}}, "097b18888685db3b4562b73d73275d5346264fa5": {"doc_ids": ["488858f6-cd0d-43a2-9fed-59327c3bf46e"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/show-tables.md", "file_name": "show-tables.md"}}, "6368f797c590508363076d28a49b64d5eb433091": {"doc_ids": ["7409b460-f6b9-42a7-bc30-ebfc80dc088d"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/update.md", "file_name": "update.md"}}, "7afa618ea49b3ff559ca5ccfa3514e799fbd7fc4": {"doc_ids": ["ffceaa65-f346-476e-a27b-c7b8eac146a3"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/use.md", "file_name": "use.md"}}, "74fa64853c91471be07cbd3bd65bea9bb9dff866": {"doc_ids": ["016647e5-1dc2-4afd-99d0-e745b235a1cb"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/SQL-statement-syntax/values.md", "file_name": "values.md"}}, "9a8056fb6210281fa3ccc658a5a7899d0d2973e7": {"doc_ids": ["008073fa-830b-46e7-bb1d-18d275925ba4", "8367c16b-b179-4b55-bff0-54ef356f0908", "c051edd3-9f84-44e5-9ceb-351062c7f0f5", "e8e90b63-1811-400f-9446-1ffe3aa554d5", "ec907295-3f60-490f-bb72-afd907111571"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/datatypes.md", "file_name": "datatypes.md"}}, "773276682d7d34e3c64b738e27fb2877edd71df7": {"doc_ids": ["979d2728-fb1e-4741-8eae-4bb17fd22aa3"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/index.md", "file_name": "index.md"}}, "a8cbb69a63ddd8d563d3c5ba325d3da01e26a906": {"doc_ids": ["9455f95b-9925-44ef-a016-acf1d825a598", "ea73ad8b-612a-4cf5-8264-e8a66aa90545"], "extra_info": {"file_path": "docs/query/DuneSQL-reference/reserved-keywords.md", "file_name": "reserved-keywords.md"}}, "ee3d8f95624e46759068e987fde30203bcfd1802": {"doc_ids": ["58b280b5-1856-43ee-ab38-d4aadfc3eca3", "90612da4-2571-4908-b270-54ca9eeeb078", "4d15162c-7f3c-479d-9ba9-bae5f5b62251", "8bb3cc4d-d0a6-429a-a91f-79c504107831", "053dbaea-71f6-4756-b7c1-de736a5b1eb6", "a488ce4f-ff80-43a7-ac05-579cfc86232d", "4b20769e-929c-4ebc-8c35-66b017022e94", "22d842d4-920b-468b-af0e-fe9192305a01", "04f89cb8-5a4c-4142-bcbf-017ce28aaa26", "ba6105d3-0e3b-4a3d-bd57-58406b2bd4cc", "a031b799-fc06-4f77-b7c1-2d4e80c44de8", "f27b4114-9cce-4bd2-8c10-894dde93b2d7"], "extra_info": {"file_path": "docs/query/Old-Query-Engines/PostgreSQL.md", "file_name": "PostgreSQL.md"}}, "04168beb41d762f692d99c7628c8e7f66188d41c": {"doc_ids": ["159ed8b6-7c68-434b-8849-97e6f859a59d", "18b1776e-3547-46a3-b00a-590ceed5981e", "476c7178-5d7e-4f18-bcf6-f04cc6fbe218", "c8508c12-7bc8-4e13-b688-bb068e58f950", "bfc01fdc-b24d-42a4-9744-96ea79c1e030", "057ea006-052c-43c7-b559-3da5071c11f2", "c8f8bc7d-eaa0-4e47-9e05-7b3fc986563b", "881da39c-bb87-43fc-b28c-a113775284bf", "72824150-4557-47be-bf7c-d6079f5e716f", "acc865b8-cb8f-40f4-bf25-b1f90a58c9f1", "e75a0a1f-c403-481e-9109-689fa794b93c", "55f24f37-e59b-40c1-a5f9-d461deb0b0c5"], "extra_info": {"file_path": "docs/query/Old-Query-Engines/SparkSQL.md", "file_name": "SparkSQL.md"}}, "e9b826d0877608e104fd6ca7c1177f78c2651ccd": {"doc_ids": ["2160814b-742e-455e-bab7-fd0b057c2ad7", "7012149e-cc50-4656-875f-64908ec4b6df"], "extra_info": {"file_path": "docs/query/Old-Query-Engines/index.md", "file_name": "index.md"}}, "8c9031686dfe23473f2d31c75d2b325a3fc9a9dd": {"doc_ids": ["a19b8444-4406-4246-a90e-cc941b3b16c8"], "extra_info": {"file_path": "docs/query/Old-Query-Engines/migration-tool.md", "file_name": "migration-tool.md"}}, "b746db3c8f1522c6026ac33c398ab33f79471031": {"doc_ids": ["1ad451cb-c5c2-4b4a-a16e-5b1b0e6a3747", "714e2964-44a6-40b5-9b72-42c2956c848b", "65f891c2-38db-41c2-adf7-4e9419e28994"], "extra_info": {"file_path": "docs/query/dunesql-changes.md", "file_name": "dunesql-changes.md"}}, "2d828ecde9b0b3efe4bfac0a52eeb11a75d45169": {"doc_ids": ["321b9cb7-45b5-4ec0-a7bd-b4e80638e846", "8301d2c4-ae88-45ae-80ac-a01872901a9d"], "extra_info": {"file_path": "docs/query/index.md", "file_name": "index.md"}}, "370acb5cf3546337e11094d1cf3ab0fe82e3f9f5": {"doc_ids": ["2f9bb95a-f856-4fd5-9528-ee4e33c3b664"], "extra_info": {"file_path": "docs/query/query-a-query.md", "file_name": "query-a-query.md"}}, "09278556c8740eaac8985264d09e4f8b5429e714": {"doc_ids": ["15d841cf-8400-4e86-bb7a-ae08cc454849", "b6772a80-ab2d-470f-a963-0c757238fa15", "41862796-570a-47db-937b-c9c26b4865ce", "a6e93cd6-10b7-4daf-a196-5b5c2c706362"], "extra_info": {"file_path": "docs/query/storage.md", "file_name": "storage.md"}}, "f98eee6afad0958bd913b26f2c39da3fe7663e33": {"doc_ids": ["dec85e87-a690-4e04-948f-eea61422cdbc", "8228e574-a7b8-4f7e-b4fd-476071f35ab5", "8463d18c-eaab-4228-9aa1-007a34b8d84b"], "extra_info": {"file_path": "docs/query/syntax-differences.md", "file_name": "syntax-differences.md"}}, "b76f2e2ce98ded7830f3c0abda7404f624838fc7": {"doc_ids": ["5c3988e1-c86c-439b-8410-da4b4649e412", "518e1fff-47b9-4fd7-b5ad-101bd0e7c6a9"], "extra_info": {"file_path": "docs/query/writing-efficient-queries.md", "file_name": "writing-efficient-queries.md"}}, "fa30bc56f2755065c0ff02de0019982df9854e56": {"doc_ids": ["f239beac-6aeb-4487-95be-3e785fe81fc2", "3e92e13a-d602-4266-ab2a-73c20414e517"], "extra_info": {"file_path": "docs/quickstart.md", "file_name": "quickstart.md"}}, "44ab32cf40b2001706c247122acb08c8c33340b3": {"doc_ids": ["42b98d55-b4a7-42a4-a633-c416a3248775"], "extra_info": {"file_path": "docs/resources/citing-dune.md", "file_name": "citing-dune.md"}}, "2d2de793bd7a82c664d96928dec3587425dd4522": {"doc_ids": ["fc91a4ae-2d20-4918-8218-fa856f7db604", "49258516-ddfb-4482-91e1-053bd7774eea", "8d277df4-9aba-4b40-b2f6-1b89cb459b2c", "46f1e19d-72c1-4951-9047-9e103db524ec"], "extra_info": {"file_path": "docs/resources/dune-bounties.md", "file_name": "dune-bounties.md"}}, "a6fbf783f9cb3b304136a43e5f783991de2efd39": {"doc_ids": ["d9715b24-c189-48e2-8032-b7f0bffcc5d9"], "extra_info": {"file_path": "docs/resources/index.md", "file_name": "index.md"}}, "510f55d8602316b1644265e636c6f243122bfc91": {"doc_ids": ["113cae10-7e20-45cf-bea4-c5317d21c168"], "extra_info": {"file_path": "docs/resources/press-kit.md", "file_name": "press-kit.md"}}, "7315845a94cddef314e2b305c18b02404f6746f3": {"doc_ids": ["febba113-1e89-4071-ab9d-2d863a169583"], "extra_info": {"file_path": "docs/resources/support-feedback.md", "file_name": "support-feedback.md"}}}}